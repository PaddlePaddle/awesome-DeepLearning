{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 16.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "..\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "from paddle.vision.transforms import Compose, Normalize\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "from paddle.metric import Accuracy\n",
    "import random\n",
    "from paddle import fluid\n",
    "from visualdl import LogWriter\n",
    "\n",
    "log_writer=LogWriter(\"./data/log/train\") #log记录器\n",
    "\n",
    "\n",
    "transform = Compose([Normalize(mean=[127.5],\n",
    "                               std=[127.5],\n",
    "                               data_format='CHW')])\n",
    "#归一化\n",
    "\n",
    "#读取训练集 测试集数据\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "\n",
    "class InceptionA(paddle.nn.Layer):  #作为网络一层\n",
    "    def __init__(self,in_channels):\n",
    "        super(InceptionA,self).__init__()\n",
    "        self.branch3x3_1=paddle.nn.Conv2D(in_channels,16,kernel_size=1) #第一个分支\n",
    "        self.branch3x3_2=paddle.nn.Conv2D( 16,24,kernel_size=3,padding=1)\n",
    "        self.branch3x3_3=paddle.nn.Conv2D(24,24,kernel_size=3,padding=1)\n",
    "\n",
    "        self.branch5x5_1=paddle.nn.Conv2D(in_channels, 16,kernel_size=1) #第二个分支\n",
    "        self.branch5x5_2=paddle.nn.Conv2D( 16,24,kernel_size=5,padding=2)\n",
    "\n",
    "        self.branch1x1=paddle.nn.Conv2D(in_channels, 16,kernel_size=1) #第三个分支\n",
    "\n",
    "        self.branch_pool=paddle.nn.Conv2D(in_channels,24,kernel_size= 1) #第四个分支\n",
    "\n",
    "    def forward(self,x):\n",
    "        #分支1处理过程\n",
    "        branch3x3= self.branch3x3_1(x)\n",
    "        branch3x3= self.branch3x3_2(branch3x3)\n",
    "        branch3x3= self.branch3x3_3(branch3x3)\n",
    "        #分支2处理过程\n",
    "        branch5x5=self.branch5x5_1(x)\n",
    "        branch5x5=self.branch5x5_2(branch5x5)\n",
    "        #分支3处理过程\n",
    "        branch1x1=self.branch1x1(x)\n",
    "        #分支4处理过程\n",
    "        branch_pool=F.avg_pool2d(x,kernel_size=3,stride=1,padding= 1)\n",
    "        branch_pool=self.branch_pool(branch_pool)\n",
    "        outputs=[branch1x1,branch5x5,branch3x3,branch_pool]     #将4个分支的输出拼接起来\n",
    "        return fluid.layers.concat(outputs,axis=1) #横着拼接， 共有24+24+16+24=88个通道\n",
    "\n",
    "class Net(paddle.nn.Layer):        #卷积，池化，inception，卷积，池化，inception，全连接\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        #定义两个卷积层\n",
    "        self.conv1=paddle.nn.Conv2D(1,10,kernel_size=5)\n",
    "        self.conv2=paddle.nn.Conv2D(88,20,kernel_size=5)\n",
    "        #Inception模块的输出均为88通道\n",
    "        self.incep1=InceptionA(in_channels=10 )\n",
    "        self.incep2=InceptionA(in_channels=20)\n",
    "        self.mp=paddle.nn.MaxPool2D(2)\n",
    "        self.fc=paddle.nn.Linear(1408,10) #5*5* 88 =2200，图像高*宽*通道数\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.mp(self.conv1(x)))# 卷积池化，relu  输出x为图像尺寸14*14*10\n",
    "        x =self.incep1(x)               #图像尺寸14*14*88\n",
    "\n",
    "        x =F.relu(self.mp(self.conv2(x)))# 卷积池化，relu  输出x为图像尺寸5*5*20\n",
    "        x = self.incep2(x)              #图像尺寸5*5*88\n",
    "\n",
    "        x = paddle.flatten(x, start_axis=1,stop_axis=-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "model = paddle.Model(Net())   # 封装模型\n",
    "optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()) # adam优化器\n",
    "\n",
    "# 配置模型\n",
    "model.prepare(\n",
    "    optim,\n",
    "    paddle.nn.CrossEntropyLoss(),\n",
    "    Accuracy()\n",
    "    )\n",
    "# 训练模型\n",
    "model.fit(train_dataset,epochs=2,batch_size=64,verbose=1)\n",
    "#评估\n",
    "model.evaluate(test_dataset, batch_size=64, verbose=1)\n",
    "\n",
    "#训练\n",
    "def train(model,Batch_size=64):\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    iterator = 0\n",
    "    epochs = 10\n",
    "    total_steps = (int(50000//Batch_size)+1)*epochs\n",
    "    lr = paddle.optimizer.lr.PolynomialDecay(learning_rate=0.01,decay_steps=total_steps,end_lr=0.001)\n",
    "    optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    # 用Adam作为优化函数\n",
    "    for epoch in range(epochs):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            x_data = data[0]\n",
    "            y_data = data[1]\n",
    "            predicts = model(x_data)\n",
    "            loss = F.cross_entropy(predicts, y_data)\n",
    "            # 计算损失\n",
    "            acc = paddle.metric.accuracy(predicts, y_data)\n",
    "            loss.backward()\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\n",
    "                log_writer.add_scalar(tag='acc',step=iterator,value=acc.numpy())\n",
    "                log_writer.add_scalar(tag='loss',step=iterator,value=loss.numpy())\n",
    "                iterator+=200\n",
    "            optim.step()\n",
    "            optim.clear_grad()\n",
    "        paddle.save(model.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdparams')\n",
    "        paddle.save(optim.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdopt')\n",
    "\n",
    "\n",
    "#测试\n",
    "def test(model):\n",
    "    # 加载测试数据集\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\n",
    "    model.eval()\n",
    "    for batch_id, data in enumerate(test_loader()):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        predicts = model(x_data)\n",
    "        # 获取预测结果\n",
    "        loss = F.cross_entropy(predicts, y_data)\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\n",
    "        if batch_id % 20 == 0:\n",
    "            print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\n",
    "\n",
    "#随机抽取100张图片进行测试\n",
    "def random_test(model,num=100):\n",
    "    select_id = random.sample(range(1, 10000), 100) #生成一百张测试图片的下标\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\n",
    "    for batch_id, data in enumerate(test_loader()):\n",
    "        x_data = data[0]\n",
    "        label = data[1]\n",
    "    predicts = model(x_data)\n",
    "    #返回正确率\n",
    "    acc = paddle.metric.accuracy(predicts, label)\n",
    "    print(\"正确率为：{}\".format(acc.numpy()))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = Net()\n",
    "    train(model)\n",
    "    test(model)\n",
    "    random_test(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
