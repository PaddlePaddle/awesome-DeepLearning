# PaddleHomework01

- author @ xiaolin199912

## 1. 深度学习发展史

![image-20210710213332547](https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210710213332547.png)

### 第一阶段(1958-1969)

​		神经网络的思想起源于**1943年提出的MCP**人工神经元模型，希望能够用计算机来模拟人的神经元反应的过程，该模型将神经元简化为了三个过程：输入信号线性加权，求和，非线性激活

<img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210709203255140.png" alt="image-20210709203255140" style="zoom:67%;" />

​		第一次将MCP用于机器学习（分类）的当属1958年Rosenblatt发明的**感知器（perceptron）**算法。该算法使用MCP模型对输入的多维数据进行二分类，且能够使用梯度下降法从训练样本中自动学习更新权值。1962年，该方法被证明为能够收敛，理论与实践效果引起第一次神经网络的浪潮。

​		然而，1969年，美国数学家及人工智能先驱Minsky在其著作中证明了感知器本质上是一种线性模型，**只能处理线性分类问题**，就连最简单的XOR（亦或）问题都无法正确分类。这等于直接宣判了感知器的死刑，神经网络的研究也陷入了近20年的停滞。


### 第二阶段(1986-2006)

​		Hinton在1986年发明了适用于多层感知器（MLP）的BP算法，并采用Sigmoid进行非线性映射，有效解决了非线性分类和学习的问题。该方法引起了神经网络的第二次热潮。

​		1989年，Robert Hecht-Nielsen证明了MLP的万能逼近定理，即对于任何闭区间内的一个连续函数 $f(x)$，都可以用含有一个隐含层的BP网络来逼近该定理的发现极大的鼓舞了神经网络的研究人员。同年，LeCun发明了卷积神经网络-LeNet，并将其用于数字识别，且取得了较好的成绩，不过当时并没有引起足够的注意。

<img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210709204152075.png" alt="image-20210709204152075" style="zoom: 25%;" />

​		值得强调的是在1989年以后由于没有特别突出的方法被提出，且NN一直缺少相应的严格的数学理论支持，神经网络的热潮渐渐冷淡下去。冰点来自于1991年，BP算法被指出存在梯度消失问题，即在误差梯度后向传递的过程中，后层梯度以乘性方式叠加到前层，由于Sigmoid函数的饱和特性，后层梯度本来就小，误差梯度传到前层时几乎为0，因此无法对前层进行有效的学习，该发现对此时的NN发展雪上加霜。

​		1997年，LSTM得到提出，尽管该模型在序列建模上的特性非常突出，但由于正处于NN的下坡期，也没有引起足够的重视。

### 第三阶段(2006-至今)

​		这一阶段可以再分为两个时期：2006-2012的快速发展期，2012依赖的爆发期.

​		2006年，Hinton提出了深层网络训练中梯度消失问题的解决方案：**无监督预训练对权值进行初始化**+**有监督训练微调**。其主要思想是先通过自学习的方法学习到训练数据的结构（自动编码器），然后在该结构上进行有监督训练微调。但是由于没有特别有效的实验验证，该论文并没有引起重视。

​		2011年，**ReLU**激活函数被提出，该激活函数能够有效的抑制梯度消失问题。

​		2011年，微软首次将DL应用在语音识别上，取得了重大突破。

​		2012年，Hinton课题组为了证明深度学习的潜力，首次参加ImageNet图像识别比赛，其通过构建的CNN网络AlexNet一举夺得冠军，且碾压第二名（SVM方法）的分类性能。也正是由于该比赛，CNN吸引到了众多研究者的注意。

​		2013,2014,2015年，通过ImageNet图像识别比赛，DL的网络结构，训练方法，GPU硬件的不断进步，促使其在其他领域也在不断的征服战场

​		2015年，Hinton，LeCun，Bengio论证了局部极值问题对于DL的影响，结果是Loss的局部极值问题对于深层网络来说影响可以忽略。该论断也消除了笼罩在神经网络上的局部极值问题的阴霾。

​		2015，DeepResidualNet发明。分层预训练，ReLU和BatchNormalization都是为了解决深度神经网络优化时的梯度消失或者爆炸问题。但是在对更深层的神经网络进行优化时，又出现了新的Degradation问题，即通常来说，如果在VGG16后面加上若干个单位映射，网络的输出特性将和VGG16一样，这说明更深次的网络其潜在的分类性能只可能>=VGG16的性能，不可能变坏，然而实际效果却是只是简单的加深VGG16的话，分类性能会下降（不考虑模型过拟合问题）. Residual网络认为这说明DL网络在恒等映射方面有困难，因此设计了一个对于恒等映射（或接近恒等映射）有较强学习能力的DL网络，极大的增强了DL网络的表达能力。此方法能够轻松的训练高达150层的网络。

<img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210709204420783.png" alt="image-20210709204420783" style="zoom:50%;" />

​		如今，深度学习已经广泛应用于计算机视觉、自然语言处理、推荐系统、自动驾驶等领域，颠覆性地改变了人们的生活方式，在未来的一段时间里都会有相当广泛的应用价值.

## 2. 人工智能、机器学习、深度学习有什么区别和联系？

<img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210709204723000.png" alt="image-20210709204723000" style="zoom:67%;" />

​		如上图所示，人工智能是一个宏观的概念，希望机器能够模拟人类的一部分行为，目前的人工智能相关技术主要聚集在“弱人工智能”领域. 

​		机器学习是实现人工智能的一种方法，即使用算法分析数据，从中学习并做出推断或预测。与传统的使用特定指令集手写软件不同，我们使用大量数据和算法来“训练”机器，由此带来机器学习如何完成任务。

​		深度学习是机器学习中一种基于对数据进行表征学习的算法，基于人工神经网络结构对从大量的数据中学习其内在规律，并做出相应的决策 。

## 3. 神经元、单层感知机、多层感知机

- **神经元**

    - <img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210709210244222.png" alt="image-20210709210244222" style="zoom:50%;" />

    神经网络中最基本的组成部分，包括输入输入信号线性加权，求和，非线性激活三个过程. 理想的激活函数是sign阶跃函数，但具有不光滑，不连续的性质，通常采用sigmoid函数. 

- **单层感知机**

    - <img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210709210723876.png" alt="image-20210709210723876" style="zoom:50%;" />

    单层感知机即只有一个神经元的线性二分类模型，只有一层输出层的功能神经元进行激活函数处理，无法处理线性不可分问题.

- **多层感知机**

    - <img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210709211004018.png" alt="image-20210709211004018" style="zoom:50%;" />

    包括三部分：**输入层**、**隐藏层**、**输出层**. 不同层之间采用全连接的结构，在隐层结点足够多的情况下，多层感知机**可以拟合任意函数**.

## 4. 什么是前向传播

<img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210709211436686.png" alt="image-20210709211436686" style="zoom:50%;" />

​		前向传播算法即：**上一层的输出作为下一层的输入，直到输出层**. 

​		例如对于`Layer 2`中的第一个结点而言，有
$$
a_1^{(2)} = \sigma(z_1^{(2)}) = \sigma(\sum_{i=1}^{3}w_{1i}^{(2)}x_i+b_i^{(2)})
$$
​		对于`Layer 3`则有
$$
a_1^{(3)} = \sigma(z_1^{(3)}) = \sigma(\sum_{i=1}^{3}w_{1i}^{(3)}a_i^{(2)}+b_i^{(3)})
$$
​		综上，前向传播算法的矩阵形式为
$$
z^{(l)} = W^{(l)}a^{(l-1)} + b^{(l)} \\
a^{(l)} = \sigma(z^{(l)})
$$

## 5. 什么是后向传播

​		反向传播(Back Propagation)算法是“误差反向传播”算法的简称，允许来自代价函数的信息通过网络向后流动. 通常与最优化算法结合使用(如梯度下降法)，该方法对网络中的所有权重计算损失函数的梯度，这个梯度会反馈给最优化方法用来更新权值，以最小化损失函数. 

​		反向传播仅指代 **用于计算梯度的方法** ，经常被误解为用于多层神经网络的整个学习算法，实际上随机梯度下降等学习算法是真正的学习算法，这些学习算法用 我们使用 BP 得到的梯度进行学习以更新参数，另外，反向传播算法不仅适用于多层神经网络，原则上**可以计算任何函数的导数**. 

​		假设我们使用**MSE均方误差**作为损失函数，即
$$
E(W,b)=\frac{1}{2} ||\hat{y}^{(l)} - y||^{2}
$$
​		其中，$\hat{y}^{(l)}$ 是训练样本预测的输出. 

推导过程如下：

- **输出层梯度**
    $$
    \frac{\partial{E}}{\partial{w^{(l)}}} = \frac{\partial{E}}{\partial{\hat{y}^{(l)}}}\frac{\partial{\hat{y}^{(l)}}}{\partial{z^{(l)}}}\frac{\partial{z^{(l)}}}{\partial{w^{(l)}}} = (\hat{y}^{(l)}-y) \odot \sigma'(z^{(l)})\hat{y}^{(l-1)} \\
    \frac{\partial{E}}{\partial{b^{(l)}}} = \frac{\partial{E}}{\partial{\hat{y}^{(l)}}}\frac{\partial{\hat{y}^{(l)}}}{\partial{z^{(l)}}}\frac{\partial{z^{(l)}}}{\partial{b^{(l)}}} = (\hat{y}^{(l)}-y) \odot \sigma'(z^{(l)})
    $$
    ​		其中，$\odot$ 表示 Hadamard积，即两个相同维度的矩阵对应元素的乘积.

    ​		将公共部分提取出，记作
    $$
    \delta^{(l)} =\frac{\partial{E}}{\partial{\hat{y}^{(l)}}}\frac{\partial{\hat{y}^{(l)}}}{\partial{z^{(l)}}}=(\hat{y}^{(l)}-y) \odot \sigma'(z^{(l)})
    $$

- **隐层梯度**

    ​	假设第 $l+1$ 层的 $\delta^{(l+1)}$ 已求出，那么第 $l$ 层的$\delta^{(l)}$ 为
    $$
    \delta^{(l)} =\frac{\partial{E}}{\partial{z^{(l+1)}}}\frac{\partial{z^{(l+1)}}}{\partial{z^{(l)}}}=\delta^{(l+1)}\frac{\partial{z^{(l+1)}}}{\partial{z^{(l)}}}
    $$
    

    ​	由于第 $l+1$ 层和第 $l$ 层的关系为：
    $$
    z^{(l+1)} = W^{(l+1)}a^{(l)} + b^{(l+1)}=W^{(l+1)}\sigma (z^{(l)}) + b^{(l+1)}
    $$
    ​	因此
    $$
    \frac{\partial{z^{(l+1)}}}{\partial{z^{(l)}}} = (W^{(l+1)})^T \odot \sigma'(z^{(l)})
    $$
    ​	可以得到
    $$
    \delta^{(l)} =  (W^{(l+1)})^T \delta^{(l+1)} \odot \sigma'(z^{(l)})
    $$
    ​	因此，现在得到了 $\delta(l)$ 的递推关系式，只要求得某一层 $\delta(l)$ ，便可求解得到 $w^{(l)}; b^{(l)}$ 的对应梯度
    $$
    \frac{\partial{E}}{\partial{w^{(l)}}} =   \delta(l)\hat{y}^{(l-1)} \\
    \frac{\partial{E}}{\partial{b^{(l)}}} =   \delta(l)
    $$
    综上，整理得到BP算法的流程为：

    **输入：** 总层数 $L$, 学习率 $\alpha$ ，停止迭代阈值 $\epsilon$ ，输入的 $m$ 个训练样本，以及各隐藏层、输出层的神经元个数、损失函数和激活函数

    **1 ** 初始化参数 $W, b$

    **2**  进行前向传播算法计算：

    $for \quad l = 2 \to L$

    ​	$z^{(l)} = W^{(l)}a^{(l-1)} + b^{(l)}$

    ​	$a^{(l)} = \sigma(z^{(l)})$

    **3 ** 通过损失函数计算输出层梯度，并进行反向传播
    $$
    \frac{\partial{E}}{\partial{w^{(L)}}} = (\hat{y}^{(L)}-y) \odot \sigma'(z^{(L)})\hat{y}^{(L-1)} \\
    \frac{\partial{E}}{\partial{b^{(L)}}}  = (\hat{y}^{(L)}-y) \odot \sigma'(z^{(L)}) = \delta^{(L)}
    $$
    $for \quad l = L-1 \to 2$

    ​    $\delta^{(l)} =  (W^{(l+1)})^T \delta^{(l+1)} \odot \sigma'(z^{(l)})$

    **4**   通过梯度下降算法更新参数 $W, b$
    $$
    w^{(l)} := w^{(l)} - \alpha \frac{\partial{E}}{\partial{w^{(l)}}} \\
    b^{(l)} := b^{(l)} - \alpha \frac{\partial{E}}{\partial{b^{(l)}}}
    $$
    **5** 若 $W,b$ 的参数变化值都小于 $\epsilon$ ，则跳出迭代循环
