## InceptionV3网络知识点

### 一.整体框架

GooleNet基于InceptionV3网络的整体的流程框架如下

<img src="4.png" style="zoom:80%;" />

输入图先经过三层卷积；最大池化后再进行两层卷积；接着通过InceptionV3网络；最后经过8×8最大之后并全连接后即得到最终的预测结果。

在Inception V3中，其主体包含了三个Inception Module，这三个Inception Module中还包含了很多个Inception Module，被称为NetWork in NetWork。这三个模块就是Inception V3的精华所在，每个Inception模块组内部的几个Inception Module结构非常相似，但是实现的细节有所不同。

### 二.具体细分

#### 1.Inception Module1

第一个Inception Module一共由三个子的Inception模块组成，每一个小的Inception模块又由多个分支所组成。其中核心的一个子模块结构如下：

<img src="1.png" style="zoom:80%;" />

Mixed_5a是第一个小的Inception Module，一共有四个分支，从Branch_0到Branch_3，第一个分支由64个1×1的卷积组成；第二个分支由48个1×1的卷积，连接64个5×5的卷积；第三个分支由64个1×1的卷积，连接2个有96输出通道的3×3的卷积；第四个分支为3×3的平均池化，连接32输出通道的1×1的卷积。最后，通过paddle.concat将4个分支的输出合并在一起(在第三个维度上进行合并，即输出通道上合并)作为Inception module的最终输出。因为卷积的步长均，padding被设置为SAME，所以输入图片的尺寸和输出图片的尺寸不会减少，输出依然是一个35×35的图片，输出的通道数为64+64+96+32=256。

Mixed_5b与Mixed_5a的结构相似，唯一不同的是第四个分支，在Mixed_5b中将Mixed_5a中的第四个分支的最后输出32通道的1×1的卷积改成了64通道的1×1的卷积。相对于Mixed_5a最终Mixed_5b的输出通道数增加了32。

Mixed_5c与Mixed_5b组成结构完全相同，最终输出为35×35×288。 

#### 2.Inception Module2

第二个Inception module是三个module中最大的一个，包含了5个子Inception Module。在这个Inception module中会将输入图片进行压缩，图片大小变为原来的一半，同时通道数会增加，由288增加到768。其中核心的一个子模块结构如下：

<img src="2.png" style="zoom:80%;" />

Mixed_6a是第一个子Inception module，它一共包含了3个分支。第一个分支是一个384输出通道的3×3的卷积，步长为2，padding为VALID，所以输出的图片尺寸会被缩小，且长、宽缩小为原来的一半;第二个分支由三层组成，第一层是一个64通道的1×1的卷积和两个96通道的3×3的卷积。最后一层最大池化层的步长为2，padding为VALID，所以图片尺寸也会被压缩。

Mixed_6b由4个分支所组成，第一个分支是一个简单的192输出通道的1×1的卷积；第二个分支由三层卷积组成，第一层是128输出通道的1×1的卷积，第二层是一个128通道的1×7的卷积，第三层是一个192通道的7×1的卷积。通过串联1×7的卷积和7×1的卷积来替代7×7的卷积，不仅可以减少参数减轻过拟合，同时还增加了一层非线性特征变换；第三个分支由五个卷积层组成，分别是128通道的1×1的卷积，128通道的7×1的卷积，128通道的1×7的卷积，128通道的7×1卷积和192通道的1×7卷积；第四个分支是一个3×3的平均池化层，再连接192通道的1×1的卷积。

Mixed_6c到Minxed_6e结构与Mixed_6b差不多，仅仅是将其中的卷积核数量进行了改变，

#### 3.Inception Module3

第三个Inception module包含了3个子Inception module，最后两个子Inception module的结构非常相似。其中核心的一个子模块结构如下：

<img src="3.png" style="zoom:80%;" />)

Mixed_7a是第一个子Inception module,它包含三个分支，第一个分支由两层卷积组成，第一层为192个1×1卷积；第二层是一个320输出通道的3×3的卷积，步长为2，padding为VALID，所以输出的图片尺寸会被缩小，长宽缩小为原来的一半，第二个分支由四层卷积组成，第一层是192输出通道的1×1的卷积，第二层是一个192通道的1×7的卷积，第三层为192通道的7×1的卷积，第四层是一个192通道的3×3，步长为2的卷积。 第三个分支为3×3，步长为2的最大池化层。

Mixed_7b是第二个子Inception module，由四个分支组成，第一个分支为320输出通道的1×1卷积；第二个分支由两个卷积层组成，第一层为384通道的1×1卷积，第二层为384通道的1×3卷积和3×1卷积的叠加；第三个分支由三个卷积层组成，第一层为448通道的1×1卷积，第二层为384通道的3×3卷积，第三层为384通道的1×3卷积和3×1卷积的叠加；第四个分支为3×3最大池化层后接192通道的1×1卷积

Mixed_7c是第三个子Inception module，它和Mixed_7b的结构一样，仅仅是输出特征图的通道数变了。

#### 4.整合

将这三个Inception module整合在一起便构成了一个完整的InceptionV3网络。

### 三.InceptionV3网络的创新之处

#### 1.基本卷积块

网络中每层卷积之后都会进行Batchnorm和relu激活，这一整个过程构成了一个基本的卷积模块。

Batchnorm不仅起着正则化的作用，还可以减少或去电Dropout，从而简化网络结构，使训练速度大大加快；而relu激活则增加网络的非线性特征。

#### 2.减小卷积核大小

通过两个3×3的卷积来代替5×5卷积，大大较少了参数数量，同时也保留了感受野的大小。

#### 3.卷积核拆分

在网络中层，中度大小的特征图卷积时，将n×n卷积核用1×n和n×1卷积进行替代。这样一方面减少了参数，加速运算；同时增加了一份非线性扩展能力，可以处理更多更丰富的空间特征，增加特征多样性

#### 4.分支中使用分支

InceptionV3可以看做是NetWork in NetWork in NetWork。网络的前部为普通的卷积层，到后面出现35×35,17×17,8×8三种不同的机构，不仅在Inception module中使用分支，还在分支中使用分支。

#### 5.网络最后用平均池化代替全连接，极大减少了参数

