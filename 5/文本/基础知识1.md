**1、如何基于层次softmax训练词向量**
层次Softmax本质上是用层级关系替代了扁平化的softmax层，每个叶子节点表示一个词语。于是，计算单个词语概率值的计算过程被拆解为一系列的概率计算，这样可以避免对所有词语进行标准化计算。
把原来的softmax看做深度为1的树，词表V中的每一个词语表示一个叶子节点。计算一个词语的softmax概率需要对|V|个节点的概率值做标准化。如果把softmax改为二叉树结构，每个word表示叶子节点，那么只需要沿着通向该词语的叶子节点的路径搜索，而不需要考虑其它的节点。平衡二叉树的深度是log2(|V|)，因此，最多只需要计算log2(|V|)个节点就能得到目标词语的概率值。注意，得到的概率值已经经过了标准化，因为二叉树所有叶子节点组成一个概率分布，所有叶子节点的概率值总和等于1。当遍历树的时候，我们需要能够计算左侧分枝或是右侧分枝的概率值。为此，给每个节点分配一个向量表示。需要计算h与树的每个节点的向量v’n的内积，而不是与每个输出词语的向量计算。而且，现在只需要计算一个概率值，这里就是偏向n节点右枝的概率值。

**2、除了情感分析，LSTM还可以实现那些其他类型的NPL任务**
1、使用LSTM读懂python程序：使用基于LSTM的深度模型用于读懂python程序并且给出正确的程序输出。文章的输入是短小简单python程序，这些程序的输出大都是简单的数字，例如0-9之内加减法程序。模型一个字符一个字符的输入python程序，经过多层LSTM后输出数字结果。
2、信息检索：
