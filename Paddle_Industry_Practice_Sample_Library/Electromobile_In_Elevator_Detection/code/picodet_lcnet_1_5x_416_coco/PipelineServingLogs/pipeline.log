WARNING 2021-12-29 02:45:16,604 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 02:45:16,604 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 02:45:16,604 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 02:45:16,604 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 02:45:16,605 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 02:45:16,605 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 02:45:16,605 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 02:45:16,605 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 02:45:16,605 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 02:45:16,605 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 02:45:16,605 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 02:45:16,605 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 02:45:16,606 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 02:45:16,606 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 02:45:16,606 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 02:45:16,606 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 02:45:16,606 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 02:45:16,606 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 02:45:16,607 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 02:45:16,607 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 02:45:16,607 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 02:45:16,607 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18082,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9998,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 02:45:16,607 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 02:45:16,607 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 02:45:16,631 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 02:45:16,632 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 02:45:16,632 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 02:45:16,632 [dag.py:655] -------------------------------------------
INFO 2021-12-29 02:45:16,677 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 02:45:16,681 [dag.py:816] [DAG] start
INFO 2021-12-29 02:45:16,682 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 02:45:16,688 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 02:45:16,710 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 02:45:16,710 [operator.py:1163] Init cuda env in process 0
INFO 2021-12-29 02:45:16,710 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 02:45:17,939 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 02:45:19,138 [operator.py:1174] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 02:45:44,185 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 02:45:44,187 [operator.py:1422] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 02:45:44,188 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 02:45:45,873 [operator.py:969] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 965, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 76, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 429, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 02:45:45,877 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 03:07:14,510 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 03:07:14,510 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 03:07:14,510 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 03:07:14,511 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 03:07:14,512 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 03:07:14,512 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 03:07:14,512 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 03:07:14,512 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 03:07:14,512 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 03:07:14,512 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 03:07:14,513 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 03:07:14,513 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 03:07:14,513 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 03:07:14,513 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18082,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9998,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 03:07:14,513 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 03:07:14,513 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 03:07:14,538 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 03:07:14,539 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 03:07:14,539 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 03:07:14,539 [dag.py:655] -------------------------------------------
INFO 2021-12-29 03:07:14,585 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 03:07:14,589 [dag.py:816] [DAG] start
INFO 2021-12-29 03:07:14,589 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 03:07:14,595 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 03:07:14,617 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 03:07:14,617 [operator.py:1163] Init cuda env in process 0
INFO 2021-12-29 03:07:14,618 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 03:07:15,847 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 03:07:17,038 [operator.py:1174] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 03:07:20,880 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 03:07:20,882 [operator.py:1422] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 03:07:20,882 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 03:07:22,696 [operator.py:969] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 965, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 77, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 429, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 03:07:22,700 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 03:10:13,372 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 03:10:13,373 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 03:10:13,374 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 03:10:13,374 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 03:10:13,374 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 03:10:13,374 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 03:10:13,374 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 03:10:13,374 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 03:10:13,374 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 03:10:13,375 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 03:10:13,375 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 03:10:13,375 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 03:10:13,375 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 03:10:13,375 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18082,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9998,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 03:10:13,375 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 03:10:13,375 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 03:10:13,393 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 03:10:13,393 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 03:10:13,394 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 03:10:13,394 [dag.py:655] -------------------------------------------
INFO 2021-12-29 03:10:13,436 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 03:10:13,439 [dag.py:816] [DAG] start
INFO 2021-12-29 03:10:13,440 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 03:10:13,445 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 03:10:13,468 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 03:10:13,469 [operator.py:1163] Init cuda env in process 0
INFO 2021-12-29 03:10:13,469 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 03:10:14,628 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 03:10:15,826 [operator.py:1174] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 03:10:19,409 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 03:10:19,411 [operator.py:1422] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 03:10:19,411 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 03:10:21,260 [operator.py:969] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 965, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 78, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 429, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 03:10:21,264 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 03:11:47,323 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 03:11:47,323 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 03:11:47,323 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 03:11:47,323 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 03:11:47,323 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 03:11:47,323 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 03:11:47,323 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 03:11:47,324 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 03:11:47,325 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 03:11:47,325 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 03:11:47,325 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 03:11:47,325 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 03:11:47,325 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 03:11:47,326 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18082,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9998,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 03:11:47,326 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 03:11:47,326 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 03:11:47,348 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 03:11:47,349 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 03:11:47,349 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 03:11:47,349 [dag.py:655] -------------------------------------------
INFO 2021-12-29 03:11:47,395 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 03:11:47,398 [dag.py:816] [DAG] start
INFO 2021-12-29 03:11:47,399 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 03:11:47,403 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 03:11:47,431 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 03:11:47,432 [operator.py:1163] Init cuda env in process 0
INFO 2021-12-29 03:11:47,432 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 03:11:48,697 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 03:11:49,910 [operator.py:1174] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 03:11:53,938 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 03:11:53,939 [operator.py:1422] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 03:11:53,940 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 03:11:55,757 [operator.py:969] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 965, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 78, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 429, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 03:11:55,761 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 05:35:58,321 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 05:35:58,321 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 05:35:58,321 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 05:35:58,321 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 05:35:58,322 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 05:35:58,323 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 05:35:58,323 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 05:35:58,323 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 05:35:58,323 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
WARNING 2021-12-29 05:37:04,889 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 05:37:04,889 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 05:37:04,889 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 05:37:04,890 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 05:37:04,891 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 05:37:04,891 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 05:37:04,891 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 05:37:04,891 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 05:37:04,891 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 05:37:04,891 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 05:37:04,892 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 05:37:04,892 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 05:37:04,892 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 05:37:04,892 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 05:37:04,892 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 05:37:04,892 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 05:37:04,915 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 05:37:04,916 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 05:37:04,916 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 05:37:04,916 [dag.py:655] -------------------------------------------
INFO 2021-12-29 05:37:04,962 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 05:37:04,967 [dag.py:816] [DAG] start
INFO 2021-12-29 05:37:04,968 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 05:37:04,974 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 05:37:04,992 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 05:37:04,993 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 05:37:04,993 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 05:37:06,170 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 05:37:07,358 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 05:37:14,620 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 05:37:14,621 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 05:37:14,621 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 05:37:16,537 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 77, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 430, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 05:37:16,542 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 05:40:11,809 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 05:40:11,809 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 05:40:11,809 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 05:40:11,809 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 05:40:11,809 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 05:40:11,810 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 05:40:11,811 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 05:40:11,811 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 05:40:11,811 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 05:40:11,811 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 05:40:11,811 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 05:40:11,811 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 05:40:11,812 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 05:40:11,812 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 05:40:11,812 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 05:40:11,837 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 05:40:11,838 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 05:40:11,839 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 05:40:11,839 [dag.py:655] -------------------------------------------
INFO 2021-12-29 05:40:11,880 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 05:40:11,884 [dag.py:816] [DAG] start
INFO 2021-12-29 05:40:11,885 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 05:40:11,890 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 05:40:11,909 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 05:40:11,910 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 05:40:11,910 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 05:40:13,297 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 05:40:14,485 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 05:40:16,831 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 05:40:16,832 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 05:40:16,834 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 05:40:18,654 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 77, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 430, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 05:40:18,658 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 05:42:11,543 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 05:42:11,543 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 05:42:11,543 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 05:42:11,544 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 05:42:11,544 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 05:42:11,544 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 05:42:11,544 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 05:42:11,544 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 05:42:11,544 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 05:42:11,544 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 05:42:11,544 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 05:42:11,545 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 05:42:11,545 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 05:42:11,545 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 05:42:11,545 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 05:42:11,545 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 05:42:11,545 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 05:42:11,545 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 05:42:11,546 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 05:42:11,546 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 05:42:11,546 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 05:42:11,546 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 05:42:11,546 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 05:42:11,546 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 05:42:11,569 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 05:42:11,569 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 05:42:11,570 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 05:42:11,570 [dag.py:655] -------------------------------------------
INFO 2021-12-29 05:42:11,615 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 05:42:11,618 [dag.py:816] [DAG] start
INFO 2021-12-29 05:42:11,619 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 05:42:11,626 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 05:42:11,650 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 05:42:11,651 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 05:42:11,651 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 05:42:12,841 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 05:42:14,032 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 05:42:17,467 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 05:42:17,469 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 05:42:17,470 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 05:42:19,333 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 77, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 430, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 05:42:19,340 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 06:08:54,355 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:08:54,355 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:08:54,355 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:08:54,356 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:08:54,356 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:08:54,356 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:08:54,356 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:08:54,356 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:08:54,356 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:08:54,356 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:08:54,356 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:08:54,357 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:08:54,357 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:08:54,357 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:08:54,357 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:08:54,357 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:08:54,357 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:08:54,357 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:08:54,358 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:08:54,358 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:08:54,358 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:08:54,358 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:08:54,358 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:08:54,358 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:08:54,380 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:08:54,381 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:08:54,381 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:08:54,381 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:08:54,427 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:08:54,431 [dag.py:816] [DAG] start
INFO 2021-12-29 06:08:54,432 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:08:54,438 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:08:54,460 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:08:54,460 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:08:54,461 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:08:55,641 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:08:56,841 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: name 'yaml' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 33, in init_op
    yml_conf = yaml.safe_load(f)
NameError: name 'yaml' is not defined
INFO 2021-12-29 06:09:00,289 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:09:00,290 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:09:00,291 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
WARNING 2021-12-29 06:10:19,803 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:10:19,803 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:10:19,803 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:10:19,803 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:10:19,804 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:10:19,805 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:10:19,805 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:10:19,805 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:10:19,805 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:10:19,805 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:10:19,805 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:10:19,806 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:10:19,806 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:10:19,806 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:10:19,806 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:10:19,806 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:10:19,830 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:10:19,831 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:10:19,831 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:10:19,831 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:10:19,878 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:10:19,882 [dag.py:816] [DAG] start
INFO 2021-12-29 06:10:19,883 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:10:19,890 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:10:19,904 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:10:19,905 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:10:19,905 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:10:21,094 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:10:22,339 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: name 'yaml' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 33, in init_op
    yml_conf = yaml.safe_load(f)
NameError: name 'yaml' is not defined
INFO 2021-12-29 06:10:26,440 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:10:26,441 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:10:26,442 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-29 06:11:59,537 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:11:59,538 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:11:59,538 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
WARNING 2021-12-29 06:12:08,931 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:12:08,931 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:12:08,931 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:12:08,932 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:12:08,933 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:12:08,933 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:12:08,933 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:12:08,933 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:12:08,933 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:12:08,933 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:12:08,934 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:12:08,934 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:12:08,934 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:12:08,934 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:12:08,934 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:12:08,934 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:12:08,958 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:12:08,959 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:12:08,959 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:12:08,959 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:12:09,004 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:12:09,008 [dag.py:816] [DAG] start
INFO 2021-12-29 06:12:09,009 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:12:09,016 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:12:09,032 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:12:09,032 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:12:09,032 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:12:10,227 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:12:11,443 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: __init__() got an unexpected keyword argument 'interp'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 40, in init_op
    self.preprocess_ops.append(eval(op_type)(**new_op_info))
TypeError: __init__() got an unexpected keyword argument 'interp'
INFO 2021-12-29 06:12:12,867 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:12:12,868 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:12:12,869 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
WARNING 2021-12-29 06:12:47,188 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:12:47,188 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:12:47,189 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:12:47,189 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:12:47,189 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:12:47,189 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:12:47,189 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:12:47,189 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:12:47,189 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:12:47,189 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:12:47,190 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:12:47,190 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:12:47,190 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:12:47,190 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:12:47,190 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:12:47,190 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:12:47,190 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:12:47,191 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:12:47,191 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:12:47,191 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:12:47,191 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:12:47,191 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:12:47,191 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:12:47,191 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:12:47,213 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:12:47,213 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:12:47,213 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:12:47,213 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:12:47,259 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:12:47,263 [dag.py:816] [DAG] start
INFO 2021-12-29 06:12:47,264 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:12:47,269 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:12:47,293 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:12:47,293 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:12:47,293 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:12:48,478 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:12:49,708 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: __init__() got an unexpected keyword argument 'interp'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 41, in init_op
    self.preprocess_ops.append(eval(op_type)(**new_op_info))
TypeError: __init__() got an unexpected keyword argument 'interp'
INFO 2021-12-29 06:12:50,036 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:12:50,037 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:12:50,038 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
WARNING 2021-12-29 06:15:10,463 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:15:10,464 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:15:10,464 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:15:10,464 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:15:10,464 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:15:10,464 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:15:10,464 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:15:10,464 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:15:10,465 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:15:10,466 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:15:10,466 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:15:10,466 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:15:10,466 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:15:10,466 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:15:10,466 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:15:10,466 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:15:10,488 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:15:10,488 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:15:10,489 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:15:10,489 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:15:10,535 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:15:10,540 [dag.py:816] [DAG] start
INFO 2021-12-29 06:15:10,540 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:15:10,546 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:15:10,568 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:15:10,569 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:15:10,569 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:15:11,748 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:15:12,951 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: __init__() got an unexpected keyword argument 'interp'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 43, in init_op
    self.preprocess_ops.append(eval(op_type)(**new_op_info))
TypeError: __init__() got an unexpected keyword argument 'interp'
WARNING 2021-12-29 06:17:36,321 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:17:36,321 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:17:36,322 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:17:36,322 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:17:36,322 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:17:36,322 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:17:36,322 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:17:36,322 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:17:36,322 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:17:36,322 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:17:36,323 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:17:36,323 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:17:36,323 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:17:36,323 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:17:36,323 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:17:36,323 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:17:36,323 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:17:36,324 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:17:36,324 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:17:36,324 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:17:36,324 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:17:36,324 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:17:36,324 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:17:36,324 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:17:36,346 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:17:36,347 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:17:36,347 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:17:36,348 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:17:36,391 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:17:36,394 [dag.py:816] [DAG] start
INFO 2021-12-29 06:17:36,395 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:17:36,401 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:17:36,427 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:17:36,428 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:17:36,428 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:17:37,610 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:17:38,816 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: __init__() got an unexpected keyword argument 'interp'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 44, in init_op
    self.preprocess_ops.append(eval(op_type)(**new_op_info))
TypeError: __init__() got an unexpected keyword argument 'interp'
WARNING 2021-12-29 06:18:17,409 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:18:17,409 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:18:17,409 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:18:17,410 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:18:17,411 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:18:17,411 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:18:17,411 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:18:17,411 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:18:17,411 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:18:17,411 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:18:17,412 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:18:17,412 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:18:17,412 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:18:17,412 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:18:17,412 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:18:17,412 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:18:17,436 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:18:17,436 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:18:17,436 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:18:17,437 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:18:17,477 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:18:17,482 [dag.py:816] [DAG] start
INFO 2021-12-29 06:18:17,483 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:18:17,491 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:18:17,505 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:18:17,506 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:18:17,506 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:18:18,701 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:18:19,908 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: __init__() got an unexpected keyword argument 'interp'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 45, in init_op
    self.preprocess_ops.append(eval(op_type)(**new_op_info))
TypeError: __init__() got an unexpected keyword argument 'interp'
WARNING 2021-12-29 06:19:57,871 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:19:57,872 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:19:57,872 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:19:57,872 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:19:57,872 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:19:57,872 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:19:57,872 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:19:57,872 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:19:57,873 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:19:57,874 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:19:57,874 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:19:57,874 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:19:57,874 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:19:57,874 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:19:57,875 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:19:57,875 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:19:57,900 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:19:57,900 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:19:57,901 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:19:57,901 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:19:57,945 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:19:57,950 [dag.py:816] [DAG] start
INFO 2021-12-29 06:19:57,951 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:19:57,957 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:19:57,975 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:19:57,975 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:19:57,976 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:19:59,153 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:20:00,415 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: name 'preprocess_ops' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 45, in init_op
    preprocess_ops.append(eval(op_type)(**new_op_info))
NameError: name 'preprocess_ops' is not defined
WARNING 2021-12-29 06:21:28,629 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:21:28,629 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:21:28,629 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:21:28,630 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:21:28,630 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:21:28,630 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:21:28,630 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:21:28,630 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:21:28,630 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:21:28,630 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:21:28,630 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:21:28,631 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:21:28,631 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:21:28,631 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:21:28,631 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:21:28,631 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:21:28,631 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:21:28,632 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:21:28,632 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:21:28,632 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:21:28,632 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:21:28,632 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:21:28,632 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:21:28,632 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:21:28,657 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:21:28,658 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:21:28,658 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:21:28,658 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:21:28,702 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:21:28,705 [dag.py:816] [DAG] start
INFO 2021-12-29 06:21:28,706 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:21:28,711 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:21:28,728 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:21:28,728 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:21:28,729 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:21:29,937 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:21:31,123 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: name 'preprocess_ops' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 46, in init_op
    preprocess_ops.append(eval(op_type)(**new_op_info))
NameError: name 'preprocess_ops' is not defined
WARNING 2021-12-29 06:25:12,051 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:25:12,051 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:25:12,052 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:25:12,052 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:25:12,052 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:25:12,052 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:25:12,052 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:25:12,052 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:25:12,052 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:25:12,052 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:25:12,053 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:25:12,053 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:25:12,053 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:25:12,053 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:25:12,053 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:25:12,053 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:25:12,053 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:25:12,054 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:25:12,054 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:25:12,054 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:25:12,054 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:25:12,054 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:25:12,054 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:25:12,054 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:25:12,078 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:25:12,078 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:25:12,079 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:25:12,079 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:25:12,121 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:25:12,125 [dag.py:816] [DAG] start
INFO 2021-12-29 06:25:12,125 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:25:12,131 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:25:12,155 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:25:12,156 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:25:12,156 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:25:13,482 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:25:14,695 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: name 'preprocess_ops' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 46, in init_op
    preprocess_ops.append(eval(op_type)(**new_op_info))
NameError: name 'preprocess_ops' is not defined
WARNING 2021-12-29 06:25:29,445 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:25:29,445 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:25:29,445 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:25:29,445 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:25:29,445 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:25:29,446 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:25:29,447 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:25:29,447 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:25:29,447 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:25:29,447 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:25:29,447 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:25:29,447 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:25:29,447 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:25:29,448 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:25:29,448 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:25:29,448 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:25:29,471 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:25:29,472 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:25:29,472 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:25:29,472 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:25:29,515 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:25:29,519 [dag.py:816] [DAG] start
INFO 2021-12-29 06:25:29,519 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:25:29,525 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:25:29,544 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:25:29,544 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:25:29,545 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:25:30,728 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:25:31,935 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: name 'preprocess_ops' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 47, in init_op
    preprocess_ops.append(eval(op_type)(**new_op_info))
NameError: name 'preprocess_ops' is not defined
WARNING 2021-12-29 06:31:43,452 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:31:43,453 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:31:43,453 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:31:43,453 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:31:43,453 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:31:43,453 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:31:43,453 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:31:43,453 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:31:43,454 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:31:43,455 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:31:43,455 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:31:43,455 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:31:43,455 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:31:43,455 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:31:43,455 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:31:43,456 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:31:43,479 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:31:43,479 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:31:43,480 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:31:43,480 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:31:43,524 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:31:43,527 [dag.py:816] [DAG] start
INFO 2021-12-29 06:31:43,528 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:31:43,534 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:31:43,559 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:31:43,560 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:31:43,560 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:31:44,753 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2021-12-29 06:31:45,962 [operator.py:1176] [ppyolo_mbv3|0] failed to init op: name 'preprocess_ops' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1171, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1360, in _initialize
    self.init_op()
  File "web_service.py", line 49, in init_op
    preprocess_ops.append(eval(op_type)(**new_op_info))
NameError: name 'preprocess_ops' is not defined
WARNING 2021-12-29 06:32:31,020 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:32:31,021 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:32:31,021 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:32:31,021 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:32:31,021 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:32:31,021 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:32:31,021 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:32:31,021 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:32:31,021 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:32:31,022 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:32:31,022 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:32:31,022 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:32:31,022 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:32:31,022 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:32:31,022 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:32:31,022 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:32:31,022 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:32:31,023 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:32:31,023 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:32:31,023 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:32:31,023 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:32:31,023 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:32:31,023 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:32:31,024 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:32:31,048 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:32:31,049 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:32:31,049 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:32:31,049 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:32:31,091 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:32:31,095 [dag.py:816] [DAG] start
INFO 2021-12-29 06:32:31,096 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:32:31,102 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:32:31,127 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:32:31,128 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:32:31,128 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:32:32,329 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:32:33,520 [operator.py:1178] [ppyolo_mbv3|0] Succ init
WARNING 2021-12-29 06:33:05,247 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:33:05,250 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:33:05,250 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:33:05,250 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:33:05,250 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:33:05,250 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:33:05,250 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:33:05,251 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:33:05,252 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:33:05,252 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:33:05,252 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:33:05,252 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:33:05,252 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:33:05,253 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:33:05,253 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:33:05,276 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:33:05,277 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:33:05,277 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:33:05,277 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:33:05,321 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:33:05,324 [dag.py:816] [DAG] start
INFO 2021-12-29 06:33:05,325 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:33:05,331 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:33:05,355 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:33:05,356 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:33:05,356 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:33:06,480 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:33:07,686 [operator.py:1178] [ppyolo_mbv3|0] Succ init
WARNING 2021-12-29 06:40:19,257 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:40:19,257 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:40:19,257 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:40:19,257 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:40:19,257 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:40:19,257 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:40:19,257 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:40:19,258 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:40:19,259 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:40:19,259 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:40:19,259 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:40:19,259 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:40:19,259 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:40:19,260 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:40:19,260 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:40:19,260 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:40:19,285 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:40:19,286 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:40:19,286 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:40:19,286 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:40:19,333 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:40:19,337 [dag.py:816] [DAG] start
INFO 2021-12-29 06:40:19,337 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:40:19,343 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:40:19,359 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:40:19,360 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:40:19,360 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:40:20,576 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:40:21,771 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 06:40:25,060 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:40:25,061 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:40:25,062 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 06:40:25,105 [operator.py:695] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: local variable 'im_info' referenced before assignment
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 678, in _run_preprocess
    parsed_data, data_id, logid_dict.get(data_id))
  File "web_service.py", line 54, in preprocess
    im_info['im_shape'] = np.array(im.shape[:2], dtype=np.float32)
UnboundLocalError: local variable 'im_info' referenced before assignment
ERROR 2021-12-29 06:40:25,111 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: local variable 'im_info' referenced before assignment
WARNING 2021-12-29 06:42:03,381 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:42:03,381 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:42:03,381 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:42:03,381 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:42:03,381 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:42:03,381 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:42:03,381 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:42:03,381 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:42:03,382 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:42:03,383 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:42:03,383 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:42:03,383 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:42:03,383 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:42:03,383 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:42:03,383 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:42:03,384 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:42:03,408 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:42:03,409 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:42:03,409 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:42:03,410 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:42:03,452 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:42:03,456 [dag.py:816] [DAG] start
INFO 2021-12-29 06:42:03,456 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:42:03,464 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:42:03,483 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:42:03,484 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:42:03,484 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:42:04,712 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:42:05,914 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 06:42:13,067 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:42:13,069 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:42:13,070 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 06:42:13,106 [operator.py:695] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: local variable 'im_info' referenced before assignment
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 678, in _run_preprocess
    parsed_data, data_id, logid_dict.get(data_id))
  File "web_service.py", line 54, in preprocess
    im_info['im_shape'] = np.array(im.shape[:2], dtype=np.float32)
UnboundLocalError: local variable 'im_info' referenced before assignment
ERROR 2021-12-29 06:42:13,112 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: local variable 'im_info' referenced before assignment
WARNING 2021-12-29 06:42:44,174 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:42:44,174 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:42:44,174 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:42:44,174 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:42:44,174 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:42:44,175 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:42:44,176 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:42:44,176 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:42:44,176 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:42:44,176 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:42:44,176 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:42:44,177 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:42:44,177 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:42:44,177 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:42:44,177 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:42:44,177 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:42:44,201 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:42:44,201 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:42:44,202 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:42:44,202 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:42:44,248 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:42:44,252 [dag.py:816] [DAG] start
INFO 2021-12-29 06:42:44,253 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:42:44,259 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:42:44,278 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:42:44,279 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:42:44,279 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:42:45,483 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:42:46,679 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 06:42:47,152 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:42:47,153 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:42:47,154 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 06:42:47,195 [operator.py:695] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: local variable 'im_info' referenced before assignment
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 678, in _run_preprocess
    parsed_data, data_id, logid_dict.get(data_id))
  File "web_service.py", line 55, in preprocess
    im_info['im_shape'] = np.array(im.shape[:2], dtype=np.float32)
UnboundLocalError: local variable 'im_info' referenced before assignment
ERROR 2021-12-29 06:42:47,200 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: local variable 'im_info' referenced before assignment
WARNING 2021-12-29 06:44:34,233 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:44:34,233 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:44:34,233 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:44:34,233 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:44:34,233 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:44:34,233 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:44:34,233 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:44:34,234 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:44:34,235 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:44:34,235 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:44:34,235 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:44:34,235 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:44:34,235 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:44:34,235 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:44:34,236 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:44:34,236 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:44:34,258 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:44:34,259 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:44:34,259 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:44:34,259 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:44:34,301 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:44:34,306 [dag.py:816] [DAG] start
INFO 2021-12-29 06:44:34,307 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:44:34,313 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:44:34,329 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:44:34,330 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:44:34,330 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:44:35,557 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:44:36,750 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 06:44:43,663 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:44:43,664 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:44:43,665 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 06:44:43,710 [operator.py:695] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: local variable 'im_info' referenced before assignment
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 678, in _run_preprocess
    parsed_data, data_id, logid_dict.get(data_id))
  File "web_service.py", line 55, in preprocess
    im_info['im_shape'] = np.array(im.shape[:2], dtype=np.float32)
UnboundLocalError: local variable 'im_info' referenced before assignment
ERROR 2021-12-29 06:44:43,715 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: local variable 'im_info' referenced before assignment
WARNING 2021-12-29 06:46:19,030 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:46:19,030 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:46:19,030 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:46:19,030 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:46:19,031 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:46:19,032 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:46:19,032 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:46:19,032 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:46:19,032 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:46:19,032 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:46:19,032 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:46:19,033 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:46:19,033 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:46:19,033 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:46:19,033 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:46:19,033 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:46:19,057 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:46:19,058 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:46:19,058 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:46:19,058 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:46:19,108 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:46:19,111 [dag.py:816] [DAG] start
INFO 2021-12-29 06:46:19,112 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:46:19,118 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:46:19,146 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:46:19,147 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:46:19,147 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:46:20,373 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:46:21,561 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 06:46:25,488 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:46:25,490 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:46:25,490 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 06:46:25,581 [operator.py:695] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: operands could not be broadcast together with shapes (3,640,640) (1,1,3) (3,640,640) 
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 678, in _run_preprocess
    parsed_data, data_id, logid_dict.get(data_id))
  File "web_service.py", line 71, in preprocess
    im = self.img_preprocess(im)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 492, in __call__
    img = t(img)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 642, in __call__
    return F.normalize(img, self.mean, self.std, self.channel_first)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/functional.py", line 33, in normalize
    img -= img_mean
ValueError: operands could not be broadcast together with shapes (3,640,640) (1,1,3) (3,640,640) 
ERROR 2021-12-29 06:46:25,587 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: operands could not be broadcast together with shapes (3,640,640) (1,1,3) (3,640,640) 
WARNING 2021-12-29 06:51:01,066 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:51:01,066 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:51:01,066 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:51:01,067 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:51:01,067 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:51:01,067 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:51:01,067 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:51:01,067 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:51:01,067 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:51:01,067 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:51:01,067 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:51:01,068 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:51:01,068 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:51:01,068 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:51:01,068 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:51:01,068 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:51:01,068 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:51:01,069 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:51:01,069 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:51:01,069 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:51:01,069 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:51:01,069 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:51:01,069 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:51:01,069 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:51:01,094 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:51:01,095 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:51:01,095 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:51:01,095 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:51:01,140 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:51:01,144 [dag.py:816] [DAG] start
INFO 2021-12-29 06:51:01,145 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:51:01,151 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:51:01,171 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:51:01,172 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:51:01,172 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:51:02,379 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:51:03,568 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 06:51:06,257 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:51:06,258 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:51:06,259 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 06:51:07,885 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 89, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 430, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 06:51:07,889 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 06:51:56,944 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:51:56,945 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:51:56,945 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:51:56,945 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:51:56,945 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:51:56,945 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:51:56,945 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:51:56,945 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:51:56,945 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:51:56,946 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:51:56,946 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:51:56,946 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:51:56,946 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:51:56,946 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:51:56,946 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:51:56,946 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:51:56,946 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:51:56,947 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:51:56,947 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:51:56,947 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:51:56,947 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:51:56,948 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:51:56,948 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:51:56,948 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:51:56,971 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:51:56,972 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:51:56,972 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:51:56,972 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:51:57,019 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:51:57,023 [dag.py:816] [DAG] start
INFO 2021-12-29 06:51:57,024 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:51:57,029 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:51:57,049 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:51:57,050 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:51:57,050 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:51:58,256 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:51:59,445 [operator.py:1178] [ppyolo_mbv3|0] Succ init
WARNING 2021-12-29 06:52:13,864 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:52:13,865 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:52:13,865 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:52:13,865 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:52:13,865 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:52:13,865 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:52:13,865 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:52:13,865 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:52:13,866 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:52:13,867 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:52:13,867 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:52:13,867 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:52:13,867 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:52:13,868 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:52:13,868 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:52:13,868 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:52:13,892 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:52:13,893 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:52:13,893 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:52:13,893 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:52:13,936 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:52:13,939 [dag.py:816] [DAG] start
INFO 2021-12-29 06:52:13,940 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:52:13,945 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:52:13,966 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:52:13,966 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:52:13,966 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:52:15,154 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:52:16,355 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 06:52:18,677 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:52:18,678 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:52:18,679 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 06:52:20,309 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 86, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 430, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 06:52:20,314 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 06:54:00,624 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 06:54:00,624 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:54:00,624 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 06:54:00,625 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 06:54:00,626 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 06:54:00,626 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 06:54:00,626 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 06:54:00,626 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 06:54:00,626 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 06:54:00,626 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 06:54:00,626 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:54:00,627 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 06:54:00,627 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 06:54:00,627 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 06:54:00,627 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 06:54:00,627 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 06:54:00,652 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 06:54:00,653 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 06:54:00,653 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 06:54:00,653 [dag.py:655] -------------------------------------------
INFO 2021-12-29 06:54:00,699 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 06:54:00,703 [dag.py:816] [DAG] start
INFO 2021-12-29 06:54:00,703 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 06:54:00,709 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 06:54:00,732 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 06:54:00,733 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 06:54:00,733 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 06:54:01,924 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 06:54:03,172 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 06:54:05,727 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 06:54:05,728 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 06:54:05,729 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 06:54:07,453 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 86, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 430, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 06:54:07,458 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 07:13:12,175 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 07:13:12,175 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:13:12,176 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 07:13:12,176 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 07:13:12,176 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 07:13:12,176 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 07:13:12,176 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:13:12,176 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 07:13:12,176 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 07:13:12,177 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 07:13:12,177 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 07:13:12,177 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 07:13:12,177 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 07:13:12,177 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 07:13:12,177 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 07:13:12,177 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 07:13:12,177 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 07:13:12,178 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 07:13:12,178 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:13:12,178 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 07:13:12,178 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 07:13:12,178 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 07:13:12,178 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 07:13:12,178 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 07:13:12,201 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 07:13:12,202 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 07:13:12,202 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 07:13:12,202 [dag.py:655] -------------------------------------------
INFO 2021-12-29 07:13:12,251 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 07:13:12,254 [dag.py:816] [DAG] start
INFO 2021-12-29 07:13:12,255 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 07:13:12,260 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 07:13:12,284 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:13:12,284 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 07:13:12,285 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 07:13:13,478 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 07:13:14,670 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 07:13:18,607 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 07:13:18,609 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 07:13:18,609 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 07:13:20,265 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 87, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 430, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 07:13:20,269 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 07:16:27,832 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 07:16:27,832 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:16:27,833 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 07:16:27,833 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 07:16:27,833 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 07:16:27,833 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 07:16:27,833 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:16:27,833 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 07:16:27,833 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 07:16:27,833 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 07:16:27,834 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 07:16:27,834 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 07:16:27,834 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 07:16:27,834 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 07:16:27,834 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 07:16:27,834 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 07:16:27,834 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 07:16:27,835 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 07:16:27,835 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:16:27,835 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 07:16:27,835 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 07:16:27,835 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 07:16:27,835 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 07:16:27,835 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 07:16:27,860 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 07:16:27,861 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 07:16:27,861 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 07:16:27,861 [dag.py:655] -------------------------------------------
INFO 2021-12-29 07:16:27,904 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 07:16:27,907 [dag.py:816] [DAG] start
INFO 2021-12-29 07:16:27,908 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 07:16:27,915 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 07:16:27,939 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:16:27,939 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 07:16:27,939 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 07:16:29,142 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 07:16:30,333 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 07:16:32,190 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 07:16:32,192 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 07:16:32,193 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 07:16:32,263 [operator.py:695] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: name 'im_shape' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 678, in _run_preprocess
    parsed_data, data_id, logid_dict.get(data_id))
  File "web_service.py", line 68, in preprocess
    "im_shape": im_info[im_shape],#np.array(list(im.shape[1:])).reshape(-1)[np.newaxis,:],
NameError: name 'im_shape' is not defined
ERROR 2021-12-29 07:16:32,267 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to preprocess: name 'im_shape' is not defined
WARNING 2021-12-29 07:17:33,514 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 07:17:33,514 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:17:33,515 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 07:17:33,515 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 07:17:33,515 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 07:17:33,515 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 07:17:33,515 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:17:33,515 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 07:17:33,515 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 07:17:33,515 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 07:17:33,516 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 07:17:33,516 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 07:17:33,516 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 07:17:33,516 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 07:17:33,516 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 07:17:33,516 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 07:17:33,516 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 07:17:33,517 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 07:17:33,517 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:17:33,517 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 07:17:33,517 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 07:17:33,517 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 07:17:33,517 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 07:17:33,518 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 07:17:33,542 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 07:17:33,543 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 07:17:33,543 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 07:17:33,543 [dag.py:655] -------------------------------------------
INFO 2021-12-29 07:17:33,585 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 07:17:33,588 [dag.py:816] [DAG] start
INFO 2021-12-29 07:17:33,589 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 07:17:33,594 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 07:17:33,615 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:17:33,616 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 07:17:33,616 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 07:17:34,803 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 07:17:35,996 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 07:17:38,155 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 07:17:38,156 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 07:17:38,158 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 07:17:39,797 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 87, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 07:17:39,802 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 07:19:06,141 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 07:19:06,142 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 07:19:06,143 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 07:19:06,143 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 07:19:06,143 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 07:19:06,143 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 07:19:06,143 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 07:19:06,143 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 07:19:06,143 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 07:19:06,144 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 07:19:06,144 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:19:06,144 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 07:19:06,144 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 07:19:06,144 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 07:19:06,144 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 07:19:06,144 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 07:19:06,167 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 07:19:06,168 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 07:19:06,168 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 07:19:06,168 [dag.py:655] -------------------------------------------
INFO 2021-12-29 07:19:06,213 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 07:19:06,217 [dag.py:816] [DAG] start
INFO 2021-12-29 07:19:06,219 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 07:19:06,224 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 07:19:06,242 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:19:06,242 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 07:19:06,243 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 07:19:07,427 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 07:19:08,615 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 07:19:11,136 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 07:19:11,137 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 07:19:11,137 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 07:19:12,763 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 87, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 07:19:12,767 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 07:40:25,237 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 07:40:25,237 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:40:25,237 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 07:40:25,237 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 07:40:25,238 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 07:40:25,239 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 07:40:25,239 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 07:40:25,239 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
WARNING 2021-12-29 07:42:11,629 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 07:42:11,629 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:42:11,629 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 07:42:11,630 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 07:42:11,631 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 07:42:11,631 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 07:42:11,631 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 07:42:11,631 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 07:42:11,631 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 07:42:11,631 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:42:11,632 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 07:42:11,632 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 07:42:11,632 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 07:42:11,632 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 07:42:11,634 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 07:42:11,659 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 07:42:11,660 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 07:42:11,660 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 07:42:11,660 [dag.py:655] -------------------------------------------
INFO 2021-12-29 07:42:11,707 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 07:42:11,711 [dag.py:816] [DAG] start
INFO 2021-12-29 07:42:11,713 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 07:42:11,719 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 07:42:11,742 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:42:11,742 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 07:42:11,743 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 07:42:12,964 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 07:42:14,178 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 07:42:24,007 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 07:42:24,009 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 07:42:24,009 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 07:42:25,683 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 87, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_0.tmp_1.lod'
ERROR 2021-12-29 07:42:25,687 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_0.tmp_1.lod'
WARNING 2021-12-29 07:49:58,432 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-29 07:49:58,433 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:49:58,433 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-29 07:49:58,433 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-29 07:49:58,433 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-29 07:49:58,433 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-29 07:49:58,433 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-29 07:49:58,433 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-29 07:49:58,433 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-29 07:49:58,434 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-29 07:49:58,434 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-29 07:49:58,434 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-29 07:49:58,434 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-29 07:49:58,434 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-29 07:49:58,434 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-29 07:49:58,434 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-29 07:49:58,434 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-29 07:49:58,435 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-29 07:49:58,435 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:49:58,435 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-29 07:49:58,435 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-29 07:49:58,435 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-29 07:49:58,435 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-29 07:49:58,435 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-29 07:49:58,458 [dag.py:493] [DAG] Succ init
INFO 2021-12-29 07:49:58,459 [dag.py:651] ================= USED OP =================
INFO 2021-12-29 07:49:58,459 [dag.py:654] ppyolo_mbv3
INFO 2021-12-29 07:49:58,460 [dag.py:655] -------------------------------------------
INFO 2021-12-29 07:49:58,505 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-29 07:49:58,509 [dag.py:816] [DAG] start
INFO 2021-12-29 07:49:58,509 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-29 07:49:58,515 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-29 07:49:58,539 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-29 07:49:58,540 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-29 07:49:58,540 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-29 07:49:59,775 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-29 07:50:00,998 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-29 07:50:03,927 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-29 07:50:03,928 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-29 07:50:03,930 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-29 07:50:05,801 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_4.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 87, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_4.tmp_1.lod'
ERROR 2021-12-29 07:50:05,806 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_4.tmp_1.lod'
WARNING 2021-12-30 06:53:16,236 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 06:53:16,237 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 06:53:16,237 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 06:53:16,237 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 06:53:16,237 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 06:53:16,237 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 06:53:16,237 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 06:53:16,237 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 06:53:16,237 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 06:53:16,238 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 06:53:16,238 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 06:53:16,238 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 06:53:16,238 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 06:53:16,238 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 06:53:16,238 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 06:53:16,238 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 06:53:16,238 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 06:53:16,239 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 06:53:16,239 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 06:53:16,239 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 06:53:16,239 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 06:53:16,239 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 06:53:16,239 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 06:53:16,239 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 06:53:16,265 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 06:53:16,266 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 06:53:16,266 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 06:53:16,266 [dag.py:655] -------------------------------------------
INFO 2021-12-30 06:53:16,310 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 06:53:16,315 [dag.py:816] [DAG] start
INFO 2021-12-30 06:53:16,316 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 06:53:16,323 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 06:53:16,341 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 06:53:16,341 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 06:53:16,342 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 06:53:17,563 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 06:53:18,787 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 06:53:26,765 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 06:53:26,766 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 06:53:26,766 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 06:53:28,471 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_3.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 81, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_3.tmp_1.lod'
ERROR 2021-12-30 06:53:28,476 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_3.tmp_1.lod'
WARNING 2021-12-30 07:57:06,805 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 07:57:06,805 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 07:57:06,805 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 07:57:06,805 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 07:57:06,805 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 07:57:06,806 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 07:57:06,807 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 07:57:06,807 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 07:57:06,807 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 07:57:06,807 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 07:57:06,807 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 07:57:06,807 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 07:57:06,808 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 07:57:06,808 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 07:57:06,808 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 07:57:06,831 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 07:57:06,832 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 07:57:06,832 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 07:57:06,832 [dag.py:655] -------------------------------------------
INFO 2021-12-30 07:57:06,878 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 07:57:06,882 [dag.py:816] [DAG] start
INFO 2021-12-30 07:57:06,883 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 07:57:06,890 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 07:57:06,909 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 07:57:06,910 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 07:57:06,910 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 07:57:08,117 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 07:57:09,361 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 07:57:13,486 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 07:57:13,487 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 07:57:13,487 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 07:57:15,249 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 81, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_7.tmp_1.lod'
ERROR 2021-12-30 07:57:15,253 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
WARNING 2021-12-30 08:12:07,133 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:12:07,133 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:12:07,133 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:12:07,133 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:12:07,133 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:12:07,133 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:12:07,133 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:12:07,134 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:12:07,135 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:12:07,135 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:12:07,135 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:12:07,135 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:12:07,135 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:12:07,135 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:12:07,136 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:12:07,160 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:12:07,161 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:12:07,161 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:12:07,161 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:12:07,206 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:12:07,210 [dag.py:816] [DAG] start
INFO 2021-12-30 08:12:07,211 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:12:07,218 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:12:07,237 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:12:07,237 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:12:07,237 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:12:08,426 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:12:09,638 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:12:13,041 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:12:13,042 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:12:13,043 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:12:14,700 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 82, in postprocess
    np_score_list.append(fetch_dict[out_idx])
KeyError: 0
ERROR 2021-12-30 08:12:14,707 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
WARNING 2021-12-30 08:13:45,672 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:13:45,673 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:13:45,673 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:13:45,673 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:13:45,673 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:13:45,673 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:13:45,673 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:13:45,673 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:13:45,673 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:13:45,674 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:13:45,674 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:13:45,674 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:13:45,674 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:13:45,674 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:13:45,674 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:13:45,674 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:13:45,674 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:13:45,675 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:13:45,675 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:13:45,675 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:13:45,675 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:13:45,675 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:13:45,675 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:13:45,675 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:13:45,700 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:13:45,701 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:13:45,701 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:13:45,701 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:13:45,748 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:13:45,751 [dag.py:816] [DAG] start
INFO 2021-12-30 08:13:45,752 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:13:45,758 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:13:45,779 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:13:45,780 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:13:45,781 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:13:46,997 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:13:48,252 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:13:50,562 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:13:50,562 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:13:50,563 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:13:52,217 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 83, in postprocess
    np_score_list.append(fetch_dict[out_idx])
KeyError: 0
ERROR 2021-12-30 08:13:52,220 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
WARNING 2021-12-30 08:17:15,481 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:17:15,481 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:17:15,481 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:17:15,481 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:17:15,481 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:17:15,481 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:17:15,481 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:17:15,482 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:17:15,483 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:17:15,483 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:17:15,483 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:17:15,483 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:17:15,483 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:17:15,483 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:17:15,484 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:17:15,508 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:17:15,509 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:17:15,509 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:17:15,509 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:17:15,556 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:17:15,560 [dag.py:816] [DAG] start
INFO 2021-12-30 08:17:15,560 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:17:15,567 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:17:15,589 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:17:15,589 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:17:15,590 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:17:16,807 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:17:18,022 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:17:20,506 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:17:20,508 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:17:20,509 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:17:22,212 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 83, in postprocess
    np_score_list.append(fetch_dict[i])
KeyError: 0
ERROR 2021-12-30 08:17:22,217 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
WARNING 2021-12-30 08:17:30,895 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:17:30,898 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:17:30,898 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:17:30,898 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:17:30,898 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:17:30,898 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:17:30,898 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:17:30,899 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:17:30,900 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:17:30,900 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:17:30,900 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:17:30,900 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:17:30,900 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:17:30,901 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:17:30,901 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:17:30,924 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:17:30,925 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:17:30,925 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:17:30,925 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:17:30,971 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:17:30,976 [dag.py:816] [DAG] start
INFO 2021-12-30 08:17:30,977 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:17:30,983 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:17:31,007 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:17:31,008 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:17:31,008 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:17:32,203 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:17:33,418 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:17:37,462 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:17:37,464 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:17:37,464 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:17:39,176 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 83, in postprocess
    np_score_list.append(fetch_dict[i])
KeyError: 0
ERROR 2021-12-30 08:17:39,180 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
WARNING 2021-12-30 08:20:13,195 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:20:13,196 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:20:13,197 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:20:13,197 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:20:13,197 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:20:13,197 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:20:13,197 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:20:13,197 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:20:13,197 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:20:13,198 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:20:13,198 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:20:13,198 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:20:13,198 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:20:13,198 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:20:13,198 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:20:13,198 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:20:13,222 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:20:13,223 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:20:13,223 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:20:13,223 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:20:13,267 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:20:13,270 [dag.py:816] [DAG] start
INFO 2021-12-30 08:20:13,271 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:20:13,276 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:20:13,295 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:20:13,295 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:20:13,296 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:20:14,485 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:20:15,692 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:20:19,232 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:20:19,233 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:20:19,233 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:20:20,892 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 84, in postprocess
    np_score_list.append(fetch_dict[i])
KeyError: 0
ERROR 2021-12-30 08:20:20,896 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 0
WARNING 2021-12-30 08:31:54,772 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:31:54,772 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:31:54,772 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:31:54,772 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:31:54,773 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:31:54,774 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:31:54,774 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:31:54,774 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:31:54,774 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:31:54,774 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:31:54,774 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:31:54,775 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:31:54,775 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:31:54,775 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:31:54,775 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:31:54,799 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:31:54,800 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:31:54,800 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:31:54,800 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:31:54,846 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:31:54,851 [dag.py:816] [DAG] start
INFO 2021-12-30 08:31:54,852 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:31:54,857 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:31:54,877 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:31:54,877 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:31:54,877 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:31:56,080 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:31:57,306 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:31:59,636 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:31:59,638 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:31:59,638 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:32:01,331 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 91, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_7.tmp_1.lod'
ERROR 2021-12-30 08:32:01,335 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
WARNING 2021-12-30 08:34:21,409 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:34:21,409 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:34:21,410 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:34:21,411 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:34:21,411 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:34:21,411 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:34:21,411 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:34:21,411 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:34:21,411 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:34:21,411 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:34:21,412 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:34:21,412 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:34:21,412 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:34:21,412 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:34:21,412 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:34:21,412 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:34:21,437 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:34:21,438 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:34:21,438 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:34:21,438 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:34:21,482 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:34:21,486 [dag.py:816] [DAG] start
INFO 2021-12-30 08:34:21,487 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:34:21,493 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:34:21,522 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:34:21,522 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:34:21,523 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:34:22,753 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:34:23,983 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:34:27,034 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:34:27,036 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:34:27,036 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:34:28,756 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 96, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_7.tmp_1.lod'
ERROR 2021-12-30 08:34:28,761 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
WARNING 2021-12-30 08:43:32,266 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:43:32,266 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:43:32,267 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:43:32,267 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:43:32,267 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:43:32,267 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:43:32,268 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:43:32,268 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:43:32,268 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:43:32,268 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:43:32,268 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:43:32,269 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:43:32,269 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:43:32,269 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:43:32,269 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:43:32,269 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:43:32,270 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:43:32,270 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:43:32,270 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:43:32,271 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:43:32,271 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:43:32,271 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:43:32,271 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:43:32,272 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:43:32,301 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:43:32,302 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:43:32,302 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:43:32,302 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:43:32,343 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:43:32,348 [dag.py:816] [DAG] start
INFO 2021-12-30 08:43:32,349 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:43:32,355 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:43:32,375 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:43:32,376 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:43:32,376 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:43:33,601 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:43:34,822 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:43:44,530 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:43:44,532 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:43:44,532 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:43:46,213 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 111, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_7.tmp_1.lod'
ERROR 2021-12-30 08:43:46,218 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
WARNING 2021-12-30 08:49:32,281 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:49:32,281 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:49:32,282 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:49:32,282 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:49:32,282 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:49:32,282 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:49:32,282 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:49:32,283 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:49:32,283 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:49:32,283 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:49:32,283 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:49:32,283 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:49:32,284 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:49:32,284 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:49:32,284 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:49:32,284 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:49:32,285 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:49:32,286 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:49:32,286 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:49:32,287 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:49:32,287 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:49:32,287 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:49:32,288 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:49:32,288 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:49:32,317 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:49:32,318 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:49:32,318 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:49:32,318 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:49:32,355 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:49:32,359 [dag.py:816] [DAG] start
INFO 2021-12-30 08:49:32,360 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:49:32,365 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:49:32,387 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:49:32,388 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:49:32,388 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:49:33,652 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:49:34,901 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:49:38,204 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:49:38,206 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:49:38,206 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:49:39,879 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 113, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_7.tmp_1.lod'
ERROR 2021-12-30 08:49:39,884 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
WARNING 2021-12-30 08:52:42,378 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:52:42,379 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:52:42,379 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:52:42,379 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:52:42,379 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:52:42,380 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:52:42,380 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:52:42,380 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:52:42,380 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:52:42,381 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:52:42,381 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:52:42,381 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:52:42,381 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:52:42,381 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:52:42,382 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:52:42,382 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:52:42,382 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:52:42,383 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:52:42,384 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:52:42,384 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:52:42,384 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:52:42,385 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:52:42,385 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:52:42,386 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:52:42,408 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:52:42,408 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:52:42,408 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:52:42,409 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:52:42,444 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:52:42,448 [dag.py:816] [DAG] start
INFO 2021-12-30 08:52:42,449 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:52:42,454 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:52:42,478 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:52:42,479 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:52:42,479 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:52:43,723 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:52:44,962 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 08:52:48,301 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 08:52:48,303 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 08:52:48,304 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 08:52:50,006 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 110, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_7.tmp_1.lod'
ERROR 2021-12-30 08:52:50,011 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
WARNING 2021-12-30 08:59:43,422 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 08:59:43,422 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:59:43,422 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 08:59:43,423 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 08:59:43,423 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 08:59:43,423 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 08:59:43,423 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 08:59:43,424 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 08:59:43,424 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 08:59:43,424 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 08:59:43,424 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 08:59:43,425 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 08:59:43,425 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 08:59:43,425 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 08:59:43,425 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 08:59:43,425 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 08:59:43,426 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 08:59:43,427 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 08:59:43,427 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:59:43,427 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 08:59:43,427 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 08:59:43,428 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 08:59:43,428 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 08:59:43,428 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 08:59:43,457 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 08:59:43,458 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 08:59:43,458 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 08:59:43,458 [dag.py:655] -------------------------------------------
INFO 2021-12-30 08:59:43,496 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 08:59:43,500 [dag.py:816] [DAG] start
INFO 2021-12-30 08:59:43,501 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 08:59:43,507 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 08:59:43,525 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 08:59:43,525 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 08:59:43,526 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 08:59:44,766 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 08:59:45,988 [operator.py:1178] [ppyolo_mbv3|0] Succ init
WARNING 2021-12-30 09:03:09,956 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:03:09,956 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:03:09,957 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:03:09,957 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:03:09,957 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:03:09,957 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:03:09,957 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:03:09,958 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:03:09,958 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:03:09,958 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:03:09,958 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:03:09,958 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:03:09,959 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:03:09,959 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:03:09,959 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:03:09,959 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:03:09,959 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:03:09,961 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:03:09,961 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:03:09,961 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:03:09,962 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:03:09,962 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:03:09,962 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:03:09,962 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:03:09,989 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:03:09,990 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:03:09,990 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:03:09,990 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:03:10,028 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:03:10,033 [dag.py:816] [DAG] start
INFO 2021-12-30 09:03:10,033 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:03:10,039 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:03:10,058 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:03:10,059 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:03:10,059 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
WARNING 2021-12-30 09:03:11,902 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:03:11,902 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:03:11,902 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:03:11,903 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:03:11,903 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:03:11,903 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:03:11,903 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:03:11,903 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:03:11,904 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:03:11,904 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:03:11,904 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:03:11,904 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:03:11,905 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:03:11,905 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:03:11,905 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:03:11,905 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:03:11,905 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:03:11,906 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:03:11,907 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:03:11,907 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:03:11,907 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:03:11,908 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:03:11,908 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:03:11,908 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:03:11,938 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:03:11,939 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:03:11,939 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:03:11,939 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:03:11,981 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:03:11,985 [dag.py:816] [DAG] start
INFO 2021-12-30 09:03:11,986 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:03:11,992 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:03:12,011 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:03:12,011 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:03:12,011 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:03:13,259 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:03:14,522 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:03:20,138 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:03:20,139 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:03:20,139 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:03:22,048 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 102, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_7.tmp_1.lod'
ERROR 2021-12-30 09:03:22,053 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
WARNING 2021-12-30 09:07:27,378 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:07:27,379 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:07:27,379 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:07:27,379 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:07:27,380 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:07:27,380 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:07:27,380 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:07:27,380 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:07:27,381 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:07:27,381 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:07:27,381 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:07:27,381 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:07:27,382 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:07:27,382 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:07:27,382 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:07:27,382 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:07:27,382 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:07:27,383 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:07:27,384 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:07:27,384 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:07:27,384 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:07:27,385 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":18083,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:07:27,385 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:07:27,385 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:07:27,415 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:07:27,416 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:07:27,416 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:07:27,416 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:07:27,458 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:07:27,462 [dag.py:816] [DAG] start
INFO 2021-12-30 09:07:27,463 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:07:27,468 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:07:27,490 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:07:27,491 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:07:27,491 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:07:28,741 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:07:29,959 [operator.py:1178] [ppyolo_mbv3|0] Succ init
WARNING 2021-12-30 09:07:48,750 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:07:48,751 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:07:48,751 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:07:48,751 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:07:48,751 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:07:48,752 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:07:48,752 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:07:48,752 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:07:48,752 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:07:48,753 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:07:48,753 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:07:48,753 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:07:48,753 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:07:48,753 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:07:48,753 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:07:48,754 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:07:48,754 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:07:48,755 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:07:48,755 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:07:48,755 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:07:48,755 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:07:48,756 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:07:48,756 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:07:48,756 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:07:48,785 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:07:48,785 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:07:48,786 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:07:48,786 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:07:48,827 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:07:48,831 [dag.py:816] [DAG] start
INFO 2021-12-30 09:07:48,832 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:07:48,838 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:07:48,859 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:07:48,859 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:07:48,860 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:07:50,077 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:07:50,732 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:07:50,733 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:07:50,734 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 09:07:51,330 [operator.py:1178] [ppyolo_mbv3|0] Succ init
ERROR 2021-12-30 09:07:53,007 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 102, in postprocess
    res_dict = {"bbox_result": str(self.img_postprocess(fetch_dict, visualize=False))}
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 431, in __call__
    self.clsid2catid)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 346, in _get_bbox_result
    lod = [fetch_map[fetch_name + '.lod']]
KeyError: 'save_infer_model/scale_7.tmp_1.lod'
ERROR 2021-12-30 09:07:53,011 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: 'save_infer_model/scale_7.tmp_1.lod'
WARNING 2021-12-30 09:08:06,502 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:08:06,503 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:08:06,503 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:08:06,503 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:08:06,504 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:08:06,504 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:08:06,504 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:08:06,504 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:08:06,505 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:08:06,505 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:08:06,505 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:08:06,505 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:08:06,505 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:08:06,506 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:08:06,506 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:08:06,506 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:08:06,506 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:08:06,507 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:08:06,507 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:08:06,508 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:08:06,508 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:08:06,508 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:08:06,508 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:08:06,508 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:08:06,533 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:08:06,534 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:08:06,534 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:08:06,534 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:08:06,572 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:08:06,576 [dag.py:816] [DAG] start
INFO 2021-12-30 09:08:06,577 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:08:06,583 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:08:06,609 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:08:06,610 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:08:06,610 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:08:07,840 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:08:09,064 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:08:09,866 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:08:09,868 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:08:09,868 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:08:11,524 [operator.py:1000] (log_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: output of postprocess funticon must be dict type, but get <class 'numpy.ndarray'>
ERROR 2021-12-30 09:08:11,527 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (log_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: output of postprocess funticon must be dict type, but get <class 'numpy.ndarray'>
WARNING 2021-12-30 09:19:39,408 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:19:39,409 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:19:39,409 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:19:39,409 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:19:39,409 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:19:39,410 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:19:39,410 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:19:39,410 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:19:39,410 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:19:39,410 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:19:39,411 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:19:39,411 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:19:39,411 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:19:39,411 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:19:39,411 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:19:39,412 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:19:39,412 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:19:39,413 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:19:39,414 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:19:39,414 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:19:39,414 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:19:39,415 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:19:39,415 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:19:39,415 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:19:39,447 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:19:39,447 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:19:39,447 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:19:39,447 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:19:39,488 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:19:39,492 [dag.py:816] [DAG] start
INFO 2021-12-30 09:19:39,493 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:19:39,499 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:19:39,520 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:19:39,520 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:19:39,520 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:19:40,827 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:19:42,045 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:19:45,115 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:19:45,116 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:19:45,117 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:19:46,754 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: name 'res_dict' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 101, in postprocess
    res_dict[b] = {}
NameError: name 'res_dict' is not defined
ERROR 2021-12-30 09:19:46,757 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: name 'res_dict' is not defined
WARNING 2021-12-30 09:20:11,181 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:20:11,181 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:20:11,181 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:20:11,182 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:20:11,182 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:20:11,182 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:20:11,182 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:20:11,182 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:20:11,182 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:20:11,182 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:20:11,182 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:20:11,183 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:20:11,183 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:20:11,183 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:20:11,183 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:20:11,183 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:20:11,183 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:20:11,184 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:20:11,184 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:20:11,184 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:20:11,184 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:20:11,184 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:20:11,184 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:20:11,185 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:20:11,204 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:20:11,205 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:20:11,205 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:20:11,205 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:20:11,244 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:20:11,247 [dag.py:816] [DAG] start
INFO 2021-12-30 09:20:11,248 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:20:11,254 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:20:11,279 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:20:11,280 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:20:11,280 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:20:12,540 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:20:13,094 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:20:13,095 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:20:13,095 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 09:20:13,763 [operator.py:1178] [ppyolo_mbv3|0] Succ init
ERROR 2021-12-30 09:20:15,417 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: list assignment index out of range
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 102, in postprocess
    res_dict[b] = {}
IndexError: list assignment index out of range
ERROR 2021-12-30 09:20:15,421 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: list assignment index out of range
WARNING 2021-12-30 09:21:19,542 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:21:19,543 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:21:19,543 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:21:19,543 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:21:19,543 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:21:19,544 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:21:19,544 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:21:19,544 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:21:19,544 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:21:19,545 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:21:19,545 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:21:19,545 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:21:19,545 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:21:19,545 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:21:19,546 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:21:19,546 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:21:19,546 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:21:19,547 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:21:19,547 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:21:19,547 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:21:19,547 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:21:19,548 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:21:19,548 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:21:19,548 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:21:19,578 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:21:19,578 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:21:19,579 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:21:19,579 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:21:19,619 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:21:19,624 [dag.py:816] [DAG] start
INFO 2021-12-30 09:21:19,625 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:21:19,632 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:21:19,655 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:21:19,655 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:21:19,656 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:21:20,877 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:21:22,086 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:21:22,662 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:21:22,663 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:21:22,666 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:21:24,326 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: list assignment index out of range
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 103, in postprocess
    res_dict[b] = {}
IndexError: list assignment index out of range
ERROR 2021-12-30 09:21:24,330 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: list assignment index out of range
WARNING 2021-12-30 09:23:31,824 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:23:31,824 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:23:31,824 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:23:31,824 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:23:31,825 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:23:31,825 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:23:31,825 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:23:31,825 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:23:31,826 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:23:31,826 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:23:31,826 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:23:31,826 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:23:31,826 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:23:31,827 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:23:31,827 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:23:31,827 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:23:31,827 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:23:31,828 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:23:31,829 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:23:31,829 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:23:31,829 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:23:31,830 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:23:31,830 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:23:31,830 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:23:31,860 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:23:31,861 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:23:31,861 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:23:31,861 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:23:31,903 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:23:31,907 [dag.py:816] [DAG] start
INFO 2021-12-30 09:23:31,907 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:23:31,913 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:23:31,943 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:23:31,943 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:23:31,943 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:23:33,178 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:23:34,435 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:23:35,932 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:23:35,933 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:23:35,934 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:23:37,722 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: name 'a' is not defined
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 101, in postprocess
    for b in range(a.ndim):
NameError: name 'a' is not defined
ERROR 2021-12-30 09:23:37,726 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: name 'a' is not defined
WARNING 2021-12-30 09:24:02,842 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:24:02,842 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:24:02,843 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:24:02,843 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:24:02,843 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:24:02,843 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:24:02,844 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:24:02,844 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:24:02,844 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:24:02,844 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:24:02,844 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:24:02,845 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:24:02,845 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:24:02,845 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:24:02,845 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:24:02,845 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:24:02,846 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:24:02,846 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:24:02,847 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:24:02,847 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:24:02,847 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:24:02,847 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:24:02,847 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:24:02,848 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:24:02,877 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:24:02,878 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:24:02,878 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:24:02,878 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:24:02,920 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:24:02,924 [dag.py:816] [DAG] start
INFO 2021-12-30 09:24:02,925 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:24:02,931 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:24:02,953 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:24:02,954 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:24:02,954 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:24:04,079 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:24:04,080 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:24:04,081 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 09:24:04,185 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:24:05,401 [operator.py:1178] [ppyolo_mbv3|0] Succ init
ERROR 2021-12-30 09:24:07,046 [operator.py:1000] (log_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: output of postprocess funticon must be dict type, but get <class 'list'>
ERROR 2021-12-30 09:24:07,049 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (log_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: output of postprocess funticon must be dict type, but get <class 'list'>
WARNING 2021-12-30 09:25:54,030 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:25:54,031 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:25:54,031 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:25:54,031 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:25:54,031 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:25:54,032 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:25:54,032 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:25:54,032 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:25:54,032 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:25:54,032 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:25:54,033 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:25:54,033 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:25:54,033 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:25:54,033 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:25:54,033 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:25:54,034 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:25:54,034 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:25:54,035 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:25:54,036 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:25:54,036 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:25:54,036 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:25:54,037 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:25:54,037 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:25:54,037 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:25:54,066 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:25:54,066 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:25:54,066 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:25:54,066 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:25:54,109 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:25:54,113 [dag.py:816] [DAG] start
INFO 2021-12-30 09:25:54,114 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:25:54,120 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:25:54,138 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:25:54,138 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:25:54,139 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:25:55,393 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:25:56,645 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:25:56,651 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:25:56,652 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:25:56,652 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 09:25:58,333 [dag.py:404] (data_id=0 log_id=0) Succ predict
ERROR 2021-12-30 09:25:58,334 [operator.py:1487] (logid=0) Failed to pack RPC response package: 
WARNING 2021-12-30 09:39:07,135 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:39:07,136 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:39:07,136 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:39:07,136 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:39:07,137 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:39:07,137 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:39:07,137 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:39:07,137 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:39:07,137 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:39:07,138 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:39:07,138 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:39:07,138 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:39:07,138 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:39:07,138 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:39:07,139 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:39:07,139 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:39:07,139 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:39:07,140 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:39:07,140 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:39:07,140 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:39:07,140 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:39:07,141 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:39:07,141 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:39:07,141 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:39:07,169 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:39:07,170 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:39:07,170 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:39:07,170 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:39:07,210 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:39:07,215 [dag.py:816] [DAG] start
INFO 2021-12-30 09:39:07,216 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:39:07,223 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:39:07,243 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:39:07,243 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:39:07,244 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:39:08,460 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:39:09,703 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:39:25,749 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:39:25,750 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:39:25,751 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 09:39:27,547 [dag.py:404] (data_id=0 log_id=0) Succ predict
INFO 2021-12-30 09:40:00,135 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:40:00,136 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:40:00,136 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:40:00,249 [operator.py:973] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 09:40:00,253 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
INFO 2021-12-30 09:40:48,641 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:40:48,642 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:40:48,642 [dag.py:368] (data_id=2 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:40:48,711 [operator.py:973] (data_id=2 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 09:40:48,714 [dag.py:409] (data_id=2 log_id=0) Failed to predict: (data_id=2 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
INFO 2021-12-30 09:40:53,612 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:40:53,613 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:40:53,614 [dag.py:368] (data_id=3 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:40:53,720 [operator.py:973] (data_id=3 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 09:40:53,723 [dag.py:409] (data_id=3 log_id=0) Failed to predict: (data_id=3 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
WARNING 2021-12-30 09:42:01,778 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:42:01,779 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:42:01,779 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:42:01,779 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:42:01,779 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:42:01,780 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:42:01,780 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:42:01,780 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:42:01,780 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:42:01,781 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:42:01,781 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:42:01,781 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:42:01,781 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:42:01,781 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:42:01,782 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:42:01,782 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:42:01,782 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:42:01,783 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:42:01,783 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:42:01,784 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:42:01,784 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:42:01,784 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:42:01,784 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:42:01,784 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:42:01,813 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:42:01,814 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:42:01,814 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:42:01,814 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:42:01,853 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:42:01,858 [dag.py:816] [DAG] start
INFO 2021-12-30 09:42:01,859 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:42:01,865 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:42:01,889 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:42:01,889 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:42:01,889 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:42:03,109 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:42:04,298 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:42:04,956 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:42:04,958 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:42:04,958 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:42:06,612 [operator.py:973] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: postprocess() missing 1 required positional argument: 'log_id'
ERROR 2021-12-30 09:42:06,616 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
INFO 2021-12-30 09:42:19,843 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:42:19,844 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:42:19,845 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:42:19,953 [operator.py:973] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: postprocess() missing 1 required positional argument: 'log_id'
ERROR 2021-12-30 09:42:19,957 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
WARNING 2021-12-30 09:42:23,963 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:42:23,963 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:42:23,963 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:42:23,963 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:42:23,964 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:42:23,964 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:42:23,964 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:42:23,964 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:42:23,965 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:42:23,965 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:42:23,965 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:42:23,965 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:42:23,966 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:42:23,966 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:42:23,966 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:42:23,966 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:42:23,967 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:42:23,968 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:42:23,968 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:42:23,968 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:42:23,969 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:42:23,969 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:42:23,970 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:42:23,970 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:42:24,000 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:42:24,001 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:42:24,001 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:42:24,001 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:42:24,042 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:42:24,047 [dag.py:816] [DAG] start
INFO 2021-12-30 09:42:24,048 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:42:24,054 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:42:24,072 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:42:24,073 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:42:24,073 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:42:25,280 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:42:26,470 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:42:26,701 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:42:26,702 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:42:26,702 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 09:42:28,405 [dag.py:404] (data_id=0 log_id=0) Succ predict
INFO 2021-12-30 09:43:10,878 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:43:10,879 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:43:10,879 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:43:10,985 [operator.py:973] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 09:43:10,988 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
INFO 2021-12-30 09:43:15,839 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:43:15,840 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:43:15,840 [dag.py:368] (data_id=2 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:43:15,944 [operator.py:973] (data_id=2 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 09:43:15,950 [dag.py:409] (data_id=2 log_id=0) Failed to predict: (data_id=2 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
WARNING 2021-12-30 09:44:54,821 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:44:54,822 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:44:54,822 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:44:54,822 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:44:54,822 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:44:54,823 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:44:54,823 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:44:54,823 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:44:54,823 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:44:54,823 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:44:54,824 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:44:54,824 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:44:54,824 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:44:54,824 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:44:54,825 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:44:54,825 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:44:54,825 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:44:54,826 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:44:54,826 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:44:54,826 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:44:54,826 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:44:54,827 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:44:54,827 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:44:54,827 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:44:54,856 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:44:54,856 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:44:54,857 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:44:54,857 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:44:54,898 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:44:54,901 [dag.py:816] [DAG] start
INFO 2021-12-30 09:44:54,902 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:44:54,908 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:44:54,927 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:44:54,927 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:44:54,927 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:44:56,140 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:44:57,521 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:44:59,119 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:44:59,121 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:44:59,122 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 09:45:00,979 [dag.py:404] (data_id=0 log_id=0) Succ predict
INFO 2021-12-30 09:45:05,363 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:45:05,364 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:45:05,364 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:45:05,468 [operator.py:973] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 09:45:05,472 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
WARNING 2021-12-30 09:46:17,679 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 09:46:17,680 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:46:17,680 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 09:46:17,680 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 09:46:17,680 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 09:46:17,680 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 09:46:17,681 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 09:46:17,681 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 09:46:17,681 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 09:46:17,681 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 09:46:17,682 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 09:46:17,682 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 09:46:17,682 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 09:46:17,682 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 09:46:17,682 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 09:46:17,683 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 09:46:17,683 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 09:46:17,684 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 09:46:17,684 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:46:17,684 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 09:46:17,684 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 09:46:17,685 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 09:46:17,685 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 09:46:17,685 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 09:46:17,714 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 09:46:17,715 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 09:46:17,715 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 09:46:17,715 [dag.py:655] -------------------------------------------
INFO 2021-12-30 09:46:17,756 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 09:46:17,760 [dag.py:816] [DAG] start
INFO 2021-12-30 09:46:17,761 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 09:46:17,766 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 09:46:17,795 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 09:46:17,796 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 09:46:17,796 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 09:46:19,035 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 09:46:20,237 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 09:46:21,068 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:46:21,070 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:46:21,071 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 09:46:22,764 [dag.py:404] (data_id=0 log_id=0) Succ predict
INFO 2021-12-30 09:46:25,462 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 09:46:25,463 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 09:46:25,463 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 09:46:25,584 [operator.py:973] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 09:46:25,588 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
INFO 2021-12-30 11:05:40,431 [pipeline_server.py:51] (log_id=0) inference request name:recognition self.name:ppyolo_mbv3
ERROR 2021-12-30 11:05:40,432 [pipeline_server.py:55] (log_id=0) name dismatch error. request.name:recognition,server.name=ppyolo_mbv3
INFO 2021-12-30 11:05:49,163 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:05:49,164 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:05:49,164 [dag.py:368] (data_id=2 log_id=0) Succ Generate ID 
ERROR 2021-12-30 11:05:49,271 [operator.py:973] (data_id=2 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 11:05:49,274 [dag.py:409] (data_id=2 log_id=0) Failed to predict: (data_id=2 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
WARNING 2021-12-30 11:05:54,559 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 11:05:54,560 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:05:54,560 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 11:05:54,560 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 11:05:54,560 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 11:05:54,560 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 11:05:54,561 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:05:54,561 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 11:05:54,561 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 11:05:54,561 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 11:05:54,562 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 11:05:54,562 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 11:05:54,562 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 11:05:54,562 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 11:05:54,563 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 11:05:54,563 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 11:05:54,563 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 11:05:54,564 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 11:05:54,564 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:05:54,565 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 11:05:54,565 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 11:05:54,566 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 11:05:54,566 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 11:05:54,566 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 11:05:54,596 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 11:05:54,597 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 11:05:54,597 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 11:05:54,597 [dag.py:655] -------------------------------------------
INFO 2021-12-30 11:05:54,636 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 11:05:54,641 [dag.py:816] [DAG] start
INFO 2021-12-30 11:05:54,642 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 11:05:54,648 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 11:05:54,671 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:05:54,671 [operator.py:1167] Init cuda env in process 0
INFO 2021-12-30 11:05:54,672 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 11:05:55,892 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 11:05:56,096 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:05:56,097 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:05:56,098 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 11:05:57,079 [operator.py:1178] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 11:05:58,729 [dag.py:404] (data_id=0 log_id=0) Succ predict
INFO 2021-12-30 11:15:50,113 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:15:50,115 [operator.py:1426] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:15:50,115 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 11:15:50,225 [operator.py:973] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 969, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 11:15:50,229 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
WARNING 2021-12-30 11:24:24,428 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 11:24:24,428 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:24:24,428 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 11:24:24,429 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 11:24:24,429 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 11:24:24,429 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 11:24:24,429 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:24:24,429 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 11:24:24,430 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 11:24:24,430 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 11:24:24,430 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 11:24:24,430 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 11:24:24,430 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 11:24:24,431 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 11:24:24,431 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 11:24:24,431 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 11:24:24,431 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 11:24:24,432 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 11:24:24,432 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:24:24,432 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 11:24:24,433 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 11:24:24,433 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 11:24:24,433 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 11:24:24,433 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 11:24:24,462 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 11:24:24,463 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 11:24:24,463 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 11:24:24,463 [dag.py:655] -------------------------------------------
INFO 2021-12-30 11:24:24,503 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 11:24:24,508 [dag.py:816] [DAG] start
INFO 2021-12-30 11:24:24,508 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 11:24:24,513 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 11:24:24,533 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:24:24,534 [operator.py:1170] Init cuda env in process 0
INFO 2021-12-30 11:24:24,534 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 11:24:25,753 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 11:24:26,946 [operator.py:1181] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 11:24:28,169 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:24:28,171 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:24:28,171 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 11:24:30,117 [dag.py:404] (data_id=0 log_id=0) Succ predict
INFO 2021-12-30 11:24:39,879 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:24:39,880 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:24:39,880 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 11:24:40,005 [operator.py:976] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 972, in _run_postprocess
    logid_dict.get(data_id))
TypeError: __call__() takes 3 positional arguments but 4 were given
ERROR 2021-12-30 11:24:40,009 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: __call__() takes 3 positional arguments but 4 were given
WARNING 2021-12-30 11:37:49,610 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 11:37:49,611 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:37:49,611 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 11:37:49,611 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 11:37:49,611 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 11:37:49,612 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 11:37:49,612 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:37:49,612 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 11:37:49,612 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 11:37:49,613 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 11:37:49,613 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 11:37:49,613 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 11:37:49,613 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 11:37:49,613 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 11:37:49,614 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 11:37:49,614 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 11:37:49,614 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 11:37:49,615 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 11:37:49,615 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:37:49,616 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 11:37:49,616 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 11:37:49,617 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 11:37:49,617 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 11:37:49,617 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 11:37:49,647 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 11:37:49,648 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 11:37:49,648 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 11:37:49,648 [dag.py:655] -------------------------------------------
INFO 2021-12-30 11:37:49,689 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 11:37:49,693 [dag.py:816] [DAG] start
INFO 2021-12-30 11:37:49,693 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 11:37:49,699 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 11:37:49,728 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:37:49,728 [operator.py:1170] Init cuda env in process 0
INFO 2021-12-30 11:37:49,729 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 11:37:50,942 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 11:37:52,133 [operator.py:1181] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 11:37:52,375 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:37:52,377 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:37:52,377 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
ERROR 2021-12-30 11:37:54,033 [operator.py:976] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 972, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 92, in postprocess
    np_boxes, np_boxes_num = self.postprocess(np_score_list, np_boxes_list)
TypeError: postprocess() missing 1 required positional argument: 'log_id'
ERROR 2021-12-30 11:37:54,039 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
INFO 2021-12-30 11:37:55,868 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:37:55,869 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:37:55,869 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 11:37:55,960 [operator.py:976] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 972, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 92, in postprocess
    np_boxes, np_boxes_num = self.postprocess(np_score_list, np_boxes_list)
TypeError: postprocess() missing 1 required positional argument: 'log_id'
ERROR 2021-12-30 11:37:55,963 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
WARNING 2021-12-30 11:38:09,257 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 11:38:09,258 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:38:09,258 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 11:38:09,258 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 11:38:09,258 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 11:38:09,259 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 11:38:09,259 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:38:09,259 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 11:38:09,259 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 11:38:09,260 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 11:38:09,260 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 11:38:09,260 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 11:38:09,260 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 11:38:09,260 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 11:38:09,261 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 11:38:09,261 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 11:38:09,261 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 11:38:09,262 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 11:38:09,262 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:38:09,262 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 11:38:09,262 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 11:38:09,263 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 11:38:09,263 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 11:38:09,263 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 11:38:09,291 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 11:38:09,292 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 11:38:09,292 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 11:38:09,292 [dag.py:655] -------------------------------------------
INFO 2021-12-30 11:38:09,331 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 11:38:09,335 [dag.py:816] [DAG] start
INFO 2021-12-30 11:38:09,336 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 11:38:09,342 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 11:38:09,360 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:38:09,361 [operator.py:1170] Init cuda env in process 0
INFO 2021-12-30 11:38:09,361 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 11:38:10,578 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 11:38:10,613 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:38:10,615 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:38:10,615 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 11:38:11,767 [operator.py:1181] [ppyolo_mbv3|0] Succ init
ERROR 2021-12-30 11:38:13,407 [operator.py:976] (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 972, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 92, in postprocess
    np_boxes, np_boxes_num = self.postprocess(np_score_list, np_boxes_list)
TypeError: postprocess() missing 1 required positional argument: 'log_id'
ERROR 2021-12-30 11:38:13,411 [dag.py:409] (data_id=0 log_id=0) Failed to predict: (data_id=0 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
INFO 2021-12-30 11:40:01,272 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:40:01,273 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:40:01,274 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
ERROR 2021-12-30 11:40:01,379 [operator.py:976] (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 972, in _run_postprocess
    logid_dict.get(data_id))
  File "web_service.py", line 92, in postprocess
    self.post_process = PicoDetPostProcess(
TypeError: postprocess() missing 1 required positional argument: 'log_id'
ERROR 2021-12-30 11:40:01,383 [dag.py:409] (data_id=1 log_id=0) Failed to predict: (data_id=1 log_id=0) [ppyolo_mbv3|0] Failed to postprocess: postprocess() missing 1 required positional argument: 'log_id'
WARNING 2021-12-30 11:40:05,557 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 11:40:05,557 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:40:05,558 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 11:40:05,558 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 11:40:05,558 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 11:40:05,558 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 11:40:05,558 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:40:05,559 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 11:40:05,559 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 11:40:05,559 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 11:40:05,559 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 11:40:05,559 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 11:40:05,560 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 11:40:05,560 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 11:40:05,560 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 11:40:05,560 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 11:40:05,560 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 11:40:05,561 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 11:40:05,561 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:40:05,562 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 11:40:05,562 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 11:40:05,562 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 11:40:05,562 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 11:40:05,562 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 11:40:05,592 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 11:40:05,593 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 11:40:05,593 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 11:40:05,593 [dag.py:655] -------------------------------------------
INFO 2021-12-30 11:40:05,633 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 11:40:05,638 [dag.py:816] [DAG] start
INFO 2021-12-30 11:40:05,639 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 11:40:05,646 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 11:40:05,665 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:40:05,665 [operator.py:1170] Init cuda env in process 0
INFO 2021-12-30 11:40:05,665 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 11:40:06,892 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 11:40:08,120 [operator.py:1181] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 11:40:08,937 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:40:08,939 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:40:08,939 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 11:40:10,596 [dag.py:404] (data_id=0 log_id=0) Succ predict
INFO 2021-12-30 11:40:13,169 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:40:13,169 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:40:13,170 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
INFO 2021-12-30 11:40:13,272 [dag.py:404] (data_id=1 log_id=0) Succ predict
INFO 2021-12-30 11:40:59,103 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:40:59,104 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:40:59,105 [dag.py:368] (data_id=2 log_id=0) Succ Generate ID 
INFO 2021-12-30 11:40:59,221 [dag.py:404] (data_id=2 log_id=0) Succ predict
WARNING 2021-12-30 11:41:26,917 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2021-12-30 11:41:26,918 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:41:26,918 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2021-12-30 11:41:26,918 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2021-12-30 11:41:26,918 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2021-12-30 11:41:26,918 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2021-12-30 11:41:26,919 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2021-12-30 11:41:26,919 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2021-12-30 11:41:26,919 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2021-12-30 11:41:26,919 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2021-12-30 11:41:26,919 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2021-12-30 11:41:26,920 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2021-12-30 11:41:26,920 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2021-12-30 11:41:26,920 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2021-12-30 11:41:26,920 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2021-12-30 11:41:26,920 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2021-12-30 11:41:26,921 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2021-12-30 11:41:26,922 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2021-12-30 11:41:26,922 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:41:26,922 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2021-12-30 11:41:26,923 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2021-12-30 11:41:26,923 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2021-12-30 11:41:26,924 [pipeline_server.py:212] -------------------------------------------
INFO 2021-12-30 11:41:26,924 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2021-12-30 11:41:26,953 [dag.py:493] [DAG] Succ init
INFO 2021-12-30 11:41:26,954 [dag.py:651] ================= USED OP =================
INFO 2021-12-30 11:41:26,954 [dag.py:654] ppyolo_mbv3
INFO 2021-12-30 11:41:26,954 [dag.py:655] -------------------------------------------
INFO 2021-12-30 11:41:26,993 [dag.py:784] [DAG] Succ build DAG
INFO 2021-12-30 11:41:26,997 [dag.py:816] [DAG] start
INFO 2021-12-30 11:41:26,997 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2021-12-30 11:41:27,003 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2021-12-30 11:41:27,026 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2021-12-30 11:41:27,027 [operator.py:1170] Init cuda env in process 0
INFO 2021-12-30 11:41:27,027 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2021-12-30 11:41:28,253 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2021-12-30 11:41:28,845 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:41:28,846 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:41:28,847 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2021-12-30 11:41:29,451 [operator.py:1181] [ppyolo_mbv3|0] Succ init
INFO 2021-12-30 11:41:31,104 [dag.py:404] (data_id=0 log_id=0) Succ predict
INFO 2021-12-30 11:41:33,109 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2021-12-30 11:41:33,110 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2021-12-30 11:41:33,110 [dag.py:368] (data_id=1 log_id=0) Succ Generate ID 
INFO 2021-12-30 11:41:33,209 [dag.py:404] (data_id=1 log_id=0) Succ predict
WARNING 2022-02-14 09:24:33,065 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2022-02-14 09:24:33,072 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2022-02-14 09:24:33,072 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2022-02-14 09:24:33,072 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2022-02-14 09:24:33,072 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2022-02-14 09:24:33,072 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2022-02-14 09:24:33,073 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2022-02-14 09:24:33,073 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2022-02-14 09:24:33,073 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2022-02-14 09:24:33,073 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2022-02-14 09:24:33,073 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2022-02-14 09:24:33,073 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2022-02-14 09:24:33,073 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2022-02-14 09:24:33,073 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2022-02-14 09:24:33,074 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2022-02-14 09:24:33,074 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2022-02-14 09:24:33,074 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2022-02-14 09:24:33,074 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2022-02-14 09:24:33,074 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-14 09:24:33,075 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2022-02-14 09:24:33,075 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2022-02-14 09:24:33,075 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2022-02-14 09:24:33,075 [pipeline_server.py:212] -------------------------------------------
INFO 2022-02-14 09:24:33,075 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2022-02-14 09:24:33,096 [dag.py:493] [DAG] Succ init
INFO 2022-02-14 09:24:33,096 [dag.py:651] ================= USED OP =================
INFO 2022-02-14 09:24:33,097 [dag.py:654] ppyolo_mbv3
INFO 2022-02-14 09:24:33,097 [dag.py:655] -------------------------------------------
INFO 2022-02-14 09:24:33,137 [dag.py:784] [DAG] Succ build DAG
INFO 2022-02-14 09:24:33,141 [dag.py:816] [DAG] start
INFO 2022-02-14 09:24:33,142 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2022-02-14 09:24:33,147 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2022-02-14 09:24:33,174 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-14 09:24:33,175 [operator.py:1170] Init cuda env in process 0
INFO 2022-02-14 09:24:33,175 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2022-02-14 09:24:34,409 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2022-02-14 09:24:35,602 [operator.py:1179] [ppyolo_mbv3|0] failed to init op: [Errno 2] No such file or directory: 'label_list.txt'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1174, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1363, in _initialize
    self.init_op()
  File "web_service.py", line 30, in init_op
    self.img_postprocess = RCNNPostprocess("label_list.txt", "output")
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 288, in __init__
    with open(label_file) as fin:
FileNotFoundError: [Errno 2] No such file or directory: 'label_list.txt'
WARNING 2022-02-14 09:24:42,704 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2022-02-14 09:24:42,705 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2022-02-14 09:24:42,705 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2022-02-14 09:24:42,705 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2022-02-14 09:24:42,705 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2022-02-14 09:24:42,706 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2022-02-14 09:24:42,706 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2022-02-14 09:24:42,706 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2022-02-14 09:24:42,706 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2022-02-14 09:24:42,707 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2022-02-14 09:24:42,707 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2022-02-14 09:24:42,707 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2022-02-14 09:24:42,707 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2022-02-14 09:24:42,708 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2022-02-14 09:24:42,708 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2022-02-14 09:24:42,708 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2022-02-14 09:24:42,708 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2022-02-14 09:24:42,709 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2022-02-14 09:24:42,709 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-14 09:24:42,710 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2022-02-14 09:24:42,710 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2022-02-14 09:24:42,710 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2022-02-14 09:24:42,710 [pipeline_server.py:212] -------------------------------------------
INFO 2022-02-14 09:24:42,710 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2022-02-14 09:24:42,741 [dag.py:493] [DAG] Succ init
INFO 2022-02-14 09:24:42,741 [dag.py:651] ================= USED OP =================
INFO 2022-02-14 09:24:42,741 [dag.py:654] ppyolo_mbv3
INFO 2022-02-14 09:24:42,742 [dag.py:655] -------------------------------------------
INFO 2022-02-14 09:24:42,783 [dag.py:784] [DAG] Succ build DAG
INFO 2022-02-14 09:24:42,789 [dag.py:816] [DAG] start
INFO 2022-02-14 09:24:42,790 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2022-02-14 09:24:42,796 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2022-02-14 09:24:42,815 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-14 09:24:42,815 [operator.py:1170] Init cuda env in process 0
INFO 2022-02-14 09:24:42,815 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2022-02-14 09:24:44,053 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
CRITICAL 2022-02-14 09:24:45,275 [operator.py:1179] [ppyolo_mbv3|0] failed to init op: [Errno 2] No such file or directory: 'label_list.txt'
Traceback (most recent call last):
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1174, in _run
    profiler = self._initialize(is_thread_op, concurrency_idx)
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_server/pipeline/operator.py", line 1363, in _initialize
    self.init_op()
  File "web_service.py", line 30, in init_op
    self.img_postprocess = RCNNPostprocess("label_list.txt", "output")
  File "/usr/local/python3.7.0/lib/python3.7/site-packages/paddle_serving_app/reader/image_reader.py", line 288, in __init__
    with open(label_file) as fin:
FileNotFoundError: [Errno 2] No such file or directory: 'label_list.txt'
INFO 2022-02-14 09:24:57,166 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2022-02-14 09:24:57,168 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2022-02-14 09:24:57,169 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
WARNING 2022-02-14 09:26:03,671 [pipeline_server.py:496] [CONF] build_dag_each_worker not set, use default: False
WARNING 2022-02-14 09:26:03,671 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2022-02-14 09:26:03,671 [pipeline_server.py:496] [CONF] client_type not set, use default: brpc
WARNING 2022-02-14 09:26:03,672 [pipeline_server.py:496] [CONF] use_profile not set, use default: False
WARNING 2022-02-14 09:26:03,672 [pipeline_server.py:496] [CONF] channel_size not set, use default: 0
WARNING 2022-02-14 09:26:03,672 [pipeline_server.py:496] [CONF] timeout not set, use default: -1
WARNING 2022-02-14 09:26:03,672 [pipeline_server.py:496] [CONF] retry not set, use default: 1
WARNING 2022-02-14 09:26:03,673 [pipeline_server.py:496] [CONF] batch_size not set, use default: 1
WARNING 2022-02-14 09:26:03,673 [pipeline_server.py:496] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2022-02-14 09:26:03,673 [pipeline_server.py:496] [CONF] workdir not set, use default: 
WARNING 2022-02-14 09:26:03,673 [pipeline_server.py:496] [CONF] thread_num not set, use default: 2
WARNING 2022-02-14 09:26:03,674 [pipeline_server.py:496] [CONF] mem_optim not set, use default: True
WARNING 2022-02-14 09:26:03,674 [pipeline_server.py:496] [CONF] ir_optim not set, use default: False
WARNING 2022-02-14 09:26:03,674 [pipeline_server.py:496] [CONF] precision not set, use default: fp32
WARNING 2022-02-14 09:26:03,674 [pipeline_server.py:496] [CONF] use_calib not set, use default: False
WARNING 2022-02-14 09:26:03,674 [pipeline_server.py:496] [CONF] use_mkldnn not set, use default: False
WARNING 2022-02-14 09:26:03,675 [pipeline_server.py:496] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2022-02-14 09:26:03,676 [operator.py:163] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2022-02-14 09:26:03,676 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-14 09:26:03,676 [operator.py:267] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2022-02-14 09:26:03,676 [pipeline_server.py:204] ============= PIPELINE SERVER =============
INFO 2022-02-14 09:26:03,677 [pipeline_server.py:207] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2022-02-14 09:26:03,677 [pipeline_server.py:212] -------------------------------------------
INFO 2022-02-14 09:26:03,677 [operator.py:290] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2022-02-14 09:26:03,706 [dag.py:493] [DAG] Succ init
INFO 2022-02-14 09:26:03,707 [dag.py:651] ================= USED OP =================
INFO 2022-02-14 09:26:03,707 [dag.py:654] ppyolo_mbv3
INFO 2022-02-14 09:26:03,707 [dag.py:655] -------------------------------------------
INFO 2022-02-14 09:26:03,747 [dag.py:784] [DAG] Succ build DAG
INFO 2022-02-14 09:26:03,752 [dag.py:816] [DAG] start
INFO 2022-02-14 09:26:03,753 [dag.py:181] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2022-02-14 09:26:03,761 [pipeline_server.py:47] [PipelineServicer] succ init
INFO 2022-02-14 09:26:03,776 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-14 09:26:03,777 [operator.py:1170] Init cuda env in process 0
INFO 2022-02-14 09:26:03,777 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2022-02-14 09:26:04,993 [local_predict.py:115] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2022-02-14 09:26:05,574 [pipeline_server.py:51] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3
INFO 2022-02-14 09:26:05,576 [operator.py:1429] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction
INFO 2022-02-14 09:26:05,577 [dag.py:368] (data_id=0 log_id=0) Succ Generate ID 
INFO 2022-02-14 09:26:06,239 [operator.py:1181] [ppyolo_mbv3|0] Succ init
INFO 2022-02-14 09:26:07,900 [dag.py:404] (data_id=0 log_id=0) Succ predict
WARNING 2022-02-16 16:56:51,836 [pipeline_server.py:509] [CONF] build_dag_each_worker not set, use default: False
WARNING 2022-02-16 16:56:51,836 [pipeline_server.py:509] [CONF] retry not set, use default: 1
WARNING 2022-02-16 16:56:51,836 [pipeline_server.py:509] [CONF] client_type not set, use default: brpc
WARNING 2022-02-16 16:56:51,836 [pipeline_server.py:509] [CONF] use_profile not set, use default: False
WARNING 2022-02-16 16:56:51,836 [pipeline_server.py:509] [CONF] channel_size not set, use default: 0
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] channel_recv_frist_arrive not set, use default: False
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] timeout not set, use default: -1
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] retry not set, use default: 1
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] batch_size not set, use default: 1
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] workdir not set, use default: 
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] thread_num not set, use default: 2
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] mem_optim not set, use default: True
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] ir_optim not set, use default: False
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] precision not set, use default: fp32
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] use_calib not set, use default: False
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] use_mkldnn not set, use default: False
WARNING 2022-02-16 16:56:51,837 [pipeline_server.py:509] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2022-02-16 16:56:51,846 [operator.py:181] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2022-02-16 16:56:51,847 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-16 16:56:51,847 [operator.py:285] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2022-02-16 16:56:51,847 [pipeline_server.py:215] ============= PIPELINE SERVER =============
INFO 2022-02-16 16:56:51,847 [pipeline_server.py:218] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0,
        "channel_recv_frist_arrive":false
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2022-02-16 16:56:51,847 [pipeline_server.py:223] -------------------------------------------
INFO 2022-02-16 16:56:51,847 [operator.py:308] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2022-02-16 16:56:51,869 [dag.py:496] [DAG] Succ init
INFO 2022-02-16 16:56:51,869 [dag.py:659] ================= USED OP =================
INFO 2022-02-16 16:56:51,869 [dag.py:662] ppyolo_mbv3
INFO 2022-02-16 16:56:51,870 [dag.py:663] -------------------------------------------
INFO 2022-02-16 16:56:51,870 [dag.py:680] ================== DAG ====================
INFO 2022-02-16 16:56:51,870 [dag.py:682] (VIEW 0)
INFO 2022-02-16 16:56:51,870 [dag.py:684]   [@DAGExecutor]
INFO 2022-02-16 16:56:51,870 [dag.py:686]     - ppyolo_mbv3
INFO 2022-02-16 16:56:51,870 [dag.py:682] (VIEW 1)
INFO 2022-02-16 16:56:51,870 [dag.py:684]   [ppyolo_mbv3]
INFO 2022-02-16 16:56:51,870 [dag.py:687] -------------------------------------------
INFO 2022-02-16 16:56:51,885 [dag.py:730] op:ppyolo_mbv3 add input channel.
INFO 2022-02-16 16:56:51,895 [dag.py:759] last op:ppyolo_mbv3 add output channel
INFO 2022-02-16 16:56:51,895 [dag.py:800] [DAG] Succ build DAG
INFO 2022-02-16 16:56:51,899 [dag.py:832] [DAG] start
INFO 2022-02-16 16:56:51,899 [dag.py:182] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2022-02-16 16:56:51,905 [pipeline_server.py:51] [PipelineServicer] succ init
INFO 2022-02-16 16:56:51,911 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-16 16:56:51,912 [operator.py:1306] Init cuda env in process 0
INFO 2022-02-16 16:56:51,912 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2022-02-16 16:56:52,885 [local_predict.py:153] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2022-02-16 16:56:55,000 [operator.py:1317] [ppyolo_mbv3|0] Succ init
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] build_dag_each_worker not set, use default: False
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] retry not set, use default: 1
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] client_type not set, use default: brpc
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] use_profile not set, use default: False
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] channel_size not set, use default: 0
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] channel_recv_frist_arrive not set, use default: False
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] timeout not set, use default: -1
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] retry not set, use default: 1
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] batch_size not set, use default: 1
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] workdir not set, use default: 
WARNING 2022-02-16 17:05:23,144 [pipeline_server.py:509] [CONF] thread_num not set, use default: 2
WARNING 2022-02-16 17:05:23,145 [pipeline_server.py:509] [CONF] mem_optim not set, use default: True
WARNING 2022-02-16 17:05:23,145 [pipeline_server.py:509] [CONF] ir_optim not set, use default: False
WARNING 2022-02-16 17:05:23,145 [pipeline_server.py:509] [CONF] precision not set, use default: fp32
WARNING 2022-02-16 17:05:23,145 [pipeline_server.py:509] [CONF] use_calib not set, use default: False
WARNING 2022-02-16 17:05:23,145 [pipeline_server.py:509] [CONF] use_mkldnn not set, use default: False
WARNING 2022-02-16 17:05:23,145 [pipeline_server.py:509] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2022-02-16 17:05:23,154 [operator.py:181] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2022-02-16 17:05:23,154 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-16 17:05:23,154 [operator.py:285] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2022-02-16 17:05:23,154 [pipeline_server.py:215] ============= PIPELINE SERVER =============
INFO 2022-02-16 17:05:23,155 [pipeline_server.py:218] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0,
        "channel_recv_frist_arrive":false
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2022-02-16 17:05:23,155 [pipeline_server.py:223] -------------------------------------------
INFO 2022-02-16 17:05:23,155 [operator.py:308] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2022-02-16 17:05:23,176 [dag.py:496] [DAG] Succ init
INFO 2022-02-16 17:05:23,177 [dag.py:659] ================= USED OP =================
INFO 2022-02-16 17:05:23,177 [dag.py:662] ppyolo_mbv3
INFO 2022-02-16 17:05:23,177 [dag.py:663] -------------------------------------------
INFO 2022-02-16 17:05:23,177 [dag.py:680] ================== DAG ====================
INFO 2022-02-16 17:05:23,177 [dag.py:682] (VIEW 0)
INFO 2022-02-16 17:05:23,177 [dag.py:684]   [@DAGExecutor]
INFO 2022-02-16 17:05:23,177 [dag.py:686]     - ppyolo_mbv3
INFO 2022-02-16 17:05:23,177 [dag.py:682] (VIEW 1)
INFO 2022-02-16 17:05:23,177 [dag.py:684]   [ppyolo_mbv3]
INFO 2022-02-16 17:05:23,177 [dag.py:687] -------------------------------------------
INFO 2022-02-16 17:05:23,192 [dag.py:730] op:ppyolo_mbv3 add input channel.
INFO 2022-02-16 17:05:23,202 [dag.py:759] last op:ppyolo_mbv3 add output channel
INFO 2022-02-16 17:05:23,202 [dag.py:800] [DAG] Succ build DAG
INFO 2022-02-16 17:05:23,205 [dag.py:832] [DAG] start
INFO 2022-02-16 17:05:23,206 [dag.py:182] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2022-02-16 17:05:23,211 [pipeline_server.py:51] [PipelineServicer] succ init
INFO 2022-02-16 17:05:23,229 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-16 17:05:23,229 [operator.py:1306] Init cuda env in process 0
INFO 2022-02-16 17:05:23,229 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2022-02-16 17:05:24,167 [local_predict.py:153] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2022-02-16 17:05:26,236 [operator.py:1317] [ppyolo_mbv3|0] Succ init
INFO 2022-02-16 17:05:47,771 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645002347.7711458
INFO 2022-02-16 17:05:47,772 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645002347.7724555
INFO 2022-02-16 17:05:47,772 [dag.py:369] (data_id=0 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:05:50,421 [dag.py:405] (data_id=0 log_id=0) Succ predict
INFO 2022-02-16 17:05:50,447 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645002350.4476814
INFO 2022-02-16 17:05:50,448 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645002350.448209
INFO 2022-02-16 17:05:50,448 [dag.py:369] (data_id=1 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:05:50,527 [dag.py:405] (data_id=1 log_id=0) Succ predict
INFO 2022-02-16 17:07:00,293 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645002420.2930179
INFO 2022-02-16 17:07:00,293 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645002420.2936485
INFO 2022-02-16 17:07:00,293 [dag.py:369] (data_id=2 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:07:00,362 [dag.py:405] (data_id=2 log_id=0) Succ predict
WARNING 2022-02-16 17:09:22,047 [pipeline_server.py:509] [CONF] build_dag_each_worker not set, use default: False
WARNING 2022-02-16 17:09:22,047 [pipeline_server.py:509] [CONF] retry not set, use default: 1
WARNING 2022-02-16 17:09:22,047 [pipeline_server.py:509] [CONF] client_type not set, use default: brpc
WARNING 2022-02-16 17:09:22,047 [pipeline_server.py:509] [CONF] use_profile not set, use default: False
WARNING 2022-02-16 17:09:22,047 [pipeline_server.py:509] [CONF] channel_size not set, use default: 0
WARNING 2022-02-16 17:09:22,047 [pipeline_server.py:509] [CONF] channel_recv_frist_arrive not set, use default: False
WARNING 2022-02-16 17:09:22,047 [pipeline_server.py:509] [CONF] timeout not set, use default: -1
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] retry not set, use default: 1
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] batch_size not set, use default: 1
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] auto_batching_timeout not set, use default: -1
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] workdir not set, use default: 
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] thread_num not set, use default: 2
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] mem_optim not set, use default: True
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] ir_optim not set, use default: False
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] precision not set, use default: fp32
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] use_calib not set, use default: False
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] use_mkldnn not set, use default: False
WARNING 2022-02-16 17:09:22,048 [pipeline_server.py:509] [CONF] mkldnn_cache_capacity not set, use default: 0
INFO 2022-02-16 17:09:22,057 [operator.py:181] local_service_conf: {'client_type': 'local_predictor', 'device_type': 2, 'devices': '0', 'fetch_list': ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], 'model_config': 'serving_server/', 'workdir': '', 'thread_num': 2, 'mem_optim': True, 'ir_optim': False, 'precision': 'fp32', 'use_calib': False, 'use_mkldnn': False, 'mkldnn_cache_capacity': 0}
INFO 2022-02-16 17:09:22,058 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1'], precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-16 17:09:22,058 [operator.py:285] ppyolo_mbv3 
	input_ops: @DAGExecutor,
	server_endpoints: None
	fetch_list: ['save_infer_model/scale_0.tmp_1', 'save_infer_model/scale_1.tmp_1', 'save_infer_model/scale_2.tmp_1', 'save_infer_model/scale_3.tmp_1', 'save_infer_model/scale_4.tmp_1', 'save_infer_model/scale_5.tmp_1', 'save_infer_model/scale_6.tmp_1', 'save_infer_model/scale_7.tmp_1']
	client_config: serving_server/serving_server_conf.prototxt
	concurrency: 1,
	timeout(s): -1,
	retry: 1,
	batch_size: 1,
	auto_batching_timeout(s): None
INFO 2022-02-16 17:09:22,058 [pipeline_server.py:215] ============= PIPELINE SERVER =============
INFO 2022-02-16 17:09:22,058 [pipeline_server.py:218] 
{
    "dag":{
        "is_thread_op":false,
        "tracer":{
            "interval_s":30
        },
        "retry":1,
        "client_type":"brpc",
        "use_profile":false,
        "channel_size":0,
        "channel_recv_frist_arrive":false
    },
    "http_port":2009,
    "op":{
        "ppyolo_mbv3":{
            "concurrency":1,
            "local_service_conf":{
                "client_type":"local_predictor",
                "device_type":2,
                "devices":"0",
                "fetch_list":[
                    "save_infer_model/scale_0.tmp_1",
                    "save_infer_model/scale_1.tmp_1",
                    "save_infer_model/scale_2.tmp_1",
                    "save_infer_model/scale_3.tmp_1",
                    "save_infer_model/scale_4.tmp_1",
                    "save_infer_model/scale_5.tmp_1",
                    "save_infer_model/scale_6.tmp_1",
                    "save_infer_model/scale_7.tmp_1"
                ],
                "model_config":"serving_server/",
                "workdir":"",
                "thread_num":2,
                "mem_optim":true,
                "ir_optim":false,
                "precision":"fp32",
                "use_calib":false,
                "use_mkldnn":false,
                "mkldnn_cache_capacity":0
            },
            "timeout":-1,
            "retry":1,
            "batch_size":1,
            "auto_batching_timeout":-1
        }
    },
    "rpc_port":9999,
    "worker_num":20,
    "build_dag_each_worker":false
}
INFO 2022-02-16 17:09:22,058 [pipeline_server.py:223] -------------------------------------------
INFO 2022-02-16 17:09:22,058 [operator.py:308] Op(ppyolo_mbv3) use local rpc service at port: []
INFO 2022-02-16 17:09:22,079 [dag.py:496] [DAG] Succ init
INFO 2022-02-16 17:09:22,080 [dag.py:659] ================= USED OP =================
INFO 2022-02-16 17:09:22,080 [dag.py:662] ppyolo_mbv3
INFO 2022-02-16 17:09:22,080 [dag.py:663] -------------------------------------------
INFO 2022-02-16 17:09:22,080 [dag.py:680] ================== DAG ====================
INFO 2022-02-16 17:09:22,080 [dag.py:682] (VIEW 0)
INFO 2022-02-16 17:09:22,080 [dag.py:684]   [@DAGExecutor]
INFO 2022-02-16 17:09:22,080 [dag.py:686]     - ppyolo_mbv3
INFO 2022-02-16 17:09:22,081 [dag.py:682] (VIEW 1)
INFO 2022-02-16 17:09:22,081 [dag.py:684]   [ppyolo_mbv3]
INFO 2022-02-16 17:09:22,081 [dag.py:687] -------------------------------------------
INFO 2022-02-16 17:09:22,095 [dag.py:730] op:ppyolo_mbv3 add input channel.
INFO 2022-02-16 17:09:22,105 [dag.py:759] last op:ppyolo_mbv3 add output channel
INFO 2022-02-16 17:09:22,105 [dag.py:800] [DAG] Succ build DAG
INFO 2022-02-16 17:09:22,108 [dag.py:832] [DAG] start
INFO 2022-02-16 17:09:22,109 [dag.py:182] [DAG] set in channel succ, name [@DAGExecutor]
INFO 2022-02-16 17:09:22,114 [pipeline_server.py:51] [PipelineServicer] succ init
INFO 2022-02-16 17:09:22,119 [local_service_handler.py:172] Models(serving_server/) will be launched by device gpu. use_gpu:True, use_trt:True, use_lite:False, use_xpu:False, device_type:2, devices:[0], mem_optim:True, ir_optim:False, use_profile:False, thread_num:2, client_type:local_predictor, fetch_names:None, precision:fp32, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None
INFO 2022-02-16 17:09:22,120 [operator.py:1306] Init cuda env in process 0
INFO 2022-02-16 17:09:22,120 [local_service_handler.py:208] GET_CLIENT : concurrency_idx=0, device_num=1
INFO 2022-02-16 17:09:23,058 [local_predict.py:153] LocalPredictor load_model_config params: model_path:serving_server/, use_gpu:True, gpu_id:0, use_profile:False, thread_num:2, mem_optim:True, ir_optim:False, use_trt:True, use_lite:False, use_xpu:False, precision:fp32, use_calib:False, use_mkldnn:False, mkldnn_cache_capacity:0, mkldnn_op_list:None, mkldnn_bf16_op_list:None, use_feed_fetch_ops:False, 
INFO 2022-02-16 17:09:24,980 [operator.py:1317] [ppyolo_mbv3|0] Succ init
INFO 2022-02-16 17:10:00,414 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645002600.4143305
INFO 2022-02-16 17:10:00,415 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645002600.4155881
INFO 2022-02-16 17:10:00,416 [dag.py:369] (data_id=0 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:10:02,981 [dag.py:405] (data_id=0 log_id=0) Succ predict
INFO 2022-02-16 17:14:52,096 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645002892.0961268
INFO 2022-02-16 17:14:52,096 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645002892.096749
INFO 2022-02-16 17:14:52,097 [dag.py:369] (data_id=1 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:14:52,172 [dag.py:405] (data_id=1 log_id=0) Succ predict
INFO 2022-02-16 17:15:06,391 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645002906.390965
INFO 2022-02-16 17:15:06,391 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645002906.3916032
INFO 2022-02-16 17:15:06,391 [dag.py:369] (data_id=2 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:15:06,459 [dag.py:405] (data_id=2 log_id=0) Succ predict
INFO 2022-02-16 17:21:25,074 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003285.0745604
INFO 2022-02-16 17:21:25,075 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003285.075034
INFO 2022-02-16 17:21:25,075 [dag.py:369] (data_id=3 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:21:25,141 [dag.py:405] (data_id=3 log_id=0) Succ predict
INFO 2022-02-16 17:21:53,963 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003313.9639173
INFO 2022-02-16 17:21:53,964 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003313.9646337
INFO 2022-02-16 17:21:53,964 [dag.py:369] (data_id=4 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:21:54,033 [dag.py:405] (data_id=4 log_id=0) Succ predict
INFO 2022-02-16 17:22:47,816 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003367.8165774
INFO 2022-02-16 17:22:47,817 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003367.8172152
INFO 2022-02-16 17:22:47,817 [dag.py:369] (data_id=5 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:22:47,886 [dag.py:405] (data_id=5 log_id=0) Succ predict
INFO 2022-02-16 17:23:03,882 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003383.882905
INFO 2022-02-16 17:23:03,883 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003383.8835778
INFO 2022-02-16 17:23:03,883 [dag.py:369] (data_id=6 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:23:03,951 [dag.py:405] (data_id=6 log_id=0) Succ predict
INFO 2022-02-16 17:23:30,593 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003410.5935636
INFO 2022-02-16 17:23:30,594 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003410.5942206
INFO 2022-02-16 17:23:30,594 [dag.py:369] (data_id=7 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:23:30,662 [dag.py:405] (data_id=7 log_id=0) Succ predict
INFO 2022-02-16 17:24:12,780 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003452.7805502
INFO 2022-02-16 17:24:12,781 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003452.7814457
INFO 2022-02-16 17:24:12,781 [dag.py:369] (data_id=8 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:24:12,853 [dag.py:405] (data_id=8 log_id=0) Succ predict
INFO 2022-02-16 17:24:23,797 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003463.7971623
INFO 2022-02-16 17:24:23,797 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003463.7978337
INFO 2022-02-16 17:24:23,798 [dag.py:369] (data_id=9 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:24:23,867 [dag.py:405] (data_id=9 log_id=0) Succ predict
INFO 2022-02-16 17:24:43,980 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003483.9801416
INFO 2022-02-16 17:24:43,980 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003483.9806335
INFO 2022-02-16 17:24:43,980 [dag.py:369] (data_id=10 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:24:44,049 [dag.py:405] (data_id=10 log_id=0) Succ predict
INFO 2022-02-16 17:24:54,159 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003494.15903
INFO 2022-02-16 17:24:54,159 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003494.1595104
INFO 2022-02-16 17:24:54,159 [dag.py:369] (data_id=11 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:24:54,226 [dag.py:405] (data_id=11 log_id=0) Succ predict
INFO 2022-02-16 17:25:12,386 [pipeline_server.py:56] (log_id=0) inference request name:ppyolo_mbv3 self.name:ppyolo_mbv3 time:1645003512.3861694
INFO 2022-02-16 17:25:12,386 [operator.py:1723] RequestOp unpack one request. log_id:0, clientip:             name:ppyolo_mbv3, method:prediction, time:1645003512.3868122
INFO 2022-02-16 17:25:12,387 [dag.py:369] (data_id=12 log_id=0) Succ Generate ID 
INFO 2022-02-16 17:25:12,455 [dag.py:405] (data_id=12 log_id=0) Succ predict
