可变形卷积v1

可变形卷积顾名思义就是卷积的位置是可变形的，并非在传统的N×N的网格上做卷积，这样的好处就是更准确地提取到我们想要的特征（传统的卷积仅仅只能提取到矩形框的特征）。可变卷积的实质就是在每一个卷积采样点加上了一个偏移量，增加了调整卷积核的方向向量，使的卷积核的形态更贴近特征物。

具体步骤如下： 1.同正常的卷积神经网络一样，根据输入的图像，利用传统的卷积核提取特征图。 2.将得到的特征图作为输入，对特征图再施加一个卷积层，这么做的目的是为了得到可变形卷积的变形的偏移量。 3.偏移层有2N个偏移量，N是卷积核的大小（如3x3的卷积核，N=9），因为我们在平面上做平移，需要改变x值和y值两个方向，且对于卷积核的每一个采样位置都要进行偏移。 4.在训练的时候，用于生成输出特征的卷积核和用于生成偏移量的卷积核是同步学习的。其中偏移量的学习是利用双线性插值算法，通过反向传播进行学习。

可变形卷积v2

可变形卷积v1能覆盖整个物体，但是同时也会引入一些无关的背景，这会干扰特征提取，降低算法的表现。于是提出了提出了三个解决方法：

1.使用更多的可变形卷积： 在可变形卷积v1中只在conv5中使用了三个可变形卷积，在可变形卷积v2中把conv3到conv5都换成了可变形卷积，提高算法对几何形变的建模能力。

2.在可变形卷积v1基础（添加offset）上添加每个采样点的权重： 在可变形卷积v1中的卷积是添加了一个offsetㅿpn: y(p0)=Σw(pn) * x(p0+pn+ㅿpn) 为了解决引入了一些无关区域的问题，在可变形卷积v2中我们不只添加每一个采样点的偏移，还添加了一个权重系数，来区分我们引入的区域是否为我们感兴趣的区域，假如这个采样点的区域我们不感兴趣，则把权重学习为0即可： y(p)=Σwk * x(p+pk+ㅿpk) * ㅿmk 总的来说，可变形卷积v1中引入的offset是要寻找有效信息的区域位置，可变形卷积v2中引入权重系数是要给找到的这个位置赋予权重，这两方面保证了有效信息的准确提取。

3.模拟R-CNN的feature: 把R-CNN和Faster RCNN的classification score结合起来可以提升performance，说明R-CNN学到的focus在物体上的feature可以解决无关上下文的问题。但是增加额外的R-CNN会使inference速度变慢很多。可变形卷积v2里的解决方法是把R-CNN当做teacher network，让可变形卷积v2的ROIPooling之后的feature去模拟R-CNN的feature。
