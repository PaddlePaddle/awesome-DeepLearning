{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data65\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 12.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加载飞桨和相关类库\r\n",
    "\r\n",
    "import paddle\r\n",
    "from paddle.vision.transforms import Compose, Normalize\r\n",
    "import paddle.nn.functional as F\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InceptionA(paddle.nn.Layer):\r\n",
    "    def __init__(self,in_channels):\r\n",
    "        super(InceptionA,self).__init__()\r\n",
    "        self.branch1x1=Conv2D(in_channels,16,kernel_size=1)\r\n",
    "\r\n",
    "        self.branch5x5_1=Conv2D(in_channels,16,kernel_size=1)\r\n",
    "        self.branch5x5_2=Conv2D(16,24,kernel_size=5,padding=2)\r\n",
    "\r\n",
    "        self.branch3x3_1=Conv2D(in_channels,16,kernel_size=1)\r\n",
    "        self.branch3x3_2=Conv2D(16,24,kernel_size=3,padding=1)\r\n",
    "        self.branch3x3_3=Conv2D(24,24,kernel_size=3,padding=1)\r\n",
    "\r\n",
    "        self.branch_pool=Conv2D(in_channels,24,kernel_size=1)\r\n",
    "\r\n",
    "    def forward(self,x):\r\n",
    "        branch1x1=self.branch1x1(x)\r\n",
    "\r\n",
    "        branch5x5=self.branch5x5_1(x)\r\n",
    "        branch5x5=self.branch5x5_2(branch5x5)\r\n",
    "\r\n",
    "        branch3x3=self.branch3x3_1(x)\r\n",
    "        branch3x3=self.branch3x3_2(branch3x3)\r\n",
    "        branch3x3=self.branch3x3_3(branch3x3)\r\n",
    "\r\n",
    "        branch_pool=F.avg_pool2d(x,kernel_size=3,stride=1,padding=1)\r\n",
    "        branch_pool=self.branch_pool(branch_pool)\r\n",
    "\r\n",
    "        outputs=[branch1x1,branch5x5,branch3x3,branch_pool]\r\n",
    "        return paddle.concat(outputs,1)   #横着拼接\r\n",
    "\r\n",
    "class MNIST(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(MNIST,self).__init__()\r\n",
    "        self.conv1=Conv2D(1,10,kernel_size=1)\r\n",
    "        self.conv2=Conv2D(88,20,kernel_size=5)\r\n",
    "\r\n",
    "        self.inception1=InceptionA(in_channels=10)\r\n",
    "        self.inception2=InceptionA(in_channels=20)\r\n",
    "\r\n",
    "        self.maxpool=MaxPool2D(2)\r\n",
    "        self.fc=Linear(2200,10)      #5*5*88=2200\r\n",
    "\r\n",
    "    def forward(self,x,label):\r\n",
    "        x=F.relu(self.maxpool(self.conv1(x)))    #图像尺寸14*14\r\n",
    "        x=self.inception1(x)                    #图像尺寸14*14\r\n",
    "        x=F.relu(self.maxpool(self.conv2(x)))    #图像尺寸5*5\r\n",
    "        x=self.inception2(x)                    #图像尺寸5*5\r\n",
    "        x = paddle.reshape(x, [x.shape[0], 88*5*5])           #88*5*5  展平成一维\r\n",
    "        x=self.fc(x)\r\n",
    "        if label is not None:\r\n",
    "             acc = paddle.metric.accuracy(input=x, label=label)\r\n",
    "             return x, acc\r\n",
    "        else:\r\n",
    "             return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "\r\n",
    "transform = Compose([Normalize(mean=[127.5],\r\n",
    "                               std=[127.5],\r\n",
    "                               data_format='CHW')])# 归一化\r\n",
    "\r\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\r\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model):\r\n",
    "    model = MNIST()\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    # 加载训练集 batch_size 设为 16\r\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, \r\n",
    "                                        batch_size=64, \r\n",
    "                                        shuffle=True)\r\n",
    "    # 定义优化器，使用ADM优化器，学习率设置为0.001\r\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\r\n",
    "    \r\n",
    "    losss = []\r\n",
    "    EPOCH_NUM = 10\r\n",
    "    for epoch_id in range(EPOCH_NUM):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            #准备数据\r\n",
    "            \r\n",
    "            images, labels = data\r\n",
    "            images = paddle.to_tensor(images)\r\n",
    "            labels = paddle.to_tensor(labels)\r\n",
    "            \r\n",
    "            #前向计算的过程\r\n",
    "            predicts, acc = model(images, labels)\r\n",
    "            \r\n",
    "            #计算损失，取一个批次样本损失的平均值\r\n",
    "            loss = F.cross_entropy(predicts, labels)\r\n",
    "            avg_loss = paddle.mean(loss)\r\n",
    "                \r\n",
    "            #后向传播，更新参数，消除梯度的过程\r\n",
    "            avg_loss.backward()#反向传播计算梯度\r\n",
    "            opt.step()#通过梯度更新网络参数\r\n",
    "            opt.clear_grad()#梯度清除，进入下一次训练\r\n",
    "\r\n",
    "            if batch_id % 200 == 0:\r\n",
    "                losss.append(float(avg_loss.numpy()))\r\n",
    "\r\n",
    "        \r\n",
    "        #每训练完一周期，打印下当前Loss的情况\r\n",
    "        print(\"epoch: {}, loss is: {}, acc is {}\".format(epoch_id, avg_loss.numpy(), acc.numpy()))\r\n",
    "        #print(\"epoch: {}， loss is: {}\".format(epoch_id, loss.numpy()))\r\n",
    "\r\n",
    "    plt.figure()\r\n",
    "    xlab = np.linspace(1, len(losss), len(losss))\r\n",
    "    plt.xlabel('iterations')\r\n",
    "    plt.ylabel('average loss')\r\n",
    "    plt.plot(xlab, losss, 'r')\r\n",
    "\r\n",
    "    #保存模型参数\r\n",
    "    paddle.save(model.state_dict(), 'mnist.pdparams')\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(model):\r\n",
    "\r\n",
    "    # 加载测试集 batch_size 设为 64\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, \r\n",
    "                                        batch_size=16, \r\n",
    "                                        shuffle=True)\r\n",
    "    # 加载模型参数\r\n",
    "    param_dict = paddle.load('mnist.pdparams')\r\n",
    "    model.load_dict(param_dict)\r\n",
    "\r\n",
    "    acc_set = []\r\n",
    "    avg_loss_set = []\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        #准备数据\r\n",
    "        images, labels = data\r\n",
    "        images = paddle.to_tensor(images)\r\n",
    "        labels = paddle.to_tensor(labels)\r\n",
    "        \r\n",
    "        predicts, acc = model(images, labels)\r\n",
    "        loss = F.cross_entropy(input=predicts, label=labels)\r\n",
    "        avg_loss = paddle.mean(loss)\r\n",
    "        acc_set.append(float(acc.numpy()))\r\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\r\n",
    "\r\n",
    "        \r\n",
    "        \r\n",
    "    acc_val_mean = np.array(acc_set).mean()\r\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\r\n",
    "    print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\r\n",
    "\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#创建模型    \r\n",
    "model = MNIST()\r\n",
    "#启动训练过程\r\n",
    "train(model)\r\n",
    "#启动测试过程\r\n",
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
