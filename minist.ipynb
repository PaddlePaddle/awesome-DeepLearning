{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 通过极简方案构建手写数字识别模型\n",
    "\n",
    "上一节介绍了创新性的“横纵式”教学法，有助于深度学习初学者快速掌握深度学习理论知识，并在过程中让读者获得真实建模的实战体验。在“横纵式”教学法中，纵向概要介绍模型的基本代码结构和极简实现方案，如 **图1** 所示。本节将使用这种极简实现方案快速完成手写数字识别的建模。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/762c127363684c32832cb61b5d6deaa013023131a36948b6b695cec2df72f791\" width=\"1000\" hegiht=\"\" ></center>\n",
    "<center><br>图1：“横纵式”教学法—纵向极简实现方案</br></center>\n",
    "<br></br>\n",
    "\n",
    "### 前提条件\n",
    "\n",
    "在数据处理前，首先要加载飞桨平台与“手写数字识别”模型相关的类库，实现方法如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "#加载飞桨和相关类库\r\n",
    "from paddle.vision.transforms import Compose, Normalize\r\n",
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "import numpy as np\r\n",
    "from paddle.metric import Accuracy\r\n",
    "import random\r\n",
    "from paddle import fluid\r\n",
    "from visualdl import LogWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_writer=LogWriter(\"./data/log/train\") #log记录器\r\n",
    "transform = Compose([Normalize(mean=[127.5],std=[127.5],data_format='CHW')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据处理\n",
    "\n",
    "飞桨提供了多个封装好的数据集API，涵盖计算机视觉、自然语言处理、推荐系统等多个领域，帮助读者快速完成深度学习任务。如在手写数字识别任务中，通过[paddle.vision.datasets.MNIST](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/datasets/mnist/MNIST_cn.html)可以直接获取处理好的MNIST训练集、测试集，飞桨API支持如下常见的学术数据集：\n",
    "\n",
    "* mnist\n",
    "* cifar\n",
    "* Conll05\n",
    "* imdb\n",
    "* imikolov\n",
    "* movielens\n",
    "* sentiment\n",
    "* uci_housing\n",
    "* wmt14\n",
    "* wmt16\n",
    "\n",
    "通过paddle.vision.datasets.MNIST API设置数据读取器，代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "..\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "# 设置数据读取器，API自动读取MNIST数据训练集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " 通过如下代码读取任意一个数据内容，观察打印结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用matplotlib工具包将其显示出来，如**图2** 所示。可以看到图片显示的数字是5，和对应标签数字一致。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/a07d9b3b5839434e98afe05a298d3ce1c9b6cbc02124488a9bd8b7c2efeb42c4\" width=\"300\" hegiht=\"\" ></center>\n",
    "<center><br>图2：matplotlib打印结果示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "飞桨将维度是28×28的手写数字图像转成向量形式存储，因此使用飞桨数据加载器读取到的手写数字图像是长度为784（28×28）的向量。\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型设计\n",
    "\n",
    "在房价预测深度学习任务中，我们使用了单层且没有非线性变换的模型，取得了理想的预测效果。在手写数字识别中，我们依然使用这个模型预测输入的图形数字值。其中，模型的输入为784维（28×28）数据，输出为1维数据，如 **图6** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/9c146e7d9c4a4119a8cd09f7c8b5ee61f2ac1820a221429a80430291728b9c4a\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图6：手写数字识别网络模型</br></center>\n",
    "<br></br>\n",
    "\n",
    "输入像素的位置排布信息对理解图像内容非常重要（如将原始尺寸为28×28图像的像素按照7×112的尺寸排布，那么其中的数字将不可识别），因此网络的输入设计为28×28的尺寸，而不是1×784，以便于模型能够正确处理像素之间的空间信息。\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "事实上，采用只有一层的简单网络（对输入求加权和）时并没有处理位置关系信息，因此可以猜测出此模型的预测效果可能有限。在后续优化环节介绍的卷积神经网络则更好的考虑了这种位置关系信息，模型的预测效果也会有显著提升。\n",
    "\n",
    "------\n",
    "\n",
    "下面以类的方式组建手写数字识别的网络，实现方法如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InceptionA(paddle.nn.Layer):  #作为网络一层\n",
    "    def __init__(self,in_channels):\n",
    "        super(InceptionA,self).__init__()\n",
    "        self.branch3x3_1=paddle.nn.Conv2D(in_channels,16,kernel_size=1) #第一个分支\n",
    "        self.branch3x3_2=paddle.nn.Conv2D( 16,24,kernel_size=3,padding=1)\n",
    "        self.branch3x3_3=paddle.nn.Conv2D(24,24,kernel_size=3,padding=1)\n",
    "\n",
    "        self.branch5x5_1=paddle.nn.Conv2D(in_channels, 16,kernel_size=1) #第二个分支\n",
    "        self.branch5x5_2=paddle.nn.Conv2D( 16,24,kernel_size=5,padding=2)\n",
    "\n",
    "        self.branch1x1=paddle.nn.Conv2D(in_channels, 16,kernel_size=1) #第三个分支\n",
    "\n",
    "        self.branch_pool=paddle.nn.Conv2D(in_channels,24,kernel_size= 1) #第四个分支\n",
    "\n",
    "    def forward(self,x):\n",
    "        #分支1处理过程\n",
    "        branch3x3= self.branch3x3_1(x)\n",
    "        branch3x3= self.branch3x3_2(branch3x3)\n",
    "        branch3x3= self.branch3x3_3(branch3x3)\n",
    "        #分支2处理过程\n",
    "        branch5x5=self.branch5x5_1(x)\n",
    "        branch5x5=self.branch5x5_2(branch5x5)\n",
    "        #分支3处理过程\n",
    "        branch1x1=self.branch1x1(x)\n",
    "        #分支4处理过程\n",
    "        branch_pool=F.avg_pool2d(x,kernel_size=3,stride=1,padding= 1)\n",
    "        branch_pool=self.branch_pool(branch_pool)\n",
    "        outputs=[branch1x1,branch5x5,branch3x3,branch_pool]     #将4个分支的输出拼接起来\n",
    "        return fluid.layers.concat(outputs,axis=1) #横着拼接， 共有24+24+16+24=88个通道\n",
    "\n",
    "class Net(paddle.nn.Layer):        #卷积，池化，inception，卷积，池化，inception，全连接\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        #定义两个卷积层\n",
    "        self.conv1=paddle.nn.Conv2D(1,10,kernel_size=5)\n",
    "        self.conv2=paddle.nn.Conv2D(88,20,kernel_size=5)\n",
    "        #Inception模块的输出均为88通道\n",
    "        self.incep1=InceptionA(in_channels=10 )\n",
    "        self.incep2=InceptionA(in_channels=20)\n",
    "        self.mp=paddle.nn.MaxPool2D(2)\n",
    "        self.fc=paddle.nn.Linear(1408,10) #图像高*宽*通道数\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.mp(self.conv1(x)))# 卷积池化，relu  输出x为图像尺寸14*14*10\n",
    "        x =self.incep1(x)               #图像尺寸14*14*88\n",
    "\n",
    "        x =F.relu(self.mp(self.conv2(x)))# 卷积池化，relu  输出x为图像尺寸5*5*20\n",
    "        x = self.incep2(x)              #图像尺寸5*5*88\n",
    "\n",
    "        x = paddle.flatten(x, start_axis=1,stop_axis=-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练配置\n",
    "\n",
    "训练配置需要先生成模型实例（设为“训练”状态），再设置优化算法和学习率（使用随机梯度下降SGD，学习率设置为0.001），实现方法如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/2\n",
      "step  10/938 [..............................] - loss: 1.6071 - acc: 0.2531 - ETA: 29s - 32ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 938/938 [==============================] - loss: 0.0025 - acc: 0.9403 - 15ms/step        \n",
      "Epoch 2/2\n",
      "step 938/938 [==============================] - loss: 7.9244e-04 - acc: 0.9741 - 15ms/step    \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 6.8436e-05 - acc: 0.9813 - 9ms/step       \n",
      "Eval samples: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [6.843645e-05], 'acc': 0.9813}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = paddle.Model(Net())   # 封装模型\r\n",
    "optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()) # adam优化器\r\n",
    "\r\n",
    "# 配置模型\r\n",
    "model.prepare(\r\n",
    "    optim,\r\n",
    "    paddle.nn.CrossEntropyLoss(),\r\n",
    "    Accuracy()\r\n",
    "    )\r\n",
    "# 训练模型\r\n",
    "model.fit(train_dataset,epochs=2,batch_size=64,verbose=1)\r\n",
    "#评估\r\n",
    "model.evaluate(test_dataset, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练过程\n",
    "\n",
    "训练过程采用二层循环嵌套方式，训练完成后需要保存模型参数，以便后续使用。\n",
    "\n",
    "- 内层循环：负责整个数据集的一次遍历，遍历数据集采用分批次（batch）方式。\n",
    "- 外层循环：定义遍历数据集的次数，本次训练中外层循环10次，通过参数EPOCH_NUM设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 0, loss is: [12.229323], acc is: [0.109375]\n",
      "epoch: 0, batch_id: 200, loss is: [0.14925715], acc is: [0.953125]\n",
      "epoch: 0, batch_id: 400, loss is: [0.24798764], acc is: [0.953125]\n",
      "epoch: 0, batch_id: 600, loss is: [0.04408206], acc is: [0.984375]\n",
      "epoch: 0, batch_id: 800, loss is: [0.15364572], acc is: [0.9375]\n",
      "epoch: 1, batch_id: 0, loss is: [0.18601947], acc is: [0.9375]\n"
     ]
    }
   ],
   "source": [
    "def train(model,Batch_size=64):\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    iterator = 0\n",
    "    epochs = 10\n",
    "    total_steps = (int(50000//Batch_size)+1)*epochs\n",
    "    lr = paddle.optimizer.lr.PolynomialDecay(learning_rate=0.01,decay_steps=total_steps,end_lr=0.001)\n",
    "    optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    # 用Adam作为优化函数\n",
    "    for epoch in range(epochs):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            x_data = data[0]\n",
    "            y_data = data[1]\n",
    "            predicts = model(x_data)\n",
    "            loss = F.cross_entropy(predicts, y_data)\n",
    "            # 计算损失\n",
    "            acc = paddle.metric.accuracy(predicts, y_data)\n",
    "            loss.backward()\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\n",
    "                log_writer.add_scalar(tag='acc',step=iterator,value=acc.numpy())\n",
    "                log_writer.add_scalar(tag='loss',step=iterator,value=loss.numpy())\n",
    "                iterator+=200\n",
    "            optim.step()\n",
    "            optim.clear_grad()\n",
    "        paddle.save(model.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdparams')\n",
    "        paddle.save(optim.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdopt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    # 加载测试数据集\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\n",
    "    model.eval()\n",
    "    for batch_id, data in enumerate(test_loader()):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        predicts = model(x_data)\n",
    "        # 获取预测结果\n",
    "        loss = F.cross_entropy(predicts, y_data)\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\n",
    "        if batch_id % 20 == 0:\n",
    "            print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\n",
    "\n",
    "\n",
    "\n",
    "def random_test(model,num=100):\n",
    "    select_id = random.sample(range(1, 10000), 100) #生成一百张测试图片的下标\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\n",
    "    for batch_id, data in enumerate(test_loader()):\n",
    "        x_data = data[0]\n",
    "        label = data[1]\n",
    "    predicts = model(x_data)\n",
    "    #返回正确率\n",
    "    acc = paddle.metric.accuracy(predicts, label)\n",
    "    print(\"正确率为：{}\".format(acc.numpy()))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = Net()\n",
    "    train(model)\n",
    "    test(model)\n",
    "    random_test(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
