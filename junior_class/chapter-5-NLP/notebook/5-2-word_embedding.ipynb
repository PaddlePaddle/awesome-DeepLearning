{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œè¯å‘é‡ï¼ˆWord Embeddingï¼‰æ˜¯è¡¨ç¤ºè‡ªç„¶è¯­è¨€é‡Œå•è¯çš„ä¸€ç§æ–¹æ³•ï¼Œå³æŠŠæ¯ä¸ªè¯éƒ½è¡¨ç¤ºä¸ºä¸€ä¸ªNç»´ç©ºé—´å†…çš„ç‚¹ï¼Œå³ä¸€ä¸ªé«˜ç»´ç©ºé—´å†…çš„å‘é‡ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œå®ç°æŠŠè‡ªç„¶è¯­è¨€è®¡ç®—è½¬æ¢ä¸ºå‘é‡è®¡ç®—ã€‚\n",
    "\n",
    "å¦‚ **å›¾1** æ‰€ç¤ºçš„è¯å‘é‡è®¡ç®—ä»»åŠ¡ä¸­ï¼Œå…ˆæŠŠæ¯ä¸ªè¯ï¼ˆå¦‚queenï¼Œkingç­‰ï¼‰è½¬æ¢æˆä¸€ä¸ªé«˜ç»´ç©ºé—´çš„å‘é‡ï¼Œè¿™äº›å‘é‡åœ¨ä¸€å®šæ„ä¹‰ä¸Šå¯ä»¥ä»£è¡¨è¿™ä¸ªè¯çš„è¯­ä¹‰ä¿¡æ¯ã€‚å†é€šè¿‡è®¡ç®—è¿™äº›å‘é‡ä¹‹é—´çš„è·ç¦»ï¼Œå°±å¯ä»¥è®¡ç®—å‡ºè¯è¯­ä¹‹é—´çš„å…³è”å…³ç³»ï¼Œä»è€Œè¾¾åˆ°è®©è®¡ç®—æœºåƒè®¡ç®—æ•°å€¼ä¸€æ ·å»è®¡ç®—è‡ªç„¶è¯­è¨€çš„ç›®çš„ã€‚\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/00ba55f7304e4f97942165cf1deb946ced404a19325d40969b7c220e30cf527e\" width=\"800\" ></center>\n",
    "<center>å›¾1ï¼šè¯å‘é‡è®¡ç®—ç¤ºæ„å›¾</center>\n",
    "<br></br>\n",
    "\n",
    "å› æ­¤ï¼Œå¤§éƒ¨åˆ†è¯å‘é‡æ¨¡å‹éƒ½éœ€è¦å›ç­”ä¸¤ä¸ªé—®é¢˜ï¼š\n",
    "\n",
    "1. **å¦‚ä½•æŠŠè¯è½¬æ¢ä¸ºå‘é‡?**\n",
    "\n",
    "è‡ªç„¶è¯­è¨€å•è¯æ˜¯ç¦»æ•£ä¿¡å·ï¼Œæ¯”å¦‚â€œé¦™è•‰â€ï¼Œâ€œæ©˜å­â€ï¼Œâ€œæ°´æœâ€åœ¨æˆ‘ä»¬çœ‹æ¥å°±æ˜¯3ä¸ªç¦»æ•£çš„è¯ã€‚\n",
    "\n",
    "å¦‚ä½•æŠŠæ¯ä¸ªç¦»æ•£çš„å•è¯è½¬æ¢ä¸ºä¸€ä¸ªå‘é‡ï¼Ÿ\n",
    "\n",
    "2. **å¦‚ä½•è®©å‘é‡å…·æœ‰è¯­ä¹‰ä¿¡æ¯?**\n",
    "\n",
    "æ¯”å¦‚ï¼Œæˆ‘ä»¬çŸ¥é“åœ¨å¾ˆå¤šæƒ…å†µä¸‹ï¼Œâ€œé¦™è•‰â€å’Œâ€œæ©˜å­â€æ›´åŠ ç›¸ä¼¼ï¼Œè€Œâ€œé¦™è•‰â€å’Œâ€œæ©˜å­â€å°±æ²¡æœ‰é‚£ä¹ˆç›¸ä¼¼ï¼ŒåŒæ—¶â€œé¦™è•‰â€å’Œâ€œé£Ÿç‰©â€ã€â€œæ°´æœâ€çš„ç›¸ä¼¼ç¨‹åº¦å¯èƒ½ä»‹äºâ€œæ©˜å­â€å’Œâ€œå¥å­â€ä¹‹é—´ã€‚\n",
    "\n",
    "é‚£ä¹ˆï¼Œæˆ‘ä»¬è¯¥å¦‚ä½•è®©è¯å‘é‡å…·å¤‡è¿™æ ·çš„è¯­ä¹‰ä¿¡æ¯ï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# å¦‚ä½•æŠŠè¯è½¬æ¢ä¸ºå‘é‡\n",
    "\n",
    "è‡ªç„¶è¯­è¨€å•è¯æ˜¯ç¦»æ•£ä¿¡å·ï¼Œæ¯”å¦‚â€œæˆ‘â€ã€â€œ çˆ±â€ã€â€œäººå·¥æ™ºèƒ½â€ã€‚å¦‚ä½•æŠŠæ¯ä¸ªç¦»æ•£çš„å•è¯è½¬æ¢ä¸ºä¸€ä¸ªå‘é‡ï¼Ÿé€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç»´æŠ¤ä¸€ä¸ªå¦‚ **å›¾2** æ‰€ç¤ºçš„æŸ¥è¯¢è¡¨ã€‚è¡¨ä¸­æ¯ä¸€è¡Œéƒ½å­˜å‚¨äº†ä¸€ä¸ªç‰¹å®šè¯è¯­çš„å‘é‡å€¼ï¼Œæ¯ä¸€åˆ—çš„ç¬¬ä¸€ä¸ªå…ƒç´ éƒ½ä»£è¡¨ç€è¿™ä¸ªè¯æœ¬èº«ï¼Œä»¥ä¾¿äºæˆ‘ä»¬è¿›è¡Œè¯å’Œå‘é‡çš„æ˜ å°„ï¼ˆå¦‚â€œæˆ‘â€å¯¹åº”çš„å‘é‡å€¼ä¸º [0.3ï¼Œ0.5ï¼Œ0.7ï¼Œ0.9ï¼Œ-0.2ï¼Œ0.03] ï¼‰ã€‚ç»™å®šä»»ä½•ä¸€ä¸ªæˆ–è€…ä¸€ç»„å•è¯ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥é€šè¿‡æŸ¥è¯¢è¿™ä¸ªexcelï¼Œå®ç°æŠŠå•è¯è½¬æ¢ä¸ºå‘é‡çš„ç›®çš„ï¼Œè¿™ä¸ªæŸ¥è¯¢å’Œæ›¿æ¢è¿‡ç¨‹ç§°ä¹‹ä¸ºEmbedding Lookupã€‚\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/2ccf57a0c4584ca5b5000da85bc48c4cbe1588f0e3f548c6b2271c26e2e7df14\" width=\"800\" ></center>\n",
    "<center><br>å›¾2ï¼šè¯å‘é‡æŸ¥è¯¢è¡¨</br></center>\n",
    "<br></br>\n",
    "\n",
    "ä¸Šè¿°è¿‡ç¨‹ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸€ä¸ªå­—å…¸æ•°æ®ç»“æ„å®ç°ã€‚äº‹å®ä¸Šå¦‚æœä¸è€ƒè™‘è®¡ç®—æ•ˆç‡ï¼Œä½¿ç”¨å­—å…¸å®ç°ä¸Šè¿°åŠŸèƒ½æ˜¯ä¸ªä¸é”™çš„é€‰æ‹©ã€‚ç„¶è€Œåœ¨è¿›è¡Œç¥ç»ç½‘ç»œè®¡ç®—çš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦å¤§é‡çš„ç®—åŠ›ï¼Œå¸¸å¸¸è¦å€ŸåŠ©ç‰¹å®šç¡¬ä»¶ï¼ˆå¦‚GPUï¼‰æ»¡è¶³è®­ç»ƒé€Ÿåº¦çš„éœ€æ±‚ã€‚GPUä¸Šæ‰€æ”¯æŒçš„è®¡ç®—éƒ½æ˜¯ä»¥å¼ é‡ï¼ˆTensorï¼‰ä¸ºå•ä½å±•å¼€çš„ï¼Œå› æ­¤åœ¨å®é™…åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æŠŠEmbedding Lookupçš„è¿‡ç¨‹è½¬æ¢ä¸ºå¼ é‡è®¡ç®—ï¼Œå¦‚ **å›¾3** æ‰€ç¤ºã€‚\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/0da8ca9f87364701a95a5d1f51736dd08bd1e6321a3f4c30bfb2ee2d2385698c\" width=\"800\" ></center>\n",
    "<center><br>å›¾3ï¼šå¼ é‡è®¡ç®—ç¤ºæ„å›¾</br></center>\n",
    "<br></br>\n",
    "\n",
    "å‡è®¾å¯¹äºå¥å­\"æˆ‘ï¼Œçˆ±ï¼Œäººå·¥ï¼Œæ™ºèƒ½\"ï¼ŒæŠŠEmbedding Lookupçš„è¿‡ç¨‹è½¬æ¢ä¸ºå¼ é‡è®¡ç®—çš„æµç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. é€šè¿‡æŸ¥è¯¢å­—å…¸ï¼Œå…ˆæŠŠå¥å­ä¸­çš„å•è¯è½¬æ¢æˆä¸€ä¸ªIDï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªå¤§äºç­‰äº0çš„æ•´æ•°ï¼‰ï¼Œè¿™ä¸ªå•è¯åˆ°IDçš„æ˜ å°„å…³ç³»å¯ä»¥æ ¹æ®éœ€æ±‚è‡ªå®šä¹‰ï¼ˆå¦‚**å›¾3**ä¸­ï¼Œæˆ‘=>1, äººå·¥=>2ï¼Œçˆ±=>3ï¼Œ...ï¼‰ã€‚\n",
    "\n",
    "2. å¾—åˆ°IDåï¼Œå†æŠŠæ¯ä¸ªIDè½¬æ¢æˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„å‘é‡ã€‚å‡è®¾å­—å…¸çš„è¯è¡¨ä¸­æœ‰5000ä¸ªè¯ï¼Œé‚£ä¹ˆï¼Œå¯¹äºå•è¯â€œæˆ‘â€ï¼Œå°±å¯ä»¥ç”¨ä¸€ä¸ª5000ç»´çš„å‘é‡æ¥è¡¨ç¤ºã€‚ç”±äºâ€œæˆ‘â€çš„IDæ˜¯1ï¼Œå› æ­¤è¿™ä¸ªå‘é‡çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯1ï¼Œå…¶ä»–å…ƒç´ éƒ½æ˜¯0ï¼ˆ[1ï¼Œ0ï¼Œ0ï¼Œâ€¦ï¼Œ0]ï¼‰ï¼›åŒæ ·å¯¹äºå•è¯â€œäººå·¥â€ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯1ï¼Œå…¶ä»–å…ƒç´ éƒ½æ˜¯0ã€‚ç”¨è¿™ç§æ–¹å¼å°±å®ç°äº†ç”¨ä¸€ä¸ªå‘é‡è¡¨ç¤ºä¸€ä¸ªå•è¯ã€‚ç”±äºæ¯ä¸ªå•è¯çš„å‘é‡è¡¨ç¤ºéƒ½åªæœ‰ä¸€ä¸ªå…ƒç´ ä¸º1ï¼Œè€Œå…¶ä»–å…ƒç´ ä¸º0ï¼Œå› æ­¤æˆ‘ä»¬ç§°ä¸Šè¿°è¿‡ç¨‹ä¸ºOne-Hot Encodingã€‚\n",
    "\n",
    "3. ç»è¿‡One-Hot Encodingåï¼Œå¥å­â€œæˆ‘ï¼Œçˆ±ï¼Œäººå·¥ï¼Œæ™ºèƒ½â€å°±è¢«è½¬æ¢æˆä¸ºäº†ä¸€ä¸ªå½¢çŠ¶ä¸º 4Ã—5000çš„å¼ é‡ï¼Œè®°ä¸º$V$ã€‚åœ¨è¿™ä¸ªå¼ é‡é‡Œå…±æœ‰4è¡Œã€5000åˆ—ï¼Œä»ä¸Šåˆ°ä¸‹ï¼Œæ¯ä¸€è¡Œåˆ†åˆ«ä»£è¡¨äº†â€œæˆ‘â€ã€â€œçˆ±â€ã€â€œäººå·¥â€ã€â€œæ™ºèƒ½â€å››ä¸ªå•è¯çš„One-Hot Encodingã€‚æœ€åï¼Œæˆ‘ä»¬æŠŠè¿™ä¸ªå¼ é‡$V$å’Œå¦å¤–ä¸€ä¸ªç¨ å¯†å¼ é‡$W$ç›¸ä¹˜ï¼Œå…¶ä¸­$W$å¼ é‡çš„å½¢çŠ¶ä¸º5000 Ã— 128ï¼ˆ5000è¡¨ç¤ºè¯è¡¨å¤§å°ï¼Œ128è¡¨ç¤ºæ¯ä¸ªè¯çš„å‘é‡å¤§å°ï¼‰ã€‚ç»è¿‡å¼ é‡ä¹˜æ³•ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†ä¸€ä¸ª4Ã—128çš„å¼ é‡ï¼Œä»è€Œå®Œæˆäº†æŠŠå•è¯è¡¨ç¤ºæˆå‘é‡çš„ç›®çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# å¦‚ä½•è®©å‘é‡å…·æœ‰è¯­ä¹‰ä¿¡æ¯\n",
    "\n",
    "å¾—åˆ°æ¯ä¸ªå•è¯çš„å‘é‡è¡¨ç¤ºåï¼Œæˆ‘ä»¬éœ€è¦æ€è€ƒä¸‹ä¸€ä¸ªé—®é¢˜ï¼šæ¯”å¦‚åœ¨å¤šæ•°æƒ…å†µä¸‹ï¼Œâ€œé¦™è•‰â€å’Œâ€œæ©˜å­â€æ›´åŠ ç›¸ä¼¼ï¼Œè€Œâ€œé¦™è•‰â€å’Œâ€œå¥å­â€å°±æ²¡æœ‰é‚£ä¹ˆç›¸ä¼¼ï¼›åŒæ—¶ï¼Œâ€œé¦™è•‰â€å’Œâ€œé£Ÿç‰©â€ã€â€œæ°´æœâ€çš„ç›¸ä¼¼ç¨‹åº¦å¯èƒ½ä»‹äºâ€œæ©˜å­â€å’Œâ€œå¥å­â€ä¹‹é—´ã€‚é‚£ä¹ˆå¦‚ä½•è®©å­˜å‚¨çš„è¯å‘é‡å…·å¤‡è¿™æ ·çš„è¯­ä¹‰ä¿¡æ¯å‘¢ï¼Ÿ\n",
    "\n",
    "æˆ‘ä»¬å…ˆå­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„ä¸€ä¸ªå°æŠ€å·§ã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶ä¸­ï¼Œç§‘ç ”äººå‘˜é€šå¸¸æœ‰ä¸€ä¸ªå…±è¯†ï¼šä½¿ç”¨ä¸€ä¸ªå•è¯çš„ä¸Šä¸‹æ–‡æ¥äº†è§£è¿™ä¸ªå•è¯çš„è¯­ä¹‰ï¼Œæ¯”å¦‚ï¼š\n",
    "\n",
    " >â€œè‹¹æœæ‰‹æœºè´¨é‡ä¸é”™ï¼Œå°±æ˜¯ä»·æ ¼æœ‰ç‚¹è´µã€‚â€\n",
    " >\n",
    " >â€œè¿™ä¸ªè‹¹æœå¾ˆå¥½åƒï¼Œéå¸¸è„†ã€‚â€\n",
    " >\n",
    " >â€œè èè´¨é‡ä¹Ÿè¿˜è¡Œï¼Œä½†æ˜¯ä¸å¦‚è‹¹æœæ”¯æŒçš„APPå¤šã€‚â€\n",
    ">\n",
    "åœ¨ä¸Šé¢çš„å¥å­ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¸Šä¸‹æ–‡å¯ä»¥æ¨æ–­å‡ºç¬¬ä¸€ä¸ªâ€œè‹¹æœâ€æŒ‡çš„æ˜¯è‹¹æœæ‰‹æœºï¼Œç¬¬äºŒä¸ªâ€œè‹¹æœâ€æŒ‡çš„æ˜¯æ°´æœè‹¹æœï¼Œè€Œç¬¬ä¸‰ä¸ªâ€œè èâ€æŒ‡çš„åº”è¯¥ä¹Ÿæ˜¯ä¸€ä¸ªæ‰‹æœºã€‚äº‹å®ä¸Šï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡æè¿°ä¸€ä¸ªè¯è¯­æˆ–è€…å…ƒç´ çš„è¯­ä¹‰æ˜¯ä¸€ä¸ªå¸¸è§ä¸”æœ‰æ•ˆçš„åšæ³•ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŒæ ·çš„æ–¹å¼è®­ç»ƒè¯å‘é‡ï¼Œè®©è¿™äº›è¯å‘é‡å…·å¤‡è¡¨ç¤ºè¯­ä¹‰ä¿¡æ¯çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "2013å¹´ï¼ŒMikolovæå‡ºçš„ç»å…¸word2vecç®—æ³•å°±æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡æ¥å­¦ä¹ è¯­ä¹‰ä¿¡æ¯ã€‚word2vecåŒ…å«ä¸¤ä¸ªç»å…¸æ¨¡å‹ï¼šCBOWï¼ˆContinuous Bag-of-Wordsï¼‰å’ŒSkip-gramï¼Œå¦‚ **å›¾4** æ‰€ç¤ºã€‚\n",
    "\n",
    "- **CBOW**ï¼šé€šè¿‡ä¸Šä¸‹æ–‡çš„è¯å‘é‡æ¨ç†ä¸­å¿ƒè¯ã€‚\n",
    "- **Skip-gram**ï¼šæ ¹æ®ä¸­å¿ƒè¯æ¨ç†ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/87b90136eef04d7285803e567a5f7f6d0e40bb552deb40a19a7540c4e6aa20a3\" width=\"700\" ></center>\n",
    "<center><br>å›¾4ï¼šCBOWå’ŒSkip-gramè¯­ä¹‰å­¦ä¹ ç¤ºæ„å›¾</br></center>\n",
    "<br></br>\n",
    "\n",
    "å‡è®¾æœ‰ä¸€ä¸ªå¥å­â€œPineapples are spiked and yellowâ€ï¼Œä¸¤ä¸ªæ¨¡å‹çš„æ¨ç†æ–¹å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "- åœ¨**CBOW**ä¸­ï¼Œå…ˆåœ¨å¥å­ä¸­é€‰å®šä¸€ä¸ªä¸­å¿ƒè¯ï¼Œå¹¶æŠŠå…¶å®ƒè¯ä½œä¸ºè¿™ä¸ªä¸­å¿ƒè¯çš„ä¸Šä¸‹æ–‡ã€‚å¦‚ **å›¾4** CBOWæ‰€ç¤ºï¼ŒæŠŠâ€œSpikedâ€ä½œä¸ºä¸­å¿ƒè¯ï¼ŒæŠŠâ€œPineapplesã€areã€andã€yellowâ€ä½œä¸ºä¸­å¿ƒè¯çš„ä¸Šä¸‹æ–‡ã€‚åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡çš„è¯å‘é‡æ¨ç†ä¸­å¿ƒè¯ï¼Œè¿™æ ·ä¸­å¿ƒè¯çš„è¯­ä¹‰å°±è¢«ä¼ é€’åˆ°ä¸Šä¸‹æ–‡çš„è¯å‘é‡ä¸­ï¼Œå¦‚â€œSpiked â†’ pineappleâ€ï¼Œä»è€Œè¾¾åˆ°å­¦ä¹ è¯­ä¹‰ä¿¡æ¯çš„ç›®çš„ã€‚\n",
    "\n",
    "- åœ¨**Skip-gram**ä¸­ï¼ŒåŒæ ·å…ˆé€‰å®šä¸€ä¸ªä¸­å¿ƒè¯ï¼Œå¹¶æŠŠå…¶ä»–è¯ä½œä¸ºè¿™ä¸ªä¸­å¿ƒè¯çš„ä¸Šä¸‹æ–‡ã€‚å¦‚ **å›¾4** Skip-gramæ‰€ç¤ºï¼ŒæŠŠâ€œSpikedâ€ä½œä¸ºä¸­å¿ƒè¯ï¼ŒæŠŠâ€œPineapplesã€areã€andã€yellowâ€ä½œä¸ºä¸­å¿ƒè¯çš„ä¸Šä¸‹æ–‡ã€‚ä¸åŒçš„æ˜¯ï¼Œåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ä¸­å¿ƒè¯çš„è¯å‘é‡å»æ¨ç†ä¸Šä¸‹æ–‡ï¼Œè¿™æ ·ä¸Šä¸‹æ–‡å®šä¹‰çš„è¯­ä¹‰è¢«ä¼ å…¥ä¸­å¿ƒè¯çš„è¡¨ç¤ºä¸­ï¼Œå¦‚â€œpineapple â†’ Spikedâ€ï¼Œ\n",
    "ä»è€Œè¾¾åˆ°å­¦ä¹ è¯­ä¹‰ä¿¡æ¯çš„ç›®çš„ã€‚\n",
    "\n",
    "------\n",
    "**è¯´æ˜ï¼š**\n",
    "\n",
    "ä¸€èˆ¬æ¥è¯´ï¼ŒCBOWæ¯”Skip-gramè®­ç»ƒé€Ÿåº¦å¿«ï¼Œè®­ç»ƒè¿‡ç¨‹æ›´åŠ ç¨³å®šï¼ŒåŸå› æ˜¯CBOWä½¿ç”¨ä¸Šä¸‹æ–‡averageçš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œæ¯ä¸ªè®­ç»ƒstepä¼šè§åˆ°æ›´å¤šæ ·æœ¬ã€‚è€Œåœ¨ç”Ÿåƒ»å­—ï¼ˆå‡ºç°é¢‘ç‡ä½çš„å­—ï¼‰å¤„ç†ä¸Šï¼Œskip-gramæ¯”CBOWæ•ˆæœæ›´å¥½ï¼ŒåŸå› æ˜¯skip-gramä¸ä¼šåˆ»æ„å›é¿ç”Ÿåƒ»å­—(CBOWç»“æ„ä¸­è¾“å…¥ä¸­å­˜åœ¨ç”Ÿåƒ»å­—æ—¶ï¼Œç”Ÿåƒ»å­—ä¼šè¢«å…¶å®ƒéç”Ÿåƒ»å­—çš„æƒé‡å†²æ·¡)ã€‚\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CBOWå’ŒSkip-gramçš„ç®—æ³•å®ç°\n",
    "\n",
    "æˆ‘ä»¬ä»¥è¿™å¥è¯ï¼šâ€œPineapples are spiked and yellowâ€ä¸ºä¾‹åˆ†åˆ«ä»‹ç»CBOWå’ŒSkip-gramçš„ç®—æ³•å®ç°ã€‚\n",
    "\n",
    "å¦‚ **å›¾5** æ‰€ç¤ºï¼ŒCBOWæ˜¯ä¸€ä¸ªå…·æœ‰3å±‚ç»“æ„çš„ç¥ç»ç½‘ç»œï¼Œåˆ†åˆ«æ˜¯ï¼š\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/72397490c0ba499692cff31484431c57bc9d20f7ef344454868e12d628ec5bd3\" width=\"400\" ></center>\n",
    "<center><br>å›¾5ï¼šCBOWçš„ç®—æ³•å®ç°</br></center>\n",
    "<br></br>\n",
    "\n",
    "* **è¾“å…¥å±‚ï¼š** ä¸€ä¸ªå½¢çŠ¶ä¸ºCÃ—Vçš„one-hotå¼ é‡ï¼Œå…¶ä¸­Cä»£è¡¨ä¸Šçº¿æ–‡ä¸­è¯çš„ä¸ªæ•°ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªå¶æ•°ï¼Œæˆ‘ä»¬å‡è®¾ä¸º4ï¼›Vè¡¨ç¤ºè¯è¡¨å¤§å°ï¼Œæˆ‘ä»¬å‡è®¾ä¸º5000ï¼Œè¯¥å¼ é‡çš„æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡è¯çš„one-hotå‘é‡è¡¨ç¤ºï¼Œæ¯”å¦‚â€œPineapples, are, and, yellowâ€ã€‚\n",
    "* **éšè—å±‚ï¼š** ä¸€ä¸ªå½¢çŠ¶ä¸ºVÃ—Nçš„å‚æ•°å¼ é‡W1ï¼Œä¸€èˆ¬ç§°ä¸ºword-embeddingï¼ŒNè¡¨ç¤ºæ¯ä¸ªè¯çš„è¯å‘é‡é•¿åº¦ï¼Œæˆ‘ä»¬å‡è®¾ä¸º128ã€‚è¾“å…¥å¼ é‡å’Œword embedding W1è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œå°±ä¼šå¾—åˆ°ä¸€ä¸ªå½¢çŠ¶ä¸ºCÃ—Nçš„å¼ é‡ã€‚ç»¼åˆè€ƒè™‘ä¸Šä¸‹æ–‡ä¸­æ‰€æœ‰è¯çš„ä¿¡æ¯å»æ¨ç†ä¸­å¿ƒè¯ï¼Œå› æ­¤å°†ä¸Šä¸‹æ–‡ä¸­Cä¸ªè¯ç›¸åŠ å¾—ä¸€ä¸ª1Ã—Nçš„å‘é‡ï¼Œæ˜¯æ•´ä¸ªä¸Šä¸‹æ–‡çš„ä¸€ä¸ªéšå«è¡¨ç¤ºã€‚\n",
    "* **è¾“å‡ºå±‚ï¼š** åˆ›å»ºå¦ä¸€ä¸ªå½¢çŠ¶ä¸ºNÃ—Vçš„å‚æ•°å¼ é‡ï¼Œå°†éšè—å±‚å¾—åˆ°çš„1Ã—Nçš„å‘é‡ä¹˜ä»¥è¯¥NÃ—Vçš„å‚æ•°å¼ é‡ï¼Œå¾—åˆ°äº†ä¸€ä¸ªå½¢çŠ¶ä¸º1Ã—Vçš„å‘é‡ã€‚æœ€ç»ˆï¼Œ1Ã—Vçš„å‘é‡ä»£è¡¨äº†ä½¿ç”¨ä¸Šä¸‹æ–‡å»æ¨ç†ä¸­å¿ƒè¯ï¼Œæ¯ä¸ªå€™é€‰è¯çš„æ‰“åˆ†ï¼Œå†ç»è¿‡softmaxå‡½æ•°çš„å½’ä¸€åŒ–ï¼Œå³å¾—åˆ°äº†å¯¹ä¸­å¿ƒè¯çš„æ¨ç†æ¦‚ç‡ï¼š\n",
    "\n",
    "$$ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥({O_i})= \\frac{exp({O_i})}{\\sum_jexp({O_j})}$$\n",
    "\n",
    "å¦‚ **å›¾6** æ‰€ç¤ºï¼ŒSkip-gramæ˜¯ä¸€ä¸ªå…·æœ‰3å±‚ç»“æ„çš„ç¥ç»ç½‘ç»œï¼Œåˆ†åˆ«æ˜¯ï¼š\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/a572953b845d4c91bdf6b7b475e7b4437bee69bd60024eb2b8c46f56adf2bdef\" width=\"400\" ></center>\n",
    "<center><br>å›¾6ï¼šSkip-gramç®—æ³•å®ç°</br></center>\n",
    "<br></br>\n",
    "\n",
    "- **Input Layerï¼ˆè¾“å…¥å±‚ï¼‰**ï¼šæ¥æ”¶ä¸€ä¸ªone-hotå¼ é‡ $V \\in R^{1 \\times \\text{vocab\\_size}}$ ä½œä¸ºç½‘ç»œçš„è¾“å…¥ï¼Œé‡Œé¢å­˜å‚¨ç€å½“å‰å¥å­ä¸­å¿ƒè¯çš„one-hotè¡¨ç¤ºã€‚\n",
    "- **Hidden Layerï¼ˆéšè—å±‚ï¼‰**ï¼šå°†å¼ é‡$V$ä¹˜ä»¥ä¸€ä¸ªword embeddingå¼ é‡$W_1 \\in R^{\\text{vocab\\_size} \\times \\text{embed\\_size}}$ï¼Œå¹¶æŠŠç»“æœä½œä¸ºéšè—å±‚çš„è¾“å‡ºï¼Œå¾—åˆ°ä¸€ä¸ªå½¢çŠ¶ä¸º$R^{1 \\times \\text{embed\\_size}}$çš„å¼ é‡ï¼Œé‡Œé¢å­˜å‚¨ç€å½“å‰å¥å­ä¸­å¿ƒè¯çš„è¯å‘é‡ã€‚\n",
    "- **Output Layerï¼ˆè¾“å‡ºå±‚ï¼‰**ï¼šå°†éšè—å±‚çš„ç»“æœä¹˜ä»¥å¦ä¸€ä¸ªword embeddingå¼ é‡$W_2 \\in R^{\\text{embed\\_size} \\times \\text{vocab\\_size}}$ï¼Œå¾—åˆ°ä¸€ä¸ªå½¢çŠ¶ä¸º$R^{1 \\times \\text{vocab\\_size}}$çš„å¼ é‡ã€‚è¿™ä¸ªå¼ é‡ç»è¿‡softmaxå˜æ¢åï¼Œå°±å¾—åˆ°äº†ä½¿ç”¨å½“å‰ä¸­å¿ƒè¯å¯¹ä¸Šä¸‹æ–‡çš„é¢„æµ‹ç»“æœã€‚æ ¹æ®è¿™ä¸ªsoftmaxçš„ç»“æœï¼Œæˆ‘ä»¬å°±å¯ä»¥å»è®­ç»ƒè¯å‘é‡æ¨¡å‹ã€‚\n",
    "\n",
    "åœ¨å®é™…æ“ä½œä¸­ï¼Œä½¿ç”¨ä¸€ä¸ªæ»‘åŠ¨çª—å£ï¼ˆä¸€èˆ¬æƒ…å†µä¸‹ï¼Œé•¿åº¦æ˜¯å¥‡æ•°ï¼‰ï¼Œä»å·¦åˆ°å³å¼€å§‹æ‰«æå½“å‰å¥å­ã€‚æ¯ä¸ªæ‰«æå‡ºæ¥çš„ç‰‡æ®µè¢«å½“æˆä¸€ä¸ªå°å¥å­ï¼Œæ¯ä¸ªå°å¥å­ä¸­é—´çš„è¯è¢«è®¤ä¸ºæ˜¯ä¸­å¿ƒè¯ï¼Œå…¶ä½™çš„è¯è¢«è®¤ä¸ºæ˜¯è¿™ä¸ªä¸­å¿ƒè¯çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "   \n",
    "### Skip-gramçš„ç†æƒ³å®ç°\n",
    "\n",
    "ä½¿ç”¨ç¥ç»ç½‘ç»œå®ç°Skip-gramä¸­ï¼Œæ¨¡å‹æ¥æ”¶çš„è¾“å…¥åº”è¯¥æœ‰2ä¸ªä¸åŒçš„tensorï¼š\n",
    "\n",
    "- ä»£è¡¨ä¸­å¿ƒè¯çš„tensorï¼šå‡è®¾æˆ‘ä»¬ç§°ä¹‹ä¸ºcenter_words $V$ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªtensoræ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º[batch_size, vocab_size]çš„one-hot tensorï¼Œè¡¨ç¤ºåœ¨ä¸€ä¸ªmini-batchä¸­ï¼Œæ¯ä¸ªä¸­å¿ƒè¯çš„IDï¼Œå¯¹åº”ä½ç½®ä¸º1ï¼Œå…¶ä½™ä¸º0ã€‚\n",
    "\n",
    "- ä»£è¡¨ç›®æ ‡è¯çš„tensorï¼šç›®æ ‡è¯æ˜¯æŒ‡éœ€è¦æ¨ç†å‡ºæ¥çš„ä¸Šä¸‹æ–‡è¯ï¼Œå‡è®¾æˆ‘ä»¬ç§°ä¹‹ä¸ºtarget_words $T$ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªtensoræ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º[batch_size, 1]çš„æ•´å‹tensorï¼Œè¿™ä¸ªtensorä¸­çš„æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª[0, vocab_size-1]çš„å€¼ï¼Œä»£è¡¨ç›®æ ‡è¯çš„IDã€‚\n",
    "\n",
    "åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ–¹å¼å®ç°skip-gramã€‚å³æŠŠéœ€è¦æ¨ç†çš„æ¯ä¸ªç›®æ ‡è¯éƒ½å½“æˆä¸€ä¸ªæ ‡ç­¾ï¼ŒæŠŠskip-gramå½“æˆä¸€ä¸ªå¤§è§„æ¨¡åˆ†ç±»ä»»åŠ¡è¿›è¡Œç½‘ç»œæ„å»ºï¼Œè¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. å£°æ˜ä¸€ä¸ªå½¢çŠ¶ä¸º[vocab_size, embedding_size]çš„å¼ é‡ï¼Œä½œä¸ºéœ€è¦å­¦ä¹ çš„è¯å‘é‡ï¼Œè®°ä¸º$W_0$ã€‚å¯¹äºç»™å®šçš„è¾“å…¥$V$ï¼Œä½¿ç”¨å‘é‡ä¹˜æ³•ï¼Œå°†$V$ä¹˜ä»¥$W_0$ï¼Œè¿™æ ·å°±å¾—åˆ°äº†ä¸€ä¸ªå½¢çŠ¶ä¸º[batch_size, embedding_size]çš„å¼ é‡ï¼Œè®°ä¸º$H=VÃ—W_0$ã€‚è¿™ä¸ªå¼ é‡$H$å°±å¯ä»¥çœ‹æˆæ˜¯ç»è¿‡è¯å‘é‡æŸ¥è¡¨åçš„ç»“æœã€‚\n",
    "1. å£°æ˜å¦å¤–ä¸€ä¸ªéœ€è¦å­¦ä¹ çš„å‚æ•°$W_1$ï¼Œè¿™ä¸ªå‚æ•°çš„å½¢çŠ¶ä¸º[embedding_size, vocab_size]ã€‚å°†ä¸Šä¸€æ­¥å¾—åˆ°çš„$H$å»ä¹˜ä»¥$W_1$ï¼Œå¾—åˆ°ä¸€ä¸ªæ–°çš„tensor $O=HÃ—W_1$ï¼Œæ­¤æ—¶çš„$O$æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º[batch_size, vocab_size]çš„tensorï¼Œè¡¨ç¤ºå½“å‰è¿™ä¸ªmini-batchä¸­çš„æ¯ä¸ªä¸­å¿ƒè¯é¢„æµ‹å‡ºçš„ç›®æ ‡è¯çš„æ¦‚ç‡ã€‚\n",
    "1. ä½¿ç”¨softmaxå‡½æ•°å¯¹mini-batchä¸­æ¯ä¸ªä¸­å¿ƒè¯çš„é¢„æµ‹ç»“æœåšå½’ä¸€åŒ–ï¼Œå³å¯å®Œæˆç½‘ç»œæ„å»ºã€‚\n",
    "\n",
    "   \n",
    "### Skip-gramçš„å®é™…å®ç°\n",
    "\n",
    "ç„¶è€Œåœ¨å®é™…æƒ…å†µä¸­ï¼Œvocab_sizeé€šå¸¸å¾ˆå¤§ï¼ˆå‡ åä¸‡ç”šè‡³å‡ ç™¾ä¸‡ï¼‰ï¼Œå¯¼è‡´$W_0$å’Œ$W_1$ä¹Ÿä¼šéå¸¸å¤§ã€‚å¯¹äº$W_0$è€Œè¨€ï¼Œæ‰€å‚ä¸çš„çŸ©é˜µè¿ç®—å¹¶ä¸æ˜¯é€šè¿‡ä¸€ä¸ªçŸ©é˜µä¹˜æ³•å®ç°ï¼Œè€Œæ˜¯é€šè¿‡æŒ‡å®šIDï¼Œå¯¹å‚æ•°$W_0$è¿›è¡Œè®¿å­˜çš„æ–¹å¼è·å–ã€‚ç„¶è€Œå¯¹$W_1$è€Œè¨€ï¼Œä»è¦å¤„ç†ä¸€ä¸ªéå¸¸å¤§çš„çŸ©é˜µè¿ç®—ï¼ˆè®¡ç®—è¿‡ç¨‹éå¸¸ç¼“æ…¢ï¼Œéœ€è¦æ¶ˆè€—å¤§é‡çš„å†…å­˜/æ˜¾å­˜ï¼‰ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œé€šå¸¸é‡‡å–è´Ÿé‡‡æ ·ï¼ˆnegative_samplingï¼‰çš„æ–¹å¼æ¥è¿‘ä¼¼æ¨¡æ‹Ÿå¤šåˆ†ç±»ä»»åŠ¡ã€‚æ­¤æ—¶æ–°å®šä¹‰çš„$W_0$å’Œ$W_1$å‡ä¸ºå½¢çŠ¶ä¸º[vocab_size, embedding_size]çš„å¼ é‡ã€‚\n",
    "\n",
    "å‡è®¾æœ‰ä¸€ä¸ªä¸­å¿ƒè¯$c$å’Œä¸€ä¸ªä¸Šä¸‹æ–‡è¯æ­£æ ·æœ¬$t_p$ã€‚åœ¨Skip-gramçš„ç†æƒ³å®ç°é‡Œï¼Œéœ€è¦æœ€å¤§åŒ–ä½¿ç”¨$c$æ¨ç†$t_p$çš„æ¦‚ç‡ã€‚åœ¨ä½¿ç”¨softmaxå­¦ä¹ æ—¶ï¼Œéœ€è¦æœ€å¤§åŒ–$t_p$çš„æ¨ç†æ¦‚ç‡ï¼ŒåŒæ—¶æœ€å°åŒ–å…¶ä»–è¯è¡¨ä¸­è¯çš„æ¨ç†æ¦‚ç‡ã€‚ä¹‹æ‰€ä»¥è®¡ç®—ç¼“æ…¢ï¼Œæ˜¯å› ä¸ºéœ€è¦å¯¹è¯è¡¨ä¸­çš„æ‰€æœ‰è¯éƒ½è®¡ç®—ä¸€éã€‚ç„¶è€Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨å¦ä¸€ç§æ–¹æ³•ï¼Œå°±æ˜¯éšæœºä»è¯è¡¨ä¸­é€‰æ‹©å‡ ä¸ªä»£è¡¨è¯ï¼Œé€šè¿‡æœ€å°åŒ–è¿™å‡ ä¸ªä»£è¡¨è¯çš„æ¦‚ç‡ï¼Œå»è¿‘ä¼¼æœ€å°åŒ–æ•´ä½“çš„é¢„æµ‹æ¦‚ç‡ã€‚æ¯”å¦‚ï¼Œå…ˆæŒ‡å®šä¸€ä¸ªä¸­å¿ƒè¯ï¼ˆå¦‚â€œäººå·¥â€ï¼‰å’Œä¸€ä¸ªç›®æ ‡è¯æ­£æ ·æœ¬ï¼ˆå¦‚â€œæ™ºèƒ½â€ï¼‰ï¼Œå†éšæœºåœ¨è¯è¡¨ä¸­é‡‡æ ·å‡ ä¸ªç›®æ ‡è¯è´Ÿæ ·æœ¬ï¼ˆå¦‚â€œæ—¥æœ¬â€ï¼Œâ€œå–èŒ¶â€ç­‰ï¼‰ã€‚æœ‰äº†è¿™äº›å†…å®¹ï¼Œæˆ‘ä»¬çš„skip-gramæ¨¡å‹å°±å˜æˆäº†ä¸€ä¸ªäºŒåˆ†ç±»ä»»åŠ¡ã€‚å¯¹äºç›®æ ‡è¯æ­£æ ·æœ¬ï¼Œæˆ‘ä»¬éœ€è¦æœ€å¤§åŒ–å®ƒçš„é¢„æµ‹æ¦‚ç‡ï¼›å¯¹äºç›®æ ‡è¯è´Ÿæ ·æœ¬ï¼Œæˆ‘ä»¬éœ€è¦æœ€å°åŒ–å®ƒçš„é¢„æµ‹æ¦‚ç‡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®Œæˆè®¡ç®—åŠ é€Ÿã€‚ä¸Šè¿°åšæ³•ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºè´Ÿé‡‡æ ·ã€‚\n",
    "\n",
    "åœ¨å®ç°çš„è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä¼šè®©æ¨¡å‹æ¥æ”¶3ä¸ªtensorè¾“å…¥ï¼š\n",
    "\n",
    "- ä»£è¡¨ä¸­å¿ƒè¯çš„tensorï¼šå‡è®¾æˆ‘ä»¬ç§°ä¹‹ä¸ºcenter_words $V$ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªtensoræ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º[batch_size, vocab_size]çš„one-hot tensorï¼Œè¡¨ç¤ºåœ¨ä¸€ä¸ªmini-batchä¸­æ¯ä¸ªä¸­å¿ƒè¯å…·ä½“çš„IDã€‚\n",
    "\n",
    "- ä»£è¡¨ç›®æ ‡è¯çš„tensorï¼šå‡è®¾æˆ‘ä»¬ç§°ä¹‹ä¸ºtarget_words $T$ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªtensoråŒæ ·æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º[batch_size, vocab_size]çš„one-hot tensorï¼Œè¡¨ç¤ºåœ¨ä¸€ä¸ªmini-batchä¸­æ¯ä¸ªç›®æ ‡è¯å…·ä½“çš„IDã€‚\n",
    "\n",
    "- ä»£è¡¨ç›®æ ‡è¯æ ‡ç­¾çš„tensorï¼šå‡è®¾æˆ‘ä»¬ç§°ä¹‹ä¸ºlabels $L$ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªtensoræ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º[batch_size, 1]çš„tensorï¼Œæ¯ä¸ªå…ƒç´ ä¸æ˜¯0å°±æ˜¯1ï¼ˆ0ï¼šè´Ÿæ ·æœ¬ï¼Œ1ï¼šæ­£æ ·æœ¬ï¼‰ã€‚\n",
    "\n",
    "æ¨¡å‹è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
    "1. ç”¨$V$å»æŸ¥è¯¢$W_0$ï¼Œç”¨$T$å»æŸ¥è¯¢$W_1$ï¼Œåˆ†åˆ«å¾—åˆ°ä¸¤ä¸ªå½¢çŠ¶ä¸º[batch_size, embedding_size]çš„tensorï¼Œè®°ä¸º$H_1$å’Œ$H_2$ã€‚\n",
    "1. ç‚¹ä¹˜è¿™ä¸¤ä¸ªtensorï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªå½¢çŠ¶ä¸º[batch_size]çš„tensor  $O = [O_i = \\sum_j H_0[i,j] Ã— H_1[i,j]]_{i=1}^{batch\\_size}$ã€‚\n",
    "1. ä½¿ç”¨sigmoidå‡½æ•°ä½œç”¨åœ¨$O$ä¸Šï¼Œå°†ä¸Šè¿°ç‚¹ä¹˜çš„ç»“æœå½’ä¸€åŒ–ä¸ºä¸€ä¸ª0-1çš„æ¦‚ç‡å€¼ï¼Œä½œä¸ºé¢„æµ‹æ¦‚ç‡ï¼Œæ ¹æ®æ ‡ç­¾ä¿¡æ¯$L$è®­ç»ƒè¿™ä¸ªæ¨¡å‹å³å¯ã€‚\n",
    "\n",
    "åœ¨ç»“æŸæ¨¡å‹è®­ç»ƒä¹‹åï¼Œä¸€èˆ¬ä½¿ç”¨$W_0$ä½œä¸ºæœ€ç»ˆè¦ä½¿ç”¨çš„è¯å‘é‡ï¼Œå¯ä»¥ç”¨$W_0$æä¾›çš„å‘é‡è¡¨ç¤ºã€‚é€šè¿‡å‘é‡ç‚¹ä¹˜çš„æ–¹å¼ï¼Œè®¡ç®—ä¸¤ä¸ªä¸åŒè¯ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ä½¿ç”¨é£æ¡¨å®ç°Skip-gram\n",
    "\n",
    "æ¥ä¸‹æ¥æˆ‘ä»¬å°†å­¦ä¹ ä½¿ç”¨é£æ¡¨å®ç°Skip-gramæ¨¡å‹çš„æ–¹æ³•ã€‚åœ¨é£æ¡¨ä¸­ï¼Œä¸åŒæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹åŸºæœ¬ä¸€è‡´ï¼Œæµç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. **æ•°æ®å¤„ç†**ï¼šé€‰æ‹©éœ€è¦ä½¿ç”¨çš„æ•°æ®ï¼Œå¹¶åšå¥½å¿…è¦çš„é¢„å¤„ç†å·¥ä½œã€‚\n",
    "\n",
    "2. **ç½‘ç»œå®šä¹‰**ï¼šä½¿ç”¨é£æ¡¨å®šä¹‰å¥½ç½‘ç»œç»“æ„ï¼ŒåŒ…æ‹¬è¾“å…¥å±‚ï¼Œä¸­é—´å±‚ï¼Œè¾“å‡ºå±‚ï¼ŒæŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•ã€‚\n",
    "\n",
    "3. **ç½‘ç»œè®­ç»ƒ**ï¼šå°†å‡†å¤‡å¥½çš„æ•°æ®é€å…¥ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ï¼Œå¹¶è§‚å¯Ÿå­¦ä¹ çš„è¿‡ç¨‹æ˜¯å¦æ­£å¸¸ï¼Œå¦‚æŸå¤±å‡½æ•°å€¼æ˜¯å¦åœ¨é™ä½ï¼Œä¹Ÿå¯ä»¥æ‰“å°ä¸€äº›ä¸­é—´æ­¥éª¤çš„ç»“æœå‡ºæ¥ç­‰ã€‚\n",
    "\n",
    "4. **ç½‘ç»œè¯„ä¼°**ï¼šä½¿ç”¨æµ‹è¯•é›†åˆæµ‹è¯•è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œï¼Œçœ‹çœ‹è®­ç»ƒæ•ˆæœå¦‚ä½•ã€‚\n",
    "\n",
    "åœ¨æ•°æ®å¤„ç†å‰ï¼Œéœ€è¦å…ˆåŠ è½½é£æ¡¨å¹³å°ï¼ˆå¦‚æœç”¨æˆ·åœ¨æœ¬åœ°ä½¿ç”¨ï¼Œè¯·ç¡®ä¿å·²ç»å®‰è£…é£æ¡¨ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encoding=utf8\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from collections import OrderedDict \n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.nn import Embedding\n",
    "import paddle.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### æ•°æ®å¤„ç†\n",
    "\n",
    "é¦–å…ˆï¼Œæ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„è¯­æ–™ç”¨äºè®­ç»ƒword2vecæ¨¡å‹ã€‚ä½¿ç”¨text8æ•°æ®é›†ï¼Œè¿™ä¸ªæ•°æ®é›†é‡ŒåŒ…å«äº†å¤§é‡ä»ç»´åŸºç™¾ç§‘æ”¶é›†åˆ°çš„è‹±æ–‡è¯­æ–™ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¦‚ä¸‹ä»£ç ä¸‹è½½æ•°æ®é›†ï¼Œä¸‹è½½åçš„æ–‡ä»¶è¢«ä¿å­˜åœ¨å½“å‰ç›®å½•çš„â€œtext8.txtâ€æ–‡ä»¶å†…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ä¸‹è½½è¯­æ–™ç”¨æ¥è®­ç»ƒword2vec\n",
    "def download():\n",
    "    # å¯ä»¥ä»ç™¾åº¦äº‘æœåŠ¡å™¨ä¸‹è½½ä¸€äº›å¼€æºæ•°æ®é›†ï¼ˆdataset.bj.bcebos.comï¼‰\n",
    "    corpus_url = \"https://dataset.bj.bcebos.com/word2vec/text8.txt\"\n",
    "    # ä½¿ç”¨pythonçš„requestsåŒ…ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°\n",
    "    web_request = requests.get(corpus_url)\n",
    "    corpus = web_request.content\n",
    "    # æŠŠä¸‹è½½åçš„æ–‡ä»¶å­˜å‚¨åœ¨å½“å‰ç›®å½•çš„text8.txtæ–‡ä»¶å†…\n",
    "    with open(\"./text8.txt\", \"wb\") as f:\n",
    "        f.write(corpus)\n",
    "    f.close()\n",
    "download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "æ¥ä¸‹æ¥ï¼ŒæŠŠä¸‹è½½çš„è¯­æ–™è¯»å–åˆ°ç¨‹åºé‡Œï¼Œå¹¶æ‰“å°å‰500ä¸ªå­—ç¬¦æŸ¥çœ‹è¯­æ–™çš„æ ¼å¼ï¼Œä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philoso\n"
     ]
    }
   ],
   "source": [
    "# è¯»å–text8æ•°æ®\n",
    "def load_text8():\n",
    "    with open(\"./text8.txt\", \"r\") as f:\n",
    "        corpus = f.read().strip(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    return corpus\n",
    "\n",
    "corpus = load_text8()\n",
    "\n",
    "# æ‰“å°å‰500ä¸ªå­—ç¬¦ï¼Œç®€è¦çœ‹ä¸€ä¸‹è¿™ä¸ªè¯­æ–™çš„æ ·å­\n",
    "print(corpus[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ä¸€èˆ¬æ¥è¯´ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œéœ€è¦å…ˆå¯¹è¯­æ–™è¿›è¡Œåˆ‡è¯ã€‚å¯¹äºè‹±æ–‡æ¥è¯´ï¼Œå¯ä»¥æ¯”è¾ƒç®€å•åœ°ç›´æ¥ä½¿ç”¨ç©ºæ ¼è¿›è¡Œåˆ‡è¯ï¼Œä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst', 'the', 'term', 'is', 'still', 'used', 'in', 'a', 'pejorative', 'way', 'to', 'describe', 'any', 'act', 'that', 'used', 'violent', 'means', 'to', 'destroy', 'the']\n"
     ]
    }
   ],
   "source": [
    "# å¯¹è¯­æ–™è¿›è¡Œé¢„å¤„ç†ï¼ˆåˆ†è¯ï¼‰\n",
    "def data_preprocess(corpus):\n",
    "    # ç”±äºè‹±æ–‡å•è¯å‡ºç°åœ¨å¥é¦–çš„æ—¶å€™ç»å¸¸è¦å¤§å†™ï¼Œæ‰€ä»¥æˆ‘ä»¬æŠŠæ‰€æœ‰è‹±æ–‡å­—ç¬¦éƒ½è½¬æ¢ä¸ºå°å†™ï¼Œ\n",
    "    # ä»¥ä¾¿å¯¹è¯­æ–™è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼ˆApple vs appleç­‰ï¼‰\n",
    "    corpus = corpus.strip().lower()\n",
    "    corpus = corpus.split(\" \")\n",
    "    return corpus\n",
    "\n",
    "corpus = data_preprocess(corpus)\n",
    "print(corpus[:50])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "åœ¨ç»è¿‡åˆ‡è¯åï¼Œéœ€è¦å¯¹è¯­æ–™è¿›è¡Œç»Ÿè®¡ï¼Œä¸ºæ¯ä¸ªè¯æ„é€ IDã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¯ä»¥æ ¹æ®æ¯ä¸ªè¯åœ¨è¯­æ–™ä¸­å‡ºç°çš„é¢‘æ¬¡æ„é€ IDï¼Œé¢‘æ¬¡è¶Šé«˜ï¼ŒIDè¶Šå°ï¼Œä¾¿äºå¯¹è¯å…¸è¿›è¡Œç®¡ç†ã€‚ä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are totoally 253854 different words in the corpus\n",
      "word the, its id 0, its word freq 1061396\n",
      "word of, its id 1, its word freq 593677\n",
      "word and, its id 2, its word freq 416629\n",
      "word one, its id 3, its word freq 411764\n",
      "word in, its id 4, its word freq 372201\n",
      "word a, its id 5, its word freq 325873\n",
      "word to, its id 6, its word freq 316376\n",
      "word zero, its id 7, its word freq 264975\n",
      "word nine, its id 8, its word freq 250430\n",
      "word two, its id 9, its word freq 192644\n",
      "word is, its id 10, its word freq 183153\n",
      "word as, its id 11, its word freq 131815\n",
      "word eight, its id 12, its word freq 125285\n",
      "word for, its id 13, its word freq 118445\n",
      "word s, its id 14, its word freq 116710\n",
      "word five, its id 15, its word freq 115789\n",
      "word three, its id 16, its word freq 114775\n",
      "word was, its id 17, its word freq 112807\n",
      "word by, its id 18, its word freq 111831\n",
      "word that, its id 19, its word freq 109510\n",
      "word four, its id 20, its word freq 108182\n",
      "word six, its id 21, its word freq 102145\n",
      "word seven, its id 22, its word freq 99683\n",
      "word with, its id 23, its word freq 95603\n",
      "word on, its id 24, its word freq 91250\n",
      "word are, its id 25, its word freq 76527\n",
      "word it, its id 26, its word freq 73334\n",
      "word from, its id 27, its word freq 72871\n",
      "word or, its id 28, its word freq 68945\n",
      "word his, its id 29, its word freq 62603\n",
      "word an, its id 30, its word freq 61925\n",
      "word be, its id 31, its word freq 61281\n",
      "word this, its id 32, its word freq 58832\n",
      "word which, its id 33, its word freq 54788\n",
      "word at, its id 34, its word freq 54576\n",
      "word he, its id 35, its word freq 53573\n",
      "word also, its id 36, its word freq 44358\n",
      "word not, its id 37, its word freq 44033\n",
      "word have, its id 38, its word freq 39712\n",
      "word were, its id 39, its word freq 39086\n",
      "word has, its id 40, its word freq 37866\n",
      "word but, its id 41, its word freq 35358\n",
      "word other, its id 42, its word freq 32433\n",
      "word their, its id 43, its word freq 31523\n",
      "word its, its id 44, its word freq 29567\n",
      "word first, its id 45, its word freq 28810\n",
      "word they, its id 46, its word freq 28553\n",
      "word some, its id 47, its word freq 28161\n",
      "word had, its id 48, its word freq 28100\n",
      "word all, its id 49, its word freq 26229\n"
     ]
    }
   ],
   "source": [
    "# æ„é€ è¯å…¸ï¼Œç»Ÿè®¡æ¯ä¸ªè¯çš„é¢‘ç‡ï¼Œå¹¶æ ¹æ®é¢‘ç‡å°†æ¯ä¸ªè¯è½¬æ¢ä¸ºä¸€ä¸ªæ•´æ•°id\n",
    "def build_dict(corpus):\n",
    "    # é¦–å…ˆç»Ÿè®¡æ¯ä¸ªä¸åŒè¯çš„é¢‘ç‡ï¼ˆå‡ºç°çš„æ¬¡æ•°ï¼‰ï¼Œä½¿ç”¨ä¸€ä¸ªè¯å…¸è®°å½•\n",
    "    word_freq_dict = dict()\n",
    "    for word in corpus:\n",
    "        if word not in word_freq_dict:\n",
    "            word_freq_dict[word] = 0\n",
    "        word_freq_dict[word] += 1\n",
    "\n",
    "    # å°†è¿™ä¸ªè¯å…¸ä¸­çš„è¯ï¼ŒæŒ‰ç…§å‡ºç°æ¬¡æ•°æ’åºï¼Œå‡ºç°æ¬¡æ•°è¶Šé«˜ï¼Œæ’åºè¶Šé å‰\n",
    "    # ä¸€èˆ¬æ¥è¯´ï¼Œå‡ºç°é¢‘ç‡é«˜çš„é«˜é¢‘è¯å¾€å¾€æ˜¯ï¼šIï¼Œtheï¼Œyouè¿™ç§ä»£è¯ï¼Œè€Œå‡ºç°é¢‘ç‡ä½çš„è¯ï¼Œå¾€å¾€æ˜¯ä¸€äº›åè¯ï¼Œå¦‚ï¼šnlp\n",
    "    word_freq_dict = sorted(word_freq_dict.items(), key = lambda x:x[1], reverse = True)\n",
    "    \n",
    "    # æ„é€ 3ä¸ªä¸åŒçš„è¯å…¸ï¼Œåˆ†åˆ«å­˜å‚¨ï¼Œ\n",
    "    # æ¯ä¸ªè¯åˆ°idçš„æ˜ å°„å…³ç³»ï¼šword2id_dict\n",
    "    # æ¯ä¸ªidå‡ºç°çš„é¢‘ç‡ï¼šword2id_freq\n",
    "    # æ¯ä¸ªidåˆ°è¯çš„æ˜ å°„å…³ç³»ï¼šid2word_dict\n",
    "    word2id_dict = dict()\n",
    "    word2id_freq = dict()\n",
    "    id2word_dict = dict()\n",
    "\n",
    "    # æŒ‰ç…§é¢‘ç‡ï¼Œä»é«˜åˆ°ä½ï¼Œå¼€å§‹éå†æ¯ä¸ªå•è¯ï¼Œå¹¶ä¸ºè¿™ä¸ªå•è¯æ„é€ ä¸€ä¸ªç‹¬ä¸€æ— äºŒçš„id\n",
    "    for word, freq in word_freq_dict:\n",
    "        curr_id = len(word2id_dict)\n",
    "        word2id_dict[word] = curr_id\n",
    "        word2id_freq[word2id_dict[word]] = freq\n",
    "        id2word_dict[curr_id] = word\n",
    "\n",
    "    return word2id_freq, word2id_dict, id2word_dict\n",
    "\n",
    "word2id_freq, word2id_dict, id2word_dict = build_dict(corpus)\n",
    "vocab_size = len(word2id_freq)\n",
    "print(\"there are totoally %d different words in the corpus\" % vocab_size)\n",
    "for _, (word, word_id) in zip(range(50), word2id_dict.items()):\n",
    "    print(\"word %s, its id %d, its word freq %d\" % (word, word_id, word2id_freq[word_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "å¾—åˆ°word2idè¯å…¸åï¼Œè¿˜éœ€è¦è¿›ä¸€æ­¥å¤„ç†åŸå§‹è¯­æ–™ï¼ŒæŠŠæ¯ä¸ªè¯æ›¿æ¢æˆå¯¹åº”çš„IDï¼Œä¾¿äºç¥ç»ç½‘ç»œè¿›è¡Œå¤„ç†ï¼Œä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17005207 tokens in the corpus\n",
      "[5233, 3080, 11, 5, 194, 1, 3133, 45, 58, 155, 127, 741, 476, 10571, 133, 0, 27349, 1, 0, 102, 854, 2, 0, 15067, 58112, 1, 0, 150, 854, 3580, 0, 194, 10, 190, 58, 4, 5, 10712, 214, 6, 1324, 104, 454, 19, 58, 2731, 362, 6, 3672, 0]\n"
     ]
    }
   ],
   "source": [
    "# æŠŠè¯­æ–™è½¬æ¢ä¸ºidåºåˆ—\n",
    "def convert_corpus_to_id(corpus, word2id_dict):\n",
    "    # ä½¿ç”¨ä¸€ä¸ªå¾ªç¯ï¼Œå°†è¯­æ–™ä¸­çš„æ¯ä¸ªè¯æ›¿æ¢æˆå¯¹åº”çš„idï¼Œä»¥ä¾¿äºç¥ç»ç½‘ç»œè¿›è¡Œå¤„ç†\n",
    "    corpus = [word2id_dict[word] for word in corpus]\n",
    "    return corpus\n",
    "\n",
    "corpus = convert_corpus_to_id(corpus, word2id_dict)\n",
    "print(\"%d tokens in the corpus\" % len(corpus))\n",
    "print(corpus[:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "æ¥ä¸‹æ¥ï¼Œéœ€è¦ä½¿ç”¨äºŒæ¬¡é‡‡æ ·æ³•å¤„ç†åŸå§‹æ–‡æœ¬ã€‚äºŒæ¬¡é‡‡æ ·æ³•çš„ä¸»è¦æ€æƒ³æ˜¯é™ä½é«˜é¢‘è¯åœ¨è¯­æ–™ä¸­å‡ºç°çš„é¢‘æ¬¡ã€‚æ–¹æ³•æ˜¯éšæœºå°†é«˜é¢‘çš„è¯æŠ›å¼ƒï¼Œé¢‘ç‡è¶Šé«˜ï¼Œè¢«æŠ›å¼ƒçš„æ¦‚ç‡å°±è¶Šå¤§ï¼›é¢‘ç‡è¶Šä½ï¼Œè¢«æŠ›å¼ƒçš„æ¦‚ç‡å°±è¶Šå°ã€‚æ ‡ç‚¹ç¬¦å·æˆ–å† è¯è¿™æ ·çš„é«˜é¢‘è¯å°±ä¼šè¢«æŠ›å¼ƒï¼Œä»è€Œä¼˜åŒ–æ•´ä¸ªè¯è¡¨çš„è¯å‘é‡è®­ç»ƒæ•ˆæœï¼Œä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8743397 tokens in the corpus\n",
      "[5233, 3080, 3133, 155, 741, 476, 10571, 133, 27349, 854, 2, 15067, 58112, 150, 854, 3580, 190, 10712, 1324, 104, 58, 2731, 362, 3672, 40, 36, 97, 1423, 2757, 567, 686, 7088, 247, 5233, 1052, 248, 44611, 2877, 792, 5233, 200, 602, 10, 1134, 2621, 8983, 279, 4147, 6437, 4186]\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨äºŒæ¬¡é‡‡æ ·ç®—æ³•ï¼ˆsubsamplingï¼‰å¤„ç†è¯­æ–™ï¼Œå¼ºåŒ–è®­ç»ƒæ•ˆæœ\n",
    "def subsampling(corpus, word2id_freq):\n",
    "    \n",
    "    # è¿™ä¸ªdiscardå‡½æ•°å†³å®šäº†ä¸€ä¸ªè¯ä¼šä¸ä¼šè¢«æ›¿æ¢ï¼Œè¿™ä¸ªå‡½æ•°æ˜¯å…·æœ‰éšæœºæ€§çš„ï¼Œæ¯æ¬¡è°ƒç”¨ç»“æœä¸åŒ\n",
    "    # å¦‚æœä¸€ä¸ªè¯çš„é¢‘ç‡å¾ˆå¤§ï¼Œé‚£ä¹ˆå®ƒè¢«é—å¼ƒçš„æ¦‚ç‡å°±å¾ˆå¤§\n",
    "    def discard(word_id):\n",
    "        return random.uniform(0, 1) < 1 - math.sqrt(\n",
    "            1e-4 / word2id_freq[word_id] * len(corpus))\n",
    "\n",
    "    corpus = [word for word in corpus if not discard(word)]\n",
    "    return corpus\n",
    "\n",
    "corpus = subsampling(corpus, word2id_freq)\n",
    "print(\"%d tokens in the corpus\" % len(corpus))\n",
    "print(corpus[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "åœ¨å®Œæˆè¯­æ–™æ•°æ®é¢„å¤„ç†ä¹‹åï¼Œéœ€è¦æ„é€ è®­ç»ƒæ•°æ®ã€‚æ ¹æ®ä¸Šé¢çš„æè¿°ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€ä¸ªæ»‘åŠ¨çª—å£å¯¹è¯­æ–™ä»å·¦åˆ°å³æ‰«æï¼Œåœ¨æ¯ä¸ªçª—å£å†…ï¼Œä¸­å¿ƒè¯éœ€è¦é¢„æµ‹å®ƒçš„ä¸Šä¸‹æ–‡ï¼Œå¹¶å½¢æˆè®­ç»ƒæ•°æ®ã€‚\n",
    "\n",
    "åœ¨å®é™…æ“ä½œä¸­ï¼Œç”±äºè¯è¡¨å¾€å¾€å¾ˆå¤§ï¼ˆ50000ï¼Œ100000ç­‰ï¼‰ï¼Œå¯¹å¤§è¯è¡¨çš„ä¸€äº›çŸ©é˜µè¿ç®—ï¼ˆå¦‚softmaxï¼‰éœ€è¦æ¶ˆè€—å·¨å¤§çš„èµ„æºï¼Œå› æ­¤å¯ä»¥é€šè¿‡è´Ÿé‡‡æ ·çš„æ–¹å¼æ¨¡æ‹Ÿsoftmaxçš„ç»“æœã€‚\n",
    "\n",
    "* ç»™å®šä¸€ä¸ªä¸­å¿ƒè¯å’Œä¸€ä¸ªéœ€è¦é¢„æµ‹çš„ä¸Šä¸‹æ–‡è¯ï¼ŒæŠŠè¿™ä¸ªä¸Šä¸‹æ–‡è¯ä½œä¸ºæ­£æ ·æœ¬ã€‚\n",
    "* é€šè¿‡è¯è¡¨éšæœºé‡‡æ ·çš„æ–¹å¼ï¼Œé€‰æ‹©è‹¥å¹²ä¸ªè´Ÿæ ·æœ¬ã€‚\n",
    "* æŠŠä¸€ä¸ªå¤§è§„æ¨¡åˆ†ç±»é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ª2åˆ†ç±»é—®é¢˜ï¼Œé€šè¿‡è¿™ç§æ–¹å¼ä¼˜åŒ–è®¡ç®—é€Ÿåº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center_word anarchism, target originated, label 1\n",
      "center_word anarchism, target armorican, label 0\n",
      "center_word anarchism, target zarzaparrilla, label 0\n",
      "center_word anarchism, target lophanthus, label 0\n",
      "center_word anarchism, target tellier, label 0\n",
      "center_word anarchism, target as, label 1\n",
      "center_word anarchism, target puniceus, label 0\n",
      "center_word anarchism, target mural, label 0\n",
      "center_word anarchism, target sailendras, label 0\n",
      "center_word anarchism, target naylan, label 0\n",
      "center_word originated, target anarchism, label 1\n",
      "center_word originated, target werburgh, label 0\n",
      "center_word originated, target muratti, label 0\n",
      "center_word originated, target condomize, label 0\n",
      "center_word originated, target vrijheit, label 0\n",
      "center_word originated, target as, label 1\n",
      "center_word originated, target universalists, label 0\n",
      "center_word originated, target hunt, label 0\n",
      "center_word originated, target tallentyre, label 0\n",
      "center_word originated, target showbusiness, label 0\n",
      "center_word originated, target a, label 1\n",
      "center_word originated, target flatrock, label 0\n",
      "center_word originated, target asf, label 0\n",
      "center_word originated, target hereticii, label 0\n",
      "center_word originated, target synthetist, label 0\n",
      "center_word originated, target term, label 1\n",
      "center_word originated, target jidan, label 0\n",
      "center_word originated, target openspectrum, label 0\n",
      "center_word originated, target pozna, label 0\n",
      "center_word originated, target crewman, label 0\n",
      "center_word as, target anarchism, label 1\n",
      "center_word as, target midday, label 0\n",
      "center_word as, target draga, label 0\n",
      "center_word as, target ivory, label 0\n",
      "center_word as, target ngamiland, label 0\n",
      "center_word as, target originated, label 1\n",
      "center_word as, target nezha, label 0\n",
      "center_word as, target wreyford, label 0\n",
      "center_word as, target backported, label 0\n",
      "center_word as, target anomalist, label 0\n",
      "center_word as, target a, label 1\n",
      "center_word as, target kyklos, label 0\n",
      "center_word as, target hemophiliac, label 0\n",
      "center_word as, target prey, label 0\n",
      "center_word as, target deogratias, label 0\n",
      "center_word as, target term, label 1\n",
      "center_word as, target mcgeoch, label 0\n",
      "center_word as, target auriti, label 0\n",
      "center_word as, target ipsp, label 0\n",
      "center_word as, target kdatlyno, label 0\n"
     ]
    }
   ],
   "source": [
    "# æ„é€ æ•°æ®ï¼Œå‡†å¤‡æ¨¡å‹è®­ç»ƒ\n",
    "# max_window_sizeä»£è¡¨äº†æœ€å¤§çš„window_sizeçš„å¤§å°ï¼Œç¨‹åºä¼šæ ¹æ®max_window_sizeä»å·¦åˆ°å³æ‰«ææ•´ä¸ªè¯­æ–™\n",
    "# negative_sample_numä»£è¡¨äº†å¯¹äºæ¯ä¸ªæ­£æ ·æœ¬ï¼Œæˆ‘ä»¬éœ€è¦éšæœºé‡‡æ ·å¤šå°‘è´Ÿæ ·æœ¬ç”¨äºè®­ç»ƒï¼Œ\n",
    "# ä¸€èˆ¬æ¥è¯´ï¼Œnegative_sample_numçš„å€¼è¶Šå¤§ï¼Œè®­ç»ƒæ•ˆæœè¶Šç¨³å®šï¼Œä½†æ˜¯è®­ç»ƒé€Ÿåº¦è¶Šæ…¢ã€‚ \n",
    "def build_data(corpus, word2id_dict, word2id_freq, max_window_size = 3, negative_sample_num = 4):\n",
    "    \n",
    "    # ä½¿ç”¨ä¸€ä¸ªlistå­˜å‚¨å¤„ç†å¥½çš„æ•°æ®\n",
    "    dataset = []\n",
    "\n",
    "    # ä»å·¦åˆ°å³ï¼Œå¼€å§‹æšä¸¾æ¯ä¸ªä¸­å¿ƒç‚¹çš„ä½ç½®\n",
    "    for center_word_idx in range(len(corpus)):\n",
    "        # ä»¥max_window_sizeä¸ºä¸Šé™ï¼Œéšæœºé‡‡æ ·ä¸€ä¸ªwindow_sizeï¼Œè¿™æ ·ä¼šä½¿å¾—è®­ç»ƒæ›´åŠ ç¨³å®š\n",
    "        window_size = random.randint(1, max_window_size)\n",
    "        # å½“å‰çš„ä¸­å¿ƒè¯å°±æ˜¯center_word_idxæ‰€æŒ‡å‘çš„è¯\n",
    "        center_word = corpus[center_word_idx]\n",
    "\n",
    "        # ä»¥å½“å‰ä¸­å¿ƒè¯ä¸ºä¸­å¿ƒï¼Œå·¦å³ä¸¤ä¾§åœ¨window_sizeå†…çš„è¯éƒ½å¯ä»¥çœ‹æˆæ˜¯æ­£æ ·æœ¬\n",
    "        positive_word_range = (max(0, center_word_idx - window_size), min(len(corpus) - 1, center_word_idx + window_size))\n",
    "        positive_word_candidates = [corpus[idx] for idx in range(positive_word_range[0], positive_word_range[1]+1) if idx != center_word_idx]\n",
    "\n",
    "        # å¯¹äºæ¯ä¸ªæ­£æ ·æœ¬æ¥è¯´ï¼Œéšæœºé‡‡æ ·negative_sample_numä¸ªè´Ÿæ ·æœ¬ï¼Œç”¨äºè®­ç»ƒ\n",
    "        for positive_word in positive_word_candidates:\n",
    "            # é¦–å…ˆæŠŠï¼ˆä¸­å¿ƒè¯ï¼Œæ­£æ ·æœ¬ï¼Œlabel=1ï¼‰çš„ä¸‰å…ƒç»„æ•°æ®æ”¾å…¥datasetä¸­ï¼Œ\n",
    "            # è¿™é‡Œlabel=1è¡¨ç¤ºè¿™ä¸ªæ ·æœ¬æ˜¯ä¸ªæ­£æ ·æœ¬\n",
    "            dataset.append((center_word, positive_word, 1))\n",
    "\n",
    "            # å¼€å§‹è´Ÿé‡‡æ ·\n",
    "            i = 0\n",
    "            while i < negative_sample_num:\n",
    "                negative_word_candidate = random.randint(0, vocab_size-1)\n",
    "\n",
    "                if negative_word_candidate not in positive_word_candidates:\n",
    "                    # æŠŠï¼ˆä¸­å¿ƒè¯ï¼Œæ­£æ ·æœ¬ï¼Œlabel=0ï¼‰çš„ä¸‰å…ƒç»„æ•°æ®æ”¾å…¥datasetä¸­ï¼Œ\n",
    "                    # è¿™é‡Œlabel=0è¡¨ç¤ºè¿™ä¸ªæ ·æœ¬æ˜¯ä¸ªè´Ÿæ ·æœ¬\n",
    "                    dataset.append((center_word, negative_word_candidate, 0))\n",
    "                    i += 1\n",
    "    return dataset\n",
    "corpus_light = corpus[:int(len(corpus)*0.2)]\n",
    "dataset = build_data(corpus_light, word2id_dict, word2id_freq)\n",
    "for _, (center_word, target_word, label) in zip(range(50), dataset):\n",
    "    print(\"center_word %s, target %s, label %d\" % (id2word_dict[center_word],\n",
    "                                                   id2word_dict[target_word], label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " è®­ç»ƒæ•°æ®å‡†å¤‡å¥½åï¼ŒæŠŠè®­ç»ƒæ•°æ®éƒ½ç»„è£…æˆmini-batchï¼Œå¹¶å‡†å¤‡è¾“å…¥åˆ°ç½‘ç»œä¸­è¿›è¡Œè®­ç»ƒï¼Œä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32))\r"
     ]
    }
   ],
   "source": [
    "# æ„é€ mini-batchï¼Œå‡†å¤‡å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒ\n",
    "# æˆ‘ä»¬å°†ä¸åŒç±»å‹çš„æ•°æ®æ”¾åˆ°ä¸åŒçš„tensoré‡Œï¼Œä¾¿äºç¥ç»ç½‘ç»œè¿›è¡Œå¤„ç†\n",
    "# å¹¶é€šè¿‡numpyçš„arrayå‡½æ•°ï¼Œæ„é€ å‡ºä¸åŒçš„tensoræ¥ï¼Œå¹¶æŠŠè¿™äº›tensoré€å…¥ç¥ç»ç½‘ç»œä¸­è¿›è¡Œè®­ç»ƒ\n",
    "def build_batch(dataset, batch_size, epoch_num):\n",
    "    \n",
    "    # center_word_batchç¼“å­˜batch_sizeä¸ªä¸­å¿ƒè¯\n",
    "    center_word_batch = []\n",
    "    # target_word_batchç¼“å­˜batch_sizeä¸ªç›®æ ‡è¯ï¼ˆå¯ä»¥æ˜¯æ­£æ ·æœ¬æˆ–è€…è´Ÿæ ·æœ¬ï¼‰\n",
    "    target_word_batch = []\n",
    "    # label_batchç¼“å­˜äº†batch_sizeä¸ª0æˆ–1çš„æ ‡ç­¾ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒ\n",
    "    label_batch = []\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        # æ¯æ¬¡å¼€å¯ä¸€ä¸ªæ–°epochä¹‹å‰ï¼Œéƒ½å¯¹æ•°æ®è¿›è¡Œä¸€æ¬¡éšæœºæ‰“ä¹±ï¼Œæé«˜è®­ç»ƒæ•ˆæœ\n",
    "        random.shuffle(dataset)\n",
    "        \n",
    "        for center_word, target_word, label in dataset:\n",
    "            # éå†datasetä¸­çš„æ¯ä¸ªæ ·æœ¬ï¼Œå¹¶å°†è¿™äº›æ•°æ®é€åˆ°ä¸åŒçš„tensoré‡Œ\n",
    "            center_word_batch.append([center_word])\n",
    "            target_word_batch.append([target_word])\n",
    "            label_batch.append(label)\n",
    "\n",
    "            # å½“æ ·æœ¬ç§¯æ”’åˆ°ä¸€ä¸ªbatch_sizeåï¼Œæˆ‘ä»¬æŠŠæ•°æ®éƒ½è¿”å›å›æ¥\n",
    "            # åœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨numpyçš„arrayå‡½æ•°æŠŠlistå°è£…æˆtensor\n",
    "            # å¹¶ä½¿ç”¨pythonçš„è¿­ä»£å™¨æœºåˆ¶ï¼Œå°†æ•°æ®yieldå‡ºæ¥\n",
    "            # ä½¿ç”¨è¿­ä»£å™¨çš„å¥½å¤„æ˜¯å¯ä»¥èŠ‚çœå†…å­˜\n",
    "            if len(center_word_batch) == batch_size:\n",
    "                yield np.array(center_word_batch).astype(\"int64\"), \\\n",
    "                    np.array(target_word_batch).astype(\"int64\"), \\\n",
    "                    np.array(label_batch).astype(\"float32\")\n",
    "                center_word_batch = []\n",
    "                target_word_batch = []\n",
    "                label_batch = []\n",
    "\n",
    "    if len(center_word_batch) > 0:\n",
    "        yield np.array(center_word_batch).astype(\"int64\"), \\\n",
    "            np.array(target_word_batch).astype(\"int64\"), \\\n",
    "            np.array(label_batch).astype(\"float32\")\n",
    "\n",
    "for _, batch in zip(range(10), build_batch(dataset, 128, 3)):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ç½‘ç»œå®šä¹‰\n",
    "\n",
    "å®šä¹‰skip-gramçš„ç½‘ç»œç»“æ„ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒã€‚åœ¨é£æ¡¨åŠ¨æ€å›¾ä¸­ï¼Œå¯¹äºä»»æ„ç½‘ç»œï¼Œéƒ½éœ€è¦å®šä¹‰ä¸€ä¸ªç»§æ‰¿è‡ª`paddle.nn.layer`çš„ç±»æ¥æ­å»ºç½‘ç»œç»“æ„ã€å‚æ•°ç­‰æ•°æ®çš„å£°æ˜ã€‚åŒæ—¶éœ€è¦åœ¨`forward`å‡½æ•°ä¸­å®šä¹‰ç½‘ç»œçš„è®¡ç®—é€»è¾‘ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä»…éœ€è¦å®šä¹‰ç½‘ç»œçš„å‰å‘è®¡ç®—é€»è¾‘ï¼Œé£æ¡¨ä¼šè‡ªåŠ¨å®Œæˆç¥ç»ç½‘ç»œçš„åå‘è®¡ç®—ã€‚\n",
    "\n",
    "åœ¨skip-gramçš„ç½‘ç»œç»“æ„ä¸­ï¼Œä½¿ç”¨çš„æœ€å…³é”®çš„APiæ˜¯[paddle.nn.Embedding](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/layer/common/Embedding_cn.html)å‡½æ•°ï¼Œå¯ä»¥ç”¨å…¶å®ç°Embeddingçš„ç½‘ç»œå±‚ã€‚é€šè¿‡æŸ¥è¯¢é£æ¡¨çš„APIæ–‡æ¡£ï¼Œå¯ä»¥å¾—åˆ°å¦‚ä¸‹æ›´è¯¦ç»†çš„è¯´æ˜ï¼š\n",
    "\n",
    "> paddle.nn.Embedding(numembeddings, embeddingdim, paddingidx=None, sparse=False, weightattr=None, name=None)\n",
    "\n",
    "è¯¥æ¥å£ç”¨äºæ„å»º Embedding çš„ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œå…¶æ ¹æ®inputä¸­çš„idä¿¡æ¯ä»embeddingçŸ©é˜µä¸­æŸ¥è¯¢å¯¹åº”embeddingä¿¡æ¯ï¼Œå¹¶ä¼šæ ¹æ®è¾“å…¥çš„size (numembeddings, embeddingdim)è‡ªåŠ¨æ„é€ ä¸€ä¸ªäºŒç»´embeddingçŸ©é˜µã€‚ è¾“å‡ºTensorçš„shapeæ˜¯åœ¨è¾“å…¥Tensor shapeçš„æœ€åä¸€ç»´åé¢æ·»åŠ äº†emb_sizeçš„ç»´åº¦ã€‚æ³¨ï¼šinputä¸­çš„idå¿…é¡»æ»¡è¶³ 0 =< id < size[0]ï¼Œå¦åˆ™ç¨‹åºä¼šæŠ›å¼‚å¸¸é€€å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#å®šä¹‰skip-gramè®­ç»ƒç½‘ç»œç»“æ„\n",
    "#ä½¿ç”¨paddlepaddleçš„2.0.0ç‰ˆæœ¬\n",
    "#ä¸€èˆ¬æ¥è¯´ï¼Œåœ¨ä½¿ç”¨paddleè®­ç»ƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡ä¸€ä¸ªç±»æ¥å®šä¹‰ç½‘ç»œç»“æ„ï¼Œè¿™ä¸ªç±»ç»§æ‰¿äº†paddle.nn.layer\n",
    "class SkipGram(paddle.nn.Layer):\n",
    "    def __init__(self, vocab_size, embedding_size, init_scale=0.1):\n",
    "        # vocab_sizeå®šä¹‰äº†è¿™ä¸ªskipgramè¿™ä¸ªæ¨¡å‹çš„è¯è¡¨å¤§å°\n",
    "        # embedding_sizeå®šä¹‰äº†è¯å‘é‡çš„ç»´åº¦æ˜¯å¤šå°‘\n",
    "        # init_scaleå®šä¹‰äº†è¯å‘é‡åˆå§‹åŒ–çš„èŒƒå›´ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œæ¯”è¾ƒå°çš„åˆå§‹åŒ–èŒƒå›´æœ‰åŠ©äºæ¨¡å‹è®­ç»ƒ\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # ä½¿ç”¨Embeddingå‡½æ•°æ„é€ ä¸€ä¸ªè¯å‘é‡å‚æ•°\n",
    "        # è¿™ä¸ªå‚æ•°çš„å¤§å°ä¸ºï¼š[self.vocab_size, self.embedding_size]\n",
    "        # æ•°æ®ç±»å‹ä¸ºï¼šfloat32\n",
    "        # è¿™ä¸ªå‚æ•°çš„åç§°ä¸ºï¼šembedding_para\n",
    "        # è¿™ä¸ªå‚æ•°çš„åˆå§‹åŒ–æ–¹å¼ä¸ºåœ¨[-init_scale, init_scale]åŒºé—´è¿›è¡Œå‡åŒ€é‡‡æ ·\n",
    "        self.embedding = Embedding( \n",
    "            num_embeddings = self.vocab_size,\n",
    "            embedding_dim = self.embedding_size,\n",
    "            weight_attr=paddle.ParamAttr(\n",
    "                initializer=paddle.nn.initializer.Uniform( \n",
    "                    low=-0.5/embedding_size, high=0.5/embedding_size)))\n",
    "\n",
    "        # ä½¿ç”¨Embeddingå‡½æ•°æ„é€ å¦å¤–ä¸€ä¸ªè¯å‘é‡å‚æ•°\n",
    "        # è¿™ä¸ªå‚æ•°çš„å¤§å°ä¸ºï¼š[self.vocab_size, self.embedding_size]\n",
    "        # è¿™ä¸ªå‚æ•°çš„åˆå§‹åŒ–æ–¹å¼ä¸ºåœ¨[-init_scale, init_scale]åŒºé—´è¿›è¡Œå‡åŒ€é‡‡æ ·\n",
    "        self.embedding_out = Embedding(\n",
    "            num_embeddings = self.vocab_size,\n",
    "            embedding_dim = self.embedding_size,\n",
    "            weight_attr=paddle.ParamAttr(\n",
    "                initializer=paddle.nn.initializer.Uniform(\n",
    "                    low=-0.5/embedding_size, high=0.5/embedding_size)))\n",
    "\n",
    "    # å®šä¹‰ç½‘ç»œçš„å‰å‘è®¡ç®—é€»è¾‘\n",
    "    # center_wordsæ˜¯ä¸€ä¸ªtensorï¼ˆmini-batchï¼‰ï¼Œè¡¨ç¤ºä¸­å¿ƒè¯\n",
    "    # target_wordsæ˜¯ä¸€ä¸ªtensorï¼ˆmini-batchï¼‰ï¼Œè¡¨ç¤ºç›®æ ‡è¯\n",
    "    # labelæ˜¯ä¸€ä¸ªtensorï¼ˆmini-batchï¼‰ï¼Œè¡¨ç¤ºè¿™ä¸ªè¯æ˜¯æ­£æ ·æœ¬è¿˜æ˜¯è´Ÿæ ·æœ¬ï¼ˆç”¨0æˆ–1è¡¨ç¤ºï¼‰\n",
    "    # ç”¨äºåœ¨è®­ç»ƒä¸­è®¡ç®—è¿™ä¸ªtensorä¸­å¯¹åº”è¯çš„åŒä¹‰è¯ï¼Œç”¨äºè§‚å¯Ÿæ¨¡å‹çš„è®­ç»ƒæ•ˆæœ\n",
    "    def forward(self, center_words, target_words, label):\n",
    "        # é¦–å…ˆï¼Œé€šè¿‡embedding_paraï¼ˆself.embeddingï¼‰å‚æ•°ï¼Œå°†mini-batchä¸­çš„è¯è½¬æ¢ä¸ºè¯å‘é‡\n",
    "        # è¿™é‡Œcenter_wordså’Œeval_words_embæŸ¥è¯¢çš„æ˜¯ä¸€ä¸ªç›¸åŒçš„å‚æ•°\n",
    "        # è€Œtarget_words_embæŸ¥è¯¢çš„æ˜¯å¦ä¸€ä¸ªå‚æ•°\n",
    "        center_words_emb = self.embedding(center_words)\n",
    "        target_words_emb = self.embedding_out(target_words)\n",
    "\n",
    "        # æˆ‘ä»¬é€šè¿‡ç‚¹ä¹˜çš„æ–¹å¼è®¡ç®—ä¸­å¿ƒè¯åˆ°ç›®æ ‡è¯çš„è¾“å‡ºæ¦‚ç‡ï¼Œå¹¶é€šè¿‡sigmoidå‡½æ•°ä¼°è®¡è¿™ä¸ªè¯æ˜¯æ­£æ ·æœ¬è¿˜æ˜¯è´Ÿæ ·æœ¬çš„æ¦‚ç‡ã€‚\n",
    "        word_sim = paddle.multiply(center_words_emb, target_words_emb)\n",
    "        word_sim = paddle.sum(word_sim, axis=-1)\n",
    "        word_sim = paddle.reshape(word_sim, shape=[-1])\n",
    "        pred = F.sigmoid(word_sim)\n",
    "\n",
    "        # é€šè¿‡ä¼°è®¡çš„è¾“å‡ºæ¦‚ç‡å®šä¹‰æŸå¤±å‡½æ•°ï¼Œæ³¨æ„æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯binary_cross_entropy_with_logitså‡½æ•°\n",
    "        # å°†sigmoidè®¡ç®—å’Œcross entropyåˆå¹¶æˆä¸€æ­¥è®¡ç®—å¯ä»¥æ›´å¥½çš„ä¼˜åŒ–ï¼Œæ‰€ä»¥è¾“å…¥çš„æ˜¯word_simï¼Œè€Œä¸æ˜¯pred\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(word_sim, label)\n",
    "        loss = paddle.mean(loss)\n",
    "\n",
    "        # è¿”å›å‰å‘è®¡ç®—çš„ç»“æœï¼Œé£æ¡¨ä¼šé€šè¿‡backwardå‡½æ•°è‡ªåŠ¨è®¡ç®—å‡ºåå‘ç»“æœã€‚\n",
    "        return pred, loss\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ç½‘ç»œè®­ç»ƒ\n",
    "\n",
    "å®Œæˆç½‘ç»œå®šä¹‰åï¼Œå°±å¯ä»¥å¯åŠ¨æ¨¡å‹è®­ç»ƒã€‚æˆ‘ä»¬å®šä¹‰æ¯éš”100æ­¥æ‰“å°ä¸€æ¬¡Lossï¼Œä»¥ç¡®ä¿å½“å‰çš„ç½‘ç»œæ˜¯æ­£å¸¸æ”¶æ•›çš„ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æ¯éš”10000æ­¥è§‚å¯Ÿä¸€ä¸‹skip-gramè®¡ç®—å‡ºæ¥çš„åŒä¹‰è¯ï¼ˆä½¿ç”¨ embeddingçš„ä¹˜ç§¯ï¼‰ï¼Œå¯è§†åŒ–ç½‘ç»œè®­ç»ƒæ•ˆæœï¼Œä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# å¼€å§‹è®­ç»ƒï¼Œå®šä¹‰ä¸€äº›è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦ä½¿ç”¨çš„è¶…å‚æ•°\n",
    "batch_size = 512\n",
    "epoch_num = 3\n",
    "embedding_size = 200\n",
    "step = 0\n",
    "learning_rate = 0.001\n",
    "\n",
    "#å®šä¹‰ä¸€ä¸ªä½¿ç”¨word-embeddingæŸ¥è¯¢åŒä¹‰è¯çš„å‡½æ•°\n",
    "#è¿™ä¸ªå‡½æ•°query_tokenæ˜¯è¦æŸ¥è¯¢çš„è¯ï¼Œkè¡¨ç¤ºè¦è¿”å›å¤šå°‘ä¸ªæœ€ç›¸ä¼¼çš„è¯ï¼Œembedæ˜¯æˆ‘ä»¬å­¦ä¹ åˆ°çš„word-embeddingå‚æ•°\n",
    "#æˆ‘ä»¬é€šè¿‡è®¡ç®—ä¸åŒè¯ä¹‹é—´çš„cosineè·ç¦»ï¼Œæ¥è¡¡é‡è¯å’Œè¯çš„ç›¸ä¼¼åº¦\n",
    "#å…·ä½“å®ç°å¦‚ä¸‹ï¼Œxä»£è¡¨è¦æŸ¥è¯¢è¯çš„Embeddingï¼ŒEmbeddingå‚æ•°çŸ©é˜µWä»£è¡¨æ‰€æœ‰è¯çš„Embedding\n",
    "#ä¸¤è€…è®¡ç®—Coså¾—å‡ºæ‰€æœ‰è¯å¯¹æŸ¥è¯¢è¯çš„ç›¸ä¼¼åº¦å¾—åˆ†å‘é‡ï¼Œæ’åºå–top_kæ”¾å…¥indicesåˆ—è¡¨\n",
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.numpy()\n",
    "    x = W[word2id_dict[query_token]]\n",
    "    cos = np.dot(W, x) / np.sqrt(np.sum(W * W, axis=1) * np.sum(x * x) + 1e-9)\n",
    "    flat = cos.flatten()\n",
    "    indices = np.argpartition(flat, -k)[-k:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    for i in indices:\n",
    "        print('for word %s, the similar word is %s' % (query_token, str(id2word_dict[i])))\n",
    "\n",
    "# å°†æ¨¡å‹æ”¾åˆ°GPUä¸Šè®­ç»ƒ\n",
    "paddle.set_device('gpu:0')\n",
    "\n",
    "# é€šè¿‡æˆ‘ä»¬å®šä¹‰çš„SkipGramç±»ï¼Œæ¥æ„é€ ä¸€ä¸ªSkip-gramæ¨¡å‹ç½‘ç»œ\n",
    "skip_gram_model = SkipGram(vocab_size, embedding_size)\n",
    "\n",
    "# æ„é€ è®­ç»ƒè¿™ä¸ªç½‘ç»œçš„ä¼˜åŒ–å™¨\n",
    "adam = paddle.optimizer.Adam(learning_rate=learning_rate, parameters = skip_gram_model.parameters())\n",
    "\n",
    "# ä½¿ç”¨build_batchå‡½æ•°ï¼Œä»¥mini-batchä¸ºå•ä½ï¼Œéå†è®­ç»ƒæ•°æ®ï¼Œå¹¶è®­ç»ƒç½‘ç»œ\n",
    "for center_words, target_words, label in build_batch(\n",
    "    dataset, batch_size, epoch_num):\n",
    "    # ä½¿ç”¨paddle.to_tensorï¼Œå°†ä¸€ä¸ªnumpyçš„tensorï¼Œè½¬æ¢ä¸ºé£æ¡¨å¯è®¡ç®—çš„tensor\n",
    "    center_words_var = paddle.to_tensor(center_words)\n",
    "    target_words_var = paddle.to_tensor(target_words)\n",
    "    label_var = paddle.to_tensor(label)\n",
    "    \n",
    "    # å°†è½¬æ¢åçš„tensoré€å…¥é£æ¡¨ä¸­ï¼Œè¿›è¡Œä¸€æ¬¡å‰å‘è®¡ç®—ï¼Œå¹¶å¾—åˆ°è®¡ç®—ç»“æœ\n",
    "    pred, loss = skip_gram_model(\n",
    "        center_words_var, target_words_var, label_var)\n",
    "\n",
    "    # ç¨‹åºè‡ªåŠ¨å®Œæˆåå‘è®¡ç®—\n",
    "    loss.backward()\n",
    "    # ç¨‹åºæ ¹æ®lossï¼Œå®Œæˆä¸€æ­¥å¯¹å‚æ•°çš„ä¼˜åŒ–æ›´æ–°\n",
    "    adam.step()\n",
    "    # æ¸…ç©ºæ¨¡å‹ä¸­çš„æ¢¯åº¦ï¼Œä»¥ä¾¿äºä¸‹ä¸€ä¸ªmini-batchè¿›è¡Œæ›´æ–°\n",
    "    adam.clear_grad()\n",
    "\n",
    "    # æ¯ç»è¿‡100ä¸ªmini-batchï¼Œæ‰“å°ä¸€æ¬¡å½“å‰çš„lossï¼Œçœ‹çœ‹lossæ˜¯å¦åœ¨ç¨³å®šä¸‹é™\n",
    "    step += 1\n",
    "    if step % 1000 == 0:\n",
    "        print(\"step %d, loss %.3f\" % (step, loss.numpy()[0]))\n",
    "\n",
    "    # æ¯éš”10000æ­¥ï¼Œæ‰“å°ä¸€æ¬¡æ¨¡å‹å¯¹ä»¥ä¸‹æŸ¥è¯¢è¯çš„ç›¸ä¼¼è¯ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨è¯å’Œè¯ä¹‹é—´çš„å‘é‡ç‚¹ç§¯ä½œä¸ºè¡¡é‡ç›¸ä¼¼åº¦çš„æ–¹æ³•ï¼Œåªæ‰“å°äº†5ä¸ªæœ€ç›¸ä¼¼çš„è¯\n",
    "    if step % 10000 ==0:\n",
    "        get_similar_tokens('movie', 5, skip_gram_model.embedding.weight)\n",
    "        get_similar_tokens('one', 5, skip_gram_model.embedding.weight)\n",
    "        get_similar_tokens('chip', 5, skip_gram_model.embedding.weight)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ä»æ‰“å°ç»“æœå¯ä»¥çœ‹åˆ°ï¼Œç»è¿‡ä¸€å®šæ­¥éª¤çš„è®­ç»ƒï¼ŒLossé€æ¸ä¸‹é™å¹¶è¶‹äºç¨³å®šã€‚åŒæ—¶ä¹Ÿå¯ä»¥å‘ç°skip-gramæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°ä¸€äº›æœ‰è¶£çš„è¯­è¨€ç°è±¡ï¼Œæ¯”å¦‚ï¼šè·Ÿwhoæ¯”è¾ƒæ¥è¿‘çš„è¯æ˜¯\"who, he, she, him, himself\"ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## è¯å‘é‡çš„æœ‰è¶£åº”ç”¨\n",
    "\n",
    "åœ¨ä½¿ç”¨word2vecæ¨¡å‹çš„è¿‡ç¨‹ä¸­ï¼Œç ”ç©¶äººå‘˜å‘ç°äº†ä¸€äº›æœ‰è¶£çš„ç°è±¡ã€‚æ¯”å¦‚å¾—åˆ°æ•´ä¸ªè¯è¡¨çš„word embeddingä¹‹åï¼Œå¯¹ä»»æ„è¯éƒ½å¯ä»¥åŸºäºå‘é‡ä¹˜æ³•è®¡ç®—å‡ºè·Ÿè¿™ä¸ªè¯æœ€æ¥è¿‘çš„è¯ã€‚æˆ‘ä»¬ä¼šå‘ç°ï¼Œword2vecæ¨¡å‹å¯ä»¥è‡ªåŠ¨å­¦ä¹ å‡ºä¸€äº›åŒä¹‰è¯å…³ç³»ï¼Œå¦‚ï¼š\n",
    "\n",
    "```shell\n",
    "Top 5 words closest to \"beijing\" are:\n",
    "1. newyork\n",
    "2. paris\n",
    "3. tokyo\n",
    "4. berlin\n",
    "5. seoul\n",
    "\n",
    "...\n",
    "\n",
    "Top 5 words closest to \"apple\" are:\n",
    "1. banana\n",
    "2. pineapple\n",
    "3. huawei\n",
    "4. peach\n",
    "5. orange\n",
    "```\n",
    "\n",
    "é™¤æ­¤ä»¥å¤–ï¼Œç ”ç©¶äººå‘˜è¿˜å‘ç°å¯ä»¥ä½¿ç”¨åŠ å‡æ³•å®Œæˆä¸€äº›åŸºäºè¯­è¨€çš„é€»è¾‘æ¨ç†ï¼Œå¦‚ï¼š\n",
    "\n",
    "```\n",
    "Top 1 words closest to \"king - man + woman\" are\n",
    "1. queen\n",
    "\n",
    "...\n",
    "\n",
    "Top 1 words closest to \"captial - china + america\" are\n",
    "1. Washington\n",
    "```\n",
    "è¿˜æœ‰æ›´å¤šæœ‰è¶£çš„ä¾‹å­ï¼Œèµ¶å¿«ä½¿ç”¨é£æ¡¨å°è¯•å®ç°ä¸€ä¸‹å§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# æ€è€ƒä¸€ä¸‹\n",
    "\n",
    "[1] å¦‚ä½•ä½¿ç”¨é£æ¡¨å®ç°CBOWç®—æ³•ã€‚\n",
    "\n",
    "[2] æœ‰äº›è¯å¤©ç„¶å…·æœ‰æ­§ä¹‰ï¼Œæ¯”å¦‚â€œè‹¹æœâ€ï¼Œåœ¨å­¦ä¹ word2vecçš„æ—¶å€™ï¼Œå¦‚ä½•è§£å†³å’ŒåŒºåˆ†æ­§ä¹‰æ€§è¯ã€‚\n",
    "\n",
    "[3] å¦‚ä½•æ„é€ ä¸€ä¸ªè‡ªç„¶è¯­è¨€å¥å­çš„å‘é‡è¡¨ç¤ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## å¼•ç”¨\n",
    "\n",
    "[1] [Linguistic Regularities in Continuous Space Word Representations](https://www.aclweb.org/anthology/N13-1090/)\n",
    "\n",
    "[2] [ç»´åŸºç™¾ç§‘ï¼šword2vec](https://en.wikipedia.org/wiki/Word2vec)\n",
    "\n",
    "[3] [text8æ•°æ®é›†](http://mattmahoney.net/dc/textdata.html)\n",
    "\n",
    "[4] [çŸ¥ä¹ï¼šSkip-gramå’ŒCBOWçš„ä¼˜ç¼ºç‚¹](https://www.zhihu.com/question/68112508)\n",
    "\n",
    "## è¯¾å¤–é˜…è¯»\n",
    "\n",
    "[1] [è¯­è¨€è¡¨ç¤ºçš„å‰ä¸–ä»Šç”Ÿ](https://mp.weixin.qq.com/s/I315hYPrxV0YYryqsUysXw)\n",
    "[2] [è¯å‘é‡çš„æœ¬è´¨](https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
