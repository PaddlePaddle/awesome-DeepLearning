### 第二题

**1.可变形卷积提出背景：**
我们知道卷积核的目的是为了提取输入物的特征。我们传统的卷积核通常是固定尺寸、固定大小的（例如3x3，5x5，7x7.）。这种卷积核存在的最大问题就是，对于未知的变化适应性差，泛化能力不强。
卷积单元对输入的特征图在固定的位置进行采样；池化层不断减小着特征图的尺寸；RoI池化层产生空间位置受限的RoI。网络内部缺乏能够解决这个问题的模块，这会产生显著的问题，例如，同一CNN层的激活单元的感受野尺寸都相同，这对于编码位置信息的浅层神经网络并不可取，因为不同的位置可能对应有不同尺度或者不同形变的物体，这些层需要能够自动调整尺度或者感受野的方法。再比如，目标检测虽然效果很好但是都依赖于基于特征提取的边界框，这并不是最优的方法，尤其是对于非网格状的物体而言。
解决上述问题最直观的想法就是，我们的卷积核可以根据实际情况调整本身的形状，更好的提取输入的特征。

**2.可变形卷积原理：**
可变形卷积是指卷积核在每一个元素上额外增加了一个参数方向参数，这样卷积核就能在训练过程中扩展到很大的范围。
如图1中，
（a）是传统的标准卷积核，尺寸为3x3（图中绿色的点）；
（b）就是我们今天要谈论的可变形卷积，通过在图（a）的基础上给每个卷积核的参数添加一个方向向量（图b中的浅绿色箭头），使的我们的卷积核可以变为任意形状；
（c）和（d）是可变形卷积的特殊形式。

**3.可变形卷积实现过程：**
可变形卷积是在传统卷积的基础上，增加了调整卷积核的方向向量，使的卷积核的形态更贴近特征物。
① 我们一开始，和正常的卷积神经网络一样，根据输入的图像，利用传统的卷积核提取特征图。
②我们把得到的特征图作为输入，对特征图再施加一个卷积层，这么做的目的是为了得到可变形卷积的变形的偏移量。
③偏移层是2N，是因为我们在平面上做平移，需要改变x xx值和y yy值两个方向。
④在训练的时候，用于生成输出特征的卷积核和用于生成偏移量的卷积核是同步学习的。其中偏移量的学习是利用插值算法，通过反向传播进行学习。
实现过程的流程图如图2所示，图3为可变形卷积核的计算思想。

**4.可变形卷积的应用：**
目前，Bounding Box（即包含物体的一个紧致矩形框）几乎主导了计算机视觉中对于物体的表示，其广泛流行得益于它简便且方便物体特征提取的特点，但另一方面也限制了对物体更精细的定位和特征提取。

北大、清华和微软亚研的研究者们提出了一种新的视觉物体表示方法，称作 RepPoints（representative points，代表性点集），这种方法能更精细地描述物体的几何位置和进行图像特征的提取，同时也兼有简便和方便特征提取的特点。利用这种表示，很自然能得到一个 anchor-free 的物体检测框架，取得了和目前 anchor-based 方法可比的性能。