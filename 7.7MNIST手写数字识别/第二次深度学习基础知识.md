# 深度学习基础知识

## 1.损失函数方法补充

回归常见的损失函数有：均方差（Mean Squared Error，MSE）、平均绝对误差（Mean Absolute Error Loss，MAE）、Huber Loss是一种将MSE与MAE结合起来，取两者优点的损失函数，也被称作Smooth Mean Absolute Error Loss 、分位数损失（Quantile Loss）损失函数。

分类常见的损失函数有：交叉熵损失（Cross Entropy Loss）、合页损失（Hinge Loss）、0/1损失函数、指数损失、对数损失/对数似然损失（Log-likelihood Loss）


在机器学习中，**Hinge loss**（铰链损失函数）作为损失函数，通常被用于最大间隔算法(maximum-margin)，而最大间隔算法又是SVM(支持向量机support vector machines)用到的重要算法。

Hinge loss专用于二分类问题，标签值y=±1，预测值$\hat{y}$∈R。该二分类问题的目标函数的要求如下：当$\hat{y}$等于+1或者小于等于-1时，都是分类器确定的分类结果，此时的损失函数loss为0；而当$\hat{y}$预测值∈(−1,1)时，分类器对分类结果不确定，loss不为0。显然，当y^=0时，loss达到最大值。

而多分类问题，则常用交叉熵损失函数.

## 2.损失函数python代码实现

（1）交叉熵损失函数

```python
import numpy as np
class CrossEntropy(object):
    def __init__(self):
        self.eps=np.finfo(float).eps
    def loss(self,y,y_pred):
        loss=-np.sun(y*np.log(y_pred+self.eps),axis=-1)
        return loss
    def grad(self,y,y_pred):
        grad=y_pred-y
        return grad
```

（2）MSE函数

```
class MSE(object):
    def __str__(self):
        return 'MSE'
    def __call__(self, y, y_pred):
        return self.loss(y, y_pred)
    def loss(self, y, y_pred):
        return 0.5 * np.sum((y_pred - y) ** 2, axis=-1)
    def grad(self, y, y_pred):
        return y_pred - y
```



## 3.池化方法补充

最常见的池化操作为平均池化mean pooling和最大池化max pooling：

（1）平均池化：计算图像区域的平均值作为该区域池化后的值。

（2）最大池化：选图像区域的最大值作为该区域池化后的值。

（3）重叠池化(Overlapping Pooling)

重叠池化，即相邻池化窗口之间会有重叠区域。如果定义池化窗口的大小为sizeX，定义两个相邻池化窗口的水平位移 / 竖直位移为stride，此时**sizeX>stride**。Alexnet中提出和使用，不仅可以提升预测精度，同时一定程度上可以减缓过拟合。相比于正常池化（步长s=2，窗口x=2），重叠池化(步长s=2，窗口x=3) 可以减少top-1, top-5的错误率分别为0.4% 和0.3%。

（4）全局池化(Global Pooling)

Global Pooling就是**池化窗口的大小 = 整张特征图的大小**。这样，每个 W×H×C 的特征图输入就会被转化为 1×1×C 的输出，也等同于每个位置权重都为 1/(W×H) 的全连接层操作。



## 4.数据增强方法修改及补充

1.几何变换类

几何变换类即对图像进行几何变换，包括***\*翻转，旋转，裁剪，变形，缩放\****等各类操作。

2.颜色变换

包括***\*噪声、模糊、颜色变换、擦除、填充\****等等。

3.GAN

通过生成对抗网络生成同类型的数据。比如生成汽车、人脸图片。通过图像风格迁移的手段，还可以生成同一物体再不同环境下的图片。



## 5.图像分类方法综述

图像分类是根据图像的语义信息将不同类别图像区分开来，是计算机视觉中重要的基本问题，也是图像检测、图像分割、物体跟踪、行为分析等其他高层视觉任务的基础。图像分类的主要过程包括图像预处理、特征提取和分类器设计。

（1）传统方法：

传统图像分类通过手工提取特征或特征学习方法对整个图像进行全部描述，然后使用分类器判别物体类别，因此如何提取图像的特征至关重要。

在特征提取方面，主要包括纹理、颜色、形状等底层视觉特征，尺度不变特征变换、局部二值模式、方向梯度直方图等局部不变性特征。

在分类器方面，主要包括k NN(k-nearest neighbor,k最近邻）决策树、SVM(support vector machine，支持向量机）、人工神经网络等方法。

（2）深度学习方法：

传统的图像分类方法往往需要对目标图像进行人工特征描述和提取，对于大数量的复杂数据很难取得低成本的有效结果。然而，深度学习方法通过神经网络自主地从训练样本中学习特征，提取出更高维、抽象的特征，并且这些特征与分类器关系紧密，很好地解决了人工提取特征和分类器选择的难题，是一种端到端的模型。

对于深度学习标准网络模型使用已经非常广泛，在这里对轻量化进行简单介绍：

常用的标准网络模型：Lenet、Alxnet、Vgg系列、Resnet系列、Inception系列、Densenet系列、Googlenet、Nasnet、Xception、Senet(state of art)；

轻量化网络模型：Mobilenet v1,v2、Shufflenet v1,v2,Squeezenet

目前轻量化模型在具体项目应用时反响很好，它主要存在的优缺点如下：

优点：（1）参数模型小，方便部署（2）计算量小，速度快

缺点：（1）轻量化模型在精度上没有Resnet系列、Inception系列、Densenet系列、Senet的accuracy高