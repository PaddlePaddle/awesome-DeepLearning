{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import paddle\n",
    "import numpy as np\n",
    "import paddle.fluid as fluid\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from paddle.fluid.dygraph.nn import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#下载数据用于训练\n",
    "def download():\n",
    "    url = \"https://dataset.bj.bcebos.com/word2vec/text8.txt\"\n",
    "    web_request = requests.get(url)\n",
    "    corpus = web_request.content\n",
    "    with open(\"./text8.txt\", \"wb\") as f:\n",
    "        f.write(corpus)\n",
    "    f.close()\n",
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philoso\n"
     ]
    }
   ],
   "source": [
    "#读取text8数据\n",
    "def load_text8():\n",
    "    with open(\"./text8.txt\", \"r\") as f:\n",
    "        corpus = f.read().strip(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    return corpus\n",
    "\n",
    "corpus = load_text8()\n",
    "\n",
    "#打印前500个字符\n",
    "print(corpus[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
     ]
    }
   ],
   "source": [
    "#对数据进行预处理，现将字母都转为小写，在用空格进行切词\n",
    "def preprocess(corpus):\n",
    "    corpus = corpus.strip().lower()\n",
    "    corpus = corpus.split(\" \")\n",
    "    return corpus\n",
    "\n",
    "corpus = preprocess(corpus)\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#构造词典，统计每个词的频率，并根据频率赋予idid\n",
    "def build_dict(corpus):\n",
    "    word_freq = dict()\n",
    "    for word in corpus:\n",
    "        if word not in word_freq:\n",
    "            word_freq[word] = 0\n",
    "        word_freq[word] += 1\n",
    "\n",
    "    word_freq = sorted(word_freq.items(), key = lambda x:x[1], reverse = True)\n",
    "\n",
    "    #构造3个不同的词典，分别存储，\n",
    "    #每个词到id的映射关系：word2id_dict\n",
    "    #每个id出现的频率：word2id_freq\n",
    "    #每个id到词典映射关系：id2word_dict\n",
    "    word2id_dict = dict()\n",
    "    word2id_freq = dict()\n",
    "    id2word_dict = dict()\n",
    "\n",
    "    #按照频率，从高到低，开始遍历每个单词，并为这个单词构造id\n",
    "    for word, freq in word_freq:\n",
    "        curr_id = len(word2id_dict)\n",
    "        word2id_dict[word] = curr_id\n",
    "        word2id_freq[word2id_dict[word]] = freq\n",
    "        id2word_dict[curr_id] = word\n",
    "\n",
    "    return word2id_freq, word2id_dict, id2word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are totoally 253854 different words in the corpus\n",
      "word: the, its id: 0, its word freq: 1061396\n",
      "word: of, its id: 1, its word freq: 593677\n",
      "word: and, its id: 2, its word freq: 416629\n",
      "word: one, its id: 3, its word freq: 411764\n",
      "word: in, its id: 4, its word freq: 372201\n",
      "word: a, its id: 5, its word freq: 325873\n",
      "word: to, its id: 6, its word freq: 316376\n",
      "word: zero, its id: 7, its word freq: 264975\n",
      "word: nine, its id: 8, its word freq: 250430\n",
      "word: two, its id: 9, its word freq: 192644\n"
     ]
    }
   ],
   "source": [
    "word2id_freq, word2id_dict, id2word_dict = build_dict(corpus)\n",
    "vocab_size = len(word2id_freq)\n",
    "print(\"there are totoally %d different words in the corpus\" % vocab_size)\n",
    "for _, (word, word_id) in zip(range(10), word2id_dict.items()):\n",
    "    print(\"word: %s, its id: %d, its word freq: %d\" % (word, word_id, word2id_freq[word_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17005207 tokens in the corpus\n",
      "[5233, 3080, 11, 5, 194, 1, 3133, 45, 58, 155]\n"
     ]
    }
   ],
   "source": [
    "#将语料库中的单词装换为对应的id\n",
    "def convert_corpus_to_id(corpus, word2id_dict):\n",
    "    corpus = [word2id_dict[word] for word in corpus]\n",
    "    return corpus\n",
    "\n",
    "corpus = convert_corpus_to_id(corpus, word2id_dict)\n",
    "print(\"%d tokens in the corpus\" % len(corpus))\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8744414 tokens in the corpus\n",
      "[5233, 3080, 3133, 155, 741, 476, 10571, 27349, 102, 854]\n"
     ]
    }
   ],
   "source": [
    "#使用二次采样算法（subsampling）处理语料，强化训练效果\n",
    "def subsampling(corpus, word2id_freq):\n",
    "    \n",
    "    #这个discard函数决定了一个词会不会被替换，这个函数是具有随机性的，每次调用结果不同\n",
    "    #如果一个词的频率很大，那么它被遗弃的概率就很大\n",
    "    def discard(word_id):\n",
    "        return random.uniform(0, 1) < 1 - math.sqrt(\n",
    "            1e-4 / word2id_freq[word_id] * len(corpus))\n",
    "\n",
    "    corpus = [word for word in corpus if not discard(word)]\n",
    "    return corpus\n",
    "\n",
    "corpus = subsampling(corpus, word2id_freq)\n",
    "print(\"%d tokens in the corpus\" % len(corpus))\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200000\n",
      "2000000\n",
      "2400000\n",
      "2600000\n",
      "2800000\n",
      "3000000\n",
      "3600000\n",
      "3800000\n",
      "4000000\n",
      "4200000\n",
      "4600000\n",
      "4800000\n",
      "5000000\n",
      "5200000\n",
      "5400000\n",
      "5600000\n",
      "6800000\n",
      "7600000\n",
      "7800000\n",
      "8400000\n",
      "center_word originated, target anarchism, label 1\n",
      "center_word originated, target rdlinger, label 0\n",
      "center_word originated, target nemean, label 0\n",
      "center_word originated, target sidling, label 0\n",
      "center_word originated, target motet, label 0\n",
      "center_word anarchism, target originated, label 1\n",
      "center_word anarchism, target fjords, label 0\n",
      "center_word anarchism, target fusarium, label 0\n",
      "center_word anarchism, target leipsig, label 0\n",
      "center_word anarchism, target zespri, label 0\n"
     ]
    }
   ],
   "source": [
    "#构造训练数据\n",
    "def build_data(corpus, word2id_dict, word2id_freq, max_window_size = 3, \n",
    "               negative_sample_num = 4):\n",
    "    \n",
    "    #使用一个list存储处理好的数据\n",
    "    dataset = []\n",
    "    center_word_idx=0\n",
    "\n",
    "    #从左到右，开始枚举每个中心点的位置\n",
    "    while center_word_idx < len(corpus):\n",
    "        #以max_window_size为上限，随机采样一个window_size，这样会使得训练更加稳定\n",
    "        window_size = random.randint(1, max_window_size)\n",
    "        #当前的中心词就是center_word_idx所指向的词，可以当作正样本\n",
    "        positive_word = corpus[center_word_idx]\n",
    "\n",
    "        #以当前中心词为中心，左右两侧在window_size内的词就是上下文\n",
    "        context_word_range = (max(0, center_word_idx - window_size), min(len(corpus) - 1, center_word_idx + window_size))\n",
    "        context_word_candidates = [corpus[idx] for idx in range(context_word_range[0], context_word_range[1]+1) if idx != center_word_idx]\n",
    "\n",
    "        #对于每个正样本来说，随机采样negative_sample_num个负样本，用于训练\n",
    "        for context_word in context_word_candidates:\n",
    "            #首先把（上下文，正样本，label=1）的三元组数据放入dataset中，\n",
    "            #这里label=1表示这个样本是个正样本\n",
    "            dataset.append((context_word, positive_word, 1))\n",
    "\n",
    "            #开始负采样\n",
    "            i = 0\n",
    "            while i < negative_sample_num:\n",
    "                negative_word_candidate = random.randint(0, vocab_size-1)\n",
    "\n",
    "                if negative_word_candidate is not positive_word:\n",
    "                    #把（上下文，负样本，label=0）的三元组数据放入dataset中，\n",
    "                    #这里label=0表示这个样本是个负样本\n",
    "                    dataset.append((context_word, negative_word_candidate, 0))\n",
    "                    i += 1\n",
    "        \n",
    "        center_word_idx = min(len(corpus) - 1, center_word_idx + window_size)\n",
    "        if center_word_idx == (len(corpus) - 1):\n",
    "            center_word_idx += 1\n",
    "        if center_word_idx % 200000 == 0:\n",
    "            print(center_word_idx)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "dataset = build_data(corpus, word2id_dict, word2id_freq)\n",
    "for _, (context_word, target_word, label) in zip(range(10), dataset):\n",
    "    print(\"center_word %s, target %s, label %d\" % (id2word_dict[context_word],\n",
    "                                                   id2word_dict[target_word], label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([[ 10334],\n",
      "       [  2059],\n",
      "       [    48],\n",
      "       [  1137],\n",
      "       [    11],\n",
      "       [  8181],\n",
      "       [  3758],\n",
      "       [   136],\n",
      "       [228752],\n",
      "       [   240],\n",
      "       [  2376],\n",
      "       [  5777],\n",
      "       [  2747],\n",
      "       [ 18910],\n",
      "       [ 24054],\n",
      "       [171546],\n",
      "       [  1742],\n",
      "       [     5],\n",
      "       [  2516],\n",
      "       [ 19796],\n",
      "       [  2114],\n",
      "       [ 30704],\n",
      "       [   939],\n",
      "       [     3],\n",
      "       [   235],\n",
      "       [    34],\n",
      "       [  1365],\n",
      "       [  1745],\n",
      "       [   111],\n",
      "       [   286],\n",
      "       [ 14132],\n",
      "       [ 36921],\n",
      "       [   818],\n",
      "       [  1751],\n",
      "       [   155],\n",
      "       [  3938],\n",
      "       [   370],\n",
      "       [    22],\n",
      "       [ 10267],\n",
      "       [  4348],\n",
      "       [ 45405],\n",
      "       [  2492],\n",
      "       [   658],\n",
      "       [  7804],\n",
      "       [ 31421],\n",
      "       [  4640],\n",
      "       [  1907],\n",
      "       [ 36672],\n",
      "       [   431],\n",
      "       [ 70155],\n",
      "       [  9224],\n",
      "       [   195],\n",
      "       [  1026],\n",
      "       [   493],\n",
      "       [  4555],\n",
      "       [  4401],\n",
      "       [   143],\n",
      "       [ 70758],\n",
      "       [  6170],\n",
      "       [   639],\n",
      "       [   485],\n",
      "       [  1579],\n",
      "       [  8459],\n",
      "       [   889],\n",
      "       [  8164],\n",
      "       [   751],\n",
      "       [   567],\n",
      "       [  3214],\n",
      "       [    22],\n",
      "       [     6],\n",
      "       [  1338],\n",
      "       [   605],\n",
      "       [ 20171],\n",
      "       [  2227],\n",
      "       [ 29472],\n",
      "       [  2185],\n",
      "       [  1662],\n",
      "       [  1650],\n",
      "       [  5361],\n",
      "       [  2021],\n",
      "       [   329],\n",
      "       [  1971],\n",
      "       [  8285],\n",
      "       [  2047],\n",
      "       [    19],\n",
      "       [   792],\n",
      "       [  5382],\n",
      "       [ 26690],\n",
      "       [  1691],\n",
      "       [  1099],\n",
      "       [  3056],\n",
      "       [  1327],\n",
      "       [  2220],\n",
      "       [ 18285],\n",
      "       [    93],\n",
      "       [   210],\n",
      "       [   159],\n",
      "       [  3873],\n",
      "       [   135],\n",
      "       [ 18693],\n",
      "       [  2614],\n",
      "       [   641],\n",
      "       [  2975],\n",
      "       [  5031],\n",
      "       [  9440],\n",
      "       [   955],\n",
      "       [  6863],\n",
      "       [ 11595],\n",
      "       [    39],\n",
      "       [  9326],\n",
      "       [ 17535],\n",
      "       [   473],\n",
      "       [   582],\n",
      "       [138923],\n",
      "       [  1326],\n",
      "       [  1351],\n",
      "       [    11],\n",
      "       [   559],\n",
      "       [ 17942],\n",
      "       [ 98563],\n",
      "       [  4934],\n",
      "       [  1546],\n",
      "       [   382],\n",
      "       [   457],\n",
      "       [  4830],\n",
      "       [  5704],\n",
      "       [ 19910],\n",
      "       [ 37584]]), array([[   417],\n",
      "       [128815],\n",
      "       [ 53171],\n",
      "       [ 95207],\n",
      "       [166654],\n",
      "       [145680],\n",
      "       [   915],\n",
      "       [ 18919],\n",
      "       [ 19255],\n",
      "       [220338],\n",
      "       [174469],\n",
      "       [200514],\n",
      "       [119788],\n",
      "       [ 20365],\n",
      "       [242154],\n",
      "       [144653],\n",
      "       [  5786],\n",
      "       [   176],\n",
      "       [   958],\n",
      "       [212507],\n",
      "       [104448],\n",
      "       [   849],\n",
      "       [   425],\n",
      "       [166799],\n",
      "       [ 85979],\n",
      "       [237829],\n",
      "       [115927],\n",
      "       [ 14616],\n",
      "       [ 43106],\n",
      "       [204046],\n",
      "       [119388],\n",
      "       [ 10563],\n",
      "       [110917],\n",
      "       [ 31478],\n",
      "       [247248],\n",
      "       [    73],\n",
      "       [  1836],\n",
      "       [ 50109],\n",
      "       [  1612],\n",
      "       [ 20841],\n",
      "       [200010],\n",
      "       [117731],\n",
      "       [   661],\n",
      "       [ 29813],\n",
      "       [208020],\n",
      "       [171912],\n",
      "       [ 70294],\n",
      "       [  3887],\n",
      "       [  6105],\n",
      "       [209207],\n",
      "       [188407],\n",
      "       [175122],\n",
      "       [212662],\n",
      "       [   420],\n",
      "       [ 61142],\n",
      "       [ 29367],\n",
      "       [ 23979],\n",
      "       [235150],\n",
      "       [149537],\n",
      "       [    63],\n",
      "       [209717],\n",
      "       [    32],\n",
      "       [  3226],\n",
      "       [213452],\n",
      "       [243616],\n",
      "       [ 83285],\n",
      "       [150048],\n",
      "       [   643],\n",
      "       [ 88005],\n",
      "       [135115],\n",
      "       [176416],\n",
      "       [ 15231],\n",
      "       [137193],\n",
      "       [226806],\n",
      "       [157050],\n",
      "       [192711],\n",
      "       [162798],\n",
      "       [ 67700],\n",
      "       [194620],\n",
      "       [ 30789],\n",
      "       [ 94695],\n",
      "       [    36],\n",
      "       [103401],\n",
      "       [  5018],\n",
      "       [143540],\n",
      "       [132446],\n",
      "       [ 15979],\n",
      "       [214356],\n",
      "       [221443],\n",
      "       [ 69181],\n",
      "       [228543],\n",
      "       [237683],\n",
      "       [  6969],\n",
      "       [ 86122],\n",
      "       [222147],\n",
      "       [ 31732],\n",
      "       [ 33531],\n",
      "       [230510],\n",
      "       [ 42788],\n",
      "       [196432],\n",
      "       [234487],\n",
      "       [ 66366],\n",
      "       [     1],\n",
      "       [229021],\n",
      "       [132714],\n",
      "       [ 83194],\n",
      "       [223164],\n",
      "       [   623],\n",
      "       [176981],\n",
      "       [ 89834],\n",
      "       [230616],\n",
      "       [ 52509],\n",
      "       [ 39559],\n",
      "       [223150],\n",
      "       [  3796],\n",
      "       [  1940],\n",
      "       [ 67691],\n",
      "       [239445],\n",
      "       [ 48855],\n",
      "       [106416],\n",
      "       [208094],\n",
      "       [  1160],\n",
      "       [227593],\n",
      "       [148159],\n",
      "       [186607],\n",
      "       [   881],\n",
      "       [154294],\n",
      "       [130911]]), array([1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), array([[  3],\n",
      "       [186],\n",
      "       [ 56]]))\n"
     ]
    }
   ],
   "source": [
    "#构造mini-batch，准备对模型进行训练\n",
    "#我们将不同类型的数据放到不同的tensor里，便于神经网络进行处理\n",
    "#并通过numpy的array函数，构造出不同的tensor来，并把这些tensor送入神经网络中进行训练\n",
    "def build_batch(dataset, batch_size, epoch_num):\n",
    "    \n",
    "    #context_word_batch缓存batch_size个中心词\n",
    "    context_word_batch = []\n",
    "    #target_word_batch缓存batch_size个目标词（可以是正样本或者负样本）\n",
    "    target_word_batch = []\n",
    "    #label_batch缓存了batch_size个0或1的标签，用于模型训练\n",
    "    label_batch = []\n",
    "    #eval_word_batch每次随机生成几个样例，用于在运行阶段对模型做评估，以便更好地可视化训练效果。\n",
    "    eval_word_batch = []\n",
    "    \n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        #每次开启一个新epoch之前，都对数据进行一次随机打乱，提高训练效果\n",
    "        random.shuffle(dataset)\n",
    "        \n",
    "        for context_word, target_word, label in dataset:\n",
    "            #遍历dataset中的每个样本，并将这些数据送到不同的tensor里\n",
    "            context_word_batch.append([context_word])\n",
    "            target_word_batch.append([target_word])\n",
    "            label_batch.append(label)\n",
    "            \n",
    "            #构造训练中评估的样本，这里我们生成'one','king','chip'三个词的同义词，\n",
    "            #看模型认为的同义词有哪些\n",
    "            if len(eval_word_batch) == 0:\n",
    "                eval_word_batch.append([word2id_dict['one']])\n",
    "            elif len(eval_word_batch) == 1:\n",
    "                eval_word_batch.append([word2id_dict['king']])\n",
    "            elif len(eval_word_batch) ==2:\n",
    "                eval_word_batch.append([word2id_dict['who']])\n",
    "\n",
    "            if len(context_word_batch) == batch_size:\n",
    "                yield epoch,\\\n",
    "                    np.array(context_word_batch).astype(\"int64\"),\\\n",
    "                    np.array(target_word_batch).astype(\"int64\"),\\\n",
    "                    np.array(label_batch).astype(\"float32\"),\\\n",
    "                    np.array(eval_word_batch).astype(\"int64\")\n",
    "                context_word_batch = []\n",
    "                target_word_batch = []\n",
    "                label_batch = []\n",
    "                eval_word_batch = []\n",
    "        \n",
    "    if len(context_word_batch) > 0:\n",
    "        yield epoch,\\\n",
    "            np.array(context_word_batch).astype(\"int64\"),\\\n",
    "            np.array(target_word_batch).astype(\"int64\"),\\\n",
    "            np.array(label_batch).astype(\"float32\"),\\\n",
    "            np.array(eval_word_batch).astype(\"int64\")\n",
    "\n",
    "for _, batch in zip(range(1), build_batch(dataset, 128, 3)):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CBOW(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, vocab_size, embedding_size, init_scale=0.1):\n",
    "        super(CBOW, self).__init__(name_scope)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = Embedding(\n",
    "            self.full_name(),\n",
    "            size=[self.vocab_size, self.embedding_size],\n",
    "            dtype='float32',\n",
    "            param_attr=fluid.ParamAttr(\n",
    "                name='embedding_para',\n",
    "                initializer=fluid.initializer.UniformInitializer(\n",
    "                    low=-0.5/embedding_size, high=0.5/embedding_size)))\n",
    "\n",
    "        self.embedding_out = Embedding(\n",
    "            self.full_name(),\n",
    "            size=[self.vocab_size, self.embedding_size],\n",
    "            dtype='float32',\n",
    "            param_attr=fluid.ParamAttr(\n",
    "                name='embedding_out_para',\n",
    "                initializer=fluid.initializer.UniformInitializer(\n",
    "                    low=-0.5/embedding_size, high=0.5/embedding_size)))\n",
    "\n",
    "    def forward(self, context_words, target_words, label, eval_words):\n",
    "        context_words_emb = self.embedding(context_words)\n",
    "        target_words_emb = self.embedding_out(target_words)\n",
    "        eval_words_emb = self.embedding(eval_words)\n",
    "        \n",
    "        word_sim = fluid.layers.elementwise_mul(context_words_emb, target_words_emb)\n",
    "        word_sim = fluid.layers.reduce_sum(word_sim, dim = -1)\n",
    "        pred = fluid.layers.sigmoid(word_sim)\n",
    "\n",
    "        #通过估计的输出概率定义损失函数\n",
    "        loss = fluid.layers.sigmoid_cross_entropy_with_logits(word_sim, label)\n",
    "        loss = fluid.layers.reduce_mean(loss)\n",
    "        \n",
    "        word_sim_on_fly = fluid.layers.matmul(eval_words_emb, \n",
    "            self.embedding._w, transpose_y = True)\n",
    "\n",
    "        #返回前向计算的结果，飞桨会通过backward函数自动计算出反向结果。\n",
    "        return pred, loss, word_sim_on_fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch num:0, step 1000, loss 0.643\n",
      "epoch num:0, step 2000, loss 0.466\n",
      "epoch num:0, step 3000, loss 0.323\n",
      "epoch num:0, step 4000, loss 0.274\n",
      "epoch num:0, step 5000, loss 0.242\n",
      "epoch num:0, step 6000, loss 0.275\n",
      "epoch num:0, step 7000, loss 0.241\n",
      "epoch num:0, step 8000, loss 0.227\n",
      "epoch num:0, step 9000, loss 0.177\n",
      "epoch num:0, step 10000, loss 0.230\n",
      "epoch num:0, step 11000, loss 0.180\n",
      "epoch num:0, step 12000, loss 0.220\n",
      "epoch num:0, step 13000, loss 0.241\n",
      "epoch num:0, step 14000, loss 0.261\n",
      "epoch num:0, step 15000, loss 0.192\n",
      "epoch num:0, step 16000, loss 0.195\n",
      "epoch num:0, step 17000, loss 0.213\n",
      "epoch num:0, step 18000, loss 0.252\n",
      "epoch num:0, step 19000, loss 0.247\n",
      "epoch num:0, step 20000, loss 0.265\n",
      "epoch num:0, step 21000, loss 0.240\n",
      "epoch num:0, step 22000, loss 0.243\n",
      "epoch num:0, step 23000, loss 0.221\n",
      "epoch num:0, step 24000, loss 0.221\n",
      "epoch num:0, step 25000, loss 0.256\n",
      "epoch num:0, step 26000, loss 0.261\n",
      "epoch num:0, step 27000, loss 0.229\n",
      "epoch num:0, step 28000, loss 0.191\n",
      "epoch num:0, step 29000, loss 0.287\n",
      "epoch num:0, step 30000, loss 0.229\n",
      "epoch num:0, step 31000, loss 0.238\n",
      "epoch num:0, step 32000, loss 0.201\n",
      "epoch num:0, step 33000, loss 0.328\n",
      "epoch num:0, step 34000, loss 0.237\n",
      "epoch num:0, step 35000, loss 0.397\n",
      "epoch num:0, step 36000, loss 0.216\n",
      "epoch num:0, step 37000, loss 0.156\n",
      "epoch num:0, step 38000, loss 0.242\n",
      "epoch num:0, step 39000, loss 0.222\n",
      "epoch num:0, step 40000, loss 0.269\n",
      "epoch num:0, step 41000, loss 0.223\n",
      "epoch num:0, step 42000, loss 0.256\n",
      "epoch num:0, step 43000, loss 0.146\n",
      "epoch num:0, step 44000, loss 0.250\n",
      "epoch num:0, step 45000, loss 0.336\n",
      "epoch num:0, step 46000, loss 0.190\n",
      "epoch num:0, step 47000, loss 0.226\n",
      "epoch num:0, step 48000, loss 0.273\n",
      "epoch num:0, step 49000, loss 0.212\n",
      "epoch num:0, step 50000, loss 0.213\n",
      "epoch num:0, step 51000, loss 0.286\n",
      "epoch num:0, step 52000, loss 0.184\n",
      "epoch num:0, step 53000, loss 0.221\n",
      "epoch num:0, step 54000, loss 0.190\n",
      "epoch num:0, step 55000, loss 0.309\n",
      "epoch num:0, step 56000, loss 0.195\n",
      "epoch num:0, step 57000, loss 0.194\n",
      "epoch num:0, step 58000, loss 0.245\n",
      "epoch num:0, step 59000, loss 0.266\n",
      "epoch num:0, step 60000, loss 0.172\n",
      "epoch num:0, step 61000, loss 0.281\n",
      "epoch num:0, step 62000, loss 0.311\n",
      "epoch num:0, step 63000, loss 0.265\n",
      "epoch num:0, step 64000, loss 0.194\n",
      "epoch num:0, step 65000, loss 0.145\n",
      "epoch num:0, step 66000, loss 0.246\n",
      "epoch num:0, step 67000, loss 0.177\n",
      "epoch num:0, step 68000, loss 0.218\n",
      "epoch num:0, step 69000, loss 0.258\n",
      "epoch num:0, step 70000, loss 0.221\n",
      "epoch num:0, step 71000, loss 0.206\n",
      "epoch num:0, step 72000, loss 0.253\n",
      "epoch num:0, step 73000, loss 0.250\n",
      "epoch num:0, step 74000, loss 0.168\n",
      "epoch num:0, step 75000, loss 0.322\n",
      "epoch num:0, step 76000, loss 0.179\n",
      "epoch num:0, step 77000, loss 0.218\n",
      "epoch num:0, step 78000, loss 0.187\n",
      "epoch num:0, step 79000, loss 0.152\n",
      "epoch num:0, step 80000, loss 0.192\n",
      "epoch num:0, step 81000, loss 0.169\n",
      "epoch num:0, step 82000, loss 0.213\n",
      "epoch num:0, step 83000, loss 0.230\n",
      "epoch num:0, step 84000, loss 0.238\n",
      "epoch num:0, step 85000, loss 0.217\n",
      "epoch num:0, step 86000, loss 0.245\n",
      "epoch num:0, step 87000, loss 0.184\n",
      "epoch num:0, step 88000, loss 0.209\n",
      "epoch num:0, step 89000, loss 0.312\n",
      "epoch num:0, step 90000, loss 0.287\n",
      "epoch num:0, step 91000, loss 0.264\n",
      "epoch num:0, step 92000, loss 0.297\n",
      "epoch num:0, step 93000, loss 0.212\n",
      "epoch num:0, step 94000, loss 0.198\n",
      "epoch num:0, step 95000, loss 0.220\n",
      "epoch num:0, step 96000, loss 0.205\n",
      "epoch num:0, step 97000, loss 0.189\n",
      "epoch num:0, step 98000, loss 0.251\n",
      "epoch num:0, step 99000, loss 0.263\n",
      "epoch num:0, step 100000, loss 0.182\n",
      "epoch num:0, step 101000, loss 0.188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c0d95177a1bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#使用build_batch函数，以mini-batch为单位，遍历训练数据，并训练网络\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     for epoch_num, context_words, target_words, label, eval_words in build_batch(\n\u001b[0;32m---> 26\u001b[0;31m         dataset, batch_size, epoch_num):\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# print(eval_words.shape[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#使用fluid.dygraph.to_variable函数，将一个numpy的tensor，转换为飞桨可计算的tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-08607d4ee5ac>\u001b[0m in \u001b[0;36mbuild_batch\u001b[0;34m(dataset, batch_size, epoch_num)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_word_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_word_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_word_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#开始训练，定义一些训练过程中需要使用的超参数\n",
    "batch_size = 512\n",
    "epoch_num = 1\n",
    "embedding_size = 200\n",
    "step = 0\n",
    "learning_rate = 0.001\n",
    "LOSS = []\n",
    "\n",
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.numpy()\n",
    "    x = W[word2id_dict[query_token]]\n",
    "    cos = np.dot(W, x) / np.sqrt(np.sum(W * W, axis=1) * np.sum(x * x) + 1e-9)\n",
    "    flat = cos.flatten()\n",
    "    indices = np.argpartition(flat, -k)[-k:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    for i in indices:\n",
    "        print('for word %s, the similar word is %s' % (query_token, str(id2word_dict[i])))\n",
    "\n",
    "with fluid.dygraph.guard(fluid.CUDAPlace(0)):\n",
    "    cbow_model = CBOW(\"cbow_model\", vocab_size, embedding_size)\n",
    "    #构造训练这个网络的优化器\n",
    "    adam = fluid.optimizer.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    #使用build_batch函数，以mini-batch为单位，遍历训练数据，并训练网络\n",
    "    for epoch_num, context_words, target_words, label, eval_words in build_batch(\n",
    "        dataset, batch_size, epoch_num):\n",
    "        # print(eval_words.shape[0])\n",
    "        #使用fluid.dygraph.to_variable函数，将一个numpy的tensor，转换为飞桨可计算的tensor\n",
    "        context_words_var = fluid.dygraph.to_variable(context_words)\n",
    "        target_words_var = fluid.dygraph.to_variable(target_words)\n",
    "        label_var = fluid.dygraph.to_variable(label)\n",
    "        eval_words_var = fluid.dygraph.to_variable(eval_words)\n",
    "        \n",
    "        #将转换后的tensor送入飞桨中，进行一次前向计算，并得到计算结果\n",
    "        pred, loss, word_sim_on_fly = cbow_model(\n",
    "            context_words_var, target_words_var, label_var, eval_words_var)\n",
    "\n",
    "        #通过backward函数，让程序自动完成反向计算\n",
    "        loss.backward()\n",
    "        #通过minimize函数，让程序根据loss，完成一步对参数的优化更新\n",
    "        adam.minimize(loss)\n",
    "        #使用clear_gradients函数清空模型中的梯度，以便于下一个mini-batch进行更新\n",
    "        cbow_model.clear_gradients()\n",
    "\n",
    "        #每经过100个mini-batch，打印一次当前的loss，看看loss是否在稳定下降\n",
    "        step += 1\n",
    "        if step % 1000 == 0:\n",
    "            LOSS.append(loss.numpy()[0])\n",
    "            print(\"epoch num:%d, step %d, loss %.3f\" % (epoch_num, step, loss.numpy()[0]))\n",
    "\n",
    "        #每经过1000个mini-batch，打印一次模型对eval_words中的10个词计算的同义词\n",
    "        #这里我们使用词和词之间的向量点积作为衡量相似度的方法\n",
    "        #我们只打印了5个最相似的词\n",
    "    if step % 1000 == 0:\n",
    "        # word_sim_on_fly = word_sim_on_fly.numpy()\n",
    "        # word_sim_on_fly = np.argsort(word_sim_on_fly)\n",
    "\n",
    "        # for _id in range(len(eval_words)):\n",
    "        #     curr_eval_word = id2word_dict[eval_words[_id][0]]\n",
    "        #     top_n_sim_words = []\n",
    "        #     for j in range(1, 6):\n",
    "        #         top_n_sim_words.append(id2word_dict[word_sim_on_fly[_id][-1 * j]])\n",
    "        #     print(\"for word %s, the most similar word is: %s\" % \n",
    "        #           (curr_eval_word, \", \".join(top_n_sim_words)))\n",
    "        get_similar_tokens('one', 5, cbow_model.embedding._w)\n",
    "        get_similar_tokens('who', 5, cbow_model.embedding._w)\n",
    "        get_similar_tokens('king', 5, cbow_model.embedding._w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for word one, the similar word is one\n",
      "for word one, the similar word is nine\n",
      "for word one, the similar word is four\n",
      "for word one, the similar word is eight\n",
      "for word one, the similar word is seven\n",
      "for word who, the similar word is who\n",
      "for word who, the similar word is herself\n",
      "for word who, the similar word is marry\n",
      "for word who, the similar word is father\n",
      "for word who, the similar word is men\n",
      "for word king, the similar word is king\n",
      "for word king, the similar word is ruled\n",
      "for word king, the similar word is antiochus\n",
      "for word king, the similar word is ruler\n",
      "for word king, the similar word is franks\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens('one', 5, cbow_model.embedding._w)\n",
    "get_similar_tokens('who', 5, cbow_model.embedding._w)\n",
    "get_similar_tokens('king', 5, cbow_model.embedding._w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbb4bb2ac50>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(LOSS)), LOSS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
