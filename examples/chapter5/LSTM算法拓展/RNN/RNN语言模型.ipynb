{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:00, 68718.85it/s]\n",
      "56it [00:00, 25782.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-21 23:49:26: Loss after num_examples_seen=1267 epoch=0: 5.779052\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "from models.RNN import RNN\r\n",
    "from utils import build_dataset,build_iterator\r\n",
    "\r\n",
    "\r\n",
    "def seqreate(str,vocab):\r\n",
    "    \"\"\"对测试输入做预处理：\r\n",
    "          网络输入长度为5，不够PAD填充，长了截取最后5个\r\n",
    "    \"\"\"\r\n",
    "    n_step = 5\r\n",
    "    lin = str.strip()\r\n",
    "    tokenizer = lambda x: [y for y in x]  # char-level\r\n",
    "    words_line = []\r\n",
    "    token = tokenizer(lin)\r\n",
    "\r\n",
    "    # # word to id\r\n",
    "    # if(len(token)<n_step):\r\n",
    "    #     for i in range(n_step-len(token)):\r\n",
    "    #         words_line.append(vocab.get('<PAD>'))\r\n",
    "    for word in token:\r\n",
    "        words_line.append(vocab.get(word, vocab.get('<UNK>')))\r\n",
    "\r\n",
    "    return words_line\r\n",
    "\r\n",
    "def testing(model,vocab,string):\r\n",
    "    \"\"\"Test(文本生成)\"\"\"\r\n",
    "    str = ''\r\n",
    "    input = seqreate(string, vocab)  # 对测试输入做预处理\r\n",
    "    result = seqreate(string, vocab)\r\n",
    "    input.insert(0,vocab.get('<START>'))\r\n",
    "    for _ in input:\r\n",
    "        str += number_dict[_]   # 输入网络的真实字符串\r\n",
    "    print(f'输入: {str}')\r\n",
    "\r\n",
    "    o, s = model.forward_propagation(input)\r\n",
    "    # 取出对每个word后的正确word的估计\r\n",
    "    o = o.tolist()\r\n",
    "    predict = o[-1].index(max(o[-1]))\r\n",
    "    result.append(predict)\r\n",
    "\r\n",
    "    str += number_dict[predict]\r\n",
    "    result_str = ' '\r\n",
    "    for _ in result:\r\n",
    "        result_str += number_dict[_]  # 输入网络的真实字符串\r\n",
    "    print(f'生成: {result_str}')\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    # 下面的目录、文件名按需更改。\r\n",
    "    train_dir = \"./data/train.txt\"\r\n",
    "    vocab_dir = \"./data/vocab.pkl\"\r\n",
    "\r\n",
    "    train_set, vocab, number_dict, nums_word = build_dataset(vocab_dir, train_dir)\r\n",
    "    train_iter = build_iterator(train_set,batch_size=32)\r\n",
    "\r\n",
    "    model = RNN(473,100,4)\r\n",
    "    model.train_with_sgd(train_iter)\r\n",
    "\r\n",
    "    string = '暴风'\r\n",
    "    # print(f'输入: {string}')\r\n",
    "    testing(model, vocab, string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
