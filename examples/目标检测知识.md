### 目标检测知识

#### （1）目标检测任务解决正负样本不均衡问题的手段

​	机器学习中，解决样本不均衡问题主要有2种思路：数据角度和算法角度。

+ 在数据角度有扩大数据集、数据类别均衡采样等方法。

+ 在算法层次，有OHEM、S-OHEM、A-Fast-RCNN、Focal Loss、GHM等解决方案     

  + OHEM：在线难例挖掘

    它在训练过程中自动选择困难样本，其核心思想是根据输入样本的损失值进行筛选，筛选出困难样本，然后将筛选得到的这些样本应用在SGD中。

  + S-OHEM：基于loss分布采样的在线困难样本挖掘

    S-OHEM是对OHEM算法的改进。OHEM算法在整个训练过程中各类损失具有相同的权重，这种方法忽略了训练过程中不同损失类型的影响。所以S-OHEM算法采用了分层抽样的方法，根据loss的分布抽样训练样本。

  + A-Fast-RCNN

    过GAN生成遮挡和变形的训练样本来训练网络，以此来提高识别网络的识别能力、增强网络的鲁棒性。区别于传统的直接生成样本图片的方法，这些变换都是基于特征图的：1).通过添加Occlusion mask来实现特征的部分遮挡；2).通过操作feature map来实现特征的部分变形。

  + Focal Loss

    在交叉熵损失函数基础上进行修改，提出了一种新的损失函数Focal Loss

    ![1](https://github.com/827184100/awesome-DeepLearning/blob/7.13_4/images/1.png)

    作者通过实验给出最佳取值：![2](https://github.com/827184100/awesome-DeepLearning/blob/7.13_4/images/2.svg)。

  + GHM

    作者在文中指出难度不同样本的不均衡性可以在梯度模长的分布上体现出来。通过对梯度分布的研究，作者提出了一种梯度均衡策略GHM可以有效地改进单阶段检测器的性能。作者提出了梯度密度，并将梯度密度的倒数作为损失函数的权重分别引入到分类损失函数(GHM-C)和边框损失函数(GHM-R)中。

#### （2）yolov1、yolov2是在yolov3之前提出的目标检测网络，yolov4，yolov5是继yolov3之后提出的用于目标检测的网络。请对比yolov1、yolov2、yolov3、yolov4和yolov5五个模型。

+ YOLOV1

  + 核心思想：将整张图片作为网络的输入，直接在输出层对BBox的位置和类别进行回归。

  + 简单概括：1) 给个一个输入图像，首先将图像划分成7*7的网格

    2) 对于每个网格，我们都预测2个边框（包括每个边框是目标的置信度以及每个边框区域在多个类别上的概率）

    3) 根据上一步可以预测出7* 7*2个目标窗口，然后根据阈值去除可能性比较低的目标窗口，最后NMS去除冗余窗口即可

+ YOLOV2

  + 使用训练方法–联合训练算法，这种算法可以把这两种的数据集混合到一起。使用一种分层的观点对物体进行分类，用巨量的分类数据集数据来扩充检测数据集，从而把两种不同的数据集混合起来。

  + 联合训练算法的基本思路就是：同时在检测数据集和分类数据集上训练物体检测器（Object Detectors ），用检测数据集的数据学习物体的准确位置，用分类数据集的数据来增加分类的类别量、提升健壮性。

  + Hierarchical classification（分层分类）

    使用检测数据集的图片去学习检测相关的信息，例如bounding box 坐标预测，是否包含物体以及属于各个物体的概率。使用仅有类别标签的分类数据集图片去扩展可以检测的种类。

  + 改进：

    + Batch Normalization（批量归一化）
    + High resolution classifier（高分辨率图像分类器）
    + Convolution with anchor boxes（使用先验框）
    + Dimension clusters（聚类提取先验框的尺度信息）
    + Direct location prediction（约束预测边框的位置）
    + Fine-Grained Features（passthrough层检测细粒度特征）
    + Multi-ScaleTraining（多尺度图像训练）
    + hi-res detector（高分辨率图像的对象检测）

+ YOLOV3

  + 先验检测（Prior detection）系统将分类器或定位器重新用于执行检测任务。他们将模型应用于图像的多个位置和尺度。而那些评分较高的区域就可以视为检测结果
  + 多适度预测
  + 改进之处
    - 多尺度预测 （引入FPN）。
    - 更好的基础分类网络（darknet-53, 类似于ResNet引入残差结构）。
    - 分类器不在使用Softmax，分类损失采用binary cross-entropy loss（二分类交叉损失熵）

+ YOLOV4

  + 集成：

    + Weighted-Residual-Connections (WRC)
    + Cross-Stage-Partial-connections (CSP)
    + Cross mini-Batch Normalization (CmBN)
    + Self-adversarial-training (SAT)
    + Mish-activation
    + Mosaic data augmentation
    + CmBN
    + DropBlock regularization
    + CIoU loss

  + 主要贡献

    +  提出了一种高效而强大的目标检测模型。它使每个人都可以使用1080 Ti或2080 Ti GPU 训练超快速和准确的目标检测器。
    + 在检测器训练期间，验证了SOTA的Bag-of Freebies 和Bag-of-Specials方法的影响。
    + 改进了SOTA的方法，使它们更有效，更适合单GPU训练，包括CBN ，PAN，SAM等。文章将目前主流的目标检测器框架进行拆分：input、backbone、neck 和 head.

  + 框架：

    + Backbone：CSPDarknet53
    + Neck：SPP，PAN
    + Head：YOLOv3

    YOLOv4 = CSPDarknet53+SPP+PAN+YOLOv3

+ YOLOV5

  + YOLOv5 宣称自己速度非常快，有非常轻量级的模型大小，同时在准确度方面又与 YOLOv4 基准相当。
  + 使用Pytorch框架，对用户非常友好，能够方便地训练自己的数据集，相对于YOLO V4采用的Darknet框架，Pytorch框架更容易投入生产。
  + 代码易读，整合了大量的计算机视觉技术，非常有利于学习和借鉴。
  + 不仅易于配置环境，模型训练也非常快速，并且批处理推理产生实时结果。
  + 能够直接对单个图像，批处理图像，视频甚至网络摄像头端口输入进行有效推理。
  + 能够轻松的将Pytorch权重文件转化为安卓使用的ONXX格式，然后可以转换为OPENCV的使用格式，或者通过CoreML转化为IOS格式，直接部署到手机应用端。
  + 最后YOLO V5s高达140FPS的对象识别速度令人印象非常深刻，使用体验非常棒。



