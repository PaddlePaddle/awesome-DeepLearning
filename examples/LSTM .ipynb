{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "import torch.optim as optim\r\n",
    "import matplotlib.pyplot as ply\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "data = [(\"What the fuck\".lower().split() , [\"O\",\"O\",\"CS\"]),\r\n",
    "        (\"The boy asked him to fuckoff\".lower().split() ,[\"O\",\"O\",\"O\",\"O\",\"O\",\"CS\"]),\r\n",
    "        (\"I hate that bastard\".lower().split() , [\"O\",\"O\",\"O\",\"CS\"]),\r\n",
    "        (\"He is a dicked\".lower().split(),[\"O\",\"O\",\"O\",\"CS\"]),\r\n",
    "        (\"Hey prick\".lower().split(),[\"O\",\"CS\"]),\r\n",
    "        (\"What a pussy you are\".lower().split() , [\"O\",\"O\",\"CS\",\"O\",\"O\"]),\r\n",
    "        (\"Dont be a cock\".lower().split(),[\"O\",\"O\",\"O\",\"CS\"])]\r\n",
    "\r\n",
    "word2idx = {}\r\n",
    "\r\n",
    "for sent , tag in data:\r\n",
    "  for word in sent:\r\n",
    "    if word not in word2idx:\r\n",
    "      word2idx[word] = len(word2idx)\r\n",
    "\r\n",
    "tag2idx = {\"O\" : 0 , \"CS\" : 1}\r\n",
    "tag2rev = {0 : \"O\" , 1 : \"CS\"}\r\n",
    "\r\n",
    "def prepare_sequence(seq , to_idx):\r\n",
    "  idxs = [to_idx[word] for word in seq]\r\n",
    "  idxs = np.array(idxs)\r\n",
    "  return torch.tensor(idxs).long()\r\n",
    "\r\n",
    "testsent = \"fuckoff boy\".lower().split()\r\n",
    "inp = prepare_sequence(testsent , word2idx)\r\n",
    "print(\"The test sentence {} is tranlated to {}\\r\\n\".format(testsent , inp))\r\n",
    "\r\n",
    "class LSTMTagger(nn.Module):\r\n",
    "\r\n",
    "  def __init__(self,embedding_dim,hidden_dim,vocab_size,tagset_size):\r\n",
    "\r\n",
    "    super(LSTMTagger , self).__init__()\r\n",
    "\r\n",
    "    self.hidden_dim = hidden_dim\r\n",
    "\r\n",
    "    self.word_embedding = nn.Embedding(vocab_size , embedding_dim= embedding_dim)\r\n",
    "\r\n",
    "    self.lstm = nn.LSTM(input_size= embedding_dim , hidden_size = hidden_dim)\r\n",
    "\r\n",
    "    self.hidden2tag = nn.Linear(hidden_dim , tagset_size)\r\n",
    "\r\n",
    "    self.hidden = self.init_hidden()\r\n",
    "\r\n",
    "  def init_hidden(self):\r\n",
    "\r\n",
    "    return (torch.randn(1 , 1 , self.hidden_dim),\r\n",
    "           torch.randn(1 , 1 , self.hidden_dim))\r\n",
    "\r\n",
    "  def forward(self , sentence):\r\n",
    "\r\n",
    "    embeds = self.word_embedding(sentence)\r\n",
    "\r\n",
    "    lstm_out , hidden_out = self.lstm(embeds.view(len(sentence) , 1 , -1) , self.hidden) \r\n",
    "\r\n",
    "    tag_outputs = self.hidden2tag(lstm_out.view(len(sentence) , -1))\r\n",
    "    tag_scores = F.log_softmax(tag_outputs , dim = 1)\r\n",
    "\r\n",
    "    return tag_scores   \r\n",
    "\r\n",
    "EMBEDDING_DIM = 6\r\n",
    "HIDDEN_DIM = 6\r\n",
    "model = LSTMTagger(EMBEDDING_DIM , HIDDEN_DIM , len(word2idx) , len(tag2idx))\r\n",
    "loss_function = nn.NLLLoss()\r\n",
    "optimizer = optim.SGD(model.parameters() , lr = 0.1)\r\n",
    "\r\n",
    "n_epochs = 500\r\n",
    "\r\n",
    "for epoch in range(n_epochs):\r\n",
    "\r\n",
    "  epoch_loss = 0.0\r\n",
    "\r\n",
    "  for sent , tags in data:\r\n",
    "\r\n",
    "    model.zero_grad()\r\n",
    "    input_sent = prepare_sequence(sent , word2idx)\r\n",
    "    tag = prepare_sequence(tags , tag2idx)\r\n",
    "\r\n",
    "    model.hidden = model.init_hidden()\r\n",
    "\r\n",
    "    output = model(input_sent)\r\n",
    "\r\n",
    "    loss = loss_function(output , tag)\r\n",
    "\r\n",
    "    epoch_loss += loss.item()\r\n",
    "\r\n",
    "    loss.backward()\r\n",
    "\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "  if epoch % 20 == 19:\r\n",
    "    print(\"Epoch : {} , loss : {}\".format(epoch , epoch_loss / len(data)))\r\n",
    "\r\n",
    "testsent = \"cock\".lower().split()\r\n",
    "inp = prepare_sequence(testsent , word2idx)\r\n",
    "\r\n",
    "print(\"Input sent : {}\".format(testsent))\r\n",
    "tags = model(inp)\r\n",
    "_,pred_tags = torch.max(tags , 1)\r\n",
    "print(\"Pred tag : {}\".format(pred_tags))\r\n",
    "pred = np.array(pred_tags)\r\n",
    "\r\n",
    "for i in range(len(testsent)):\r\n",
    "  print(\"Word : {} , Predicted tag : {}\".format(testsent[i] , tag2rev[pred[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Epoch : 19 , loss : 0.544454289334161\r\n",
    "Epoch : 39 , loss : 0.3774886301585606\r\n",
    "Epoch : 59 , loss : 0.2139089980295726\r\n",
    "Epoch : 79 , loss : 0.06951503774949483\r\n",
    "Epoch : 99 , loss : 0.03730010560580662\r\n",
    "Epoch : 119 , loss : 0.014456807901816708\r\n",
    "Epoch : 139 , loss : 0.012173087735261236\r\n",
    "Epoch : 159 , loss : 0.00817690380582852\r\n",
    "Epoch : 179 , loss : 0.006234340702316591\r\n",
    "Epoch : 199 , loss : 0.004644184456472951\r\n",
    "Epoch : 219 , loss : 0.006766662267701966\r\n",
    "Epoch : 239 , loss : 0.004715066569458161\r\n",
    "Epoch : 259 , loss : 0.0036120133341423105\r\n",
    "Epoch : 279 , loss : 0.003041490596452994\r\n",
    "Epoch : 299 , loss : 0.002717309714561062\r\n",
    "Epoch : 319 , loss : 0.0024321148271805476\r\n",
    "Epoch : 339 , loss : 0.002902481156135244\r\n",
    "Epoch : 359 , loss : 0.0019416070094199053\r\n",
    "Epoch : 379 , loss : 0.001698540590171303\r\n",
    "Epoch : 399 , loss : 0.001596083290808435\r\n",
    "Epoch : 419 , loss : 0.0020627019444613586\r\n",
    "Epoch : 439 , loss : 0.0028247457313617425\r\n",
    "Epoch : 459 , loss : 0.001204681965256376\r\n",
    "Epoch : 479 , loss : 0.0011837564192579261\r\n",
    "Epoch : 499 , loss : 0.0013983721645282848\r\n",
    "the accuracy is:0.9300119803572617"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
