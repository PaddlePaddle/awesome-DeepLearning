# Hinge Loss （铰链损失）

在机器学习中，**Hinge loss**（铰链损失函数）作为损失函数，通常被用于最大间隔算法(maximum-margin)，而最大间隔算法又是SVM(支持向量机support vector machines)用到的重要算法。

Hinge loss专用于二分类问题，标签值y=±1，预测值$\hat{y}$∈R。该二分类问题的目标函数的要求如下：当$\hat{y}$等于+1或者小于等于-1时，都是分类器确定的分类结果，此时的损失函数loss为0；而当$\hat{y}$预测值∈(−1,1)时，分类器对分类结果不确定，loss不为0。显然，当y^=0时，loss达到最大值。

### python代码实现

```python
% 铰链损失
hinge = [zeros(20,1)];
for j = 1:20
    for i = 1:D
        k(i) = t(i) * dot(wi{j,1}, x(i,:));
        hinge_i(i) = max(0,1 - t(i) * dot(wi{j,1}, x(i,:)));
        hinge(j) = hinge(j) + hinge_i(i);
    end
    if j==1
            h = scatter(k, hinge_i, '.');
    end
    
    % 平均
    hinge(j) = hinge(j)/D;
end
```
# 感知损失(perceptron loss)函数

是Hinge损失函数的一个变种，Hinge loss对判定边界附近的点(正确端)惩罚力度很高。而perceptron loss只要样本的判定类别正确的话，它就满意，不管其判定边界的距离。它比Hinge loss简单，因为不是max-margin boundary，所以模型的泛化能力没 hinge loss强。


# 池化方法补充

随机池化(Stochastic Pooling)

Stochastic pooling是**一种简单有效的正则化CNN的方法，能够降低max pooling的过拟合现象，提高泛化能力**。对于pooling层的输入，根据输入的多项式分布随机选择一个值作为输出。

**训练阶段：**

1）前向传播：先将池化窗口中的元素全部除以它们的和，得到概率矩阵；再按照概率随机选中的方格的值，作为该区域池化后的值。

2）反向传播：求导时，只需保留前向传播中已经被选中节点的位置的值，其它值都为0，类似max-pooling的反向传播。

**测试阶段：**

在测试时也使用Stochastic Pooling会对预测值引入噪音，降低性能。取而代之的是使用概率矩阵加权平均。比使用Average Pooling表现要好一些。在平均意义上，与Average Pooling近似，在局部意义上，服从Max Pooling准则。

# 数据增强方法补充

数据增强也叫数据扩增，意思是在不实质性的增加数据的情况下，让有限的数据产生等价于更多数据的价值。数据增强可以分为，有监督的数据增强和无监督的数据增强方法。其中有监督的数据增强又可以分为单样本数据增强和多样本数据增强方法，无监督的数据增强分为生成新的数据和学习增强策略两个方向。

1、有监督的数据增强

有监督数据增强，即采用预设的数据变换规则，在已有数据的基础上进行数据的扩增，包含单样本数据增强和多样本数据增强，其中单样本又包括几何操作类，颜色变换类。

(1) 几何变换类

几何变换类即对图像进行几何变换，包括翻转，旋转，裁剪，变形，缩放等各类操作，下面展示其中的若干个操作。

(2) 颜色变换类

2、无监督的数据增强

无监督的数据增强方法包括两类：

(1) 通过模型学习数据的分布，随机生成与训练数据集分布一致的图片，代表方法GAN

(2) 通过模型，学习出适合当前任务的数据增强方法，代表方法AutoAugment


# 图像分类方法综述
什么是图像分类，核心是从给定的分类集合中给图像分配一个标签的任务。实际上，这意味着我们的任务是分析一个输入图像并返回一个将图像分类的标签。标签来自预定义的可能类别集。图像分类更适用于图像中待分类的物体是单一的，如上图1中待分类物体是单一的，如果图像中包含多个目标物，如下图3，可以使用多标签分类或者目标检测算法。
## 传统方法

传统方法通常完整建立图像识别模型一般包括底层特征学习、特征编码、空间约束、分类器设计、模型融合等几个阶段。

**1).** **底层特征提取**: 通常从图像中按照固定步长、尺度提取大量局部特征描述。常用的局部特征包括SIFT(Scale-Invariant Feature Transform, 尺度不变特征转换) 、HOG(Histogram of Oriented Gradient, 方向梯度直方图) 、LBP(Local Bianray Pattern, 局部二值模式)等，一般也采用多种特征描述，防止丢失过多的有用信息。

**2).** **特征编码**: 底层特征中包含了大量冗余与噪声，为了提高特征表达的鲁棒性，需要使用一种特征变换算法对底层特征进行编码，称作特征编码。常用的特征编码方法包括向量量化编码、稀疏编码、局部线性约束编码、Fisher向量编码等。

**3).** **空间特征约束**: 特征编码之后一般会经过空间特征约束，也称作特征汇聚。特征汇聚是指在一个空间范围内，对每一维特征取最大值或者平均值，可以获得一定特征不变形的特征表达。金字塔特征匹配是一种常用的特征汇聚方法，这种方法提出将图像均匀分块，在分块内做特征汇聚。

**4).** **通过分类器分类**: 经过前面步骤之后一张图像可以用一个固定维度的向量进行描述，接下来就是经过分类器对图像进行分类。通常使用的分类器包括SVM(Support Vector Machine, 支持向量机)、随机森林等。而使用核方法的SVM是最为广泛的分类器，在传统图像分类任务上性能很好。

## 深度学习方法

Alex Krizhevsky在2012年ILSVRC提出的CNN模型取得了历史性的突破，效果大幅度超越传统方法，获得了ILSVRC2012冠军，该模型被称作AlexNet。这也是首次将深度学习用于大规模图像分类中。从AlexNet之后，涌现了一系列CNN模型，不断地在ImageNet上刷新成绩，如图5展示。随着模型变得越来越深以及精妙的结构设计，Top-5的错误率也越来越低，降到了3.5%附近。而在同样的ImageNet数据集上，人眼的辨识错误率大概在5.1%，也就是目前的深度学习模型的识别能力已经超过了人眼。

自从2015年深度学习占领各大图像处理比赛榜首之后，现在的图像处理大部分使用的方法都是深度学习，也就是神经网络。神经网络通过很多的神经元构建成一层一层的网络，通过激活层来使得模型有很强的非线性拟合的能力。设计者只需要将图像输入，然后告诉模型需要的结果是什么，模型便会自动的学习特征提取与结果映射。

通过深度学习，剩下设计者在传统图像处理时最为费时费力的特征提取的那一部分。设计者只需要设计网络结果，使得网络自动提取的特征越好，效果就会也好，正确率越高。

神经网络本质上是矩阵相乘与非线性的组合，通过很多很多的滤波核，来过滤对结果最为有用的特征而抑制对结果没有用的特征，来进行学习与分类。

现在在工程中最为常用的还是vgg、resnet、inception这几种结构，设计者通常会先直接套用原版的模型对数据进行训练一次，然后选择效果较为好的模型进行微调与模型缩减。因为工程上使用的模型必须在精度高的同时速度要快。常用的模型缩减的方法是减少卷积和个数与减少resnet的模块数。

现在常用的检测模型，还是FRCNN、Mask-RCNN、YOLO、SSD等网络模型，一方面精度确实是高，另一方面速度现在进过优化也可以做到实时了。像上面的人脸检测的功能，只需要准备好人脸图片及对应的框标注文件，便可直接跑模型，得到一个还不错的检测模型。