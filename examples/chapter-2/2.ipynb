{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# 使得我们能够手动输入命令行参数\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "usage: ipykernel_launcher [-h] [--batch-size N] [--test-batch-size N]\n                          [--epochs N] [--lr LR] [--momentum M] [--no-cuda]\n                          [--seed S] [--log-interval N]\nipykernel_launcher: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"006a173b-fcb6-4a85-83c1-39f51f499f53\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=C:\\Users\\24577\\AppData\\Local\\Temp\\tmp-16344AJt9XlS2OTgm.json\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Pytorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=True,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "# 跑多少次batch进行一次日志记录\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "# 这个是使用argparse模块时的必备行,将参数进行关联\n",
    "args = parser.parse_args()\n",
    "# 这个是在确认是否使用GPU的参数\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集数量:  50000\n"
     ]
    }
   ],
   "source": [
    "# 设置一个随机数种子\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    # 为GPU设置一个随机数种子\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印第一个batch数据的维度:\n",
      "图像维度: (100, 784), 标签维度: (100,)\n"
     ]
    }
   ],
   "source": [
    "# 声明数据读取函数，从训练集中读取数据\n",
    "train_loader = data_generator\n",
    "# 以迭代的形式读取数据\n",
    "for batch_id, data in enumerate(train_loader()):\n",
    "    image_data, label_data = data\n",
    "    if batch_id == 0:\n",
    "        # 打印数据shape和类型\n",
    "        print(\"打印第一个batch数据的维度:\")\n",
    "        print(\"图像维度: {}, 标签维度: {}\".format(image_data.shape, label_data.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(root='./datasets', train=True, transform=transform, download=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=True)\n",
    "test_set = datasets.MNIST(root='./datasets', train=False, transform=transform, download=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印第一个batch数据的维度，以及数据的类型:\n",
      "图像维度: (100, 784), 标签维度: (100,), 图像数据类型: <class 'numpy.ndarray'>, 标签数据类型: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    每一个ResidualBlock,需要保证输入和输出的维度不变\n",
    "    所以卷积核的通道数都设置成一样\n",
    "    \"\"\"\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channel, channel, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channel, channel, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        ResidualBlock中有跳跃连接;\n",
    "        在得到第二次卷积结果时,需要加上该残差块的输入,\n",
    "        再将结果进行激活,实现跳跃连接 ==> 可以避免梯度消失\n",
    "        在求导时,因为有加上原始的输入x,所以梯度为: dy + 1,在1附近\n",
    "        \"\"\"\n",
    "        y = F.relu(self.conv1(x))\n",
    "        y = self.conv2(y)\n",
    "\n",
    "        return F.relu(x + y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dclass Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.res_block_1 = ResidualBlock(16)\n",
    "        self.res_block_2 = ResidualBlock(32)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = self.res_block_1(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = self.res_block_2(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "# 判断是否调用GPU模式\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "# 初始化优化器 model.train()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [100, 784] [100]\n",
      "1 [100, 784] [100]\n",
      "2 [100, 784] [100]\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    \"\"\"\n",
    "    定义每个epoch的训练细节\n",
    "    \"\"\"\n",
    "    # 设置为training模式\n",
    "    losses = []\n",
    "    a = []\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 如果要调用GPU模式,就把数据转存到GPU\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # 优化器梯度初始化为零\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # 负对数似然函数损失\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()\n",
    "            ))\n",
    "        losses.append(loss.item())\n",
    "        a.append(batch_idx * len(data))\n",
    "    # print(\"a=\",a)\n",
    "    # print(\"losses=\",losses)\n",
    "    plt.plot(a, losses)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # 设置为test模式\n",
    "    model.eval()\n",
    "    # 初始化测试损失值为0\n",
    "    test_loss = 0\n",
    "    # 初始化预测正确的数据个数为0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        # 把所有loss值进行累加\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        # 获取最大对数概率值的索引\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # 对预测正确的个数进行累加\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    # 因为把所有loss值进行累加,所以最后要除以总的数据长度才能得到平均loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 进行每个epoch的训练\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "34dfee18d5f4a96df9a8fcc719c91cf50e8ed50de2aa108bf45cd20982063274"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}