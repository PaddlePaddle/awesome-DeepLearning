# Group normalization

定义群组个数G，GN将一个batch中一张图片的C个channel分成G个组，对每个组的元素求均值与方差，并对群组进行归一化。

图示：![](C:\Users\13073\Desktop\深度学习基础知识\images\image1.JPG)



代码流程如下：

![](C:\Users\13073\Desktop\深度学习基础知识\images\image2.png)

作用：

普通的batch norm虽然很有效，但是弊端也很大，当batch size非常小时，batch norm造成的误差会非常大，而GN解决了这个问题，使得网络对batch size的依赖度变小。
应用场景：
对于图像识别、目标检测等许多场景所用的神经网络都非常有效。



# 可变形卷积

一、可变形卷积简介

由于构造卷积神经网络 (CNN)所用的模块中几何结构是固定的，其几何变换建模的能力本质上是有限的。为了提高卷积神经网络(CNN) 对变换的建模能力，可变形卷积 (deformable convolution)和可变形兴趣区域池化 (deformable ROI pooling)被创造出来。它们都是基于在模块中对空间采样的位置信息作进一步位移调整的想法，该位移可在目标任务中学习得到，并不需要额外的监督信号。新的模块可以很方便在现有的卷积神经网络
中取代它们的一般版本，并能很容易进行标准反向传播端到端的训练，从而得到可变形卷积网络(deformable convolutional network)。


二、DCN V1

CNNs对大型，未知形状变换的建模存在固有的缺陷，这种缺陷来源于CNNs模块固有的几何结构：卷积单元对输入特征图的固定位置进行采样；池化层以固定的比例进行池化；即使是ROI
pooling也是将ROI分割到固定的bin中去。这些特性是有影响的，例如，在同一层Conv中，所有的激活单元的感受野是一样的，但由于不同位置可能对应着不同尺度或变形的物体，因此对尺度或者感受野大小进行自适应是进行精确定位所需要的。为了解决或者减轻这个问题，本文提出了两种新的模块，可变形卷积（deformable
conv）和可变形感兴趣区域池化（deformable ROI Pooling）,来提高对形变的建模能力。这两个模块都是基于一个平行网络学习offset（偏移），使得卷积核在input
feature map的采样点发生偏移，集中于我们感兴趣的区域或者目标。通过研究发现，标准卷积中的规则格点采样是导致网络难以适应几何形变的“罪魁祸首”，为了削弱这个限制，对卷积核中每个采样点的位置都增加了一个偏移变量，可以实现在当前位置附近随意采样而不局限于之前的规则格点。如下图所示，是常见的采样点和可变形卷积采样的对比

![](C:\Users\13073\Desktop\深度学习基础知识\images\1-1626325005556.jpg)
（a）是常见的3x3卷积核的采样方式，（b）是采样可变形卷积，加上偏移量之后的采样点的变化，其中（c）(d)是可变形卷积的特殊形式

(a) 所示的正常卷积规律的采样 9 个点（绿点），(b)©(d)
为可变形卷积，在正常的采样坐标上加上一个位移量（蓝色箭头），其中 ©(d) 作为 (b)
的特殊情况，展示了可变形卷积可以作为尺度变换，比例变换和旋转变换等特殊情况。

可变形卷积就是在传统的卷积操作上加入了一个偏移量，正是这个偏移量才让卷积变形为不规则的卷积，这里要注意这个偏移量可以是小数，所以下面的式子的特征值需要通过*双线性插值*的方法来计算。：

那这个偏移量如何算呢？我们来看：  
![](C:\Users\13073\Desktop\深度学习基础知识\images\2-1626325009401.jpg)

对于输入的一张feature
map，假设原来的卷积操作是3×3的，那么为了学习偏移量offset，我们定义另外一个3×3的卷积层（图中上面的那层），输出的维度其实就是原来feature
map大小，channel数等于2N（分别表示x,y方向的偏移）。下面的可变形卷积可以看作先基于上面那部分生成的offset做了一个插值操作，然后再执行普通的卷积。

可变形池化

![](C:\Users\13073\Desktop\深度学习基础知识\images\3-1626325011962.jpg)

理解了可变形卷积之后，Deformable
RoIPooling（可变形池化）就比较好理解了。原始的RoIPooling在操作过程中是将RoI划分为k×k个子区域。*而可变形池化的偏移量其实就是子区域的偏移*。同理每一个子区域都有一个偏移，偏移量对应子区域有k×k个。与可变形卷积不同的是，可变形池化的偏移量是通过全连接层得到的。因为和可变形卷积类似，这里就不多讲了。

三、DCN v2

背景

DCN
v1听起来不错，但其实也有问题：可变形卷积有可能引入了无用的上下文（区域）来干扰我们的特征提取，这显然会降低算法的表现。虽然DCN
v1更能覆盖整个物体，但是同时也会引入一些无关的背景，这造成了干扰，所以有三个解决方法：

（1）*More Deformable Conv Layers（使用更多的可变形卷积）*。

（2）*Modulated Deformable
Modules（在DCNv1基础（添加offset）上添加每个采样点的权重）*

（3）*R-CNN Feature Mimicking（模拟R-CNN的feature）。*

使用更多的可变形卷积

在DCN v1中只在conv 5中使用了三个可变形卷积，在DCN
v2中把conv3到conv5都换成了可变形卷积，提高算法对几何形变的建模能力。  
![](C:\Users\13073\Desktop\深度学习基础知识\images\4-1626325014310.jpg)

在DCNv1基础（添加offset）上添加每个采样点的权重

我们知道在DCN v1中的卷积是添加了一个

为了解决引入了一些无关区域的问题，在DCN
v2中我们不只添加每一个采样点的偏移，还添加了一个权重系数​，来区分我们引入的区域是否为我们感兴趣的区域，假如这个采样点的区域我们不感兴趣，则把权重学习为0即可：

*总的来说，DCN v1中引入的offset是要寻找有效信息的区域位置，DCN
v2中引入权重系数是要给找到的这个位置赋予权重，这两方面保证了有效信息的准确提取*。

R-CNN Feature Mimicking

把R-CNN和Faster RCNN的classification
score结合起来可以提升performance，说明R-CNN学到的focus在物体上的feature可以解决无关上下文的问题。但是增加额外的R-CNN会使inference速度变慢很多。DCNV2里的解决方法是*把R-CNN当做teacher
network，让DCN
V2的ROIPooling之后的feature去模拟R-CNN的feature*，类似知识蒸馏的做法，下面会具体展开：

![](C:\Users\13073\Desktop\深度学习基础知识\images\5-1626325016183.jpg)

左边的网络为主网络（Faster
RCNN），右边的网络为子网络（RCNN）。实现上大致是用主网络训练过程中得到的RoI去裁剪原图，然后将裁剪到的图resize到224×224大小作为子网络的输入，这部分最后提取的特征和主网络输出的1024维特征作为feature
mimicking
loss的输入，用来约束这2个特征的差异（通过一个余弦相似度计算，如下图所示），同时子网络通过一个分类损失进行监督学习，因为并不需要回归坐标，所以没有回归损失。在inference阶段仅有主网络部分，因此这个操作不会在inference阶段增加计算成本。

再用直白一点的话说，*因为RCNN这个子网络的输入就是RoI在原输入图像上裁剪出来的图像，因此不存在RoI以外区域信息的干扰，这就使得RCNN这个网络训练得到的分类结果更加可靠，以此通过一个损失函数监督主网络Faster
RCNN的分类支路训练就能够使网络提取到更多RoI内部特征，而不是自己引入的外部特征。*

总的loss由三部分组成：mimic loss + R-CNN classification loss + Faster-RCNN loss.