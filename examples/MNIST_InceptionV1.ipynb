{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MNIST——InceptionV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 简介\n",
    "GoogleNet是google公司推出的高性能网络结构。\n",
    "- 其独特的 inception 结构，让网络自行学习不同感受野特征的融合。\n",
    "\n",
    "![inception模块示意图](https://ai-studio-static-online.cdn.bcebos.com/800ec8fdeab14c87a2cfb0fe94ea1bab1294b96ccf164b3aa28bbdbb96460518)\n",
    "- 为了应对深度网络训练时，反向传播梯度过小的问题，训练时候将分类 loss 在网络中间引入，加强对浅层网络参数的学习\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fd0d09e9892f470bb550b4130cb3bc7569ba827d59504dc589094313bfadd6d7)\n",
    "\n",
    "\n",
    "- Inception 块由四条并行路径组成。前三条路径使用窗口大小为 11、33 和\n",
    "55 的卷积层，从不同空间大小中提取信息。中间的两条路径在输入上执行 11\n",
    "卷积，以减少通道数，从而降低模型的复杂性。第四条路径使用 33 最大池化\n",
    "层，然后使用 11 卷积层来改变通道数。这四条路径都使用合适的填充来使输入\n",
    "与输出的高和宽一致，最后将每条线路的输出在通道维度上连结，并构成\n",
    "Inception 块的输出。在 Inception 块中，通常调整的超参数是每层输出通道的\n",
    "数量。\n",
    "Inception 块相当于一个有 4 条路径的子网络。它通过不同窗口形状的卷积\n",
    "层和最大池化层来并行抽取信息，并使用 11 卷积层减少每像素级别上的通道\n",
    "维数从而降低模型复杂度。不同大小的卷积核使得网络可以有效识别不同范围\n",
    "的图像细节，使得网络更加有效。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d059552f5da34fe69de6eab6aeb8b409db4f9eab2c9f46adb2414a152664a304)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import paddle.fluid as fluid\r\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\r\n",
    "from paddle.vision.transforms import Compose, Normalize\r\n",
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "import numpy as np \r\n",
    "from paddle.metric import Accuracy\r\n",
    "import random\r\n",
    "\r\n",
    "class InceptionA(paddle.nn.Layer):\r\n",
    "    def __init__(self, in_channels):\r\n",
    "        super(InceptionA, self).__init__()\r\n",
    "        self.branch3x3_1 = Conv2D(in_channels, 16, kernel_size=1)\r\n",
    "        self.bn1 = fluid.BatchNorm(16)\r\n",
    "        self.branch3x3_2 = Conv2D(16, 24, kernel_size=3, padding=1)\r\n",
    "        self.bn2 = fluid.BatchNorm(24)\r\n",
    "        self.branch3x3_3 = Conv2D(24, 24, kernel_size=3, padding=1)\r\n",
    "        self.bn3 = fluid.BatchNorm(24)\r\n",
    "        self.branch5x5_1 = Conv2D(in_channels, 16, kernel_size=1)\r\n",
    "        self.bn4 = fluid.BatchNorm(16)\r\n",
    "        self.branch5x5_2 = Conv2D(16, 24, kernel_size=5, padding=2)\r\n",
    "        self.bn5 = fluid.BatchNorm(24)\r\n",
    "        self.branch1x1 = Conv2D(in_channels, 16, kernel_size=1)\r\n",
    "        self.bn6 = fluid.BatchNorm(16)\r\n",
    "        self.branch_pool = Conv2D(in_channels, 24, kernel_size=1)\r\n",
    "        self.bn7 = fluid.BatchNorm(24)\r\n",
    "    def forward(self, x):\r\n",
    "        branch3x3 = self.branch3x3_1(x)\r\n",
    "        branch3x3 = F.relu(branch3x3)\r\n",
    "        branch3x3 = self.bn1(branch3x3)\r\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\r\n",
    "        branch3x3 = F.relu(branch3x3)\r\n",
    "        branch3x3 = self.bn2(branch3x3)\r\n",
    "        branch3x3 = self.branch3x3_3(branch3x3)\r\n",
    "        branch3x3 = F.relu(branch3x3)\r\n",
    "        branch3x3 = self.bn3(branch3x3)\r\n",
    "\r\n",
    "        branch5x5 = self.branch5x5_1(x)\r\n",
    "        branch5x5 = F.relu(branch5x5)\r\n",
    "        branch5x5 = self.bn4(branch5x5)\r\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\r\n",
    "        branch5x5 = F.relu(branch5x5)\r\n",
    "        branch5x5 = self.bn5(branch5x5)\r\n",
    "\r\n",
    "        branch1x1 = self.branch1x1(x)\r\n",
    "        branch1x1 = F.relu(branch1x1)\r\n",
    "        branch1x1 = self.bn6(branch1x1)\r\n",
    "\r\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\r\n",
    "        branch_pool = self.branch_pool(branch_pool)\r\n",
    "        branch_pool = F.relu(branch_pool)\r\n",
    "        branch_pool = self.bn7(branch_pool)\r\n",
    "        cat = fluid.layers.concat((branch1x1, branch5x5, branch3x3, branch_pool), axis=1)\r\n",
    "        output = F.relu(cat)\r\n",
    "\r\n",
    "        return  output\r\n",
    "\r\n",
    "class net(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(net, self).__init__()\r\n",
    "        self.conv1 = Conv2D(1, 10, kernel_size=5)  #24*24*10\r\n",
    "        self.conv2 = Conv2D(88, 20, kernel_size=5) #8***20\r\n",
    "        self.incep1 = InceptionA(in_channels=10)\r\n",
    "        self.incep2 = InceptionA(in_channels=20)\r\n",
    "        self.mp =MaxPool2D(2)\r\n",
    "        self.fc = Linear(1408, 10)  # 4*4*88=1408\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = F.relu(self.mp(self.conv1(x)))\r\n",
    "        x = self.incep1(x)\r\n",
    "        x = F.relu(self.mp(self.conv2(x)))\r\n",
    "        x = self.incep2(x)\r\n",
    "        x =fluid.layers.flatten(x=x, axis=1) \r\n",
    "        x = self.fc(x)\r\n",
    "\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "2021-07-11 06:28:19,802 - INFO - font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2021-07-11 06:28:20,138 - INFO - generated new fontManager\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "..\n",
      "Download finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load finished\n"
     ]
    }
   ],
   "source": [
    "#数据处理部分之前的代码，保持不变\r\n",
    "import os\r\n",
    "import random\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "import gzip\r\n",
    "import json\r\n",
    "\r\n",
    "# 读取数据\r\n",
    "def load_data(mode='train'):\r\n",
    "    # 数据预处理，这里用到了随机调整亮度、对比度和饱和度\r\n",
    "    transform = Compose([Normalize(mean=[0.1307],std=[0.3081],data_format='CHW')])\r\n",
    "\r\n",
    "#读取训练集 测试集数据\r\n",
    "    train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\r\n",
    "    test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\r\n",
    "    print('load finished')\r\n",
    "    return train_dataset ,test_dataset\r\n",
    "train_dataset ,test_dataset = load_data(mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/2\n",
      "step  10/938 [..............................] - loss: 1.0360 - acc: 0.4234 - ETA: 37s - 40ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 938/938 [==============================] - loss: 0.0119 - acc: 0.9634 - 21ms/step        \n",
      "Epoch 2/2\n",
      "step 938/938 [==============================] - loss: 0.0026 - acc: 0.9884 - 21ms/step         \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 1.1910e-04 - acc: 0.9896 - 12ms/step      \n",
      "Eval samples: 10000\n",
      "epoch: 0, batch_id: 0, loss is: [3.0492208], acc is: [0.03125]\n",
      "epoch: 0, batch_id: 200, loss is: [0.10507393], acc is: [0.953125]\n",
      "epoch: 0, batch_id: 400, loss is: [0.09254543], acc is: [0.96875]\n",
      "epoch: 0, batch_id: 600, loss is: [0.0170632], acc is: [1.]\n",
      "epoch: 0, batch_id: 800, loss is: [0.05097996], acc is: [0.984375]\n",
      "epoch: 1, batch_id: 0, loss is: [0.00766523], acc is: [1.]\n",
      "epoch: 1, batch_id: 200, loss is: [0.03294438], acc is: [0.984375]\n",
      "epoch: 1, batch_id: 400, loss is: [0.06893445], acc is: [0.96875]\n",
      "epoch: 1, batch_id: 600, loss is: [0.04710901], acc is: [0.984375]\n",
      "epoch: 1, batch_id: 800, loss is: [0.01074302], acc is: [1.]\n",
      "epoch: 2, batch_id: 0, loss is: [0.05583237], acc is: [0.96875]\n",
      "epoch: 2, batch_id: 200, loss is: [0.04181864], acc is: [0.984375]\n",
      "epoch: 2, batch_id: 400, loss is: [0.00540922], acc is: [1.]\n",
      "epoch: 2, batch_id: 600, loss is: [0.07419629], acc is: [0.984375]\n",
      "epoch: 2, batch_id: 800, loss is: [0.01751333], acc is: [1.]\n",
      "epoch: 3, batch_id: 0, loss is: [0.09027364], acc is: [0.984375]\n",
      "epoch: 3, batch_id: 200, loss is: [0.00031665], acc is: [1.]\n",
      "epoch: 3, batch_id: 400, loss is: [0.05514818], acc is: [0.984375]\n",
      "epoch: 3, batch_id: 600, loss is: [0.01808944], acc is: [0.984375]\n",
      "epoch: 3, batch_id: 800, loss is: [0.02182116], acc is: [0.984375]\n",
      "epoch: 4, batch_id: 0, loss is: [0.04250156], acc is: [0.984375]\n",
      "epoch: 4, batch_id: 200, loss is: [0.01769988], acc is: [0.984375]\n",
      "epoch: 4, batch_id: 400, loss is: [0.04417125], acc is: [0.984375]\n",
      "epoch: 4, batch_id: 600, loss is: [0.01923622], acc is: [1.]\n",
      "epoch: 4, batch_id: 800, loss is: [0.00434066], acc is: [1.]\n",
      "epoch: 5, batch_id: 0, loss is: [0.00023084], acc is: [1.]\n",
      "epoch: 5, batch_id: 200, loss is: [0.00124487], acc is: [1.]\n",
      "epoch: 5, batch_id: 400, loss is: [2.1827978e-05], acc is: [1.]\n",
      "epoch: 5, batch_id: 600, loss is: [0.01082046], acc is: [1.]\n",
      "epoch: 5, batch_id: 800, loss is: [0.00312009], acc is: [1.]\n",
      "epoch: 6, batch_id: 0, loss is: [0.01512346], acc is: [0.984375]\n",
      "epoch: 6, batch_id: 200, loss is: [0.00173522], acc is: [1.]\n",
      "epoch: 6, batch_id: 400, loss is: [0.00861133], acc is: [1.]\n",
      "epoch: 6, batch_id: 600, loss is: [0.02146053], acc is: [0.984375]\n",
      "epoch: 6, batch_id: 800, loss is: [0.03016113], acc is: [0.984375]\n",
      "epoch: 7, batch_id: 0, loss is: [0.00366162], acc is: [1.]\n",
      "epoch: 7, batch_id: 200, loss is: [0.0167724], acc is: [1.]\n",
      "epoch: 7, batch_id: 400, loss is: [4.2185064e-05], acc is: [1.]\n",
      "epoch: 7, batch_id: 600, loss is: [0.00430068], acc is: [1.]\n",
      "epoch: 7, batch_id: 800, loss is: [0.05651587], acc is: [0.984375]\n",
      "epoch: 8, batch_id: 0, loss is: [0.00079738], acc is: [1.]\n",
      "epoch: 8, batch_id: 200, loss is: [0.06646551], acc is: [0.984375]\n",
      "epoch: 8, batch_id: 400, loss is: [0.00141636], acc is: [1.]\n",
      "epoch: 8, batch_id: 600, loss is: [0.0007495], acc is: [1.]\n",
      "epoch: 8, batch_id: 800, loss is: [0.01025955], acc is: [1.]\n",
      "epoch: 9, batch_id: 0, loss is: [0.00239272], acc is: [1.]\n",
      "epoch: 9, batch_id: 200, loss is: [0.01712213], acc is: [0.984375]\n",
      "epoch: 9, batch_id: 400, loss is: [0.00559214], acc is: [1.]\n",
      "epoch: 9, batch_id: 600, loss is: [0.00016176], acc is: [1.]\n",
      "epoch: 9, batch_id: 800, loss is: [0.00073058], acc is: [1.]\n",
      "batch_id: 0, loss is: [0.00091112], acc is: [1.]\n",
      "batch_id: 20, loss is: [0.00855334], acc is: [1.]\n",
      "batch_id: 40, loss is: [0.14415486], acc is: [0.984375]\n",
      "batch_id: 60, loss is: [0.03174749], acc is: [0.984375]\n",
      "batch_id: 80, loss is: [0.00936899], acc is: [1.]\n",
      "batch_id: 100, loss is: [0.00176497], acc is: [1.]\n",
      "batch_id: 120, loss is: [9.498588e-06], acc is: [1.]\n",
      "batch_id: 140, loss is: [0.03361116], acc is: [0.984375]\n",
      "正确率为：[1.]\n"
     ]
    }
   ],
   "source": [
    "model = paddle.Model(net())  \r\n",
    "optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()) # adam优化器\r\n",
    "\r\n",
    "# 配置模型\r\n",
    "model.prepare(\r\n",
    "    optim,\r\n",
    "    paddle.nn.CrossEntropyLoss(),\r\n",
    "    Accuracy()\r\n",
    "    )\r\n",
    "# 训练模型\r\n",
    "model.fit(train_dataset,epochs=2,batch_size=64,verbose=1)\r\n",
    "#评估\r\n",
    "model.evaluate(test_dataset, batch_size=64, verbose=1)\r\n",
    "\r\n",
    "#训练\r\n",
    "def train(model,Batch_size=64):\r\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\r\n",
    "    model.train()\r\n",
    "    iterator = 0\r\n",
    "    epochs = 10\r\n",
    "    total_steps = (int(50000//Batch_size)+1)*epochs\r\n",
    "    lr = paddle.optimizer.lr.PolynomialDecay(learning_rate=0.01,decay_steps=total_steps,end_lr=0.001)\r\n",
    "    optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\r\n",
    "    # 用Adam作为优化函数\r\n",
    "    for epoch in range(epochs):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            x_data = data[0]\r\n",
    "            y_data = data[1]\r\n",
    "            predicts = model(x_data)\r\n",
    "            loss = F.cross_entropy(predicts, y_data)\r\n",
    "            # 计算损失\r\n",
    "            acc = paddle.metric.accuracy(predicts, y_data)\r\n",
    "            loss.backward()\r\n",
    "            if batch_id % 200 == 0:\r\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\r\n",
    "                iterator+=200\r\n",
    "            optim.step()\r\n",
    "            optim.clear_grad()\r\n",
    "        paddle.save(model.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdparams')\r\n",
    "        paddle.save(optim.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdopt')\r\n",
    "\r\n",
    "\r\n",
    "#测试\r\n",
    "def test(model):\r\n",
    "    # 加载测试数据集\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\r\n",
    "    model.eval()\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data = data[0]\r\n",
    "        y_data = data[1]\r\n",
    "        predicts = model(x_data)\r\n",
    "        # 获取预测结果\r\n",
    "        loss = F.cross_entropy(predicts, y_data)\r\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\r\n",
    "        if batch_id % 20 == 0:\r\n",
    "            print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\r\n",
    "\r\n",
    "#随机抽取100张图片进行测试\r\n",
    "def random_test(model,num=100):\r\n",
    "    select_id = random.sample(range(1, 10000), 100) #生成一百张测试图片的下标\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data = data[0]\r\n",
    "        label = data[1]\r\n",
    "    predicts = model(x_data)\r\n",
    "    #返回正确率\r\n",
    "    acc = paddle.metric.accuracy(predicts, label)\r\n",
    "    print(\"正确率为：{}\".format(acc.numpy()))\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    model = net()\r\n",
    "    train(model)\r\n",
    "    test(model)\r\n",
    "    random_test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
