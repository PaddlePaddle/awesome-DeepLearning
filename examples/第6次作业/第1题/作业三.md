# 1. **CNN-DSSM**

**1. 1. 概念**

DSSM 用字向量作为输入既可以减少切词的依赖，又可以提高模型的范化能力，因为每个汉字所能表达的语义是可以复用的。另一方面，传统的输入层是用 Embedding 的方式（如 Word2Vec 的词向量）或者主题模型的方式（如 LDA 的主题向量）来直接做词的映射，再把各个词的向量累加或者拼接起来，由于 Word2Vec 和 LDA 都是无监督的训练，这样会给整个模型引入误差，DSSM 采用统一的有监督训练，不需要在中间过程做无监督模型的映射，因此精准度会比较高。

但是由于DSSM 采用词袋模型（BOW），因此丧失了语序信息和上下文信息。另一方面，DSSM 采用弱监督、端到端的模型，预测结果不可控。

针对 DSSM 词袋模型丢失上下文信息的缺点。通过卷积层实现的“窗口”，模型可以捕获文本中类似n-gram的上下文结构信息，并用最显著的上下文特征转化为表示文本的语义向量。最终提升模型的效果。

**1. 2. 模型**

**1. 2. 1. 输入层**

![](https://ai-studio-static-online.cdn.bcebos.com/3378073f47f44a1a811f9ee25cf6656e4d653d079a90468381e4b34fff12d612)


**1. 2. 1. 1. 英文**

英文的处理方式，除了 letter-trigram，CNN-DSSM 还在输入层增加了word-trigram，word-trigram其实就是一个包含了上下文信息的滑动窗口。

**1. 2. 1. 2. 中文**

英文的处理方式（word-trigram letter-trigram）在中文中并不可取，因为英文中虽然用了 word-ngram 把样本空间拉成了百万级，但是经过 letter-trigram 又把向量空间降到可控级别，只有 3 * 30K（9 万）。而中文如果用 word-trigram，那向量空间就是百万级的了，显然还是字向量（1.5 万维）比较可控。

**1. 2. 2. 表示层**

CNN-DSSM 的表示层由一个卷积神经网络组成，如下图所示：

![](https://ai-studio-static-online.cdn.bcebos.com/c6c1a72221ba4e2992b511ea4f2cccfa80813848700242f2b22064921e6d0b71)


**1. 2. 2. 1. 卷积层**

卷积层的作用是提取滑动窗口下的上下文特征。以下图为例，假设输入层是一个 302 * 90000（302 行，9 万列）的矩阵，代表 302 个字向量（query 的和 Doc 的长度一般小于 300，这里少了就补全，多了就截断），每个字向量有 9 万维。而卷积核是一个 3 * 90000 的权值矩阵，卷积核以步长为 1 向下移动，得到的 feature map 是一个 300 * 1 的矩阵，feature map 的计算公式是(输入层维数 302-卷积核大小 3 步长 1)/步长 1=300。而这样的卷积核有 300 个，所以形成了 300 个 300 * 1 的 feature map 矩阵。

![](https://ai-studio-static-online.cdn.bcebos.com/9f375c4f6b824980990b620c4743376fa5adebd288c9481aaa3df429a042eec3)


**1. 2. 2. 2. 池化层**

池化层的作用是为句子找到全局的上下文特征。池化层以 Max-over-time pooling 的方式，每个 feature map 都取最大值，得到一个 300 维的向量。Max-over-pooling 可以解决可变长度的句子输入问题（因为不管 Feature Map 中有多少个值，只需要提取其中的最大值）。不过我们在上一步已经做了句子的定长处理（固定句子长度为 302），所以就没有可变长度句子的问题。最终池化层的输出为各个 Feature Map 的最大值，即一个 300 * 1 的向量。这里多提一句，之所以 Max pooling 层要保持固定的输出维度，是因为下一层全链接层要求有固定的输入层数，才能进行训练。

**1. 2. 2. 3. 全连接层**

最后通过全连接层把一个 300 维的向量转化为一个 128 维的低维语义向量。全连接层采用 tanh 函数：

![](https://ai-studio-static-online.cdn.bcebos.com/e45bf6c6ab02466c9d564496749c677b863ab82a08304d059d32f13c4f705e86)


**1. 2. 3. 匹配层**

Query 和 Doc 的语义相似性可以用这两个语义向量(128 维) 的 cosine 距离来表示：

![](https://ai-studio-static-online.cdn.bcebos.com/f666d5d4c72249eda0a7fed55642cc0e37520bc947c143eeb6806f149678a133)


通过softmax 函数可以把Query 与正样本 Doc 的语义相似性转化为一个后验概率：



![](https://ai-studio-static-online.cdn.bcebos.com/16e655ea4d2f46afab67ac48e408740513d5751bdc2d4688be68829d7d88e036)


其中 r 为 softmax 的平滑因子，D 为 Query 下的正样本，D-为 Query 下的负样本（采取随机负采样），D 为 Query 下的整个样本空间。

在训练阶段，通过极大似然估计，我们最小化损失函数：



![](https://ai-studio-static-online.cdn.bcebos.com/f009d0c92a6f4484ab9959547584d164ea1f32127ae64ced92ed052106a8fcc6)


残差会在表示层的 DNN 中反向传播，最终通过随机梯度下降（SGD）使模型收敛，得到各网络层的参数{Wi,bi}。

**1. 3. 作用**

CNN-DSSM用以解决 DSSM 词袋模型丢失上下文信息的缺点。

CNN-DSSM的结构可分为数据预处理（把文本向量化），在经过深度神经网络，压缩矩阵，最后拿压缩后的矩阵进行相似度计算。

**1. 4. 场景**

解决搜索引擎和搜索广告中的语义相似度问题。

克服DSSM 词袋模型丢失上下文信息的缺点。

**1. 5. 优缺点**

优点：

CNN-DSSM 通过卷积层提取了滑动窗口下的上下文信息，又通过池化层提取了全局的上下文信息，上下文信息得到较为有效的保留。

缺点：

对于间隔较远的上下文信息，难以有效保留。

# 2. **LSTM-DSSM**

**2. 1. 概念**

LSTM(（Long-Short-Term Memory）是一种 RNN 特殊的类型，可以学习长期依赖信息。

而LSTM-DSSM 其实用的是 LSTM 的一个变种——加入了peephole的 LSTM。

**2. 2. 模型**

![](https://ai-studio-static-online.cdn.bcebos.com/fabf5317809d4195b188d35a19c2347ac00b1dbd6bd34b7783b721d076121ef6)


![](https://ai-studio-static-online.cdn.bcebos.com/ac3fdb2d1d5e4ba2b22eeecc75c62283f70493e5bad94d6c889d948064cb37e2)


这里三条黑线就是所谓的 peephole，传统的 LSTM 中遗忘门、输入门和输出门只用了 h(t-1) 和 xt 来控制门缝的大小，peephole 的意思是说不但要考虑 h(t-1) 和 xt，也要考虑 Ct-1 和 Ct，其中遗忘门和输入门考虑了 Ct-1，而输出门考虑了 Ct。总体来说需要考虑的信息更丰富了。

 LSTM-DSSM 整体的网络结构：

![](https://ai-studio-static-online.cdn.bcebos.com/d2f08ff32f924825b19c7b1890643f84775e0220dd2044e68e741dc8ade9d8da)

红色的部分为残差传递的方向。

**2. 3. 作用**

解决CNN-DSSM 无法捕获较远距离上下文特征的缺点。

**2. 4. 场景**

在电商领域，document除开标题以外，可能还会有其他很重要的信息，例如品牌和类目。此时可以将品牌、类目通过Embedding表示学习层、两层MLP直接映射成和LSTM提取的语义向量同一维度的向量，再将两者相加得到最终的语义向量表示，使用最终的语义向量表示输入到DSSM模型中进行召回。

**2. 5. 优缺点**

优点：

除了比R-DSSM 更快的收敛和更好的实际性能之外，LSTM-DSSM 可以潜在地提供关于不同之间的相关性的有价值的信息主题以及关于在长文档中从一个主题到另一个主题的转换。 

# 3. **ShareBottom多任务学习**

**3. 1. 概念**

在多任务学习模型当中，最常见的一种模型就是ShareBottom模型。首先每个任务共享底部的network，然后再根据任务的个数在上面划分出多个tower network来分别学习不同的目标。转换成公式是：

![](https://ai-studio-static-online.cdn.bcebos.com/0c7c9488ef0a475294422332c344c6ff384126d037c74e8f872c344de73c8a2a)

其中f表示ShareBottom network， hk表示第k个tower network，yk是最终的输出。

**3. 2. 模型**

![](https://ai-studio-static-online.cdn.bcebos.com/1522175879e1462b9f595f006289220179380a3e31544a9fb82f3ff87cabdc8d)


ShareBottom的思路就是多个目标底层共用一套共享layer，在这之上基于不同的目标构建不同的Tower。这样的好处就是底层的layer复用，减少计算量，同时也可以防止过拟合的情况出现。

**3. 3. 作用**

在推荐业务中经常有“既要、也要、还要”的场景，比如做视频推荐业务的时候既要提升用户对于视频的点击率，也希望同时提升用户观看视频的时长。面对这样的诉求，通常需要在推荐系统中使用多目标建模算法。而多目标建模目前业内有两种模式，其中一种便为ShareBottom模式。

**3. 4. 场景**

![](https://ai-studio-static-online.cdn.bcebos.com/2681e0dce60b43fca0b815254218dbdfb28a898edd88481db63c1e502aa8d0dd)


上图是ShareBottom以及OMOE、MMOE在不同目标相关性下的的效果比对，不难发现，无论目标Correlation是什么数值，MOE结构的算法的loss永远低于ShareBottom类型的，显然MOE结构更优。

**3. 5. 优缺点**

优点：

降低overfit风险，利用任务之间的关联性使模型学习效果更强

缺点：

任务之间的相关性将严重影响模型效果。假如任务之间相关性较低，模型的效果相对会较差。

  # 4. **MMoE多任务学习**

**4. 1. 概念**

MMOE模型，全称为：Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts。

近年来，深度神经网络的应用越来越广，如推荐系统。推荐系统通常需要同时优化多个目标，如电影推荐中不仅需要预测用户是否会购买，还需要预测用户对于电影的评分，在比如电商领域同时需要预测物品的点击率CTR和转化率CVR。因此，多任务学习模型成为研究领域的一大热点。

许多多任务学习模型取得了不错的效果，但是实践中多任务学习模型并不总比单任务模型效果更突出。这主要是因为不同任务之间的相关性低（如数据的分布不同等等）导致的。

为了进行不相关任务的多任务学习，很多人做了很多工作都见效甚微，然后后来就有了Google的这个相当新颖的模型MMoE。

**4. 2. 模型**

![](https://ai-studio-static-online.cdn.bcebos.com/a702ceb54f3143909bae04ea94e46b135c767370c6c94caf81beac186b8f0671)


MMoE模型为每一个task设置了一个gate，使不同的任务和不同的数据可以多样化的使用共享层。

门控网络采用输入特性和输出Softmax门，以不同的权重组装专家，允许不同的任务以不同的方式利用专家。 然 后将组装专家的结果传递到特定任务的塔网络中。这样，不同任务的门控网络可以学习专家组装的不同混合模式，从而捕获任务关系。

每个任务的共享层的输出不同，第k个任务的共享层输出计算公式如下：

![](https://ai-studio-static-online.cdn.bcebos.com/b90c79291d3949b0bf59f1e3629a217e3852c68f168940f0af50b98ffbf6e7d0)

随后每个任务对应的共享层输出，经过多层全连接神经网络得到每个任务的输出：

![](https://ai-studio-static-online.cdn.bcebos.com/5295b81169af4a68b9f101abf226e499d3277981592f493a93b26baa4a8d1760)

如果两个任务并不十分相关，经过Gate之后，二者得到的权重系数会差别比较大，可以利用部分expert网络输出的信息，近似于多个单任务学习模型。如果两个任务紧密相关，经过Gate得到的权重分布相差不多，类似于一般的多任务学习框架。

**4. 3. 作用**

在MMoE提出之前，多任务模型已经有许多经典架构被提出，其中绝大多数的优化都基于ShareBottom架构，即不同的任务共享相同的feature或feature_map。

然而，这种架构极大地限制了模型表达的能力，因为我们在共享特征的上层直接接入了多个目标的输出，而由于多个任务各自有不同的数据分布，也就是说我们对不同任务的输出具有一定的差异性，而相同的特征输入会极大地削弱模型的多任务输出表达而在某种程度上降低了多目标模型的泛化能力。

One-gate MoE model，这种模型架构就在一定程度上解决了上述问题，即虽然说多个模型还是共享相同的输入特征，但是每个任务都利用"gate network"来区分特征表达的权重，从而提高了模型的表达能力。但是这种模型架构的"区分"还不是很大，毕竟输入的特征还是只有一个。

受集成学习（ensemble learning）思想的影响，multi-experts应运而生。我们可以把单个的共享特征看做是一个弱学习器的输入，那么，根据集成思想，若干弱学习器的组合可以作为一个强学习器来对结果进行推理，再通过"gate network"就可以极大地提高多任务模型的表达能力了。

**4. 4. 场景**

在工业界基于神经网络的多任务学习在推荐等场景业务应用广泛，比如在推荐系统中对用户推荐物品时，不仅要推荐用户感兴趣的物品，还要尽可能地促进转化和购买，因此要对用户评分和购买两种目标同时建模。阿里之前提出的 ESSM 模型属于同时对点击率和转换率进行建模，提出的模型是典型的 shared-bottom 结构。多任务学习中有个问题就是如果子任务差异很大，往往导致多任务模型效果不佳。谷歌的一个内容推荐团队考虑了多任务之间的区别提出了 MMoE 模型，并取得了不错的效果。

随着在线推理服务瓶颈的到来，多任务模型是未来的一个趋势，因为在推荐场景中，人的交互行为是并发甚至是并行的，所以我们单单去预测用户的某一种行为，可能会在某种角度上降低了用户其他行为的体验，而随着多目标模型的发展，我们可以同时对用户的不同行为做判断，那么这会在一定程度上提高用户的体验。

![](https://ai-studio-static-online.cdn.bcebos.com/e60eb351a633491d87992ef849f8b26010b1f9fd605640378156b2706ce78f08)


上图是ShareBottom以及OMOE、MMOE在不同目标相关性下的的效果比对，不难发现，无论目标Correlation是什么数值，MOE结构的算法的loss永远低于ShareBottom类型的，显然MOE结构更优。

而OMOE在目标相关性最高的情况下（Correlation=1）和MMOE的效果相似，其它情况下不如MMOE。也就是说，目标相关性越低MMOE较其它二者的优势越明显，相关性非常高的情况下MMOE会近似于OMOE。


![](https://ai-studio-static-online.cdn.bcebos.com/878b624094734487a91f840baeb3b18812d2d9c972a6424ea93d96ca92d53826)


通过使用不同的random seeds生成相同分布下的数据以及不同的模型初始化，上图描述了MMoE, OMoE, Shared-Bottom最终的loss分布直方图，可以发现：

1. ShareBottom model 有更大的方差, 也就是说ShareBottom 通常具有更多质量较差的局部最小值。

2. task correlation =1时，OMoE和MMoE健壮性相当，但是当任务相关性下降，OMoE的健壮性出现显著下滑，可见，multi-gate structure在解决由任务差异引起的冲突导致的不良局部最小值是有效的。

**4. 5. 优缺点**

优点：

1. MMoE能够对于任务之间的关系明确地建模。

2. Gating networks是轻量的，而expert networks是共享的，因此并不会引入造成计算成本太大的情况。

3. MMoE更容易训练。


# 5. **YouTube深度学习视频推荐系统**

**5. 1. 概念**

作为全球最大的视频分享网站，YouTube 平台中几乎所有的视频都来自 UGC（User Generated Content，用户原创内容），这样的内容产生模式使得 YouTube 的视频推荐面临三方面的挑战：

1. Scale：视频和用户数量巨大，很多现有的推荐算法能够在小的数据集上表现得很好，但是在这里效果不佳。需要构建高度专业化的分布式学习算法和高效的服务系统来处理youtube庞大的用户和视频数量。

2. Freshness：这体现在两方面，一方面视频更新频繁，另一方面用户行为更新频繁。

3. Noise：相较于庞大的视频库，用户的行为是十分稀疏的，同时，我们基本上能获得的都是用户的隐式反馈信号。构造一个强健的系统是十分困难的。

**5. 2. 流程**

![](https://ai-studio-static-online.cdn.bcebos.com/08aef594290f46ed94edcb7f4237f0549ed62c11e3c74f16a81ee2543a1823b5)


由于候选视频集合过大，考虑online系统延迟问题，不宜用复杂网络直接进行推荐，所以Youtube采取了两层深度网络完成整个推荐过程：

* 第一层是Candidate Generation Model完成候选视频的快速筛选，这一步候选视频集合由百万降低到了百的量级。

* 第二层是用Ranking Model完成几百个候选视频的精排。

**5. 2. 1. 候选集生成Candidate Generation**

Candidate Generation阶段，会从巨大的视频库中挑选几百个用户可能感兴趣的候选集。模型的结构如下图所示：


![](https://ai-studio-static-online.cdn.bcebos.com/7e4a9bddb066404883546ae46b506172547786def96d497fb02664bc8b72a73b)


**5. 2. 1. 1. 输入特征**

可以看到，模型的输入包括用户的观看过的视频的embedding，用户搜索过的token的embedding，用户的地理信息embedding，用户的年龄和性别信息。

每一秒中，YouTube都有大量视频被上传，推荐这些最新视频对于YouTube来说是极其重要的。同时，通过观察历史数据发现，用户更倾向于推荐那些尽管相关度不高但是是最新（fresh）的视频。Example Age为训练时间Sample Log的产生时间而在线上服务阶段，该特征被赋予0值甚至是一个比较小的负数。这样的做法类似于在广告排序中消除position bias。

假设这样一个视频十天前发布的，许多用户在当前观看了该视频，那么在当天会产生许多Sample Log，而在后面的九天里，观看记录不多，Sample Log也很少。如果我们没有加入Example Age这个特征的话，无论何时训练模型，这个视频对应的分类概率都是差不多的，但是如果我们加入这个特征，模型就会知道，如果这条记录是十天前产生的话，该视频会有很高的分类概率，如果是最近几天产生的话，分类概率应该低一些，这样可以更加逼近实际的数据。

![](https://ai-studio-static-online.cdn.bcebos.com/36f2a5ae96434bc59cca4f381130ccdfb7ca3e269f9d4eae8b9cf2b5574ed711)


**5. 2. 1. 2. 样本和上下文选择**

在这里，正样本是用户所有完整观看过的视频，其余可以视作负样本。

训练样本是从Youtube所有的用户观看记录里产生的，而并非只是通过推荐系统产生的。同时，针对每一个用户的观看记录，都生成了固定数量的训练样本，这样，每个用户在损失函数中的地位都是相等的，防止一小部分超级活跃用户主导损失函数。

在对待用户的搜索历史或者观看历史时，可以看到Youtube并没有选择时序模型，而是完全摒弃了序列关系，采用求平均的方式对历史记录进行了处理。这是因为考虑时序关系，用户的推荐结果将过多受最近观看或搜索的一个视频的影响。文章中给出一个例子，如果用户刚搜索过“tayer swift”，你就把用户主页的推荐结果大部分变成tayer swift有关的视频，这其实是非常差的体验。为了综合考虑之前多次搜索和观看的信息，YouTube丢掉了时序信息，讲用户近期的历史纪录等同看待。但是上述仅是经验之谈，也许类似阿里深度学习演化网络中RNN + Attention的方法，能够取得更好的推荐效果。

最后，在处理测试集的时候，YouTube没有采用经典的随机留一法（random holdout），而是把用户最近的一次观看行为作为测试集，如下图。这主要是避免引入超越特征。

![](https://ai-studio-static-online.cdn.bcebos.com/23f59402442b46d289d7b6590ea42d9d6cc51d83e5d8408c82fc103500749842)


**5. 2. 1. 3. 离线训练**

从模型结构可以看出，在离线训练阶段，我们将其视为了一个分类问题。我们使用隐式反馈来进行学习，用户完整观看过一个视频，便视作一个正例。如果将视频库中的每一个视频当作一个类别，那么在时刻 t ，对于用户U和上下文 C ，用户会观看视频 i 的概率为：

![](https://ai-studio-static-online.cdn.bcebos.com/655f785f16ea4eb0b4cf8a151237b0d1867418467dfa4406a07e54cc250b3827)


其中，u是用户的embedding，这个embedding，是网络最后一个Relu激活函数的输出，vi是视频i的embedding。那么问题来了，输入时，每一个视频也有一个对应的embedding，这个embedding是不是计算softmax的embedding呢？这里文章也没有说清楚？也许一个视频对应一个embedding，也许一个视频对应两组不同的embedding。关于这个问题的理解，欢迎大家在评论区留言！

使用多分类问题的一个弊端是，我们有百万级别的classes，模型是非常难以训练的，因此在实际中，Youtube并使用负样本采样(negative sampling)的方法，将class的数量减小。还有一种可以替换的方法，成为hierarchical softmax，但经过尝试，这种方法并没有取得很好的效果。关于上面的两种方法，大家是不是想起了word2vec中训练词向量的两种方式？但是这里的负采样和word2vec中的负采样方法是不同的，这里采样之后还是一个多分类问题，而word2vec中的负采样方法是将问题转为了一个二分类问题。

下图是离线训练的结果，使用的评价指标是MAP(Mean Average Precision)，主要考察的两个点是输入特征以及网络层数对于实验效果的影响：

![](https://ai-studio-static-online.cdn.bcebos.com/ad8e1008e5894dcc952d4f98b582f4ee5e06f9dd05a8496cb1bbcdf45c920c43)


**5. 2. 1. 4. 在线服务**

对于在线服务来说，有严格的性能要求，必须在几十毫秒内返回结果。因此，youtube没有重新跑一遍模型，而是通过保存用户的embedding和视频的embedding，通过最近邻搜索的方法得到top N的结果。

最终的结果是approx topN的结果，而并不是直接计算用户embedding和每个视频embedding的内积。如果这样做的话，N个视频的内积计算 + 排序，时间复杂度大概是NlogN，这样很难满足时间复杂度要求。如果使用局部敏感哈希(Locality-Sensitive Hashing, LSH)等近似最近邻快速查找技术，时间复杂度是可以大大降低的。

**5. 2. 2. 排序Ranking**

排序过程是对生成的候选集做进一步细粒度的排序。模型的结构图如下所示：

![](https://ai-studio-static-online.cdn.bcebos.com/05691de7472142728529853295b7040e9c340d2235554a54aef103123fa96966)


**5. 2. 2. 1. 输入特征**

在排序阶段，输入的特征主要有：

* impression video ID embedding: 当前要计算的video的embedding
* watched video IDs average embedding: 用户观看过的最后N个视频embedding的average pooling
* language embedding: 用户语言的embedding和当前视频语言的embedding
* time since last watch: 用户上次观看同频道时间距现在的时间间隔
* previous impressions: 该视频已经被曝光给该用户的次数

第4个特征是用户上次观看同频道时间距现在的时间间隔，这里有一点attention的意思，加入我们刚看了一场NBA比赛的集锦，我们很可能继续观看NBA频道的其他视频，那么这个特征就很好地捕捉到了这一行为。第5个特征previous impressions则一定程度上引入了exploration的思想，避免同一个视频持续对同一用户进行无效曝光。尽量增加用户没看过的新视频的曝光可能性。

**5. 2. 2. 2. 特征处理**

特征处理主要包含对于离散变量的处理和连续变量的处理。

对于离散变量，这里主要是视频ID，Youtube这里的做法是有两点：

1. 只保留用户最常点击的N个视频的embedding，剩余的长尾视频的embedding被赋予全0值。可能的解释主要有两点，一是出现次数较少的视频的embedding没法被充分训练。二是也可以节省线上服务宝贵的内存资源。

2. 对于相同域的特征可以共享embedding，比如用户点击过的视频ID，用户观看过的视频ID，用户收藏过的视频ID等等，这些公用一套embedding可以使其更充分的学习，同时减少模型的大小，加速模型的训练。

对于连续特征，主要进行归一化处理，神经网络对于输入的分布及特征的尺度是十分敏感。因此作者设计了一种积分函数将连续特征映射为一个服从[0,1]分布的变量。该积分函数为：

![](https://ai-studio-static-online.cdn.bcebos.com/5b9f20598dea4d98860f3cae0b0c6c81886cda468224495aa8672147d14387ca)

为了引入特征的非线性，除了加入归一化后的特征外，还加入了该特征的平方和开方值。

**5. 2. 2. 3. 建模期望观看时间**

在训练阶段，Youtube没有把问题当作一个CTR预估问题，而是通过weighted logistic 建模了用户的期望观看时间。

在这种情况下，对于正样本，权重是观看时间，而对于负样本，权重是单位权重(可以认为是1)，那么，此时，观看时长的几率(odds，在原逻辑回归中，指正例发生的概率与负例发生概率的比值)为：

![](https://ai-studio-static-online.cdn.bcebos.com/03cd54492894453a92e8bb4363b14f8480decdda7cee4a329c5ec7a31bebc999)

上式中，Ti指样本中第i条正样本的观看时长，N是所有的训练样本，k是正样本的个数。在k特别小的情况下，上式近似为ET，P是点击率，E[T]是视频的期望观看时长，因为P非常小，那么乘积近似于E[T]。

同时，对于逻辑回归，我们知道几率的计算公式其实就是exp(wx + b)，同时几率可以近似于期望观看时长E[T]，那么我们在测试阶段，就可以直接输出exp(wx + b)，作为期望观看时长。

离线训练的效果如下图：

![](https://ai-studio-static-online.cdn.bcebos.com/197207324d53405fa0da56e475119faf36b618b110d745a8954c5985f55971e6)


**5. 3. 原理**

主架构通过 candidate generation（候选生成）模块，从百万video corpus（所有推荐候选池）找出几百个与用户相关的待推荐视频；然后ranking（排序）模块将候选模块产生的推荐列表中在选择十几个视频展示给用户。

YouTube将推荐问题转换为极多分类问题（extreme multiclass classication），公式如下：

![](https://ai-studio-static-online.cdn.bcebos.com/f392a782f401431b8e30fd28ef2052d4b71030f1688b4f85999df43576b55d97)

表示在时刻 t，用户U（上下文信息C）在视频库V中精准的预测出视频 i 的类别（每个具体的视频视为一个类别，i 即为一个类别）的概率。

其中 u 和 v，分别是用户的 embdded 向量和视频的 embdded 向量。YouTube采用了 word embedding 的方式计算出每个视频的 embedded 向量，而 u 则是通过输入用户信息和上下文信息给上面模型架构训练得到。

整个模型由包含三个隐层DNN组成，输入层输入的的信息有，用户播放历史和搜索历史embedded向量分别取average，再加入用户基础画像（年龄、性别等）其余特征：视频质量、视频age等特征concat成向量输入；输出分为serving和training两个部分。Training部分输出层是softmax层，也就是上面的公式表示的概率值，线上部分通过u向量和v向量得出用户相关topN视频。

Ranking 层从架构上跟候选生成层基本一致，不同是的最后输出层training是一个 weighted logistic，而serving阶段激活函数是ex；ranking层针对视频播放时长进行建模，以有没有点击来划分正负样本，正样本根据播放时长进行加权，正样本的权重是播放时长 Ti，负样本权重是1，而最后一层模型是weighted logistic regression；那么LR学到的odds为：

![](https://ai-studio-static-online.cdn.bcebos.com/9f56037878a947498302e295f93fe10c3f5dfa26aefe498b93f0bd56408a7acf)

其中 N 是总的样本数量，k 是正样本数量，Ti 是第i正样本的观看时长。k 相对 N 比较小，因此上式的 odds 可以转换成E[T]/(1+P)，其中 P 是点击率，点击率一般很小，这样 odds接近于E[T]，即期望观看时长。因此在线上 serving 的 inference 阶段，我们采用 ex 作为激励函数，就是近似的估计期望的观看时长。

虽然深度学习可以缓解人工构造特征的负担，但是原始数据也是无法直接喂给前馈神经网络，所以特征工程依旧非常重要。

在架构上整个推荐系统是建立在 Google brain 上面，使用 TensorFlow 进行建模。

**5. 4. 作用**

YouTube 推荐系统的架构是一个典型的召回层加排序层的架构，其中候选集生成模型负责从百万候选集中召回几百个候选视频，排序模型负责几百个候选视频的精排，最终选出几十个推荐给用户。

候选集生成模型是一个典型的 Embedding MLP 的架构，要注意的是它的输出层一个多分类的输出层，预测的是用户点击了“哪个”视频。在候选集生成模型的 serving 过程中，需要从输出层提取出视频 Embedding，从最后一层 ReLU 层得到用户 Embedding，然后利用 最近邻搜索快速 得到候选集。

排序模型同样是一个 Embedding MLP 的架构，不同的是，它的输入层包含了更多的用户和视频的特征，输出层采用了 Weighted LR 作为输出层，并且使用观看时长作为正样本权重，让模型能够预测出观看时长，这更接近 YouTube 要达成的商业目标。

**5. 5. 优缺点**

优点：

1. Youtube采用word2vec中常用的 负采样训练方法减少每次预测的分类数量，从而加快整个模型的收敛速度。

2. YouTube在对训练集的预处理过程中，没有采用原始的用户日志，而是对每个用户提取等数量的训练样本，这样减少高度活跃用户对模型损失的过度影响，使模型过于偏向活跃用户的行为模式，忽略数量更广大的长尾用户体验。

3. 在处理测试集时，Youtube没有采用经典的随机留一法，而是一定要以用户最近一次观看的行为作为测试集，这样做避免了引入未来信息(future information)，产生于事实不符的数据穿越问题。
