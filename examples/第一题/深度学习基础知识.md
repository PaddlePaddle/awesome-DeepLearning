# 深度学习基础知识3.1-GN


## 群组归一化

### $\bullet$批量归一化的局限

**批量归一化**（Batch Normalization，以下简称 **BN**）是深度学习发展中的一项里程碑式技术，可让各种网络并行训练。但是，批量维度进行归一化会带来一些问题——**批量（batch size）变小时，BN 的误差会迅速增加**。在训练大型网络任务中（包括检测、分割和视频），内存消耗限制了只能使用小批量的BN。

### $\bullet$群组归一化概念

**群组归一化** （Group Normalization ，简称 **GN**) 将通道（channel）分成组，并在每组内计算归一化的均值和方差。**GN 的计算与批量大小无关，并且其准确度在各种批量大小下都很稳定**。在 ImageNet 上训练的 ResNet-50 上，GN 使用批量大小为 2 时的错误率比 BN 的错误率低 10.6％；当使用典型的批量时，GN 与 BN 相当，并且优于其他标归一化变体。而且，GN 可以自然地从预训练迁移到微调。在进行 COCO 中的目标检测和分割以及 Kinetics 中的视频分类比赛中，GN 可以胜过其竞争对手，表明 GN 可以在各种任务中有效地取代强大的 BN。

## 算法流程

各种归一化方法的原理如下所示：

![img](https://upload-images.jianshu.io/upload_images/5357893-7cb3612b9a21bb73.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp)



为了改进**BN**的batch_size的问题，相继出现了Layer Normalization (**LN**)，Instance Normalization (**IN**)，它们可以在RNN/LSTM有效地工作，但**在机器视觉上达不到BN的精度**。

所有的归一化方法均能用下式描述：
$$
\hat{x}_i=\dfrac{1}{\sigma_i}(x_i-\mu_i)
$$
其中$\sigma$是标准差，$\mu$是均值，x是待归一化的数据，i是索引，对于图片来说，**代入模型的数据一般是(N,C,W,H)，它们分别是batch中图片的张数，通道数，图片的宽和图片的高**，不同的归一化方法在不同的维度计算。标准差和均值计算方法如下：
$$
\mu_i=\dfrac{1}{m}\sum\limits_{k\in S_i}x_k
$$

$$
\sigma_i=\sqrt{\dfrac{1}{m}\sum\limits_{k\in S_i}(x_k-\mu_i)^2+\epsilon}
$$

其中$\epsilon$(eps)是个很小的数用于防止$\sigma_i$等于0，S是像素点的值，m是数据个数。<u>不同的归一化方法的主要差别在于对S的定义不同</u>。

***BN***的S定义如下：
$$
S_i=\{k\ |\ k_C=i_C\}
$$

它表示对具有同样通道的数据归一化，即在(N,H,W)三个维度上计算均值和方差。

***LN***的S定义如下：
$$
S_i=\{k\ |\ k_N=i_N\}
$$

它表示在(C,H,W) 维度上，对每个实例（每张图）计算均值和方差。

***IN***的S定义如下：
$$
S_i=\{k\ |\ k_N=i_N, k_C=i_C\}
$$

它表示仅在(H,W) 维度上，对每个实例的每个通道计算均值和方差。

一般的归一化层除了上述功能以外，还**使用线性变换**补偿可能损失的表征能力（实现仿射变换），该层输出的y定义如下：
$$
y_i=\gamma\hat{x}_i+\beta
$$

其中，$\gamma$和$\beta$通过训练求得，分别对应缩放和平移。

***GN***的S定义如下：


它与IN类似，差别在于对通道分组处理。G是预先定义的分组数，默认为32，⌊.⌋为向下取整符号，在**(H,W,C/G)三个维度**上计算均值和方差，上图最右侧展示了G=2，每组三个通道的情况，GN针对每个组计算均值$\mu$和方差$\sigma$，针对每个通道学习$\gamma$和$\beta$。

LN、IN、GN三种方法都与batch_size无关，LN和IN可视为GN的极端形式，当G=1时 GN=LN， LN假设层中的所有通道具有相同的分布（与全连接层不同，这个假设在卷积层很少有效，因此在机器视觉中效果较差），相对的GN把通道分成几组，这样更有弹性。当G=C时GN=IN，IN只依赖于空间中的点计算，未考虑各个Channel的共性，过于片面。

GN的TensorFlow代码实现如下：

![何恺明团队最新力作：群组归一化（Group Normalization）](https://static.leiphone.com/uploads/new/article/740_740/201803/5ab4c237db607.png?imageMogr2/format/jpg/quality/90)

## 作用

不同特征往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据归一化处理，以解决数据指标之间的可比性。原始数据经过数据归一化处理后，各指标处于同一数量级，适合进行综合对比评价。

归一化的作用就是使得预处理的数据被限定在一定的范围内（比如[0,1]或者[-1,1]），从而消除奇异样本数据导致的不良影响。

<center><img src="https://ai-studio-static-online.cdn.bcebos.com/903f552bc55b4a5eba71caa7dd86fd2d7b71b8ebb6cb4500a5f5711f465707f3" width="300" hegiht="40" ></center>
<center><br>未归一化的特征，会导致不同特征维度的理想步长不同</br></center>

如果不进行归一化，那么由于特征向量中不同特征的取值相差较大，会导致目标函数变“扁”。这样在进行梯度下降的时候，梯度的方向就会偏离最小值的方向，走很多弯路，即训练时间过长。






# 深度学习基础知识3.2-DCN


## 可变形卷积的引入

近年来，**CNNs**在计算机视觉领域取得了飞速的发展和进步，在图像分类，语义分割，目标检测领域都有很好的应用。但是由于CNNs固定的几何结构，导致对几何形变的建模受到限制。“deformable convolution”，基于在模块中增加额外偏移量的空间采样位置，从目标任务中学习到偏移量且不需要额外的监督。这些新的模块可以很容易的取代现有CNNs的普通模块并且利用反向传播进行端到端的训练，**产生可变形的卷积神经网络**。

**CNNs**对大型，未知形状变换的建模存在固有的缺陷，这种缺陷来源于CNNs模块固有的几何结构：卷积单元对输入特征图的**固定位置**进行采样；池化层以**固定的比例**进行池化。这些特性是有影响的，例如，在同一层Conv中，所有的激活单元的感受野是一样的，但由于不同位置可能对应着不同尺度或变形的物体，因此对尺度或者感受野大小进行自适应是进行精确定位所需要的。为了解决或者减轻这个问题，就出现了**可变形卷积**（deformable conv），来提高对形变的建模能力。该模块基于网络学习offset（偏移），使得卷积核在input feature map的采样点发生偏移，集中于我们感兴趣的区域或者目标。通过研究发现，标准卷积中的规则格点采样是导致网络难以适应几何形变的“罪魁祸首”，**为了削弱这个限制，对卷积核中每个采样点的位置都增加了一个偏移变量，可以实现在当前位置附近随意采样而不局限于之前的规则格点**。如下图所示，是常见的采样点和可变形卷积采样的对比：

![img](http://5b0988e595225.cdn.sohucs.com/images/20180830/e516778a4b114da090eb7714f4242dc3.png)

（a）是常见的3x3卷积核的采样方式，（b）是采样可变形卷积，加上偏移量之后的采样点的变化，其中（c）(d)是可变形卷积的特殊形式。

## 可变形卷积-v1

可变形卷积是在传统卷积的基础上，增加了调整卷积核的方向向量，使的卷积核的形态更贴近特征物。具体实现步骤如下：

$\bullet$ Step1：同正常的卷积神经网络一样，根据输入的图像，利用传统的卷积核提取特征图。

$\bullet$ Step2：将得到的特征图作为输入，对特征图**再施加一个卷积层**，这么做的目的是为了得到可变形卷积的变形的偏移量。

$\bullet$ Step3：偏移层有2$\times$N个偏移量，N 是卷积核的大小（如 3x3 的卷积核，N = 9），因为我们在平面上做平移，需要改变x值和y值两个方向，且对于卷积核的每一个采样位置都要进行偏移。

$\bullet$ Step4：在训练的时候，用于生成输出特征的卷积核和用于生成偏移量的卷积核是同步学习的。其中**偏移量的学习是利用双线性插值算法，通过反向传播进行学习**。

对于**步骤1中的正常卷积**，可以表示为：
$$
y(p_0)=\sum\limits_{P_n\in \mathfrak{R}}w(P_n)\cdot x(P_0+P_n)
$$
其中，$w(P_n)$是每个卷积核采样点对应的权重，P表示采样点的位置信息，对于一个3$\times$3的卷积核，$\mathfrak{R}$为：
$$
\mathfrak{R}=\{(-1,-1),(-1,0),...,(0,1),(1,1)\}
$$
即$\sum\limits_{P_n\in \mathfrak{R}}(P_0+P_n)$是以$P_0$为中心点的3$\times$3的小正方形。

对于**步骤2中的可变形卷积**，就是在传统的卷积操作上加了一个偏移量，可以表示为：
$$
y(p_0)=\sum\limits_{P_n\in \mathfrak{R}}w(P_n)\cdot x(P_0+P_n+\Delta P_n)
$$

## 可变形卷积-v2

DCN v1同样具有自身的局限性：可变形卷积更能覆盖整个物体，但同时引入了无用的区域来干扰我们的特征提取，这显然会降低算法的表现。所以作者提出了三个解决方法：

**$\bullet$ 使用更多的可变形卷积**

在DCN v1中只在conv 5中使用了三个可变形卷积，在DCN v2中把conv 3到conv 5都换成了可变形卷积，提高算法对几何形变的建模能力。

**$\bullet$ 在DCN v1基础上添加每个采样点的权重**

DCN v2中我们不只添加每一个采样点的偏移，还添加了一个权重系数$\Delta m_n$来区分我们引入的区域是否为我们感兴趣的区域，：
$$
y(p_0)=\sum\limits_{P_n\in \mathfrak{R}}w(P_n)\cdot x(P_0+P_n+\Delta P_n)\cdot \Delta m_n
$$
DCN v1中引入的offset是要寻找有效信息的区域位置，DCN v2中引入权重系数是要给找到的这个位置赋予权重，这两方面保证了有效信息的准确提取。

**$\bullet$ 模拟R-CNN的feature**

