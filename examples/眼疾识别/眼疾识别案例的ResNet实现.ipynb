{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data19469  data93479\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "# !ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "# !mkdir /home/aistudio/external-libraries\n",
    "# !pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "# import sys \n",
    "# sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 眼疾识别案例的ResNet实现\n",
    "本文通过paddle框架实现了ResNet模型基础B版本和变体D版本，通过模型API：version进行切换版本。训练部分和验证部分都采用分批训练的方式，用来解决模型迭代过程中显存不足的问题。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import os\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据的解压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data exist\n",
      "The data has been decompressed\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"train_data\"):\r\n",
    "    os.mkdir(\"train_data\")\r\n",
    "else:\r\n",
    "    print('Train_data exist')\r\n",
    "if not os.path.isdir('PALM-Training400'):\r\n",
    "    !unzip -oq /home/aistudio/data/data19469/training.zip\r\n",
    "    !unzip -oq /home/aistudio/data/data19469/validation.zip\r\n",
    "    !unzip -oq /home/aistudio/data/data19469/valid_gt.zip\r\n",
    "    !unzip -oq /home/aistudio/PALM-Training400/PALM-Training400.zip -d /home/aistudio/train_data/\r\n",
    "else:\r\n",
    "    print('The data has been decompressed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 图像的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_img(img):\r\n",
    "    # 将图片尺寸缩放到 224x224\r\n",
    "    img=cv2.resize(img,(224,224))\r\n",
    "    # 读入的图像数据格式是[H,W,C]\r\n",
    "    # 使用转置操作将其变成[C,H,W]\r\n",
    "    img=np.transpose(img,(2,0,1))\r\n",
    "    img.astype('float32')\r\n",
    "    img=img/255.0\r\n",
    "    img=img*2.0-1.0\r\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练数据和验证数据的读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_loader(datadir,batch_size=10,mode='train'):\r\n",
    "    filenames=os.listdir(datadir)\r\n",
    "    def reader():\r\n",
    "        if mode =='train':\r\n",
    "            np.random.shuffle(filenames)\r\n",
    "        batch_imgs=[]\r\n",
    "        batch_labels=[]\r\n",
    "        for name in filenames:\r\n",
    "            filepath=os.path.join(datadir,name)\r\n",
    "            img=cv2.imread(filepath)\r\n",
    "            img=transform_img(img)\r\n",
    "            if name[0]=='H' or name[0]=='N':\r\n",
    "                label=0\r\n",
    "            elif name[0]=='P':\r\n",
    "                label=1\r\n",
    "            elif name[0]=='V':\r\n",
    "                continue\r\n",
    "            else:\r\n",
    "                raise('Not excepted file name')\r\n",
    "            batch_imgs.append(img)\r\n",
    "            batch_labels.append(label)\r\n",
    "            if len(batch_imgs)==batch_size:\r\n",
    "                imgs_array=np.array(batch_imgs).astype('float32')\r\n",
    "                labels_array=np.array(batch_labels).astype('float32').reshape(-1,1)\r\n",
    "                yield imgs_array,labels_array\r\n",
    "                batch_imgs=[]\r\n",
    "                batch_labels=[]\r\n",
    "        if len(batch_imgs)>0:\r\n",
    "            imgs_array=np.array(batch_imgs).astype('float32')\r\n",
    "            labels_array=np.array(batch_labels).astype('float32').reshape(-1,1)\r\n",
    "            yield imgs_array,labels_array\r\n",
    "    return reader\r\n",
    "def valid_data_loader(datadir,annotiondir):\r\n",
    "    labeldir=annotiondir\r\n",
    "    def reader(batch_size=50):\r\n",
    "        images=[]\r\n",
    "        labels=[]\r\n",
    "        workbook=openpyxl.load_workbook(labeldir,data_only=True)\r\n",
    "        worksheet=workbook.active\r\n",
    "        for row in worksheet.iter_rows(min_row=2,max_row=worksheet.max_row):\r\n",
    "            image=cv2.imread(datadir+'/'+row[1].value)\r\n",
    "            image=transform_img(image)\r\n",
    "            images.append(image)\r\n",
    "            label=float(row[2].value)\r\n",
    "            labels.append(label)\r\n",
    "            if len(images)==batch_size:\r\n",
    "                images_array=np.array(images).astype('float32')\r\n",
    "                labels_array=np.array(labels).astype('float32').reshape(-1,1)\r\n",
    "                yield images_array,labels_array\r\n",
    "                images=[]\r\n",
    "                labels=[]\r\n",
    "        if len(images)>0:\r\n",
    "            images_array=np.array(images).astype('float32')\r\n",
    "            labels_array=np.array(labels).astype('float32').reshape(-1,1)\r\n",
    "            yield images_array,labels_array\r\n",
    "    return reader\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ResNet网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ResNet中使用BatchNorm层，在卷积层的后面加上BatchNorm以提升数值稳定性\r\n",
    "# 定义卷积BN块\r\n",
    "class ConvBNLayer(nn.Layer):\r\n",
    "    def __init__(self,\r\n",
    "                 num_channels,\r\n",
    "                 num_filters,\r\n",
    "                 filter_size,\r\n",
    "                 stride=1,\r\n",
    "                 groups=1,\r\n",
    "                 act='relu'):\r\n",
    "        \"\"\"\r\n",
    "        num_channels,卷积层的输入通道数\r\n",
    "        num_filters,卷积层的输出通道数\r\n",
    "        stride,卷积层的步幅\r\n",
    "        groups,分组卷积的组数，默认groups=1不使用分组卷积\r\n",
    "        \"\"\"\r\n",
    "        super(ConvBNLayer,self).__init__()\r\n",
    "        self._conv=nn.Conv2D(\r\n",
    "            in_channels=num_channels,\r\n",
    "            out_channels=num_filters,\r\n",
    "            kernel_size=filter_size,\r\n",
    "            stride=stride,\r\n",
    "            padding=(filter_size-1)//2,\r\n",
    "            groups=groups,\r\n",
    "            bias_attr=False,\r\n",
    "        )\r\n",
    "        self._batch_norm=nn.BatchNorm2D(num_filters)\r\n",
    "        self.act=act\r\n",
    "    def forward(self,inputs):\r\n",
    "        x=self._conv(inputs)\r\n",
    "        x=self._batch_norm(x)\r\n",
    "        if self.act=='leaky':\r\n",
    "            x=nn.functional.leaky_relu(x=x,negative_slope=0.1)\r\n",
    "        elif self.act=='relu':\r\n",
    "            x=nn.functional.relu(x=x)\r\n",
    "        return x\r\n",
    "\r\n",
    "# 定义残差块\r\n",
    "# 每个残差块会对输入图片做三次卷积，然后跟输入图片进行短接\r\n",
    "# 如果残差块中第三次卷积输出特征图的形状和输入不一致，则对输入图片做1x1卷积，将其输出形状调整为一致\r\n",
    "class BottleneckBlock(nn.Layer):\r\n",
    "    def __init__(self,\r\n",
    "                 num_channels,\r\n",
    "                 num_filters,\r\n",
    "                 stride=1,\r\n",
    "                 shortcut=True,\r\n",
    "                 version='B'\r\n",
    "                 ):\r\n",
    "        super(BottleneckBlock,self).__init__()\r\n",
    "        # 创建第一个1x1卷积层\r\n",
    "        self.conv1=ConvBNLayer(\r\n",
    "            num_channels=num_channels,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=1,\r\n",
    "            act='relu',\r\n",
    "        )\r\n",
    "        # 创建第二个3x3卷积层\r\n",
    "        self.conv2=ConvBNLayer(\r\n",
    "            num_channels=num_filters,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=3,\r\n",
    "            stride=stride,\r\n",
    "            act='relu'\r\n",
    "        )\r\n",
    "        # 创建第三个1x1层，但是输出通道数乘4\r\n",
    "        self.conv3=ConvBNLayer(\r\n",
    "            num_channels=num_filters,\r\n",
    "            num_filters=num_filters*4,\r\n",
    "            filter_size=1,\r\n",
    "            act='relu'\r\n",
    "        )\r\n",
    "        # 如果conv3的输出跟此残差块的输入数据形状一致，则shortcut=True\r\n",
    "        # 否则shortcut=False，添加1个1x1的卷积作用在输入数据上，使其形状变为和conv3一样 \r\n",
    "        if not shortcut:\r\n",
    "            if version=='B':\r\n",
    "                self.short=ConvBNLayer(\r\n",
    "                    num_channels=num_channels,\r\n",
    "                    num_filters=num_filters*4,\r\n",
    "                    filter_size=1,\r\n",
    "                    stride=stride\r\n",
    "                )\r\n",
    "            elif version=='D':\r\n",
    "                self.short=nn.Sequential(\r\n",
    "                    nn.AvgPool2D(kernel_size=stride,stride=stride),\r\n",
    "                    ConvBNLayer(num_channels=num_channels,\r\n",
    "                                num_filters=num_filters*4,\r\n",
    "                                filter_size=1))      \r\n",
    "            else:\r\n",
    "                raise(f'bottleneck block version:{version} error, you can choice B or D')          \r\n",
    "        self.shortcut=shortcut\r\n",
    "        self._num_channels_out=num_filters*4\r\n",
    "    def forward(self,inputs):\r\n",
    "        x=self.conv1(inputs)\r\n",
    "        x=self.conv2(x)\r\n",
    "        x=self.conv3(x)\r\n",
    "        # 如果shortcut=Ture，直接将inputs跟conv2的输出相加\r\n",
    "        # 否则需要对inputs进行一次 卷积，将形状调整成跟conv2输出一致\r\n",
    "        if self.shortcut:\r\n",
    "            short=inputs\r\n",
    "        else:\r\n",
    "            short=self.short(inputs)\r\n",
    "        y=paddle.add(x=short,y=x)\r\n",
    "        return y\r\n",
    "\r\n",
    "# 定义ResNet模型\r\n",
    "class ResNet(nn.Layer):\r\n",
    "    def __init__(self,layers=50,class_dim=10,version='B'):\r\n",
    "        \"\"\"\r\n",
    "        layers,网络层数，可以可选项：50,101,152\r\n",
    "        class_dim,分类标签的类别数\r\n",
    "        \"\"\"\r\n",
    "        super(ResNet,self).__init__()\r\n",
    "        self.version=version\r\n",
    "        self.layers=layers\r\n",
    "        supported_layers=[50,101,152]\r\n",
    "        assert layers in supported_layers,\\\r\n",
    "        \"supported layers are {} but input layer is {}\".format(supported_layers,layers)\r\n",
    "        # ResNet50包含的第2-5模块分别包括3,4,6,3个残差块\r\n",
    "        if layers==50:\r\n",
    "            depth=[3,4,6,3]\r\n",
    "        # ResNet101包含的第2-5模块分别包括3,4,23,3个残差块\r\n",
    "        if layers==101:\r\n",
    "            depth=[3,4,23,3]\r\n",
    "        # ResNet152包含的第2-5模块分别包括3,8,36,3个残差块\r\n",
    "        if layers==152:\r\n",
    "            depth=[3,8,36,3]\r\n",
    "        # 第2-5模块所使用残差块的输出通道数\r\n",
    "        num_filters=[64,128,256,512]\r\n",
    "\r\n",
    "        # 第1个模块,64个7x7的卷积加上一个3x3最大化池化层，步长均为2\r\n",
    "        self.conv=ConvBNLayer(\r\n",
    "            num_channels=3,\r\n",
    "            num_filters=64,\r\n",
    "            filter_size=7,\r\n",
    "            stride=2,\r\n",
    "            act='relu')\r\n",
    "        self.pool2d_max=nn.MaxPool2D(\r\n",
    "            kernel_size=3,\r\n",
    "            stride=2,\r\n",
    "            padding=1)\r\n",
    "        # 第2-5模块，使用各个残差块进行卷积操作\r\n",
    "        self.bottleneck_block_list=[]\r\n",
    "        num_channels=64\r\n",
    "        for block in range(len(depth)):\r\n",
    "            shortcut=False\r\n",
    "            for i in range(depth[block]):\r\n",
    "                bottleneck_block=self.add_sublayer(\r\n",
    "                    'bb_%d_%d'%(block,i),\r\n",
    "                    BottleneckBlock(\r\n",
    "                        num_channels=num_channels,\r\n",
    "                        num_filters=num_filters[block],\r\n",
    "                        stride=2 if i==0 and block!=0 else 1,\r\n",
    "                        shortcut=shortcut,\r\n",
    "                        version=version))\r\n",
    "                num_channels=bottleneck_block._num_channels_out\r\n",
    "                self.bottleneck_block_list.append(bottleneck_block)\r\n",
    "                shortcut=True\r\n",
    "\r\n",
    "        # 在c5的输出特征图上使用全局池化\r\n",
    "        self.pool2d_avg=nn.AdaptiveAvgPool2D(output_size=1)\r\n",
    "        \r\n",
    "        # stdv用来作为全连接层随机初始化参数的方差\r\n",
    "        import math\r\n",
    "        stdv=1.0/math.sqrt(2048*1.0)\r\n",
    "        # 创建全连接层，输出大小为类别数目，经过残差网络的卷积核全局池化后，\r\n",
    "        # 卷积特征的维度是[B,2048,1,1]，故最后一层全连接层的输入维度是2048\r\n",
    "        self.out=nn.Linear(in_features=2048,out_features=class_dim,\r\n",
    "        weight_attr=paddle.ParamAttr(\r\n",
    "            initializer=paddle.nn.initializer.Uniform(-stdv,stdv)))\r\n",
    "    \r\n",
    "    def forward(self,inputs):\r\n",
    "        x=self.conv(inputs)\r\n",
    "        x=self.pool2d_max(x)\r\n",
    "        for bottleneck_block in self.bottleneck_block_list:\r\n",
    "            x=bottleneck_block(x)\r\n",
    "        x=self.pool2d_avg(x)\r\n",
    "        x=paddle.reshape(x,[x.shape[0],-1])\r\n",
    "        x=self.out(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ResNet的变体 ResNet-vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义残差块BottleneckBlock_vd模块\r\n",
    "# 每个残差块会对输入图片做三次卷积，然后跟输入图片进行短接\r\n",
    "# 如果残差块中第三次卷积输出特征图的形状和输入不一致，则对输入图片做1x1卷积，将其输出形状调整为一致\r\n",
    "class BottleneckBlock_vd(nn.Layer):\r\n",
    "    def __init__(self,\r\n",
    "                 num_channels,\r\n",
    "                 num_filters,\r\n",
    "                 stride=1,\r\n",
    "                 shortcut=True,\r\n",
    "                 ):\r\n",
    "        super(BottleneckBlock_vd,self).__init__()\r\n",
    "        # 创建第一个1x1卷积层\r\n",
    "        self.conv1=ConvBNLayer(\r\n",
    "            num_channels=num_channels,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=1,\r\n",
    "            act='relu',\r\n",
    "        )\r\n",
    "        # 创建第二个3x3卷积层\r\n",
    "        self.conv2=ConvBNLayer(\r\n",
    "            num_channels=num_filters,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=3,\r\n",
    "            stride=stride,\r\n",
    "            act='relu'\r\n",
    "        )\r\n",
    "        # 创建第三个1x1层，但是输出通道数乘4\r\n",
    "        self.conv3=ConvBNLayer(\r\n",
    "            num_channels=num_filters,\r\n",
    "            num_filters=num_filters*4,\r\n",
    "            filter_size=1,\r\n",
    "            act='relu'\r\n",
    "        )\r\n",
    "        # 如果conv3的输出跟此残差块的输入数据形状一致，则shortcut=True\r\n",
    "        # 否则shortcut=False，添加1个1x1的卷积作用在输入数据上，使其形状变为和conv3一样 \r\n",
    "        if not shortcut:\r\n",
    "            self.short=nn.Sequential(\r\n",
    "                nn.AvgPool2D(kernel_size=stride,stride=stride),\r\n",
    "                ConvBNLayer(num_channels=num_channels,\r\n",
    "                            num_filters=num_filters*4,\r\n",
    "                            filter_size=1))\r\n",
    "        self.shortcut=shortcut\r\n",
    "        self._num_channels_out=num_filters*4\r\n",
    "    def forward(self,inputs):\r\n",
    "        x=self.conv1(inputs)\r\n",
    "        x=self.conv2(x)\r\n",
    "        x=self.conv3(x)\r\n",
    "        # 如果shortcut=Ture，直接将inputs跟conv2的输出相加\r\n",
    "        # 否则需要对inputs进行一次卷积，将形状调整成跟conv2输出一致\r\n",
    "        if self.shortcut:\r\n",
    "            short=inputs\r\n",
    "        else:\r\n",
    "            # print('inputs:',inputs.shape)\r\n",
    "            short=self.short(inputs)\r\n",
    "            # print('output:',short.shape)\r\n",
    "        y=paddle.add(x=short,y=x)\r\n",
    "        return y\r\n",
    "\r\n",
    "# 定义ResNet_vd模型\r\n",
    "class ResNet_vd(nn.Layer):\r\n",
    "    def __init__(self,layers=50,class_dim=10):\r\n",
    "        \"\"\"\r\n",
    "        layers,网络层数，可以可选项：50,101,152\r\n",
    "        class_dim,分类标签的类别数\r\n",
    "        \"\"\"\r\n",
    "        super(ResNet_vd,self).__init__()\r\n",
    "        self.layers=layers\r\n",
    "        supported_layers=[50,101,152]\r\n",
    "        assert layers in supported_layers,\\\r\n",
    "        \"supported layers are {} but input layer is {}\".format(supported_layers,layers)\r\n",
    "        # ResNet50包含的第2-5模块分别包括3,4,6,3个残差块\r\n",
    "        if layers==50:\r\n",
    "            depth=[3,4,6,3]\r\n",
    "        # ResNet101包含的第2-5模块分别包括3,4,23,3个残差块\r\n",
    "        if layers==101:\r\n",
    "            depth=[3,4,23,3]\r\n",
    "        # ResNet152包含的第2-5模块分别包括3,8,36,3个残差块\r\n",
    "        if layers==152:\r\n",
    "            depth=[3,8,36,3]\r\n",
    "        # 第2-5模块所使用残差块的输出通道数\r\n",
    "        num_filters=[64,128,256,512]\r\n",
    "\r\n",
    "        # 第1个模块,64个7x7的卷积加上一个3x3最大化池化层，步长均为2\r\n",
    "        self.conv=ConvBNLayer(\r\n",
    "            num_channels=3,\r\n",
    "            num_filters=64,\r\n",
    "            filter_size=7,\r\n",
    "            stride=2,\r\n",
    "            act='relu')\r\n",
    "        self.pool2d_max=nn.MaxPool2D(\r\n",
    "            kernel_size=3,\r\n",
    "            stride=2,\r\n",
    "            padding=1)\r\n",
    "        # 第2-5模块，使用各个残差块进行卷积操作\r\n",
    "        self.bottleneck_block_vd_list=[]\r\n",
    "        num_channels=64\r\n",
    "        for block in range(len(depth)):\r\n",
    "            shortcut=False\r\n",
    "            for i in range(depth[block]):\r\n",
    "                bottleneck_block_vd=self.add_sublayer(\r\n",
    "                    'bb_%d_%d'%(block,i),\r\n",
    "                    BottleneckBlock_vd(\r\n",
    "                        num_channels=num_channels,\r\n",
    "                        num_filters=num_filters[block],\r\n",
    "                        stride=2 if i==0 and block!=0 else 1,\r\n",
    "                        shortcut=shortcut))\r\n",
    "                num_channels=bottleneck_block_vd._num_channels_out\r\n",
    "                self.bottleneck_block_vd_list.append(bottleneck_block_vd)\r\n",
    "                shortcut=True\r\n",
    "\r\n",
    "        # 在c5的输出特征图上使用全局池化\r\n",
    "        self.pool2d_avg=nn.AdaptiveAvgPool2D(output_size=1)\r\n",
    "        \r\n",
    "        # stdv用来作为全连接层随机初始化参数的方差\r\n",
    "        import math\r\n",
    "        stdv=1.0/math.sqrt(2048*1.0)\r\n",
    "        # 创建全连接层，输出大小为类别数目，经过残差网络的卷积核全局池化后，\r\n",
    "        # 卷积特征的维度是[B,2048,1,1]，故最后一层全连接层的输入维度是2048\r\n",
    "        self.out=nn.Linear(in_features=2048,out_features=class_dim,\r\n",
    "        weight_attr=paddle.ParamAttr(\r\n",
    "            initializer=paddle.nn.initializer.Uniform(-stdv,stdv)))\r\n",
    "    \r\n",
    "    def forward(self,inputs):\r\n",
    "        # print('0:',inputs.shape)\r\n",
    "        x=self.conv(inputs)\r\n",
    "        # print('1:',x.shape)\r\n",
    "        x=self.pool2d_max(x)\r\n",
    "        # print('2:',x.shape)\r\n",
    "        for bottleneck_block in self.bottleneck_block_vd_list:\r\n",
    "            x=bottleneck_block(x)\r\n",
    "            # print(3+self.bottleneck_block_vd_list.index(bottleneck_block),':',x.shape)\r\n",
    "        x=self.pool2d_avg(x)\r\n",
    "        x=paddle.reshape(x,[x.shape[0],-1])\r\n",
    "        x=self.out(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  验证函数\n",
    "分批次验证，求平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def valid_pm(model,valid_loader,batch_size=100):\r\n",
    "    model.eval()\r\n",
    "    print(\"*****valid data import success*****\")\r\n",
    "    batch_accuracy=[]\r\n",
    "    batch_loss=[]\r\n",
    "    for batch_id,data in enumerate(valid_loader(batch_size=batch_size)):\r\n",
    "        x_data,y_data=data\r\n",
    "        img=paddle.to_tensor(x_data)\r\n",
    "        label=paddle.to_tensor(y_data).astype('int64')\r\n",
    "        out=model(img)\r\n",
    "        predict=paddle.argmax(out,1)\r\n",
    "        loss=nn.functional.cross_entropy(out,label,reduction='none')\r\n",
    "        avg_loss=paddle.mean(loss)\r\n",
    "        accuracy=sum(predict.numpy().reshape(-1,1)==label.numpy())/float(label.shape[0])\r\n",
    "        batch_loss.append(float(avg_loss.numpy()))\r\n",
    "        batch_accuracy.append(accuracy)\r\n",
    "        # print('batch_id:{}===accuracy:{}/loss:{}'.format(batch_id,accuracy,avg_loss.numpy()))\r\n",
    "        # if batch_id==1:\r\n",
    "        #     print('predict:{}'.format(predict.numpy()))\r\n",
    "        #     print('label  :{}'.format(label.numpy()[:,0]))\r\n",
    "    avg_loss=np.mean(batch_loss)\r\n",
    "    avg_accuracy=np.mean(batch_accuracy)\r\n",
    "    return avg_accuracy,avg_loss\r\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练函数\n",
    "采用gpu进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_pm(model,\r\n",
    "             datadir,\r\n",
    "             annotiondir,\r\n",
    "             optimizer,\r\n",
    "             batch_size=10,\r\n",
    "             EPOCH_NUM=20,\r\n",
    "             use_gpu=False):\r\n",
    "    # 使用0号GPU训练\r\n",
    "    paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\r\n",
    "\r\n",
    "    print('********start training********')\r\n",
    "    model.train()\r\n",
    "    # 定义数据读取器\r\n",
    "    train_loader=data_loader(datadir=datadir+'/train_data/PALM-Training400',batch_size=batch_size,mode='train')\r\n",
    "    valid_loader=valid_data_loader(datadir+'/PALM-Validation400',annotiondir)\r\n",
    "    for epoch in range(EPOCH_NUM):\r\n",
    "        for batch_id,data in enumerate(train_loader()):\r\n",
    "            x_data,y_data=data\r\n",
    "            img=paddle.to_tensor(x_data)\r\n",
    "            label=paddle.to_tensor(y_data).astype('int64')\r\n",
    "            # 使用模型进行前向计算，得到预测值\r\n",
    "            out=model(img)\r\n",
    "            loss=nn.functional.cross_entropy(out,label,reduction='none')\r\n",
    "            avg_loss=paddle.mean(loss)\r\n",
    "            if batch_id%10==0:\r\n",
    "                print(\"epoch:{}===batch_id:{}===loss:{:.4f}\".format(\r\n",
    "                    epoch,batch_id,float(avg_loss.numpy())))\r\n",
    "            # 反向传播，更新权重，消除梯度\r\n",
    "            avg_loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.clear_grad()\r\n",
    "        valid_accuracy,valid_loss=valid_pm(model,valid_loader,batch_size=50)\r\n",
    "        print('[validation]:======accuracy:{:.5f}/loss:{:.5f}'.format(valid_accuracy,valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练的超参数及训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件主路径： /home/aistudio\n",
      "********start training********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0===batch_id:0===loss:2.6458\n",
      "epoch:0===batch_id:10===loss:2.1836\n",
      "epoch:0===batch_id:20===loss:0.4206\n",
      "epoch:0===batch_id:30===loss:2.3614\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.75250/loss:0.58844\n",
      "epoch:1===batch_id:0===loss:0.4651\n",
      "epoch:1===batch_id:10===loss:0.6753\n",
      "epoch:1===batch_id:20===loss:1.9894\n",
      "epoch:1===batch_id:30===loss:0.8380\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.91750/loss:0.23243\n",
      "epoch:2===batch_id:0===loss:0.1823\n",
      "epoch:2===batch_id:10===loss:0.1626\n",
      "epoch:2===batch_id:20===loss:0.4546\n",
      "epoch:2===batch_id:30===loss:0.5587\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.93750/loss:0.18169\n",
      "epoch:3===batch_id:0===loss:0.4962\n",
      "epoch:3===batch_id:10===loss:0.2235\n",
      "epoch:3===batch_id:20===loss:0.2855\n",
      "epoch:3===batch_id:30===loss:0.2191\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.87250/loss:0.29890\n",
      "epoch:4===batch_id:0===loss:0.1854\n",
      "epoch:4===batch_id:10===loss:0.4282\n",
      "epoch:4===batch_id:20===loss:0.5546\n",
      "epoch:4===batch_id:30===loss:0.4010\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.91750/loss:0.22131\n",
      "epoch:5===batch_id:0===loss:0.1275\n",
      "epoch:5===batch_id:10===loss:0.1826\n",
      "epoch:5===batch_id:20===loss:0.7353\n",
      "epoch:5===batch_id:30===loss:0.3133\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.91500/loss:0.29240\n",
      "epoch:6===batch_id:0===loss:0.2944\n",
      "epoch:6===batch_id:10===loss:0.2880\n",
      "epoch:6===batch_id:20===loss:0.5254\n",
      "epoch:6===batch_id:30===loss:0.2844\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.92250/loss:0.22775\n",
      "epoch:7===batch_id:0===loss:0.2863\n",
      "epoch:7===batch_id:10===loss:0.0206\n",
      "epoch:7===batch_id:20===loss:0.2236\n",
      "epoch:7===batch_id:30===loss:0.5300\n",
      "[validation]:======accuracy:0.95000/loss:0.13579\n",
      "epoch:8===batch_id:0===loss:0.1286\n",
      "epoch:8===batch_id:10===loss:0.0564\n",
      "epoch:8===batch_id:20===loss:0.2554\n",
      "epoch:8===batch_id:30===loss:0.4220\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.87500/loss:0.37557\n",
      "epoch:9===batch_id:0===loss:0.1757\n",
      "epoch:9===batch_id:10===loss:0.1057\n",
      "epoch:9===batch_id:20===loss:0.2116\n",
      "epoch:9===batch_id:30===loss:0.1838\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.91500/loss:0.25677\n",
      "epoch:10===batch_id:0===loss:0.5225\n",
      "epoch:10===batch_id:10===loss:0.4859\n",
      "epoch:10===batch_id:20===loss:0.3091\n",
      "epoch:10===batch_id:30===loss:0.1323\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.89250/loss:0.34202\n",
      "epoch:11===batch_id:0===loss:0.4107\n",
      "epoch:11===batch_id:10===loss:0.2240\n",
      "epoch:11===batch_id:20===loss:0.0063\n",
      "epoch:11===batch_id:30===loss:0.1485\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94000/loss:0.17190\n",
      "epoch:12===batch_id:0===loss:0.0877\n",
      "epoch:12===batch_id:10===loss:0.1586\n",
      "epoch:12===batch_id:20===loss:0.0231\n",
      "epoch:12===batch_id:30===loss:0.0450\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95500/loss:0.14956\n",
      "epoch:13===batch_id:0===loss:0.5288\n",
      "epoch:13===batch_id:10===loss:0.5016\n",
      "epoch:13===batch_id:20===loss:0.2265\n",
      "epoch:13===batch_id:30===loss:0.0227\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.92750/loss:0.25259\n",
      "epoch:14===batch_id:0===loss:0.0856\n",
      "epoch:14===batch_id:10===loss:0.0969\n",
      "epoch:14===batch_id:20===loss:0.5539\n",
      "epoch:14===batch_id:30===loss:0.2916\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95000/loss:0.15547\n",
      "epoch:15===batch_id:0===loss:0.0794\n",
      "epoch:15===batch_id:10===loss:0.2389\n",
      "epoch:15===batch_id:20===loss:0.7839\n",
      "epoch:15===batch_id:30===loss:0.4447\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95250/loss:0.13815\n",
      "epoch:16===batch_id:0===loss:0.0370\n",
      "epoch:16===batch_id:10===loss:0.0828\n",
      "epoch:16===batch_id:20===loss:0.1719\n",
      "epoch:16===batch_id:30===loss:0.3056\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.96000/loss:0.12773\n",
      "epoch:17===batch_id:0===loss:0.2212\n",
      "epoch:17===batch_id:10===loss:0.0483\n",
      "epoch:17===batch_id:20===loss:0.0289\n",
      "epoch:17===batch_id:30===loss:0.0417\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95500/loss:0.13902\n",
      "epoch:18===batch_id:0===loss:0.0291\n",
      "epoch:18===batch_id:10===loss:0.0076\n",
      "epoch:18===batch_id:20===loss:0.0493\n",
      "epoch:18===batch_id:30===loss:0.1445\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95250/loss:0.13908\n",
      "epoch:19===batch_id:0===loss:0.1152\n",
      "epoch:19===batch_id:10===loss:0.3546\n",
      "epoch:19===batch_id:20===loss:0.0979\n",
      "epoch:19===batch_id:30===loss:0.0236\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95250/loss:0.18154\n"
     ]
    }
   ],
   "source": [
    "filedir=os.getcwd()\r\n",
    "print('文件主路径：',filedir)\r\n",
    "model_version='D'\r\n",
    "lr=0.001\r\n",
    "load_model=False\r\n",
    "if os.path.exists(f'./model/resnet50_v{model_version}_PALM.pdmodel') and load_model:\r\n",
    "    model=paddle.load(f'./model/resnet50_v{model_version}_PALM.pdmodel')\r\n",
    "else:\r\n",
    "    model=ResNet(layers=50,version=model_version)\r\n",
    "annotion_path=filedir+'/PALM-Validation-GT/PM_Label_and_Fovea_Location.xlsx'\r\n",
    "optimizer=paddle.optimizer.Momentum(learning_rate=lr,momentum=0.9,parameters=model.parameters())\r\n",
    "use_gpu=True\r\n",
    "train_pm(model,filedir,annotion_path,optimizer,use_gpu=use_gpu)\r\n",
    "paddle.save(model,f'./model/resnet50_v{model_version}_PALM.pdmodel_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ResNet导入和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94500/loss:0.15782\n"
     ]
    }
   ],
   "source": [
    "annotion_path='./PALM-Validation-GT/PM_Label_and_Fovea_Location.xlsx'\r\n",
    "valid_loader=valid_data_loader('./PALM-Validation400',annotion_path)\r\n",
    "model_version='B'\r\n",
    "model=paddle.load(f'./model/resnet50_v{model_version}_PALM.pdmodel')\r\n",
    "valid_accuracy,valid_loss=valid_pm(model,valid_loader,batch_size=50)\r\n",
    "print('[validation]:======accuracy:{:.5f}/loss:{:.5f}'.format(valid_accuracy,valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ResNet-vd的导入和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94250/loss:0.21037\n"
     ]
    }
   ],
   "source": [
    "annotion_path='./PALM-Validation-GT/PM_Label_and_Fovea_Location.xlsx'\r\n",
    "valid_loader=valid_data_loader('./PALM-Validation400',annotion_path)\r\n",
    "model_version='D'\r\n",
    "model=paddle.load(f'./model/resnet50_v{model_version}_PALM.pdmodel')\r\n",
    "valid_accuracy,valid_loss=valid_pm(model,valid_loader,batch_size=50)\r\n",
    "print('[validation]:======accuracy:{:.5f}/loss:{:.5f}'.format(valid_accuracy,valid_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
