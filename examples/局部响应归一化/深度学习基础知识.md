# 深度学习基础知识

## 局部响应归一化

### 概念

​        LRN全称为Local Response Normalization，即局部响应归一化层，LRN函数类似DROPOUT和数据增强作为relu激励之后防止数据过拟合而提出的一种处理方法。

​        这个函数很少使用，基本上被类似DROPOUT这样的方法取代，见最早的出处AlexNet论文对它的定义, 《ImageNet Classification with Deep ConvolutionalNeural Networks》

### 算法流程

![模型公式](C:\Users\1\Desktop\111\images\模型公式.webp)

这个公式中的a表示卷积层（包括卷积操作和池化操作）后的输出结果，这个输出结果的结构是一个四维数组[batch,height,width,channel]，
【batch:批次数(每一批为一张图片)；height:图片高度，；width：图片宽度，；channel：通道数可以理解成一批图片中的某一个图片经过卷积操作后输出的神经元个数(或是理解成处理后的图片深度)。】
ai(x,y)表示在这个输出结构中的一个位置[a,b,c,d]，可以理解成在某一张图中的某一个通道下的某个高度和某个宽度位置的点，即第a张图的第d个通道下的高度为b宽度为c的点。
a,n/2,k,α,β分别表示函数中的input,depth_radius,bias,alpha,beta，其中n/2,k,α,β都是自定义的，特别注意一下∑叠加的方向是沿着通道方向的，即每个点值的平方和是沿着a中的第3维channel方向的，也就是一个点同方向的前面n/2个通道（最小为第0个通道）和后n/2个通道（最大为第d-1个通道）的点的平方和(共n+1个点)。而函数的英文注解中也说明了把input当成是d个3维的矩阵，说白了就是把input的通道数当作3维矩阵的个数，叠加的方向也是在通道方向。

过程示意：

![14512145-32c9c3afb0a1f566](C:\Users\1\Desktop\111\images\14512145-32c9c3afb0a1f566.webp)

1.归一化有助于快速收敛；

2.对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力；

3.有利于增加泛化能力，做了平滑处理，识别率提高；

### 应用场景

局部响应归一化是对同一个位置的邻近特征映射中地神经元进行抑制



## 可变形卷积

### DCN v1

​        可变形卷积顾名思义就是卷积的位置是可变形的，并非在传统的N × N的网格上做卷积，这样的好处就是更准确地提取到我们想要的特征。可变形卷积的实质是，是在每一个卷积采样点加上了一个偏移量，如下图所示：

![v2-6509faf5c740ea9005e8fea2d979edba_720w](C:\Users\1\Desktop\111\images\v2-6509faf5c740ea9005e8fea2d979edba_720w.jpg)

​          (a) 所示的正常卷积规律的采样 9 个点（绿点），(b)(c)(d) 为可变形卷积，在正常的采样坐标上加上一个位移量（蓝色箭头），其中 (c)(d) 作为 (b) 的特殊情况，展示了可变形卷积可以作为尺度变换，比例变换和旋转变换等特殊情况。

​          在传统的卷积上加上偏移量后，正是这个偏移量才让卷积变形为不规则的卷积，这里要注意这个偏移量可以是小数，所以下面的式子的特征值需要通过双线性插值的方法来计算。

![v2-7a06b5893d8008a7f7219f204803da8f_720w](C:\Users\1\Desktop\111\images\v2-7a06b5893d8008a7f7219f204803da8f_720w.png)

​        对于输入的一张feature map，假设原来的卷积操作是3×3的，那么为了学习偏移量offset，我们定义另外一个3×3的卷积层（图中上面的那层），输出的维度其实就是原来feature map大小，channel数等于2N（分别表示x,y方向的偏移）。下面的可变形卷积可以看作先基于上面那部分生成的offset做了一个插值操作，然后再执行普通的卷积。

### DCN v2

​        对于DCN v1训练结果的有效感受野、有效采样位置、显著性区域边界错误进行评价，能够得出：标准卷积也具有一定程度的对物体的几何形变进行建模的能力；通过引入可变形卷积，这种能力显著增强，空间上网络接收了更大的区域，覆盖整个目标的同时也包含了更多的不相关的背景信息等。很明显可变形卷积能够更好的提升网络对几何形变进行建模的能力，对潜在区域的采样区域更大。因此需要进行进一步提升，得到一个介于原区域与更大区域二者之间的采样区域以提升精度。

* 加入更多的可变形卷积层

* 可调节的变形模块：引入一种调节机制，不但能够调整接收输入的特征的位置，还能调节不同输入特征的振幅(重要性)，极端情况下，一个模块可以通过将重要性设置为0来表示不接收该特征，结果对应采样区域的图像像素点显著减少同时不影响模块的输出，因此这种调节机制能够给网络模块新维度上的能力去调节支持区域。

* R-CNN特征融合：使用R-CNN作为一个教师网络，让DCNV2的RoI池化之后的feature去模拟R-CNN的特征

  ![v2-6b19538af42e6613ef3b463a3f7c69b5_720w](C:\Users\1\Desktop\111\images\v2-6b19538af42e6613ef3b463a3f7c69b5_720w.jpg)

