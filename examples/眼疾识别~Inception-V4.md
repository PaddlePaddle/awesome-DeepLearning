# 1„ÄÅÁêÜËÆ∫Áü•ËØÜ

&emsp;&emsp;Âç∑ÁßØÁΩëÁªúÂú®ÂõæÂÉèËØÜÂà´È¢ÜÂüüÂ∑≤ÁªèÂçÅÂàÜÊµÅË°åÔºåÁªèÂÖ∏ÁΩëÁªúÊúâAlexNet„ÄÅVGGNet„ÄÅGoogLeNetÁ≠â„ÄÇResidual connectionÁöÑÊèêÂá∫ÊòØÁî®‰∫éËÆ≠ÁªÉÊõ¥Ê∑±ÁöÑÁΩëÁªúÔºå‰ΩÜÊòØ‰ΩúËÄÖÂèëÁé∞‰∏ç‰ΩøÁî®Residual connection‰πüÂèØ‰ª•ËÆ≠ÁªÉÊõ¥Ê∑±ÁöÑÁΩëÁªú„ÄÇResidual connectionÂπ∂‰∏çÊòØÂøÖË¶ÅÊù°‰ª∂ÔºåÂè™ÊòØ‰ΩøÁî®‰∫ÜResidual connection‰ºöÂä†Âø´ËÆ≠ÁªÉÈÄüÂ∫¶„ÄÇInceptionÁªìÊûÑÊúÄÂàùÁî±GoogLeNetÂºïÂÖ•ÔºåGoogLeNetÂè´ÂÅöInception-v1Ôºõ‰πãÂêéÂºïÂÖ•‰∫ÜBatchNormalizationÔºåÂè´ÂÅöInception-v2ÔºõÈöèÂêéÂºïÂÖ•ÂàÜËß£ÔºåÂè´ÂÅöInception-v3„ÄÇ

&emsp;&emsp;InceptionÁªìÊûÑÊúâÁùÄËâØÂ•ΩÁöÑÊÄßËÉΩÔºå‰∏îËÆ°ÁÆóÈáè‰Ωé„ÄÇResidual connection‰∏çÂêå‰∫é‰º†ÁªüÁΩëÁªúÁªìÊûÑÔºå‰∏îÂú®2015 ILSVRCÂèñÂæóÂÜ†ÂÜõÔºåÂÆÉÁöÑÊÄßËÉΩÂíåInception-v3Êé•Ëøë„ÄÇ‰ΩúËÄÖÂ∞ùËØïÂ∞ÜInceptionÁªìÊûÑÂíåResidual connectionÁªìÂêàÔºåÂêåÊó∂‰πüËÆæËÆ°‰∫Ü‰∏çÁî®Residual connectionÁâàÊú¨ÁöÑInception-v4„ÄÇ

## 1.1InceptionËøõÂåñÂè≤

### Inception v1

&emsp;&emsp;Inception v1Âç≥Â§ßÂêçÈºéÈºéÁöÑGoogLeNetÔºåGoogleÂú®2014Âπ¥ImageNetÊØîËµõ‰∏≠Â§∫ÂÜ†ÁöÑÂ§ßÊùÄÂô®„ÄÇÁõ∏ÊØî‰πãÂâçÁöÑAlexNetÂíåZFNetÔºåInception v1Âú®ÁªìÊûÑ‰∏äÊúâ‰∏§‰∏™Á™ÅÂá∫ÁöÑÁâπÁÇπÔºö
1. Multi-branchÁªìÊûÑ„ÄÇÊØè‰∏™inception moduleÂàÜ‰∏∫Âõõ‰∏™branchÔºåËæìÂá∫Êó∂ÂØπÊâÄÊúâbranchÁöÑËæìÂá∫ÂÅöconcatenation
1. Heterogeneous branchÁªìÊûÑ„ÄÇÊØè‰∏™branchÁöÑÁªìÊûÑÈÉΩÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑÔºå‰∏ªË¶ÅË°®Áé∞Âú®branchÁöÑdepthÂíåkernel size‰∏§ÊñπÈù¢„ÄÇ

### Inception v2„ÄÅV3

&emsp;&emsp;Inception  v2Âíåv3ÊòØÂú®Âêå‰∏ÄÁØáÊñáÁ´†‰∏≠ÊèêÂá∫Êù•ÁöÑ„ÄÇÁõ∏ÊØîInception v1ÔºåÁªìÊûÑ‰∏äÁöÑÊîπÂèò‰∏ªË¶ÅÊúâ‰∏§ÁÇπÔºö1ÔºâÁî®Â†ÜÂè†ÁöÑÂ∞èkernel  sizeÔºà3*3ÔºâÁöÑÂç∑ÁßØÊù•Êõø‰ª£Inception v1‰∏≠ÁöÑÂ§ßkernel sizeÔºà5*5ÔºâÂç∑ÁßØÔºõ2ÔºâÂºïÂÖ•‰∫ÜÁ©∫Èó¥ÂàÜÁ¶ªÂç∑ÁßØÔºàFactorized  ConvolutionÔºâÊù•Ëøõ‰∏ÄÊ≠•Èôç‰ΩéÁΩëÁªúÁöÑÂ§çÊùÇÂ∫¶„ÄÇ

###   Inception v4

&emsp;&emsp;Inception  v4Âú®Ê®°ÂùóËÆæËÆ°‰∏äÂπ∂Ê≤°ÊúâÊèêÂá∫ÈùûÂ∏∏ÊúâinsightÁöÑprincpleÔºåÊÑüËßâÂè™ÊòØÊää‰πãÂâçÁöÑInception  moduleÂèòÂæóÊõ¥Â§çÊùÇ‰∫ÜÔºåÁÑ∂ÂêéÂØπÁΩëÁªúÁöÑstemËøõË°å‰∫Ü‰∏ÄÂÆöÁöÑ‰øÆÊîπ„ÄÇInception-ResNetÂú®Inception  module‰∏≠ÂºïÂÖ•‰∫Üresidual connection„ÄÇ

## 1.2 InceptionÁöÑ‰∏ªÊµÅËß£Èáä

&emsp;&emsp;InceptionÁ≥ªÂàóÁöÑÁªìÊûÑÊ°ÜÊû∂Âú®v1ÁöÑÊó∂ÂÄôÂ∞±Âü∫Êú¨Á°ÆÂÆö‰∏ãÊù•ÁöÑÔºåÂêéÁª≠ÁöÑÁâàÊú¨ÊòØÂØπv1‰∏äÁöÑËø≠‰ª£ÂçáÁ∫ßÔºåËÄåÈùûÈ¢†Ë¶Ü„ÄÇÊâÄ‰ª•ÔºåÂ§ßÂÆ∂ÂÖ≥‰∫éInceptionÁöÑËß£ËØª‰πüÈÉΩ‰æßÈáç‰∫év1„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÂ§ßÂÆ∂ÊôÆÈÅçËÆ§‰∏∫Inception moduleÁöÑ‰∏§‰∏™ËÆæËÆ°ÂéüÂàôÊòØÂÆÉÊàêÂäüÁöÑÂÖ≥ÈîÆÔºö

1. Multi-branchÁªìÊûÑ„ÄÇInception  v1ÁöÑ‰ΩúËÄÖÂèó‰∫∫ËÑëÁªìÊûÑÁöÑÂêØÂèëÔºåËÆ§‰∏∫CNNÂÜÖÈÉ®ÁöÑËøûÊé•Â∫îËØ•ÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÁ®ÄÁñèÊÄßÔºåÊâÄ‰ª•Âú®Inception  module‰∏≠ÂºïÂÖ•‰∫Ümulti-branchÁöÑÁªìÊûÑ„ÄÇÂõ†‰∏∫ÊØè‰∏™branchÂÜÖÈÉ®1*1convÁöÑÂ∫îÁî®Ôºå‰ΩøÂæóInception  moduleÁõ∏ÊØîsingle branchÁªìÊûÑÁöÑFLOPsË¶Å‰Ωé„ÄÇ
1. Heterogeneous  branchÁªìÊûÑ„ÄÇInception‰∏≠ÊØè‰∏™branchÁöÑÁªìÊûÑÈÉΩÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑÔºåÁâπÂà´ÊòØkernel  size„ÄÇ‰ΩúËÄÖËÆ§‰∏∫ÂêåÁ±ªÂà´ÁöÑÂØπË±°Âú®‰∏çÂêåÂõæÁâá‰∏≠ÁöÑsizeÂèØËÉΩÊòØ‰∏çÂêåÁöÑÔºåÊâÄ‰ª•Â∫îËØ•Âú®Âêå‰∏Ä‰∏™moduleÂÜÖÈÉ®ËûçÂêà‰∏çÂêåsizeÁöÑkernel‰∫ßÁîüÁöÑfeatureÔºåÊúâÂà©‰∫éCNNËØÜÂà´‰∏çÂêåsizeÁöÑÂØπË±°„ÄÇ


# 2„ÄÅÁΩëÁªúÁªìÊûÑ
## 2.1Inception v4‰∏≠ÁöÑ‰∏â‰∏™Âü∫Êú¨Ê®°Âùó
![](https://ai-studio-static-online.cdn.bcebos.com/da40a93f99f64a919bd0c22b9cba08be7dc4e717d2184aa09cc22db9336b820c)
1. Â∑¶ÂõæÊòØÂü∫Êú¨ÁöÑInception v2/v3Ê®°ÂùóÔºå‰ΩøÁî®‰∏§‰∏™3x3Âç∑ÁßØ‰ª£Êõø5x5Âç∑ÁßØÔºåÂπ∂‰∏î‰ΩøÁî®average poolingÔºåËØ•Ê®°Âùó‰∏ªË¶ÅÂ§ÑÁêÜÂ∞∫ÂØ∏‰∏∫35x35ÁöÑfeature mapÔºõ
1. ‰∏≠ÂõæÊ®°Âùó‰ΩøÁî®1xnÂíånx1Âç∑ÁßØ‰ª£ÊõønxnÂç∑ÁßØÔºåÂêåÊ†∑‰ΩøÁî®average poolingÔºåËØ•Ê®°Âùó‰∏ªË¶ÅÂ§ÑÁêÜÂ∞∫ÂØ∏‰∏∫17x17ÁöÑfeature mapÔºõ
1. Âè≥ÂõæÂú®ÂéüÂßãÁöÑ8x8Â§ÑÁêÜÊ®°Âùó‰∏äÂ∞Ü3x3Âç∑ÁßØÁî®1x3Âç∑ÁßØÂíå3x1Âç∑ÁßØ„ÄÇ 

## 2.2 Inception v4ÁΩëÁªúÁªìÊûÑ(Âè≥Âõæ‰∏∫Inception v4ÁöÑStemÊ®°Âùó)
![](https://ai-studio-static-online.cdn.bcebos.com/46040c6650914a0684753a880e203b974344bde9f7304fd3b362ba05d359ba53)

## 2.3 Êï¥‰ΩìÁΩëÁªúÁªìÊûÑ
![](https://ai-studio-static-online.cdn.bcebos.com/4028f8cb075a43eab71e327d5ebf674bc262170f6bae413f8eacff64742c3015)



# 3„ÄÅ‰ª£Á†ÅÂÆûÁé∞
## Êï∞ÊçÆÂèØËßÜÂåñ


```python
import os
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
from PIL import Image
DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'
file1 = 'N0011.jpg'
file2 = 'P0085.jpg'
# ËØªÂèñÂõæÁâá
img1 = Image.open(os.path.join(DATADIR, file1))
img1 = np.array(img1)
img2 = Image.open(os.path.join(DATADIR, file2))
img2 = np.array(img2)
# ÁîªÂá∫ËØªÂèñÁöÑÂõæÁâá
#plt.figure(figsize=(16, 8))
#f = plt.subplot(121)
#f.set_title('Normal', fontsize=20)
#plt.imshow(img1)
#f = plt.subplot(122)
#f.set_title('PM', fontsize=20)
#plt.imshow(img2)
#plt.show()
```

![](https://ai-studio-static-online.cdn.bcebos.com/7085ef06732f4ebdaddc5d9fa5b2a0a356ab7335347c4654812ebcc2b7e15118)



```python
#ÂÆö‰πâÊï∞ÊçÆËØªÂèñÂô®
import cv2
import random
import numpy as np

# ÂØπËØªÂÖ•ÁöÑÂõæÂÉèÊï∞ÊçÆËøõË°åÈ¢ÑÂ§ÑÁêÜ
def transform_img(img):
    # Â∞ÜÂõæÁâáÂ∞∫ÂØ∏Áº©ÊîæÈÅì 224x224
    img = cv2.resize(img, (224, 224))
    # ËØªÂÖ•ÁöÑÂõæÂÉèÊï∞ÊçÆÊ†ºÂºèÊòØ[H, W, C]
    # ‰ΩøÁî®ËΩ¨ÁΩÆÊìç‰ΩúÂ∞ÜÂÖ∂ÂèòÊàê[C, H, W]
    img = np.transpose(img, (2,0,1))
    img = img.astype('float32')
    # Â∞ÜÊï∞ÊçÆËåÉÂõ¥Ë∞ÉÊï¥Âà∞[-1.0, 1.0]‰πãÈó¥
    img = img / 255.
    img = img * 2.0 - 1.0
    return img


```


```python
# ÂÆö‰πâËÆ≠ÁªÉÈõÜÊï∞ÊçÆËØªÂèñÂô®
def data_loader(datadir, batch_size=10, mode = 'train'):
    # Â∞ÜdatadirÁõÆÂΩï‰∏ãÁöÑÊñá‰ª∂ÂàóÂá∫Êù•ÔºåÊØèÊù°Êñá‰ª∂ÈÉΩË¶ÅËØªÂÖ•
    filenames = os.listdir(datadir)
    def reader():
        if mode == 'train':
            # ËÆ≠ÁªÉÊó∂ÈöèÊú∫Êâì‰π±Êï∞ÊçÆÈ°∫Â∫è
            random.shuffle(filenames)
        batch_imgs = []
        batch_labels = []
        for name in filenames:
            filepath = os.path.join(datadir, name)
            img = cv2.imread(filepath)
            img = transform_img(img)
            if name[0] == 'H' or name[0] == 'N':
                # HÂºÄÂ§¥ÁöÑÊñá‰ª∂ÂêçË°®Á§∫È´òÂ∫¶Ëøë‰ººÔºåNÂºÄÂ§¥ÁöÑÊñá‰ª∂ÂêçË°®Á§∫Ê≠£Â∏∏ËßÜÂäõ
                # È´òÂ∫¶ËøëËßÜÂíåÊ≠£Â∏∏ËßÜÂäõÁöÑÊ†∑Êú¨ÔºåÈÉΩ‰∏çÊòØÁóÖÁêÜÊÄßÁöÑÔºåÂ±û‰∫éË¥üÊ†∑Êú¨ÔºåÊ†áÁ≠æ‰∏∫0
                label = 0
            elif name[0] == 'P':
                # PÂºÄÂ§¥ÁöÑÊòØÁóÖÁêÜÊÄßËøëËßÜÔºåÂ±û‰∫éÊ≠£Ê†∑Êú¨ÔºåÊ†áÁ≠æ‰∏∫1
                label = 1
            else:
                raise('Not excepted file name')
            # ÊØèËØªÂèñ‰∏Ä‰∏™Ê†∑Êú¨ÁöÑÊï∞ÊçÆÔºåÂ∞±Â∞ÜÂÖ∂ÊîæÂÖ•Êï∞ÊçÆÂàóË°®‰∏≠
            batch_imgs.append(img)
            batch_labels.append(label)
            if len(batch_imgs) == batch_size:
                # ÂΩìÊï∞ÊçÆÂàóË°®ÁöÑÈïøÂ∫¶Á≠â‰∫ébatch_sizeÁöÑÊó∂ÂÄôÔºå
                # ÊääËøô‰∫õÊï∞ÊçÆÂΩì‰Ωú‰∏Ä‰∏™mini-batchÔºåÂπ∂‰Ωú‰∏∫Êï∞ÊçÆÁîüÊàêÂô®ÁöÑ‰∏Ä‰∏™ËæìÂá∫
                imgs_array = np.array(batch_imgs).astype('float32')
                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)
                yield imgs_array, labels_array
                batch_imgs = []
                batch_labels = []

        if len(batch_imgs) > 0:
            # Ââ©‰ΩôÊ†∑Êú¨Êï∞ÁõÆ‰∏çË∂≥‰∏Ä‰∏™batch_sizeÁöÑÊï∞ÊçÆÔºå‰∏ÄËµ∑ÊâìÂåÖÊàê‰∏Ä‰∏™mini-batch
            imgs_array = np.array(batch_imgs).astype('float32')
            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)
            yield imgs_array, labels_array

    return reader


```


```python
# ÂÆö‰πâÈ™åËØÅÈõÜÊï∞ÊçÆËØªÂèñÂô®
def valid_data_loader(datadir, csvfile, batch_size=10, mode='valid'):
    filelists = open(csvfile).readlines()
    def reader():
        batch_imgs = []
        batch_labels = []
        for line in filelists[1:]:
            line = line.strip().split(',')
            name = line[1]
            label = int(line[2])
            # Ê†πÊçÆÂõæÁâáÊñá‰ª∂ÂêçÂä†ËΩΩÂõæÁâáÔºåÂπ∂ÂØπÂõæÂÉèÊï∞ÊçÆ‰ΩúÈ¢ÑÂ§ÑÁêÜ
            filepath = os.path.join(datadir, name)
            img = cv2.imread(filepath)
            img = transform_img(img)
            # ÊØèËØªÂèñ‰∏Ä‰∏™Ê†∑Êú¨ÁöÑÊï∞ÊçÆÔºåÂ∞±Â∞ÜÂÖ∂ÊîæÂÖ•Êï∞ÊçÆÂàóË°®‰∏≠
            batch_imgs.append(img)
            batch_labels.append(label)
            if len(batch_imgs) == batch_size:
                # ÂΩìÊï∞ÊçÆÂàóË°®ÁöÑÈïøÂ∫¶Á≠â‰∫ébatch_sizeÁöÑÊó∂ÂÄôÔºå
                # ÊääËøô‰∫õÊï∞ÊçÆÂΩì‰Ωú‰∏Ä‰∏™mini-batchÔºåÂπ∂‰Ωú‰∏∫Êï∞ÊçÆÁîüÊàêÂô®ÁöÑ‰∏Ä‰∏™ËæìÂá∫
                imgs_array = np.array(batch_imgs).astype('float32')
                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)
                yield imgs_array, labels_array
                batch_imgs = []
                batch_labels = []

        if len(batch_imgs) > 0:
            # Ââ©‰ΩôÊ†∑Êú¨Êï∞ÁõÆ‰∏çË∂≥‰∏Ä‰∏™batch_sizeÁöÑÊï∞ÊçÆÔºå‰∏ÄËµ∑ÊâìÂåÖÊàê‰∏Ä‰∏™mini-batch
            imgs_array = np.array(batch_imgs).astype('float32')
            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)
            yield imgs_array, labels_array

    return reader
```


```python
# Êü•ÁúãÊï∞ÊçÆÂΩ¢Áä∂
DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'
train_loader = data_loader(DATADIR, 
                           batch_size=10, mode='train')
data_reader = train_loader()
data = next(data_reader)
data[0].shape, data[1].shape
```




    ((10, 3, 224, 224), (10, 1))




```python
!pip install xlrd==1.2.0
```

    Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/
    Collecting xlrd==1.2.0
    [?25l  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)
    [K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112kB 7.2MB/s eta 0:00:01
    [?25hInstalling collected packages: xlrd
    Successfully installed xlrd-1.2.0



```python
import pandas as pd
df=pd.read_excel('/home/aistudio/work/palm/PALM-Validation-GT/PM_Label_and_Fovea_Location.xlsx')
df.to_csv('/home/aistudio/work/palm/PALM-Validation-GT/labels.csv',index=False)
```

## ËÆ≠ÁªÉÂíåËØÑ‰º∞‰ª£Á†Å


```python
#ËÆ≠ÁªÉÂíåËØÑ‰º∞‰ª£Á†Å
import os
import random
import paddle
import paddle.fluid as fluid
import numpy as np

DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'
DATADIR2 = '/home/aistudio/work/palm/PALM-Validation400'
CSVFILE = '/home/aistudio/work/palm/PALM-Validation-GT/labels.csv'

# ÂÆö‰πâËÆ≠ÁªÉËøáÁ®ã
def train(model):
    with fluid.dygraph.guard():
        print('start training ... ')
        model.train()
        epoch_num = 5
        # ÂÆö‰πâ‰ºòÂåñÂô®
        opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9)
        # ÂÆö‰πâÊï∞ÊçÆËØªÂèñÂô®ÔºåËÆ≠ÁªÉÊï∞ÊçÆËØªÂèñÂô®ÂíåÈ™åËØÅÊï∞ÊçÆËØªÂèñÂô®
        train_loader = data_loader(DATADIR, batch_size=10, mode='train')
        valid_loader = valid_data_loader(DATADIR2, CSVFILE)
        for epoch in range(epoch_num):
            for batch_id, data in enumerate(train_loader()):
                x_data, y_data = data
                img = fluid.dygraph.to_variable(x_data)
                label = fluid.dygraph.to_variable(y_data)
                label = fluid.layers.cast(label, dtype='int64')
                one_hot_label = fluid.layers.one_hot(input=label, depth=2)
                # ËøêË°åÊ®°ÂûãÂâçÂêëËÆ°ÁÆóÔºåÂæóÂà∞È¢ÑÊµãÂÄº
                logits = model(img)
                # ËøõË°ålossËÆ°ÁÆó
                loss = fluid.layers.cross_entropy(logits, label)
                avg_loss = fluid.layers.mean(loss)

                if batch_id % 10 == 0:
                    print("epoch: {}, batch_id: {}, loss is: {}".format(epoch, batch_id, avg_loss.numpy()))
                # ÂèçÂêë‰º†Êí≠ÔºåÊõ¥Êñ∞ÊùÉÈáçÔºåÊ∏ÖÈô§Ê¢ØÂ∫¶
                avg_loss.backward()
                opt.minimize(avg_loss)
                model.clear_gradients()

            model.eval()
            accuracies = []
            losses = []
            for batch_id, data in enumerate(valid_loader()):
                x_data, y_data = data
                img = fluid.dygraph.to_variable(x_data)
                label = fluid.dygraph.to_variable(y_data)
                label = fluid.layers.cast(label, dtype='int64')
                one_hot_label = fluid.layers.one_hot(input=label, depth=2)
                # ËøêË°åÊ®°ÂûãÂâçÂêëËÆ°ÁÆóÔºåÂæóÂà∞È¢ÑÊµãÂÄº
                logits = model(img)
                # ËøõË°ålossËÆ°ÁÆó
                loss = fluid.layers.cross_entropy(logits, label)
                
                acc = fluid.layers.accuracy(logits, fluid.layers.cast(label, dtype='int64'))
                accuracies.append(acc.numpy())
                losses.append(loss.numpy())
            print("[validation] accuracy/loss: {}/{}".format(np.mean(accuracies), np.mean(losses)))
            model.train()
```

## Inception V4 ÁΩëÁªúÊê≠Âª∫



```python
# -*- coding:utf-8 -*-

# InceptionV4Ê®°Âûã‰ª£Á†Å
import numpy as np
import paddle
import paddle.fluid as fluid
from paddle.fluid.layer_helper import LayerHelper
from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, FC
from paddle.fluid.dygraph.base import to_variable

import os
import numpy as np
import time
import math
import paddle
import paddle.fluid as fluid
import codecs
import logging

from paddle.fluid.initializer import MSRA
from paddle.fluid.initializer import Uniform
from paddle.fluid.param_attr import ParamAttr
from PIL import Image
from PIL import ImageEnhance

class InceptionV4(fluid.dygraph.Layer):

    def __init__(self,name_scope):
        super(InceptionV4,self).__init__(name_scope)
        pass

    
    def name(self):
        """
        ËøîÂõûÁΩëÁªúÂêçÂ≠ó
        :return:
        """
        return 'InceptionV4'

    def forward(self, input, class_dim=2):
        x = self.inception_stem(input)

        for i in range(4):
            x = self.inceptionA(x, name=str(i + 1))
        x = self.reductionA(x)

        for i in range(7):
            x = self.inceptionB(x, name=str(i + 1))
        x = self.reductionB(x)

        for i in range(3):
            x = self.inceptionC(x, name=str(i + 1))

        pool = fluid.layers.pool2d(
            input=x, pool_size=8, pool_type='avg', global_pooling=True)

        drop = fluid.layers.dropout(x=pool, dropout_prob=0.2)

        stdv = 1.0 / math.sqrt(drop.shape[1] * 1.0)
        out = fluid.layers.fc(
            input=drop,
            size=class_dim,
            act='softmax',
            param_attr=ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv),
                name="final_fc_weights"),
            bias_attr=ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv),
                name="final_fc_offset"))
        return out

    def conv_bn_layer(self,
                      data,
                      num_filters,
                      filter_size,
                      stride=1,
                      padding=0,
                      groups=1,
                      act='relu',
                      name=None):
        conv = fluid.layers.conv2d(
            input=data,
            num_filters=num_filters,
            filter_size=filter_size,
            stride=stride,
            padding=padding,
            groups=groups,
            act=None,
            param_attr=ParamAttr(name=name + "_weights"),
            bias_attr=False,
            name=name)
        bn_name = name + "_bn"
        return fluid.layers.batch_norm(
            input=conv,
            act=act,
            name=bn_name,
            param_attr=ParamAttr(name=bn_name + "_scale"),
            bias_attr=ParamAttr(name=bn_name + "_offset"),
            moving_mean_name=bn_name + '_mean',
            moving_variance_name=bn_name + '_variance')

    def inception_stem(self, data, name=None):
        conv = self.conv_bn_layer(
            data, 32, 3, stride=2, act='relu', name="conv1_3x3_s2")
        conv = self.conv_bn_layer(conv, 32, 3, act='relu', name="conv2_3x3_s1")
        conv = self.conv_bn_layer(
            conv, 64, 3, padding=1, act='relu', name="conv3_3x3_s1")

        pool1 = fluid.layers.pool2d(
            input=conv, pool_size=3, pool_stride=2, pool_type='max')
        conv2 = self.conv_bn_layer(
            conv, 96, 3, stride=2, act='relu', name="inception_stem1_3x3_s2")
        concat = fluid.layers.concat([pool1, conv2], axis=1)

        conv1 = self.conv_bn_layer(
            concat, 64, 1, act='relu', name="inception_stem2_3x3_reduce")
        conv1 = self.conv_bn_layer(
            conv1, 96, 3, act='relu', name="inception_stem2_3x3")

        conv2 = self.conv_bn_layer(
            concat, 64, 1, act='relu', name="inception_stem2_1x7_reduce")
        conv2 = self.conv_bn_layer(
            conv2,
            64, (7, 1),
            padding=(3, 0),
            act='relu',
            name="inception_stem2_1x7")
        conv2 = self.conv_bn_layer(
            conv2,
            64, (1, 7),
            padding=(0, 3),
            act='relu',
            name="inception_stem2_7x1")
        conv2 = self.conv_bn_layer(
            conv2, 96, 3, act='relu', name="inception_stem2_3x3_2")

        concat = fluid.layers.concat([conv1, conv2], axis=1)

        conv1 = self.conv_bn_layer(
            concat, 192, 3, stride=2, act='relu', name="inception_stem3_3x3_s2")
        pool1 = fluid.layers.pool2d(
            input=concat, pool_size=3, pool_stride=2, pool_type='max')

        concat = fluid.layers.concat([conv1, pool1], axis=1)

        return concat

    def inceptionA(self, data, name=None):
        pool1 = fluid.layers.pool2d(
            input=data, pool_size=3, pool_padding=1, pool_type='avg')
        conv1 = self.conv_bn_layer(
            pool1, 96, 1, act='relu', name="inception_a" + name + "_1x1")

        conv2 = self.conv_bn_layer(
            data, 96, 1, act='relu', name="inception_a" + name + "_1x1_2")

        conv3 = self.conv_bn_layer(
            data, 64, 1, act='relu', name="inception_a" + name + "_3x3_reduce")
        conv3 = self.conv_bn_layer(
            conv3,
            96,
            3,
            padding=1,
            act='relu',
            name="inception_a" + name + "_3x3")

        conv4 = self.conv_bn_layer(
            data,
            64,
            1,
            act='relu',
            name="inception_a" + name + "_3x3_2_reduce")
        conv4 = self.conv_bn_layer(
            conv4,
            96,
            3,
            padding=1,
            act='relu',
            name="inception_a" + name + "_3x3_2")
        conv4 = self.conv_bn_layer(
            conv4,
            96,
            3,
            padding=1,
            act='relu',
            name="inception_a" + name + "_3x3_3")

        concat = fluid.layers.concat([conv1, conv2, conv3, conv4], axis=1)

        return concat

    def reductionA(self, data, name=None):
        pool1 = fluid.layers.pool2d(
            input=data, pool_size=3, pool_stride=2, pool_type='max')

        conv2 = self.conv_bn_layer(
            data, 384, 3, stride=2, act='relu', name="reduction_a_3x3")

        conv3 = self.conv_bn_layer(
            data, 192, 1, act='relu', name="reduction_a_3x3_2_reduce")
        conv3 = self.conv_bn_layer(
            conv3, 224, 3, padding=1, act='relu', name="reduction_a_3x3_2")
        conv3 = self.conv_bn_layer(
            conv3, 256, 3, stride=2, act='relu', name="reduction_a_3x3_3")

        concat = fluid.layers.concat([pool1, conv2, conv3], axis=1)

        return concat

    def inceptionB(self, data, name=None):
        pool1 = fluid.layers.pool2d(
            input=data, pool_size=3, pool_padding=1, pool_type='avg')
        conv1 = self.conv_bn_layer(
            pool1, 128, 1, act='relu', name="inception_b" + name + "_1x1")

        conv2 = self.conv_bn_layer(
            data, 384, 1, act='relu', name="inception_b" + name + "_1x1_2")

        conv3 = self.conv_bn_layer(
            data, 192, 1, act='relu', name="inception_b" + name + "_1x7_reduce")
        conv3 = self.conv_bn_layer(
            conv3,
            224, (1, 7),
            padding=(0, 3),
            act='relu',
            name="inception_b" + name + "_1x7")
        conv3 = self.conv_bn_layer(
            conv3,
            256, (7, 1),
            padding=(3, 0),
            act='relu',
            name="inception_b" + name + "_7x1")

        conv4 = self.conv_bn_layer(
            data,
            192,
            1,
            act='relu',
            name="inception_b" + name + "_7x1_2_reduce")
        conv4 = self.conv_bn_layer(
            conv4,
            192, (1, 7),
            padding=(0, 3),
            act='relu',
            name="inception_b" + name + "_1x7_2")
        conv4 = self.conv_bn_layer(
            conv4,
            224, (7, 1),
            padding=(3, 0),
            act='relu',
            name="inception_b" + name + "_7x1_2")
        conv4 = self.conv_bn_layer(
            conv4,
            224, (1, 7),
            padding=(0, 3),
            act='relu',
            name="inception_b" + name + "_1x7_3")
        conv4 = self.conv_bn_layer(
            conv4,
            256, (7, 1),
            padding=(3, 0),
            act='relu',
            name="inception_b" + name + "_7x1_3")

        concat = fluid.layers.concat([conv1, conv2, conv3, conv4], axis=1)

        return concat

    def reductionB(self, data, name=None):
        pool1 = fluid.layers.pool2d(
            input=data, pool_size=3, pool_stride=2, pool_type='max')

        conv2 = self.conv_bn_layer(
            data, 192, 1, act='relu', name="reduction_b_3x3_reduce")
        conv2 = self.conv_bn_layer(
            conv2, 192, 3, stride=2, act='relu', name="reduction_b_3x3")

        conv3 = self.conv_bn_layer(
            data, 256, 1, act='relu', name="reduction_b_1x7_reduce")
        conv3 = self.conv_bn_layer(
            conv3,
            256, (1, 7),
            padding=(0, 3),
            act='relu',
            name="reduction_b_1x7")
        conv3 = self.conv_bn_layer(
            conv3,
            320, (7, 1),
            padding=(3, 0),
            act='relu',
            name="reduction_b_7x1")
        conv3 = self.conv_bn_layer(
            conv3, 320, 3, stride=2, act='relu', name="reduction_b_3x3_2")

        concat = fluid.layers.concat([pool1, conv2, conv3], axis=1)

        return concat

    def inceptionC(self, data, name=None):
        pool1 = fluid.layers.pool2d(
            input=data, pool_size=3, pool_padding=1, pool_type='avg')
        conv1 = self.conv_bn_layer(
            pool1, 256, 1, act='relu', name="inception_c" + name + "_1x1")

        conv2 = self.conv_bn_layer(
            data, 256, 1, act='relu', name="inception_c" + name + "_1x1_2")

        conv3 = self.conv_bn_layer(
            data, 384, 1, act='relu', name="inception_c" + name + "_1x1_3")
        conv3_1 = self.conv_bn_layer(
            conv3,
            256, (1, 3),
            padding=(0, 1),
            act='relu',
            name="inception_c" + name + "_1x3")
        conv3_2 = self.conv_bn_layer(
            conv3,
            256, (3, 1),
            padding=(1, 0),
            act='relu',
            name="inception_c" + name + "_3x1")

        conv4 = self.conv_bn_layer(
            data, 384, 1, act='relu', name="inception_c" + name + "_1x1_4")
        conv4 = self.conv_bn_layer(
            conv4,
            448, (1, 3),
            padding=(0, 1),
            act='relu',
            name="inception_c" + name + "_1x3_2")
        conv4 = self.conv_bn_layer(
            conv4,
            512, (3, 1),
            padding=(1, 0),
            act='relu',
            name="inception_c" + name + "_3x1_2")
        conv4_1 = self.conv_bn_layer(
            conv4,
            256, (1, 3),
            padding=(0, 1),
            act='relu',
            name="inception_c" + name + "_1x3_3")
        conv4_2 = self.conv_bn_layer(
            conv4,
            256, (3, 1),
            padding=(1, 0),
            act='relu',
            name="inception_c" + name + "_3x1_3")

        concat = fluid.layers.concat(
            [conv1, conv2, conv3_1, conv3_2, conv4_1, conv4_2], axis=1)

        return concat
```

## ÂºÄÂßãËÆ≠ÁªÉ


```python
with fluid.dygraph.guard():
    model = InceptionV4('InceptionV4')

train(model)
```

    start training ... 
    epoch: 0, batch_id: 0, loss is: [0.88028544]
    epoch: 0, batch_id: 10, loss is: [0.6625659]
    epoch: 0, batch_id: 20, loss is: [0.77900946]
    epoch: 0, batch_id: 30, loss is: [0.81022865]
    [validation] accuracy/loss: 0.4350000023841858/0.7083271741867065
    epoch: 1, batch_id: 0, loss is: [0.69155926]
    epoch: 1, batch_id: 10, loss is: [0.6982287]
    epoch: 1, batch_id: 20, loss is: [0.85588396]
    epoch: 1, batch_id: 30, loss is: [0.56334096]
    [validation] accuracy/loss: 0.4949999749660492/0.6976350545883179
    epoch: 2, batch_id: 0, loss is: [0.7289728]
    epoch: 2, batch_id: 10, loss is: [0.79815567]
    epoch: 2, batch_id: 20, loss is: [0.76212335]
    epoch: 2, batch_id: 30, loss is: [0.7391117]
    [validation] accuracy/loss: 0.5550000071525574/0.6830703616142273
    epoch: 3, batch_id: 0, loss is: [0.61926126]
    epoch: 3, batch_id: 10, loss is: [0.6321007]
    epoch: 3, batch_id: 20, loss is: [0.68893206]
    epoch: 3, batch_id: 30, loss is: [0.6742482]
    [validation] accuracy/loss: 0.5099999904632568/0.6953158378601074
    epoch: 4, batch_id: 0, loss is: [0.7741206]
    epoch: 4, batch_id: 10, loss is: [0.69841546]
    epoch: 4, batch_id: 20, loss is: [0.79569894]
    epoch: 4, batch_id: 30, loss is: [0.7748053]
    [validation] accuracy/loss: 0.5175000429153442/0.6993484497070312

