**1.深度学习基础知识**
**①损失函数方法补充**
（1）MAE损失函数
平均绝对误差（MAE）是另一种常用的回归损失函数，它是目标值与预测值之差绝对值的和，表示了预测值的平均误差幅度，而不需要考虑误差的方向（注：平均偏差误差MBE则是考虑的方向的误差，是残差的和），范围是0到∞，其公式如下所示：
![](https://ai-studio-static-online.cdn.bcebos.com/ca675d32ee264a0ca2c60ee04ace54a923235803dbab4d3eb83fbaebf177c5dc)

（2）L1_Loss和L2_Loss
L1范数损失函数，也被称为最小绝对值偏差（LAD），最小绝对值误差（LAE）。总的说来，它是把目标值（Yi)与估计值（f(xi))的绝对差值的总和（S)最小化：
![](https://ai-studio-static-online.cdn.bcebos.com/1fbe305d3d7a4fe9a60fcdeb641b2f7754b4aff8176e41398138c3135888d2ab)
L2范数损失函数，也被称为最小平方误差（LSE）。总的来说，它是把目标值（Yi)与估计值（f(xi))的差值的平方和（S)最小化：
![](https://ai-studio-static-online.cdn.bcebos.com/044cddc80c484d60a5b179d0f2526f4f119f6ab3b40b46f289d71f6b6b5b7723)

（3）Softmax Loss
S![](https://ai-studio-static-online.cdn.bcebos.com/f33759870cf04b76a42464a246194c5c457e1947ddac496c8a7460d73cbdfb78)oftmax Loss
首先L是损失。Sj是softmax的输出向量S的第j个值，前面已经介绍过了，表示的是这个样本属于第j个类别的概率。yj前面有个求和符号，j的范围也是1到类别数T，因此y是一个1*T的向量，里面的T个值，而且只有1个值是1，其他T-1个值都是0。那么哪个位置的值是1呢？答案是真实标签对应的位置的那个值是1，其他都是0。所以结果为：
![](https://ai-studio-static-online.cdn.bcebos.com/667a72d2dd364858b5834ced28e04ede52cc3c19241b498787387667a783fbc8)
j指向当前样本的真是标签。假设一个5分类问题，然后一个样本I的标签y=[0,0,0,1,0]，也就是说样本I的真实标签是4，假设模型预测的结果概率（softmax的输出）p=[0.2,0.3,0.4,0.6,0.5]，可以看出这个预测是对的，那么对应的损失L=-log(0.6)，也就是当这个样本经过这样的网络参数产生这样的预测p时，它的损失是-log(0.6)。那么假设p=[0.2,0.3,0.4,0.1,0.5]，这个预测结果就很离谱了，因为真实标签是4，而你觉得这个样本是4的概率只有0.1（远不如其他概率高，如果是在测试阶段，那么模型就会预测该样本属于类别5），对应损失L=-log(0.1)。那么假设p=[0.2,0.3,0.4,0.3,0.5]，这个预测结果虽然也错了，但是没有前面那个那么离谱，对应的损失L=-log(0.3)。我们知道log函数在输入小于1的时候是个负数，而且log函数是递增函数，所以-log(0.6) < -log(0.3) < -log(0.1)。简单讲就是你预测错比预测对的损失要大，预测错得离谱比预测错得轻微的损失要大。

**②池化方法补充**
（1）重叠池化（OverlappingPooling）
重叠池化正如其名字所说的，相邻池化窗口之间会有重叠区域，此时sizeX>stride。
论文中[2]中，作者使用了重叠池化，其他的设置都不变的情况下， top-1和top-5 的错误率分别减少了0.4% 和0.3%。

（2）空金字塔池化（Spatial Pyramid Pooling）
空间金字塔池化可以把任何尺度的图像的卷积特征转化成相同维度，这不仅可以让CNN处理任意尺度的图像，还能避免cropping和warping操作，导致一些信息的丢失，具有非常重要的意义。
一般的CNN都需要输入图像的大小是固定的，这是因为全连接层的输入需要固定输入维度，但在卷积操作是没有对图像尺度有限制，所有作者提出了空间金字塔池化，先让图像进行卷积操作，然后转化成维度相同的特征输入到全连接层，这个可以把CNN扩展到任意大小的图像。
空间金字塔池化的思想来自于Spatial Pyramid Model，它一个pooling变成了多个scale的pooling。用不同大小池化窗口作用于卷积特征，我们可以得到1X1,2X2,4X4的池化结果，由于conv5中共有256个过滤器，所以得到1个256维的特征，4个256个特征，以及16个256维的特征，然后把这21个256维特征链接起来输入全连接层，通过这种方式把不同大小的图像转化成相同维度的特征。

**③数据增强方法**
（1）随机裁切（random crop）
随机裁切几乎是所有深度学习框架训练都具有的数据增强方法，在很多有名的深度学习网络（VGG,AlexNet,GoogleNet,ResNet……）的训练中，对输入256*256的图像，通常会以224或227的窗口随机获得子图像作为训练，而在测试时则是以图像中心的子块（Patch）。最终使用则直接将图像resize到训练时用的crop size大小。实现也是比较简单，在红色区域内随机取点作为滑窗左上角顶点。

（2）翻转
左右翻转也叫做水平翻转或镜像（mirror）,将图像的左右部分以图像垂直中轴线为中心进行镜像对换。假设原图像高度为h,宽度为w,原图像某一像素点P(x0,y0), 经过水平镜像变换后为P(w-1-x0,y0),矩阵表示：![](https://ai-studio-static-online.cdn.bcebos.com/276ed712af354dc38c0f88223913a635b64c64480123486db7921c3d63bdbefa)

（3）颜色抖动（color jitter）
颜色抖动是指对图像的曝光度（exposure）、饱和度（saturation）和色调（hue）进行随机变化形成不同光照及颜色下的图片，达到数据增强的目的，尽可能使得模型能够使用不同光照条件小的情形，提高模型泛化能力。
YOLOv2-v3的目标检测就用到了这一数据增强方法，YOLO在训练的每一Batch中对训练数据进行在线数据增强（包括颜色抖动） ，实现上首先将图像变换到HSV颜色空间，然后对图像在HSV颜色空间中随机的改变图像的曝光度、饱和度和色调,然后再将变换后的图像转到RGB空间。具体实现代码可以参考YOLO源码（image.c）。

（4）噪声（高斯噪声）
一般对图像加入高斯噪声可以使得图像变得模糊，从而模拟模糊情况。

（5）旋转
图像旋转一般是以图像中心为旋转中心进行随机旋转（一般有一个正负角度约束）

（6）缩放
全卷积网络对于尺度没有严格要求，如目标检测算法yolov2-v3在训练过程中会对样本进行随机尺度变换（每隔10步变换一次），实现多尺度训练，进而跨尺度特征融合。同时也使得模型对于不同尺度的图像有更强的适应性。

（7） PCA jitter
PCA jitter是实际上对RGB颜色空间添加扰动，从而达到对RGB颜色添加噪声的目的，具体为对RGB空间做PCA，然后对主成分做一个(0, 0.1)的高斯扰动。最早使用是在2012年的AlexNet,从论文实验中可以看出，PCA jitter对于分类的性能提升比较显著。

**④图像分类方法综述**
（1）图像分类介绍
什么是图像分类，核心是从给定的分类集合中给图像分配一个标签的任务。实际上，这意味着我们的任务是分析一个输入图像并返回一个将图像分类的标签。标签来自预定义的可能类别集。
这里的目标是根据输入图像，从类别集中分配一个类别，这里为dog,我们的分类系统也可以根据概率给图像分配多个标签，如dog:95%，cat:4%，eagle:1%。

图像分类的任务就是给定一个图像，正确给出该图像所属的类别。对于超级强大的人类视觉系统来说，判别出一个图像的类别是件很容易的事，但是对于计算机来说，并不能像人眼那样一下获得图像的语义信息。

计算机能看到的只是一个个像素的数值，对于一个RGB图像来说，假设图像的尺寸是3232，那么机器看到的就是一个形状为332*32的矩阵，或者更正式地称其为“张量”（“张量”简单来说就是高维的矩阵），那么机器的任务其实也就是寻找一个函数关系，这个函数关系能够将这些像素的数值映射到一个具体的类别（类别可以用某个数值表示）。

（2）传统图像分类算法
1). 底层特征提取: 通常从图像中按照固定步长、尺度提取大量局部特征描述。常用的局部特征包括SIFT(Scale-Invariant Feature Transform, 尺度不变特征转换) 、HOG(Histogram of Oriented Gradient, 方向梯度直方图) 、LBP(Local Bianray Pattern, 局部二值模式)等，一般也采用多种特征描述，防止丢失过多的有用信息。

2). 特征编码: 底层特征中包含了大量冗余与噪声，为了提高特征表达的鲁棒性，需要使用一种特征变换算法对底层特征进行编码，称作特征编码。常用的特征编码方法包括向量量化编码、稀疏编码、局部线性约束编码、Fisher向量编码等。

3). 空间特征约束: 特征编码之后一般会经过空间特征约束，也称作特征汇聚。特征汇聚是指在一个空间范围内，对每一维特征取最大值或者平均值，可以获得一定特征不变形的特征表达。金字塔特征匹配是一种常用的特征汇聚方法，这种方法提出将图像均匀分块，在分块内做特征汇聚。

4). 通过分类器分类: 经过前面步骤之后一张图像可以用一个固定维度的向量进行描述，接下来就是经过分类器对图像进行分类。通常使用的分类器包括SVM(Support Vector Machine, 支持向量机)、随机森林等。而使用核方法的SVM是最为广泛的分类器，在传统图像分类任务上性能很好。

这种传统的图像分类方法在PASCAL VOC竞赛中的图像分类算法中被广泛使用 。

（3）深度学习算法
1）CNN
传统CNN包含卷积层、全连接层等组件，并采用softmax多类别分类器和多类交叉熵损失函数，一个典型的卷积神经网络如图6所示，我们先介绍用来构造CNN的常见组件。
l 卷积层(convolution layer): 执行卷积操作提取底层到高层的特征，发掘出图片局部关联性质和空间不变性质。

l 池化层(pooling layer): 执行降采样操作。通过取卷积输出特征图中局部区块的最大值(max-pooling)或者均值(avg-pooling)。降采样也是图像处理中常见的一种操作，可以过滤掉一些不重要的高频信息。

l 全连接层(fully-connected layer，或者fc layer): 输入层到隐藏层的神经元是全部连接的。

l 非线性变化: 卷积层、全连接层后面一般都会接非线性变化函数，例如Sigmoid、Tanh、ReLu等来增强网络的表达能力，在CNN里最常使用的为ReLu激活函数。

l Dropout: 在模型训练阶段随机让一些隐层节点权重不工作，提高网络的泛化能力，一定程度上防止过拟合。

另外，在训练过程中由于每层参数不断更新，会导致下一次输入分布发生变化，这样导致训练过程需要精心设计超参数。如2015年Sergey Ioffe和Christian Szegedy提出了Batch Normalization (BN)算法 中，每个batch对网络中的每一层特征都做归一化，使得每层分布相对稳定。BN算法不仅起到一定的正则作用，而且弱化了一些超参数的设计。

经过实验证明，BN算法加速了模型收敛过程，在后来较深的模型中被广泛使用。

2）VGG
牛津大学VGG(Visual Geometry Group)组在2014年ILSVRC提出的模型被称作VGG模型。该模型相比以往模型进一步加宽和加深了网络结构，它的核心是五组卷积操作，每两组之间做Max-Pooling空间降维。同一组内采用多次连续的3X3卷积，卷积核的数目由较浅组的64增多到最深组的512，同一组内的卷积核数目是一样的。卷积之后接两层全连接层，之后是分类层。

由于每组内卷积层的不同，有11、13、16、19层这几种模型，下图展示一个16层的网络结构。VGG模型结构相对简洁，提出之后也有很多文章基于此模型进行研究，如在ImageNet上首次公开超过人眼识别的模型就是借鉴VGG模型的结构。

3）GoogLeNet
GoogLeNet 在2014年ILSVRC的获得了冠军，在介绍该模型之前我们先来了解NIN(Network in Network)模型和Inception模块，因为GoogLeNet模型由多组Inception模块组成，模型设计借鉴了NIN的一些思想。

NIN模型主要有两个特点：

1.引入了多层感知卷积网络(Multi-Layer Perceptron Convolution, MLPconv)代替一层线性卷积网络。MLPconv是一个微小的多层卷积网络，即在线性卷积后面增加若干层1x1的卷积，这样可以提取出高度非线性特征。

2.传统的CNN最后几层一般都是全连接层，参数较多。而NIN模型设计最后一层卷积层包含类别维度大小的特征图，然后采用全局均值池化(Avg-Pooling)替代全连接层，得到类别维度大小的向量，再进行分类。这种替代全连接层的方式有利于减少参数。

Inception模块如下图8所示，下图左是最简单的设计，输出是3个卷积层和一个池化层的特征拼接。这种设计的缺点是池化层不会改变特征通道数，拼接后会导致特征的通道数较大，经过几层这样的模块堆积后，通道数会越来越大，导致参数和计算量也随之增大。

为了改善这个缺点，下图右引入3个1x1卷积层进行降维，所谓的降维就是减少通道数，同时如NIN模型中提到的1x1卷积也可以修正线性特征。
GoogLeNet由多组Inception模块堆积而成。另外，在网络最后也没有采用传统的多层全连接层，而是像NIN网络一样采用了均值池化层；但与NIN不同的是，GoogLeNet在池化层后加了一个全连接层来映射类别数。

除了这两个特点之外，由于网络中间层特征也很有判别性，GoogLeNet在中间层添加了两个辅助分类器，在后向传播中增强梯度并且增强正则化，而整个网络的损失函数是这个三个分类器的损失加权求和。

GoogLeNet整体网络结构如图9所示，总共22层网络：开始由3层普通的卷积组成；接下来由三组子网络组成，第一组子网络包含2个Inception模块，第二组包含5个Inception模块，第三组包含2个Inception模块；然后接均值池化层、全连接层。

4）ResNet
ResNet(Residual Network) 是2015年ImageNet图像分类、图像物体定位和图像物体检测比赛的冠军。针对随着网络训练加深导致准确度下降的问题，ResNet提出了残差学习方法来减轻训练深层网络的困难。

在已有设计思路(BN, 小卷积核，全卷积网络)的基础上，引入了残差模块。每个残差模块包含两条路径，其中一条路径是输入特征的直连通路，另一条路径对该特征做两到三次卷积操作得到该特征的残差，最后再将两条路径上的特征相加。

残差模块如图10所示，左边是基本模块连接方式，由两个输出通道数相同的3x3卷积组成。右边是瓶颈模块(Bottleneck)连接方式，之所以称为瓶颈，是因为上面的1x1卷积用来降维(图示例即256->64)，下面的1x1卷积用来升维(图示例即64->256)，这样中间3x3卷积的输入和输出通道数都较小(图示例即64->64)。


```python

```
