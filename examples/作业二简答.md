### 1.损失函数补充：

##### 0-1损失：

最自然的损失函数是0-1损失，表示的是，当且仅当预测为真的时候取值为1，否则取值为0。该损失函数能够直观的刻画分类的错误率，但是由于其非凸、非光滑的特点，使得算法很难直接对该函数进行优化。

##### Hinge损失：

Hinge损失函数是0-1损失函数相对紧的凸上界，且当 f . y ≤ 1 f.y\leq1 f.y≤1时候,该函数不对其做任何处罚。由于Hinge损失在f.y=1处不可导，因此不能使用梯度下降算法优化，而是使用次梯度下降法。

##### Logistic损失：

Logistic损失函数也是0-1损失函数的凸上界，且该函数处处光滑，因此可以使用梯度下降法进行优化。但是，该函数对所有样本点都做惩罚，因此对异常点更为敏感。

### 2.损失函数代码实现：

##### 0-1：

```python
def 0-1_loss(Y,P):
	if abs(P-Y)<T:
		return 0
	else:
		return 1
```

##### Hinge：

```python
def update_weights_Hinge(m1, m2, b, X1, X2, Y, learning_rate):
    m1_deriv = 0
    m2_deriv = 0
    b_deriv = 0
    N = len(X1)
    for i in range(N):
        # 计算偏导数
        if Y[i]*(m1*X1[i] + m2*X2[i] + b) <= 1:
            m1_deriv += -X1[i] * Y[i]
            m2_deriv += -X2[i] * Y[i]
            b_deriv += -Y[i]
        # 否则偏导数为0
    # 我们减去它，因为导数指向最陡的上升方向
    m1 -= (m1_deriv / float(N)) * learning_rate
    m2 -= (m2_deriv / float(N)) * learning_rate
    b -= (b_deriv / float(N)) * learning_rate
return m1, m2, b
```

##### Logistic：

```python
def logloss(y_true, y_pred, eps=1e-15):
    import numpy as np
    # Prepare numpy array data
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    assert (len(y_true) and len(y_true) == len(y_pred))
    # Clip y_pred between eps and 1-eps
    p = np.clip(y_pred, eps, 1-eps)
    loss = np.sum(- y_true * np.log(p) - (1 - y_true) * np.log(1-p))
    return loss / len(y_true)
```

### 3.池化方法补充：

##### 重叠池化：

如果步长和池化模板尺寸不相等且两个池化区域存在重叠，这种池化方法称之为重叠池化。

![img](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTA5MTg1NjA0NTk4?x-oss-process=image/format,png)

代码：

```C
Mat pooling(Mat img, int grid, int overlap)
{
	Mat pool_img = Mat((int)((img.rows - 1) / overlap) + 1, (int)((img.cols - 1) / overlap)+1, CV_8UC1);
	for (int col = 0,pool_col=0; col < img.cols; col+= overlap)
	{
		for (int row = 0,pool_row=0; row < img.rows; row+= overlap)
		{
			int minCol = min(col + overlap, img.cols);
			int maxData = 0;
			for (int poolX = col; poolX < minCol; poolX++)
			{
				int minRow = min(row + overlap, img.rows);
				for (int poolY = row; poolY<minRow; poolY++)
				{
					if (img.at<uchar>(poolY, poolX)>maxData)
					{
						maxData = img.at<uchar>(poolY, poolX);
					}
				}
			}
			pool_img.at<uchar>(pool_row, pool_col) = maxData;
			pool_row++;
		}
		pool_col++;
	}
	return pool_img;
}
```



##### 金字塔池化：

一般CNN对输入的图像尺寸有着特定的要求，因为这是全卷积层的神经元个数对输入的特征维度是固定的。但采用金字塔池化，则可以将任意图像的卷积特征图像转化为所指定维度的特征向量输入给全卷积层。这就解决了CNN输入图像可以是任意尺寸的问题。
空间金字塔池化是将池化层转化为多尺度的池化，即利用多个不同大小尺度的池化模板来进行池化操作。
![img](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTA5MjEwODIzOTU5?x-oss-process=image/format,png)

```python
import math
import torch
import torch.nn.functional as F
# 构建SPP层(空间金字塔池化层)
class SPPLayer(torch.nn.Module):
    def __init__(self, num_levels, pool_type='max_pool'):
        super(SPPLayer, self).__init__()
        self.num_levels = num_levels
        self.pool_type = pool_type
    def forward(self, x):
        num, c, h, w = x.size() # num:样本数量 c:通道数 h:高 w:宽
        for i in range(self.num_levels):
            level = i+1
            kernel_size = (math.ceil(h / level), math.ceil(w / level))
            stride = (math.ceil(h / level), math.ceil(w / level))
            pooling = (math.floor((kernel_size[0]*level-h+1)/2), math.floor((kernel_size[1]*level-w+1)/2))
            # 选择池化方式 
            if self.pool_type == 'max_pool':
                tensor = F.max_pool2d(x, kernel_size=kernel_size, stride=stride, padding=pooling).view(num, -1)
            else:
                tensor = F.avg_pool2d(x, kernel_size=kernel_size, stride=stride, padding=pooling).view(num, -1)
            # 展开、拼接
            if (i == 0):
                x_flatten = tensor.view(num, -1)
            else:
                x_flatten = torch.cat((x_flatten, tensor.view(num, -1)), 1)
        return x_flatten
```

##### 最大池化：

mean-pooling，即对邻域内特征点只求平均，max-pooling，即对邻域内特征点取最大。根据相关理论，特征提取的误差主要来自两个方面：（1）邻域大小受限造成的估计值方差增大；（2）卷积层参数误差造成估计均值的偏移。一般来说，mean-pooling能减小第一种误差，更多的保留图像的背景信息，max-pooling能减小第二种误差，更多的保留纹理信息。Stochastic-pooling则介于两者之间，通过对像素点按照数值大小赋予概率，再按照概率进行亚采样，在平均意义上，与mean-pooling近似，在局部意义上，则服从max-pooling的准则。

```python
import numpy as np
def max_pooling(det,pool_param):
    M,N,H,W=det.shape()
    H1,W1,stride=pool_param['pool_heaight'],pool_param['pool_width',pool_param['stride']]
    H2=int(（H-H1）/stride)+1
    W2=int(（W-W1）/stride)+1
    out=np.zeros(M,N,H,W)
    for i in range(len(H2)):
        for j in range(len(W2)):
            out[...,i,j]=np.max(det[...,i*stride:i*stride+H2,j*stride:j*stride+W2],axis=(2,3))
    result=(det,out,pool_param)
    return out,result
np.max()
```

##### 

### 4.数据增强方法补充及修改：

##### 翻转： 

 随机旋转图像一定角度; 改变图像内容的朝向

```python
with tf.Session() as sess:
    # tensorflow
    flipped1=tf.image.flip_left_right(img_data)
    flipped2=tf.image.flip_up_down(img_data)
    transpose_img=tf.image.transpose_image(img_data)
    # PIL
    flipped1=Image.FLIP_LEFT_RIGHT(img_data)
    flipped2=Image.FLIP_UP_DOWN(img_data)
    transpose_img=Image.TRANSPOSE(img_data)    
    
    for i,img in enumerate([img_data,flipped1,flipped2,transpose_img]):
        plt.subplot(1,4,i+1)
        plt.tight_layout()
        plt.imshow(img.eval())
    plt.show()
```

##### 裁剪：

裁剪图片的感兴趣区域（ROI），通常在训练的时候，会采用随机裁剪的方法。

```python
# tensorflow
    img = tf.image.random_crop(img_data, [400, 600, 3])
    # tf.image.central_crop(image,0.5) 按比例裁剪
    
    with tf.Session() as sess:
        img = sess.run(img)
        plt.subplot(1,2,1)
        plt.imshow(img)
        plt.title("tensorflow")
    
    # PIL
    img = img_data.crop((200, 100, 800, 500))  # 参数为坐标左上右下
    plt.subplot(1, 2, 2)
    plt.imshow(img)
    plt.title("PIL")
    plt.show()
```

##### 旋转：

对图像做一定角度的旋转操作。

```python
 # tensorflow
    img = tf.image.rot90(img_data, 1)

    with tf.Session() as sess:
        img = sess.run(img)
        plt.subplot(1,2,1)
        plt.title("tensorflow")
        plt.imshow(img)

    # PIL
    img = img_data.rotate(90)  # 逆时针旋转
    plt.subplot(1, 2, 2)
    plt.title("PIL")
    plt.imshow(img)
    plt.show()
```

##### 缩放变形：

随机选取图像的一部分，然后将其缩放到原图像尺度。

```python
# PIL
    plt.subplot(1,2,1)
    plt.title("original")
    plt.imshow(img_data)

    img = img_data.crop((200, 100, 800, 500))
    img = img.resize((1000,600),resample=Image.LANCZOS)
    plt.subplot(1,2,2)
    plt.title("scale")
    plt.imshow(img)
    plt.show()
```

##### 平移变换：

图像整体平移一段距离

```python
# PIL
    plt.subplot(1,2,1)
    plt.title("original")
    plt.imshow(img)

    img = ImageChops.offset(img_data,200,100)
    plt.subplot(1,2,2)
    plt.title("scale")
    plt.imshow(img)
    plt.show()
```

##### 噪声变换：

对图像的每个像素RGB进行随机扰动, 常用的噪声模式是椒盐噪声和高斯噪声。

### 5.图像分类方法综述：

#### 传统方法：

##### SVM：

支持向量机（SVM）是一种强大而灵活的有监督机器学习算法是多维空间中超平面上不同类的表示。目标是分裂将数据集分成类，寻找最大边缘超平面。它建立了一个超平面或一组高维空间中的超平面和两类之间的良好分离是通过到任何类中最近的训练数据点距离最大的超平面。真正的力量该算法的性能取决于所使用的核函数。

##### KNN：

K-最近邻（K-NN）是一种非参数的惰性学习算法，用于分类和分类回归。该算法简单地依赖于特征向量和分类器之间的距离通过在k-最近的例子中找到最常见的类来获得未知的数据点。

#### 深度学习方法：

##### 卷积神经网络：

卷积神经网络（CNN，或ConvNet）是一种多层神经网络，旨在通过最少的预处理直接从像素图像中识别视觉模式。这是一个特殊的人工神经网络结构。它包括两个重要的元素，即卷积层和池化层。