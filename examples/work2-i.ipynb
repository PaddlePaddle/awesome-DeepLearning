{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ff035939\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import torchvision\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.utils.data.dataloader as Data\\n\",\n",
    "    \"from torch.autograd import Variable\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"import torch.nn.functional as F\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"import matplotlib.pyplot as plt\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"fbae3dfe\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#残差块\\n\",\n",
    "    \"if_use_gpu=0\\n\",\n",
    "    \"class ResidualBlock(nn.Module):\\n\",\n",
    "    \"    def __init__(self, inchannel, outchannel, stride=1):\\n\",\n",
    "    \"        super(ResidualBlock, self).__init__()\\n\",\n",
    "    \"        self.left = nn.Sequential(\\n\",\n",
    "    \"            nn.Conv2d(inchannel,outchannel,kernel_size=3,padding=1,stride=stride,bias=False),\\n\",\n",
    "    \"            nn.BatchNorm2d(outchannel),\\n\",\n",
    "    \"            nn.ReLU(),\\n\",\n",
    "    \"            nn.Conv2d(outchannel, outchannel, kernel_size=3, padding=1, stride=stride, bias=False),\\n\",\n",
    "    \"            nn.BatchNorm2d(outchannel)\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        self.right = nn.Sequential()\\n\",\n",
    "    \"        #输入输出信道数不一样，把残差块的信道卷积到和输出一样\\n\",\n",
    "    \"        if(inchannel != outchannel):\\n\",\n",
    "    \"            self.right = nn.Sequential(\\n\",\n",
    "    \"                nn.Conv2d(inchannel, outchannel, kernel_size=3, padding=1, stride=stride, bias=False),\\n\",\n",
    "    \"                nn.BatchNorm2d(outchannel),\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def forward(self, x):\\n\",\n",
    "    \"        out = self.left(x)\\n\",\n",
    "    \"        out += self.right(x)\\n\",\n",
    "    \"        out =F.relu(out)\\n\",\n",
    "    \"        return out\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"41e299b7\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class ResNet(nn.Module):\\n\",\n",
    "    \"    def __init__(self, ResidualBlock, num_classes=10):\\n\",\n",
    "    \"        super(ResNet, self).__init__()\\n\",\n",
    "    \"        self.inchannel = 64\\n\",\n",
    "    \"        self.conv1 = nn.Sequential(\\n\",\n",
    "    \"            nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1,bias=False),\\n\",\n",
    "    \"            nn.BatchNorm2d(64),\\n\",\n",
    "    \"            nn.ReLU(),\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\\n\",\n",
    "    \"        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=1)\\n\",\n",
    "    \"        self.conv2 = nn.Conv2d(128,128,3,stride=2)\\n\",\n",
    "    \"        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=1)\\n\",\n",
    "    \"        self.conv3 = nn.Conv2d(256, 256, 3, stride=2)\\n\",\n",
    "    \"        #self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=1)\\n\",\n",
    "    \"        self.conv4 = nn.Conv2d(256,256,6)\\n\",\n",
    "    \"        self.fc = nn.Linear(256, num_classes)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def make_layer(self, block, channels, num_blocks, stride):\\n\",\n",
    "    \"        layer = []\\n\",\n",
    "    \"        for i in range(num_blocks):\\n\",\n",
    "    \"            layer.append(block(self.inchannel,channels,stride))\\n\",\n",
    "    \"            self.inchannel = channels\\n\",\n",
    "    \"        #对layer拆包\\n\",\n",
    "    \"        return nn.Sequential(*layer)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def forward(self, x):\\n\",\n",
    "    \"        out = self.conv1(x)\\n\",\n",
    "    \"        out = self.layer1(out)\\n\",\n",
    "    \"        out = self.layer2(out)\\n\",\n",
    "    \"        out = self.conv2(out)\\n\",\n",
    "    \"        out = self.layer3(out)\\n\",\n",
    "    \"        out = self.conv3(out)\\n\",\n",
    "    \"        #out = self.layer4(out)\\n\",\n",
    "    \"        out = self.conv4(out)\\n\",\n",
    "    \"        #out = F.avg_pool2d(out,4)\\n\",\n",
    "    \"        out = out.view(out.size(0), -1)\\n\",\n",
    "    \"        out = self.fc(out)\\n\",\n",
    "    \"        return out\\n\",\n",
    "    \"\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"f3179977\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def ResNet18():\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return ResNet(ResidualBlock)\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_data = torchvision.datasets.MNIST(\\n\",\n",
    "    \"    './mnist', train=True,transform=torchvision.transforms.Compose([\\n\",\n",
    "    \"    torchvision.transforms.ToTensor(),\\n\",\n",
    "    \"    ]), download=True\\n\",\n",
    "    \")\\n\",\n",
    "    \"train_data.data = train_data.data[:10000]\\n\",\n",
    "    \"train_data.targets = train_data.targets[:10000]\\n\",\n",
    "    \"test_data = torchvision.datasets.MNIST(\\n\",\n",
    "    \"    './mnist', train=False, transform=torchvision.transforms.Compose([\\n\",\n",
    "    \"    torchvision.transforms.ToTensor(),\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \")\\n\",\n",
    "    \"print(\\\"train_data:\\\", train_data.train_data.size())\\n\",\n",
    "    \"print(\\\"train_labels:\\\", train_data.train_labels.size())\\n\",\n",
    "    \"print(\\\"test_data:\\\", test_data.test_data.size())\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_loader = Data.DataLoader(dataset=train_data, batch_size=32, shuffle=True)\\n\",\n",
    "    \"test_loader = Data.DataLoader(dataset=test_data, batch_size=32)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = ResNet18()\\n\",\n",
    "    \"if if_use_gpu:\\n\",\n",
    "    \"    model = model.cuda()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(model)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ee33c32c\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"optimizer = torch.optim.Adam(model.parameters())\\n\",\n",
    "    \"loss_func = torch.nn.CrossEntropyLoss()\\n\",\n",
    "    \"for epoch in range(1):\\n\",\n",
    "    \"    print('epoch {}'.format(epoch + 1))\\n\",\n",
    "    \"    for i, data in enumerate(train_loader, 0):\\n\",\n",
    "    \"        # get the inputs\\n\",\n",
    "    \"        inputs, labels = data\\n\",\n",
    "    \"        batch_x, batch_y = Variable(inputs), Variable(labels)\\n\",\n",
    "    \"        if if_use_gpu:\\n\",\n",
    "    \"            batch_x = batch_x.cuda()\\n\",\n",
    "    \"            batch_y = batch_y.cuda()\\n\",\n",
    "    \"        out = model(batch_x)\\n\",\n",
    "    \"        batch_y = batch_y.long()\\n\",\n",
    "    \"        loss = loss_func(out, batch_y)\\n\",\n",
    "    \"        optimizer.zero_grad()\\n\",\n",
    "    \"        loss.backward()\\n\",\n",
    "    \"        optimizer.step()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # 返回每行元素最大值\\n\",\n",
    "    \"        pred = torch.max(out, 1)[1]\\n\",\n",
    "    \"        train_correct = (pred == batch_y).sum()\\n\",\n",
    "    \"        train_correct = train_correct.item()\\n\",\n",
    "    \"        train_loss = loss.item()\\n\",\n",
    "    \"        print('batch:{},Train Loss: {:.6f}, Acc: {:.6f}'.format(i+1,train_loss , train_correct /32))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"a8f11afc\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"    # evaluation--------------------------------\\n\",\n",
    "    \"model.eval()\\n\",\n",
    "    \"eval_loss = 0.\\n\",\n",
    "    \"eval_acc = 0.\\n\",\n",
    "    \"for batch_x, batch_y in test_loader:\\n\",\n",
    "    \"    batch_x, batch_y = Variable(batch_x, requires_grad=False), Variable(batch_y,requires_grad=False)\\n\",\n",
    "    \"    if if_use_gpu:\\n\",\n",
    "    \"        batch_x = batch_x.cuda()\\n\",\n",
    "    \"        batch_y = batch_y.cuda()\\n\",\n",
    "    \"    out = model(batch_x)\\n\",\n",
    "    \"    loss = loss_func(out, batch_y)\\n\",\n",
    "    \"    eval_loss += loss.item()\\n\",\n",
    "    \"    pred = torch.max(out, 1)[1]\\n\",\n",
    "    \"    num_correct = (pred == batch_y).sum()\\n\",\n",
    "    \"    eval_acc += num_correct.item()\\n\",\n",
    "    \"print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\\n\",\n",
    "    \"    test_data)), eval_acc / (len(test_data))))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"645ef449\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"b90731b7\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"59a5e57d\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.4\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
