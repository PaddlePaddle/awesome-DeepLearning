深度学习发展历史

深度学习的起源

1943年，神经科学家麦卡洛克和数学家皮兹发表论文《神经活动中内在思想的逻辑运算》，建立了神经网络数学模型，从此，人工神经网络诞生。1958年，罗森布拉特提出了感知器模型，推动了深度学习的浪潮。

深度学习的发展

1982年，约翰·霍普菲尔德发明了Hopfield神经网络，四年后，杰弗里·辛顿提出了BP算法，解决了非线性分类的问题，人工神经网络再次引起了人们的广泛关注。

深度学习的爆发

2006年，杰弗里·辛顿正式提出了深度学习的概念。2012年，杰弗里·辛顿的小组凭借CNN网络AlexNet模型以碾压第二名SVM算法的性能在ImageNet大赛中夺冠，再次掀起深度学习的发展浪潮。2017年，AlphaGo以3:0的比分战胜围棋九段柯洁，标志着其实力已超过人类顶尖围棋选手的水平。



人工智能、机器学习、深度学习有什么区别和联系？

人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学，是计算机科学的分支。

机器学习是专门研究计算机如何模拟和实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能的多领域交叉学科，是人工智能的核心，是使计算机具有智能的途径。

深度学习目的在于使机器实现像人一样的分析学习能力，实现图像、文字、声音等的识别和分析，是机器学习领域的新的研究方向。

机器学习是实现人工智能的一种方法，深度学习是实现机器学习的一种技术。



神经元、单层感知机、多层感知机

神经元是神经系统最基本的结构和功能单位。分为细胞体和突起两部分。细胞体具有联络和整合输入信息并传出信息的作用。突起有树突和轴突两种。树突短而分枝多，直接由细胞体扩张突出，形成树枝状，其作用是接受其他神经元轴突传来的冲动并传给细胞体。轴突长而分枝少，为粗细均匀的细长突起，常起于轴丘，其作用是接受外来刺激，再由细胞体传出。

根据神经元结构可以构建神经元模型。多个输入分别计算权值后求和，并经过非线性函数运算后输出。

单层感知机是一种单层前向网络，除了输入层和输出层之外，只拥有一层神经元节点。数据在单层感知机中由输入层输入，经由隐藏层向输出层传播，相邻两层的神经元之间相互连接，同一层的神经元之间没有连接。

多层感知机又叫人工神经网络，除了输入输出层，它中间可以有多个隐层，最简单的MLP只含一个隐层，即三层的结构。，多层感知机层与层之间是全连接的。多层感知机最底层是输入层，中间是隐藏层，最后是输出层。



什么是前向传播

前向传播通过对一层的结点以及对应的连接权值进行加权和运算，结果加上一个偏置项，然后通过一个非线性函数（即激活函数），如ReLu，sigmoid等函数，得到的结果就是下一层结点的输出。从第一层（输入层）开始不断的通过这种方法一层层的运算，最后得到输出层结果。

![说明: https://www.icode9.com/i/l/?n=20&i=blog/1950546/202008/1950546-20200802184100393-1783239279.jpg](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image002.jpg)



什么是反向传播

后向传播通过迭代地处理-组训练样本,将每个样本的网络预测与实际知道的类标号比较，进行学习。对于每个训练样本，修改权，使得网络预测和实际类之间的均方误差最小。这种修改“后向”进行，即由输出层，经每个隐藏层，到第一个隐藏层。

![说明: 这里写图片描述](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image003.jpg)