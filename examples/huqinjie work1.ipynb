{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data16317  data269\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!unzip -oq /home/aistudio/data/data269/房价预测.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 17.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# **（一）深度学习发展历史**\n",
    "**1. 深度学习的起源阶段**\n",
    "\n",
    "\t1943年，心里学家麦卡洛克和数学逻辑学家皮兹发表论文《神经活动中内在思想的逻辑演算》，提出了MP模型。MP模型是模仿神经元的结构和工作原理，构成出的一个基于神经网络的数学模型，本质上是一种“模拟人类大脑”的神经元模型。MP模型作为人工神经网络的起源，开创了人工神经网络的新时代，也奠定了神经网络模型的基础。\n",
    "    \n",
    "\t1949年，加拿大著名心理学家唐纳德·赫布在《行为的组织》中提出了一种基于无监督学习的规则——海布学习规则(Hebb Rule)。海布规则模仿人类认知世界的过程建立一种“网络模型”，该网络模型针对训练集进行大量的训练并提取训练集的统计特征，然后按照样本的相似程度进行分类，把相互之间联系密切的样本分为一类，这样就把样本分成了若干类。海布学习规则与“条件反射”机理一致，为以后的神经网络学习算法奠定了基础，具有重大的历史意义。\n",
    "    \n",
    "\t20世纪50年代末，在MP模型和海布学习规则的研究基础上，美国科学家罗森布拉特发现了一种类似于人类学习过程的学习算法——感知机学习。并于1958年，正式提出了由两层神经元组成的神经网络，称之为“感知器”。感知器本质上是一种线性模型，可以对输入的训练集数据进行二分类，且能够在训练集中自动更新权值。感知器的提出吸引了大量科学家对人工神经网络研究的兴趣，对神经网络的发展具有里程碑式的意义。\n",
    "    \n",
    "\t但随着研究的深入，在1969年，“AI之父”马文·明斯基和LOGO语言的创始人西蒙·派珀特共同编写了一本书籍《感知器》，在书中他们证明了单层感知器无法解决线性不可分问题（例如：异或问题）。由于这个致命的缺陷以及没有及时推广感知器到多层神经网络中，在20世纪70年代，人工神经网络进入了第一个寒冬期，人们对神经网络的研究也停滞了将近20年。\n",
    "\n",
    "**2. 深度学习的发展阶段**\n",
    "\n",
    "\t1982年，著名物理学家约翰·霍普菲尔德发明了Hopfield神经网络。Hopfield神经网络是一种结合存储系统和二元系统的循环神经网络。Hopfield网络也可以模拟人类的记忆，根据激活函数的选取不同，有连续型和离散型两种类型，分别用于优化计算和联想记忆。但由于容易陷入局部最小值的缺陷，该算法并未在当时引起很大的轰动。\n",
    "    \n",
    "\t直到1986年，深度学习之父杰弗里·辛顿提出了一种适用于多层感知器的反向传播算法——BP算法。BP算法在传统神经网络正向传播的基础上，增加了误差的反向传播过程。反向传播过程不断地调整神经元之间的权值和阈值，直到输出的误差达到减小到允许的范围之内，或达到预先设定的训练次数为止。BP算法完美的解决了非线性分类问题，让人工神经网络再次的引起了人们广泛的关注。\n",
    "    \n",
    "\t但是由于八十年代计算机的硬件水平有限，如：运算能力跟不上，这就导致当神经网络的规模增大时，再使用BP算法会出现“梯度消失”的问题。这使得BP算法的发展受到了很大的限制。再加上90年代中期，以SVM为代表的其它浅层机器学习算法被提出，并在分类、回归问题上均取得了很好的效果，其原理又明显不同于神经网络模型，所以人工神经网络的发展再次进入了瓶颈期。\n",
    "\n",
    "**3.深度学习的爆发阶段**\n",
    "\n",
    "\t2006年，杰弗里·辛顿以及他的学生鲁斯兰·萨拉赫丁诺夫正式提出了深度学习的概念。他们在世界顶级学术期刊《科学》发表的一篇文章中详细的给出了“梯度消失”问题的解决方案——通过无监督的学习方法逐层训练算法，再使用有监督的反向传播算法进行调优。该深度学习方法的提出，立即在学术圈引起了巨大的反响，以斯坦福大学、多伦多大学为代表的众多世界知名高校纷纷投入巨大的人力、财力进行深度学习领域的相关研究。而后又在迅速蔓延到工业界中。\n",
    "    \n",
    "\t2006年，杰弗里·辛顿以及他的学生鲁斯兰·萨拉赫丁诺夫正式提出了深度学习的概念。他们在世界顶级学术期刊《科学》发表的一篇文章中详细的给出了“梯度消失”问题的解决方案——通过无监督的学习方法逐层训练算法，再使用有监督的反向传播算法进行调优。该深度学习方法的提出，立即在学术圈引起了巨大的反响，以斯坦福大学、多伦多大学为代表的众多世界知名高校纷纷投入巨大的人力、财力进行深度学习领域的相关研究。而后又在迅速蔓延到工业界中。\n",
    "    \n",
    "\t2012年，在著名的ImageNet图像识别大赛中，杰弗里·辛顿领导的小组采用深度学习模型AlexNet一举夺冠。AlexNet采用ReLU激活函数，从根本上解决了梯度消失问题，并采用GPU极大的提高了模型的运算速度。同年，由斯坦福大学著名的吴恩达教授和世界顶尖计算机专家Jeff Dean共同主导的深度神经网络——DNN技术在图像识别领域取得了惊人的成绩，在ImageNet评测中成功的把错误率从26％降低到了15％。深度学习算法在世界大赛的脱颖而出，也再一次吸引了学术界和工业界对于深度学习领域的关注。\n",
    "    \n",
    "\t随着深度学习技术的不断进步以及数据处理能力的不断提升，2014年，Facebook基于深度学习技术的DeepFace项目，在人脸识别方面的准确率已经能达到97%以上，跟人类识别的准确率几乎没有差别。这样的结果也再一次证明了深度学习算法在图像识别方面的一骑绝尘。\n",
    "    \n",
    "\t2016年，随着谷歌公司基于深度学习开发的AlphaGo以4:1的比分战胜了国际顶尖围棋高手李世石，深度学习的热度一时无两。后来，AlphaGo又接连和众多世界级围棋高手过招，均取得了完胜。这也证明了在围棋界，基于深度学习技术的机器人已经超越了人类。\n",
    "    \n",
    "\t2017年，基于强化学习算法的AlphaGo升级版AlphaGo Zero横空出世。其采用“从零开始”、“无师自通”的学习模式，以100:0的比分轻而易举打败了之前的AlphaGo。除了围棋，它还精通国际象棋等其它棋类游戏，可以说是真正的棋类“天才”。此外在这一年，深度学习的相关算法在医疗、金融、艺术、无人驾驶等多个领域均取得了显著的成果。所以，也有专家把2017年看作是深度学习甚至是人工智能发展最为突飞猛进的一年。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# **（二）人工智能、机器学习、和深度学习有什么区别和联系**\n",
    "\n",
    "**区别**\n",
    "\n",
    "人工智能：为机器赋予人的智能\n",
    "\n",
    "机器学习：一种实现人工智能的方法\n",
    "\n",
    "深度学习：一种实现机器学习的技术\n",
    "\n",
    "**联系**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e76708ca9bed481daf43d503f66c903618d3ae973fff4929a0b437e2cecf2f4f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# **（三）神经元、单层感知机、多层感知机**\n",
    "\n",
    "**人工神经元模型**\n",
    "\n",
    "生物学上神经元通常由细胞体，细胞核，树突和轴突构成。\n",
    "\n",
    "树突用来接收其他神经元传导过来的信号，一个神经元有多个树突；\n",
    "\n",
    "细胞核是神经元中的核心模块，用来处理所有的传入信号；\n",
    "\n",
    "轴突是输出信号的单元，它有很多个轴突末梢，可以给其它神经元的树突传递信号。\n",
    "\n",
    "生物学神经元如下图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/255356fddd484cb59c8505bf7fe3a59b2979dcd5899648feba97df7deb341723)\n",
    "\n",
    "人工神经元的模型如下图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6c527f77c23f473db572ced6eebb010655c8d9217b2a4b6bbabb885f6bdc96d9)\n",
    "\n",
    "图中Xi是从其它神经元传入的输入信号，Win分别是传入信号的权重，θ表示一个阈值，或称为偏置（bias），偏置的设置是为了正确分类样本，是模型中一个重要的参数。神经元综合的输入信号和偏置相加之后产生当前神经元最终的处理信号net，该信号称为净激活或净激励（net activation），激活信号作为上图中圆圈的右半部分f（*）函数的输入，即f(net)； f称为激活函数或激励函数（Activation Function），激活函数的主要作用是加入非线性因素，解决线性模型的表达、分类能力不足的问题。上图中的yi是当前神经元的输出。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b3340a4096754883b16c8d5fe9c6d05a7ac8012c8fb14948b8a876974f220974)\n",
    "\n",
    "**单层感知机**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4641b006895f4370a364aaae49d9c6910fdeaf227e214276b621abb0512b0227)\n",
    "\n",
    "\n",
    "单层感知机目标是将被感知数据集划分为两类的分离超平面，并计算出该超平面。单层感知机是二分类的线性分类模型，输入是被感知数据集的特征向量，输出时数据集的类别{+1,-1}。感知器的模型可以简单表示为：\n",
    "\n",
    "f(x)=sign(w.x+b)\n",
    "\n",
    "该函数称为单层感知机，其中w是网络的N维权重向量，b是网络的N维偏置向量, w.x是w和x的内积，w和b的N维向量取值要求在实数域。\n",
    "\n",
    "sign函数是感知机的早期激活函数，后面又演化出一系列的激活函数。激活函数一般采用非线性激活函数，以增强网络的表达能力。常见的激活函数有：sign, sigmoid,tanh,ReLU等。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/173492fd80134f5a91e0b95cbbb22581b2a1d730ff9d4bfcaceba81bf9466e15)\n",
    "\n",
    "**多层感知机**\n",
    "多层感知机（MLP，Multilayer Perceptron）也叫人工神经网络（ANN，Artificial Neural Network），除了输入输出层，它中间可以有多个隐层，最简单的MLP只含一个隐层，即三层的结构，如下图：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/909abb78a4f1420288378799d6c0f6052f831e4dc00c4b97bc4d53dff470a134)\n",
    "\n",
    "从上图可以看到，多层感知机层与层之间是全连接的。多层感知机最底层是输入层，中间是隐藏层，最后是输出层。\n",
    "\n",
    "隐藏层的神经元怎么得来？首先它与输入层是全连接的，假设输入层用向量X表示，则隐藏层的输出就是 f ( W 1 X + b 1 )， Wi是权重（也叫连接系数），bi是偏置，函数f可以是激活函数，比如常用的sigmoid函数或者tanh函数。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**（四）什么是前向传播**\n",
    "\n",
    "所谓的前向传播算法就是：将上一层的输出作为下一层的输入，并计算下一层的输出，一直到运算到输出层为止。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2c4d201a47cb41eea0e61da9130b442e84b39694e8d248938be885d83763e88f)\n",
    "\n",
    "其中layer1为输入层，layer2为隐藏层，layer3为输出层\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a484a8d572064f5cb10948cc2d4f33875cab7723214a45f0b8e0b7998d24d9d5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**（五）什么是反向传播**\n",
    "\n",
    "反向传播（back propagation, BP）算法是 \"误差反向传播\" 的简称，也称为backprop，允许来自代价函数的信息通过网络向后流动，以便计算梯度。\n",
    "\n",
    "反向传播是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。该方法对网络中所有权重计算损失函数的梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。\n",
    "\n",
    "反向传播这个术语经常被误解为用于多层神经网络的整个学习算法。实际上，反向传播仅指用于计算梯度的方法。而另一种算法，例如随机梯度下降法，才是使用该梯度来进行学习。另外，反向传播还经常被误解为仅适用于多层神经网络，但是原则上它可以计算任何函数的到导数\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8625a1c1153746d99c1f8947e020d2b12663783b9fbc4eb8bb0b4c6014e71ac5)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/69e117a489a8444497eac655dc2f688a7787b091efd44d0bb64b36078df7c5ed)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/754cd8bd65b347468e30addf2afcfe28828a02d04dbe42bf903dcb5dca6e923b)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ce1a956b3b6445ac95e6ed8c785b3940161090d0b06d41abad008513576da413)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/aebd1cccaf5d46659bcfb30be5963427db396b68d1f440f293d2c1d241329752)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "（六）房价预测\n",
    "\n",
    "线性回归中：\n",
    "\n",
    "（1）假设函数是指，用数学的方法描述自变量和因变量之间的关系，它们之间可以是一个线性函数或非线性函数。 在本次线性回顾模型中，我们的假设函数为 Y’= wX+b ，其中，Y’表示模型的预测结果（预测房价），用来和真实的Y区分。模型要学习的参数即：w,b。\n",
    "\n",
    "（2）损失函数是指，用数学的方法衡量假设函数预测结果与真实值之间的误差。这个差距越小预测越准确，而算法的任务就是使这个差距越来越小。 建立模型后，我们需要给模型一个优化目标，使得学到的参数能够让预测值Y’尽可能地接近真实值Y。这个实值通常用来反映模型误差的大小。不同问题场景下采用不同的损失函数。 对于线性模型来讲，最常用的损失函数就是均方误差（Mean Squared Error， MSE）。\n",
    "\n",
    "（3）优化算法：神经网络的训练就是调整权重（参数）使得损失函数值尽可能得小，在训练过程中，将损失函数值逐渐收敛，得到一组使得神经网络拟合真实模型的权重（参数）。所以，优化算法的最终目标是找到损失函数的最小值。而这个寻找过程就是不断地微调变量w和b的值，一步一步地试出这个最小值。 常见的优化算法有随机梯度下降法（SGD）、Adam算法等等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "首先导入必要的包，分别是：\n",
    "\n",
    "paddle.fluid--->PaddlePaddle深度学习框架\n",
    "\n",
    "numpy---------->python基本库，用于科学计算\n",
    "\n",
    "os------------------>python的模块，可使用该模块对操作系统进行操作\n",
    "\n",
    "matplotlib----->python绘图库，可方便绘制折线图、散点图等图形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "\r\n",
    "def load_data():\r\n",
    "    # 从文件导入数据\r\n",
    "    df =  pd.read_csv(\"./房价预测/data/data.txt\",sep=',')\r\n",
    "    data = np.array(df)\r\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\r\n",
    "    feature_names = [ 'mianji', 'money'] \r\n",
    "    feature_num = len(feature_names)\r\n",
    "    # 将原始数据进行Reshape，变成[N, 2]这样的形状\r\n",
    "    data = data.reshape([data.shape[0], feature_num])\r\n",
    "    # 将原数据集拆分成训练集和测试集\r\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\r\n",
    "    # 测试集和训练集必须是没有交集的\r\n",
    "    ratio = 0.8\r\n",
    "    offset = int(data.shape[0] * ratio) \r\n",
    "    training_data = data[:offset]\r\n",
    "    # 计算train数据集的最大值，最小值，平均值\r\n",
    "    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), \\\r\n",
    "                                 training_data.sum(axis=0) / training_data.shape[0]\r\n",
    "    # 对数据进行归一化处理\r\n",
    "    for i in range(feature_num):\r\n",
    "        #print(maximums[i], minimums[i], avgs[i])\r\n",
    "        data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])\r\n",
    "    # 训练集和测试集的划分比例\r\n",
    "    training_data = data[:offset]\r\n",
    "    test_data = data[offset:]\r\n",
    "    return training_data, test_data\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 / iter   0, loss = 0.0457\n",
      "Epoch   0 / iter   1, loss = 0.0349\n",
      "Epoch   0 / iter   2, loss = 0.0227\n",
      "Epoch   0 / iter   3, loss = 0.0205\n",
      "Epoch   0 / iter   4, loss = 0.0479\n",
      "Epoch   0 / iter   5, loss = 0.0283\n",
      "Epoch   0 / iter   6, loss = 0.0271\n",
      "Epoch   1 / iter   0, loss = 0.0258\n",
      "Epoch   1 / iter   1, loss = 0.0310\n",
      "Epoch   1 / iter   2, loss = 0.0381\n",
      "Epoch   1 / iter   3, loss = 0.0366\n",
      "Epoch   1 / iter   4, loss = 0.0269\n",
      "Epoch   1 / iter   5, loss = 0.0319\n",
      "Epoch   1 / iter   6, loss = 0.0269\n",
      "Epoch   2 / iter   0, loss = 0.0330\n",
      "Epoch   2 / iter   1, loss = 0.0396\n",
      "Epoch   2 / iter   2, loss = 0.0272\n",
      "Epoch   2 / iter   3, loss = 0.0297\n",
      "Epoch   2 / iter   4, loss = 0.0292\n",
      "Epoch   2 / iter   5, loss = 0.0209\n",
      "Epoch   2 / iter   6, loss = 0.0284\n",
      "Epoch   3 / iter   0, loss = 0.0279\n",
      "Epoch   3 / iter   1, loss = 0.0408\n",
      "Epoch   3 / iter   2, loss = 0.0338\n",
      "Epoch   3 / iter   3, loss = 0.0211\n",
      "Epoch   3 / iter   4, loss = 0.0238\n",
      "Epoch   3 / iter   5, loss = 0.0210\n",
      "Epoch   3 / iter   6, loss = 0.0308\n",
      "Epoch   4 / iter   0, loss = 0.0215\n",
      "Epoch   4 / iter   1, loss = 0.0296\n",
      "Epoch   4 / iter   2, loss = 0.0248\n",
      "Epoch   4 / iter   3, loss = 0.0350\n",
      "Epoch   4 / iter   4, loss = 0.0271\n",
      "Epoch   4 / iter   5, loss = 0.0227\n",
      "Epoch   4 / iter   6, loss = 0.0300\n",
      "Epoch   5 / iter   0, loss = 0.0190\n",
      "Epoch   5 / iter   1, loss = 0.0210\n",
      "Epoch   5 / iter   2, loss = 0.0239\n",
      "Epoch   5 / iter   3, loss = 0.0308\n",
      "Epoch   5 / iter   4, loss = 0.0259\n",
      "Epoch   5 / iter   5, loss = 0.0356\n",
      "Epoch   5 / iter   6, loss = 0.0267\n",
      "Epoch   6 / iter   0, loss = 0.0234\n",
      "Epoch   6 / iter   1, loss = 0.0218\n",
      "Epoch   6 / iter   2, loss = 0.0292\n",
      "Epoch   6 / iter   3, loss = 0.0282\n",
      "Epoch   6 / iter   4, loss = 0.0182\n",
      "Epoch   6 / iter   5, loss = 0.0220\n",
      "Epoch   6 / iter   6, loss = 0.0330\n",
      "Epoch   7 / iter   0, loss = 0.0216\n",
      "Epoch   7 / iter   1, loss = 0.0290\n",
      "Epoch   7 / iter   2, loss = 0.0230\n",
      "Epoch   7 / iter   3, loss = 0.0152\n",
      "Epoch   7 / iter   4, loss = 0.0256\n",
      "Epoch   7 / iter   5, loss = 0.0266\n",
      "Epoch   7 / iter   6, loss = 0.0275\n",
      "Epoch   8 / iter   0, loss = 0.0196\n",
      "Epoch   8 / iter   1, loss = 0.0248\n",
      "Epoch   8 / iter   2, loss = 0.0182\n",
      "Epoch   8 / iter   3, loss = 0.0380\n",
      "Epoch   8 / iter   4, loss = 0.0230\n",
      "Epoch   8 / iter   5, loss = 0.0190\n",
      "Epoch   8 / iter   6, loss = 0.0191\n",
      "Epoch   9 / iter   0, loss = 0.0143\n",
      "Epoch   9 / iter   1, loss = 0.0277\n",
      "Epoch   9 / iter   2, loss = 0.0195\n",
      "Epoch   9 / iter   3, loss = 0.0310\n",
      "Epoch   9 / iter   4, loss = 0.0241\n",
      "Epoch   9 / iter   5, loss = 0.0170\n",
      "Epoch   9 / iter   6, loss = 0.0220\n",
      "Epoch  10 / iter   0, loss = 0.0157\n",
      "Epoch  10 / iter   1, loss = 0.0232\n",
      "Epoch  10 / iter   2, loss = 0.0152\n",
      "Epoch  10 / iter   3, loss = 0.0276\n",
      "Epoch  10 / iter   4, loss = 0.0204\n",
      "Epoch  10 / iter   5, loss = 0.0255\n",
      "Epoch  10 / iter   6, loss = 0.0221\n",
      "Epoch  11 / iter   0, loss = 0.0247\n",
      "Epoch  11 / iter   1, loss = 0.0229\n",
      "Epoch  11 / iter   2, loss = 0.0133\n",
      "Epoch  11 / iter   3, loss = 0.0201\n",
      "Epoch  11 / iter   4, loss = 0.0209\n",
      "Epoch  11 / iter   5, loss = 0.0212\n",
      "Epoch  11 / iter   6, loss = 0.0212\n",
      "Epoch  12 / iter   0, loss = 0.0146\n",
      "Epoch  12 / iter   1, loss = 0.0139\n",
      "Epoch  12 / iter   2, loss = 0.0128\n",
      "Epoch  12 / iter   3, loss = 0.0214\n",
      "Epoch  12 / iter   4, loss = 0.0219\n",
      "Epoch  12 / iter   5, loss = 0.0262\n",
      "Epoch  12 / iter   6, loss = 0.0285\n",
      "Epoch  13 / iter   0, loss = 0.0310\n",
      "Epoch  13 / iter   1, loss = 0.0143\n",
      "Epoch  13 / iter   2, loss = 0.0192\n",
      "Epoch  13 / iter   3, loss = 0.0200\n",
      "Epoch  13 / iter   4, loss = 0.0188\n",
      "Epoch  13 / iter   5, loss = 0.0158\n",
      "Epoch  13 / iter   6, loss = 0.0147\n",
      "Epoch  14 / iter   0, loss = 0.0198\n",
      "Epoch  14 / iter   1, loss = 0.0191\n",
      "Epoch  14 / iter   2, loss = 0.0173\n",
      "Epoch  14 / iter   3, loss = 0.0193\n",
      "Epoch  14 / iter   4, loss = 0.0194\n",
      "Epoch  14 / iter   5, loss = 0.0148\n",
      "Epoch  14 / iter   6, loss = 0.0197\n",
      "Epoch  15 / iter   0, loss = 0.0196\n",
      "Epoch  15 / iter   1, loss = 0.0172\n",
      "Epoch  15 / iter   2, loss = 0.0227\n",
      "Epoch  15 / iter   3, loss = 0.0231\n",
      "Epoch  15 / iter   4, loss = 0.0138\n",
      "Epoch  15 / iter   5, loss = 0.0174\n",
      "Epoch  15 / iter   6, loss = 0.0109\n",
      "Epoch  16 / iter   0, loss = 0.0215\n",
      "Epoch  16 / iter   1, loss = 0.0096\n",
      "Epoch  16 / iter   2, loss = 0.0194\n",
      "Epoch  16 / iter   3, loss = 0.0177\n",
      "Epoch  16 / iter   4, loss = 0.0188\n",
      "Epoch  16 / iter   5, loss = 0.0188\n",
      "Epoch  16 / iter   6, loss = 0.0153\n",
      "Epoch  17 / iter   0, loss = 0.0141\n",
      "Epoch  17 / iter   1, loss = 0.0142\n",
      "Epoch  17 / iter   2, loss = 0.0141\n",
      "Epoch  17 / iter   3, loss = 0.0187\n",
      "Epoch  17 / iter   4, loss = 0.0160\n",
      "Epoch  17 / iter   5, loss = 0.0148\n",
      "Epoch  17 / iter   6, loss = 0.0255\n",
      "Epoch  18 / iter   0, loss = 0.0156\n",
      "Epoch  18 / iter   1, loss = 0.0152\n",
      "Epoch  18 / iter   2, loss = 0.0191\n",
      "Epoch  18 / iter   3, loss = 0.0214\n",
      "Epoch  18 / iter   4, loss = 0.0148\n",
      "Epoch  18 / iter   5, loss = 0.0167\n",
      "Epoch  18 / iter   6, loss = 0.0102\n",
      "Epoch  19 / iter   0, loss = 0.0197\n",
      "Epoch  19 / iter   1, loss = 0.0129\n",
      "Epoch  19 / iter   2, loss = 0.0154\n",
      "Epoch  19 / iter   3, loss = 0.0132\n",
      "Epoch  19 / iter   4, loss = 0.0140\n",
      "Epoch  19 / iter   5, loss = 0.0183\n",
      "Epoch  19 / iter   6, loss = 0.0165\n",
      "Epoch  20 / iter   0, loss = 0.0111\n",
      "Epoch  20 / iter   1, loss = 0.0181\n",
      "Epoch  20 / iter   2, loss = 0.0132\n",
      "Epoch  20 / iter   3, loss = 0.0167\n",
      "Epoch  20 / iter   4, loss = 0.0126\n",
      "Epoch  20 / iter   5, loss = 0.0210\n",
      "Epoch  20 / iter   6, loss = 0.0139\n",
      "Epoch  21 / iter   0, loss = 0.0126\n",
      "Epoch  21 / iter   1, loss = 0.0190\n",
      "Epoch  21 / iter   2, loss = 0.0111\n",
      "Epoch  21 / iter   3, loss = 0.0183\n",
      "Epoch  21 / iter   4, loss = 0.0113\n",
      "Epoch  21 / iter   5, loss = 0.0118\n",
      "Epoch  21 / iter   6, loss = 0.0196\n",
      "Epoch  22 / iter   0, loss = 0.0157\n",
      "Epoch  22 / iter   1, loss = 0.0151\n",
      "Epoch  22 / iter   2, loss = 0.0092\n",
      "Epoch  22 / iter   3, loss = 0.0203\n",
      "Epoch  22 / iter   4, loss = 0.0136\n",
      "Epoch  22 / iter   5, loss = 0.0123\n",
      "Epoch  22 / iter   6, loss = 0.0144\n",
      "Epoch  23 / iter   0, loss = 0.0161\n",
      "Epoch  23 / iter   1, loss = 0.0141\n",
      "Epoch  23 / iter   2, loss = 0.0149\n",
      "Epoch  23 / iter   3, loss = 0.0107\n",
      "Epoch  23 / iter   4, loss = 0.0111\n",
      "Epoch  23 / iter   5, loss = 0.0186\n",
      "Epoch  23 / iter   6, loss = 0.0123\n",
      "Epoch  24 / iter   0, loss = 0.0164\n",
      "Epoch  24 / iter   1, loss = 0.0148\n",
      "Epoch  24 / iter   2, loss = 0.0126\n",
      "Epoch  24 / iter   3, loss = 0.0111\n",
      "Epoch  24 / iter   4, loss = 0.0136\n",
      "Epoch  24 / iter   5, loss = 0.0165\n",
      "Epoch  24 / iter   6, loss = 0.0100\n",
      "Epoch  25 / iter   0, loss = 0.0178\n",
      "Epoch  25 / iter   1, loss = 0.0101\n",
      "Epoch  25 / iter   2, loss = 0.0115\n",
      "Epoch  25 / iter   3, loss = 0.0123\n",
      "Epoch  25 / iter   4, loss = 0.0119\n",
      "Epoch  25 / iter   5, loss = 0.0160\n",
      "Epoch  25 / iter   6, loss = 0.0134\n",
      "Epoch  26 / iter   0, loss = 0.0174\n",
      "Epoch  26 / iter   1, loss = 0.0112\n",
      "Epoch  26 / iter   2, loss = 0.0094\n",
      "Epoch  26 / iter   3, loss = 0.0086\n",
      "Epoch  26 / iter   4, loss = 0.0119\n",
      "Epoch  26 / iter   5, loss = 0.0186\n",
      "Epoch  26 / iter   6, loss = 0.0137\n",
      "Epoch  27 / iter   0, loss = 0.0088\n",
      "Epoch  27 / iter   1, loss = 0.0079\n",
      "Epoch  27 / iter   2, loss = 0.0176\n",
      "Epoch  27 / iter   3, loss = 0.0099\n",
      "Epoch  27 / iter   4, loss = 0.0113\n",
      "Epoch  27 / iter   5, loss = 0.0115\n",
      "Epoch  27 / iter   6, loss = 0.0220\n",
      "Epoch  28 / iter   0, loss = 0.0102\n",
      "Epoch  28 / iter   1, loss = 0.0157\n",
      "Epoch  28 / iter   2, loss = 0.0114\n",
      "Epoch  28 / iter   3, loss = 0.0102\n",
      "Epoch  28 / iter   4, loss = 0.0123\n",
      "Epoch  28 / iter   5, loss = 0.0127\n",
      "Epoch  28 / iter   6, loss = 0.0141\n",
      "Epoch  29 / iter   0, loss = 0.0112\n",
      "Epoch  29 / iter   1, loss = 0.0159\n",
      "Epoch  29 / iter   2, loss = 0.0097\n",
      "Epoch  29 / iter   3, loss = 0.0188\n",
      "Epoch  29 / iter   4, loss = 0.0106\n",
      "Epoch  29 / iter   5, loss = 0.0114\n",
      "Epoch  29 / iter   6, loss = 0.0068\n",
      "Epoch  30 / iter   0, loss = 0.0129\n",
      "Epoch  30 / iter   1, loss = 0.0085\n",
      "Epoch  30 / iter   2, loss = 0.0144\n",
      "Epoch  30 / iter   3, loss = 0.0155\n",
      "Epoch  30 / iter   4, loss = 0.0065\n",
      "Epoch  30 / iter   5, loss = 0.0104\n",
      "Epoch  30 / iter   6, loss = 0.0147\n",
      "Epoch  31 / iter   0, loss = 0.0169\n",
      "Epoch  31 / iter   1, loss = 0.0140\n",
      "Epoch  31 / iter   2, loss = 0.0094\n",
      "Epoch  31 / iter   3, loss = 0.0091\n",
      "Epoch  31 / iter   4, loss = 0.0118\n",
      "Epoch  31 / iter   5, loss = 0.0078\n",
      "Epoch  31 / iter   6, loss = 0.0122\n",
      "Epoch  32 / iter   0, loss = 0.0129\n",
      "Epoch  32 / iter   1, loss = 0.0135\n",
      "Epoch  32 / iter   2, loss = 0.0128\n",
      "Epoch  32 / iter   3, loss = 0.0083\n",
      "Epoch  32 / iter   4, loss = 0.0114\n",
      "Epoch  32 / iter   5, loss = 0.0096\n",
      "Epoch  32 / iter   6, loss = 0.0110\n",
      "Epoch  33 / iter   0, loss = 0.0131\n",
      "Epoch  33 / iter   1, loss = 0.0091\n",
      "Epoch  33 / iter   2, loss = 0.0127\n",
      "Epoch  33 / iter   3, loss = 0.0089\n",
      "Epoch  33 / iter   4, loss = 0.0108\n",
      "Epoch  33 / iter   5, loss = 0.0104\n",
      "Epoch  33 / iter   6, loss = 0.0130\n",
      "Epoch  34 / iter   0, loss = 0.0151\n",
      "Epoch  34 / iter   1, loss = 0.0070\n",
      "Epoch  34 / iter   2, loss = 0.0078\n",
      "Epoch  34 / iter   3, loss = 0.0064\n",
      "Epoch  34 / iter   4, loss = 0.0119\n",
      "Epoch  34 / iter   5, loss = 0.0124\n",
      "Epoch  34 / iter   6, loss = 0.0163\n",
      "Epoch  35 / iter   0, loss = 0.0088\n",
      "Epoch  35 / iter   1, loss = 0.0144\n",
      "Epoch  35 / iter   2, loss = 0.0102\n",
      "Epoch  35 / iter   3, loss = 0.0117\n",
      "Epoch  35 / iter   4, loss = 0.0106\n",
      "Epoch  35 / iter   5, loss = 0.0110\n",
      "Epoch  35 / iter   6, loss = 0.0084\n",
      "Epoch  36 / iter   0, loss = 0.0145\n",
      "Epoch  36 / iter   1, loss = 0.0070\n",
      "Epoch  36 / iter   2, loss = 0.0160\n",
      "Epoch  36 / iter   3, loss = 0.0096\n",
      "Epoch  36 / iter   4, loss = 0.0086\n",
      "Epoch  36 / iter   5, loss = 0.0101\n",
      "Epoch  36 / iter   6, loss = 0.0080\n",
      "Epoch  37 / iter   0, loss = 0.0086\n",
      "Epoch  37 / iter   1, loss = 0.0131\n",
      "Epoch  37 / iter   2, loss = 0.0100\n",
      "Epoch  37 / iter   3, loss = 0.0118\n",
      "Epoch  37 / iter   4, loss = 0.0093\n",
      "Epoch  37 / iter   5, loss = 0.0115\n",
      "Epoch  37 / iter   6, loss = 0.0085\n",
      "Epoch  38 / iter   0, loss = 0.0127\n",
      "Epoch  38 / iter   1, loss = 0.0088\n",
      "Epoch  38 / iter   2, loss = 0.0104\n",
      "Epoch  38 / iter   3, loss = 0.0144\n",
      "Epoch  38 / iter   4, loss = 0.0096\n",
      "Epoch  38 / iter   5, loss = 0.0074\n",
      "Epoch  38 / iter   6, loss = 0.0082\n",
      "Epoch  39 / iter   0, loss = 0.0068\n",
      "Epoch  39 / iter   1, loss = 0.0102\n",
      "Epoch  39 / iter   2, loss = 0.0116\n",
      "Epoch  39 / iter   3, loss = 0.0139\n",
      "Epoch  39 / iter   4, loss = 0.0081\n",
      "Epoch  39 / iter   5, loss = 0.0087\n",
      "Epoch  39 / iter   6, loss = 0.0113\n",
      "Epoch  40 / iter   0, loss = 0.0070\n",
      "Epoch  40 / iter   1, loss = 0.0095\n",
      "Epoch  40 / iter   2, loss = 0.0086\n",
      "Epoch  40 / iter   3, loss = 0.0093\n",
      "Epoch  40 / iter   4, loss = 0.0128\n",
      "Epoch  40 / iter   5, loss = 0.0112\n",
      "Epoch  40 / iter   6, loss = 0.0113\n",
      "Epoch  41 / iter   0, loss = 0.0078\n",
      "Epoch  41 / iter   1, loss = 0.0096\n",
      "Epoch  41 / iter   2, loss = 0.0091\n",
      "Epoch  41 / iter   3, loss = 0.0093\n",
      "Epoch  41 / iter   4, loss = 0.0125\n",
      "Epoch  41 / iter   5, loss = 0.0084\n",
      "Epoch  41 / iter   6, loss = 0.0120\n",
      "Epoch  42 / iter   0, loss = 0.0117\n",
      "Epoch  42 / iter   1, loss = 0.0087\n",
      "Epoch  42 / iter   2, loss = 0.0130\n",
      "Epoch  42 / iter   3, loss = 0.0099\n",
      "Epoch  42 / iter   4, loss = 0.0057\n",
      "Epoch  42 / iter   5, loss = 0.0065\n",
      "Epoch  42 / iter   6, loss = 0.0123\n",
      "Epoch  43 / iter   0, loss = 0.0147\n",
      "Epoch  43 / iter   1, loss = 0.0084\n",
      "Epoch  43 / iter   2, loss = 0.0072\n",
      "Epoch  43 / iter   3, loss = 0.0093\n",
      "Epoch  43 / iter   4, loss = 0.0085\n",
      "Epoch  43 / iter   5, loss = 0.0121\n",
      "Epoch  43 / iter   6, loss = 0.0067\n",
      "Epoch  44 / iter   0, loss = 0.0091\n",
      "Epoch  44 / iter   1, loss = 0.0061\n",
      "Epoch  44 / iter   2, loss = 0.0101\n",
      "Epoch  44 / iter   3, loss = 0.0124\n",
      "Epoch  44 / iter   4, loss = 0.0067\n",
      "Epoch  44 / iter   5, loss = 0.0144\n",
      "Epoch  44 / iter   6, loss = 0.0072\n",
      "Epoch  45 / iter   0, loss = 0.0144\n",
      "Epoch  45 / iter   1, loss = 0.0120\n",
      "Epoch  45 / iter   2, loss = 0.0092\n",
      "Epoch  45 / iter   3, loss = 0.0066\n",
      "Epoch  45 / iter   4, loss = 0.0065\n",
      "Epoch  45 / iter   5, loss = 0.0097\n",
      "Epoch  45 / iter   6, loss = 0.0069\n",
      "Epoch  46 / iter   0, loss = 0.0099\n",
      "Epoch  46 / iter   1, loss = 0.0084\n",
      "Epoch  46 / iter   2, loss = 0.0094\n",
      "Epoch  46 / iter   3, loss = 0.0118\n",
      "Epoch  46 / iter   4, loss = 0.0086\n",
      "Epoch  46 / iter   5, loss = 0.0080\n",
      "Epoch  46 / iter   6, loss = 0.0084\n",
      "Epoch  47 / iter   0, loss = 0.0112\n",
      "Epoch  47 / iter   1, loss = 0.0089\n",
      "Epoch  47 / iter   2, loss = 0.0070\n",
      "Epoch  47 / iter   3, loss = 0.0066\n",
      "Epoch  47 / iter   4, loss = 0.0101\n",
      "Epoch  47 / iter   5, loss = 0.0098\n",
      "Epoch  47 / iter   6, loss = 0.0104\n",
      "Epoch  48 / iter   0, loss = 0.0104\n",
      "Epoch  48 / iter   1, loss = 0.0070\n",
      "Epoch  48 / iter   2, loss = 0.0078\n",
      "Epoch  48 / iter   3, loss = 0.0053\n",
      "Epoch  48 / iter   4, loss = 0.0103\n",
      "Epoch  48 / iter   5, loss = 0.0078\n",
      "Epoch  48 / iter   6, loss = 0.0151\n",
      "Epoch  49 / iter   0, loss = 0.0069\n",
      "Epoch  49 / iter   1, loss = 0.0085\n",
      "Epoch  49 / iter   2, loss = 0.0062\n",
      "Epoch  49 / iter   3, loss = 0.0073\n",
      "Epoch  49 / iter   4, loss = 0.0119\n",
      "Epoch  49 / iter   5, loss = 0.0104\n",
      "Epoch  49 / iter   6, loss = 0.0116\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "class Network(object):\r\n",
    "    def __init__(self, num_of_weights):\r\n",
    "        # 随机产生w的初始值\r\n",
    "        # 为了保持程序每次运行结果的一致性，此处设置固定的随机数种子\r\n",
    "        #np.random.seed(0)\r\n",
    "        self.w = np.random.randn(num_of_weights, 1)\r\n",
    "        self.b = 0.\r\n",
    "\r\n",
    "    # 前向传播过程\r\n",
    "    def forward(self, x):\r\n",
    "        z = np.dot(x, self.w) + self.b\r\n",
    "        return z\r\n",
    "    \r\n",
    "    # 均方差损失函数\r\n",
    "    def loss(self, z, y):\r\n",
    "        error = z - y\r\n",
    "        num_samples = error.shape[0]\r\n",
    "        cost = error * error\r\n",
    "        cost = np.sum(cost) / num_samples\r\n",
    "        return cost\r\n",
    "    \r\n",
    "    # 梯度下降法\r\n",
    "    def gradient(self, x, y):\r\n",
    "        z = self.forward(x)\r\n",
    "        N = x.shape[0]\r\n",
    "        gradient_w = 1. / N * np.sum((z-y) * x, axis=0)\r\n",
    "        gradient_w = gradient_w[:, np.newaxis]\r\n",
    "        gradient_b = 1. / N * np.sum(z-y)\r\n",
    "        return gradient_w, gradient_b\r\n",
    "    \r\n",
    "    # 参数更新公式\r\n",
    "    def update(self, gradient_w, gradient_b, eta = 0.01):\r\n",
    "        self.w = self.w - eta * gradient_w\r\n",
    "        self.b = self.b - eta * gradient_b\r\n",
    "            \r\n",
    "    # 训练过程            \r\n",
    "    def train(self, training_data, num_epoches, batch_size=10, eta=0.01):\r\n",
    "        n = len(training_data)\r\n",
    "        losses = []\r\n",
    "        for epoch_id in range(num_epoches):\r\n",
    "            # 在每轮迭代开始之前，将训练数据的顺序随机的打乱，\r\n",
    "            # 然后再按每次取batch_size条数据的方式取出\r\n",
    "            np.random.shuffle(training_data)\r\n",
    "            # 将训练数据进行拆分，每个mini_batch包含batch_size条的数据\r\n",
    "            mini_batches = [training_data[k:k+batch_size] for k in range(0, n, batch_size)]\r\n",
    "            for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "                #print(self.w.shape)\r\n",
    "                #print(self.b)\r\n",
    "                x = mini_batch[:, :-1]\r\n",
    "                y = mini_batch[:, -1:]\r\n",
    "                a = self.forward(x)\r\n",
    "                loss = self.loss(a, y)\r\n",
    "                gradient_w, gradient_b = self.gradient(x, y)\r\n",
    "                self.update(gradient_w, gradient_b, eta)\r\n",
    "                losses.append(loss)\r\n",
    "                print('Epoch {:3d} / iter {:3d}, loss = {:.4f}'.\r\n",
    "                                 format(epoch_id, iter_id, loss))\r\n",
    "        \r\n",
    "        return losses\r\n",
    "\r\n",
    "# 获取数据\r\n",
    "train_data, test_data = load_data()\r\n",
    "\r\n",
    "# 创建网络\r\n",
    "net = Network(1)\r\n",
    "# 启动训练\r\n",
    "losses = net.train(train_data, num_epoches=50, batch_size=100, eta=0.1)\r\n",
    "\r\n",
    "# 画出损失函数的变化趋势\r\n",
    "plot_x = np.arange(len(losses))\r\n",
    "plot_y = np.array(losses)\r\n",
    "plt.plot(plot_x, plot_y)\r\n",
    "plt.show()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "首先导入必要的包，分别是：\n",
    "\n",
    "paddle.fluid--->PaddlePaddle深度学习框架\n",
    "\n",
    "numpy---------->python基本库，用于科学计算\n",
    "\n",
    "os------------------>python的模块，可使用该模块对操作系统进行操作\n",
    "\n",
    "matplotlib----->python绘图库，可方便绘制折线图、散点图等图形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加载飞桨、Numpy和相关类库\r\n",
    "import paddle\r\n",
    "from paddle.nn import Linear\r\n",
    "import paddle.nn.functional as F\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1）uci-housing数据集介绍\n",
    "\n",
    "数据集共506行,每行14列。前13列用来描述房屋的各种信息，最后一列为该类房屋价格中位数。\n",
    "\n",
    "PaddlePaddle提供了读取uci_housing训练集和测试集的接口，分别为paddle.dataset.uci_housing.train()和paddle.dataset.uci_housing.test()。\n",
    "\n",
    "(2)train_reader和test_reader\n",
    "\n",
    "paddle.reader.shuffle()表示每次缓存BUF_SIZE个数据项，并进行打乱\n",
    "\n",
    "paddle.batch()表示每BATCH_SIZE组成一个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \u001b[93m\n",
      "Warning:\n",
      "API \"paddle.dataset.uci_housing.train\" is deprecated since 2.0.0, and will be removed in future versions. Please use \"paddle.text.datasets.UCIHousing\" instead.\n",
      "reason: Please use new dataset API which supports paddle.io.DataLoader \u001b[0m\n",
      "  \n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: \u001b[93m\n",
      "Warning:\n",
      "API \"paddle.dataset.uci_housing.test\" is deprecated since 2.0.0, and will be removed in future versions. Please use \"paddle.text.datasets.UCIHousing\" instead.\n",
      "reason: Please use new dataset API which supports paddle.io.DataLoader \u001b[0m\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "BUF_SIZE=500\r\n",
    "BATCH_SIZE=20\r\n",
    "\r\n",
    "#用于训练的数据提供器，每次从缓存中随机读取批次大小的数据\r\n",
    "train_reader = paddle.batch(\r\n",
    "    paddle.reader.shuffle(paddle.dataset.uci_housing.train(), \r\n",
    "                          buf_size=BUF_SIZE),                    \r\n",
    "    batch_size=BATCH_SIZE)   \r\n",
    "#用于测试的数据提供器，每次从缓存中随机读取批次大小的数据\r\n",
    "test_reader = paddle.batch(\r\n",
    "    paddle.reader.shuffle(paddle.dataset.uci_housing.test(),\r\n",
    "                          buf_size=BUF_SIZE),\r\n",
    "    batch_size=BATCH_SIZE)  \r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "模型设计\n",
    "模型定义的实质是定义线性回归的网络结构，飞桨建议通过创建Python类的方式完成模型网络的定义，该类需要继承paddle.nn.Layer父类，并且在类中定义init函数和forward函数。forward函数是框架指定实现前向计算逻辑的函数，程序在调用模型实例时会自动执行forward方法。在forward函数中使用的网络层需要在init函数中声明。\n",
    "\n",
    "实现过程分如下两步：\n",
    "\n",
    "定义init函数：在类的初始化函数中声明每一层网络的实现函数。在房价预测模型中，只需要定义一层全连接层，模型结构和使用Python和Numpy构建神经网络模型》章节模型保持一致。\n",
    "\n",
    "定义forward函数：构建神经网络结构，实现前向计算过程，并返回预测结果，在本任务中返回的是房价预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.0405441 ,  0.06636364, -0.32356227, -0.06916996, -0.03435197,\n",
      "        0.05563625, -0.03475696,  0.02682186, -0.37171335, -0.21419304,\n",
      "       -0.33569506,  0.10143217, -0.21172912]), array([24.]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \u001b[93m\n",
      "Warning:\n",
      "API \"paddle.dataset.uci_housing.train\" is deprecated since 2.0.0, and will be removed in future versions. Please use \"paddle.text.datasets.UCIHousing\" instead.\n",
      "reason: Please use new dataset API which supports paddle.io.DataLoader \u001b[0m\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#用于打印，查看uci_housing数据\r\n",
    "train_data=paddle.dataset.uci_housing.train();\r\n",
    "sampledata=next(train_data())\r\n",
    "print(sampledata)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "声明定义好的回归模型Regressor实例，并将模型的状态设置为训练。\n",
    "使用load_data函数加载训练数据和测试数据。\n",
    "设置优化算法和学习率，优化算法采用随机梯度下降SGD，学习率设置为0.01。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fluid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-eb477accf04e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#定义张量变量x，表示13维的特征值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#定义张量y,表示目标值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#定义一个简单的线性网络,连接输入和输出的全连接层\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fluid' is not defined"
     ]
    }
   ],
   "source": [
    "#定义张量变量x，表示13维的特征值\r\n",
    "x = fluid.layers.data(name='x', shape=[13], dtype='float32')\r\n",
    "#定义张量y,表示目标值\r\n",
    "y = fluid.layers.data(name='y', shape=[1], dtype='float32')\r\n",
    "#定义一个简单的线性网络,连接输入和输出的全连接层\r\n",
    "#input:输入tensor;\r\n",
    "#size:该层输出单元的数目\r\n",
    "#act:激活函数\r\n",
    "y_predict=fluid.layers.fc(input=x,size=1,act=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(2)定义损失函数\n",
    "\n",
    "此处使用均方差损失函数。\n",
    "\n",
    "square_error_cost(input,lable):接受输入预测值和目标值，并返回方差估计,即为（y-y_predict）的平方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fluid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-80ffed7a17c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare_error_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#求一个batch的损失值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mavg_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m                              \u001b[0;31m#对损失值求平均值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fluid' is not defined"
     ]
    }
   ],
   "source": [
    "cost = fluid.layers.square_error_cost(input=y_predict, label=y) #求一个batch的损失值\r\n",
    "avg_cost = fluid.layers.mean(cost)                              #对损失值求平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(3)定义优化函数\n",
    "\n",
    "此处使用的是随机梯度下降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fluid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-43b0c1a55dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGDOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fluid' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.001)\r\n",
    "opts = optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fluid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0a06cd4b6937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_program\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_main_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fluid' is not defined"
     ]
    }
   ],
   "source": [
    "test_program = fluid.default_main_program().clone(for_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "在上述模型配置完毕后，得到两个fluid.Program：fluid.default_startup_program() 与fluid.default_main_program() 配置完毕了。\n",
    "\n",
    "参数初始化操作会被写入fluid.default_startup_program()\n",
    "\n",
    "fluid.default_main_program()用于获取默认或全局main program(主程序)。该主程序用于训练和测试模型。fluid.layers 中的所有layer函数可以向 default_main_program 中添加算子和变量。default_main_program 是fluid的许多编程接口（API）的Program参数的缺省值。例如,当用户program没有传入的时候， Executor.run() 会默认执行 default_main_program 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The ``path`` (LR_model.pdparams) to load model not exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2c02b4d79248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 参数为保存模型参数的文件地址\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR_model.pdparams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, **configs)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0mload_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(path, **configs)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;31m# file prefix and directory are compatible cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_load_path_and_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;31m# check whether model file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py\u001b[0m in \u001b[0;36m_build_load_path_and_config\u001b[0;34m(path, config)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"example, it should be written as `paddle.load('model.pdparams')` instead of \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;34m\"`paddle.load('model')`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprefix_format_exist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The ``path`` (LR_model.pdparams) to load model not exists."
     ]
    }
   ],
   "source": [
    "# 参数为保存模型参数的文件地址\r\n",
    "model_dict = paddle.load('LR_model.pdparams')\r\n",
    "model.load_dict(model_dict)\r\n",
    "model.eval()\r\n",
    "\r\n",
    "# 参数为数据集的文件地址\r\n",
    "one_data, label = load_one_example()\r\n",
    "# 将数据转为动态图的variable格式 \r\n",
    "one_data = paddle.to_tensor(one_data)\r\n",
    "predict = model(one_data)\r\n",
    "\r\n",
    "# 对结果做反归一化处理\r\n",
    "predict = predict * (max_values[-1] - min_values[-1]) + avg_values[-1]\r\n",
    "# 对label数据做反归一化处理\r\n",
    "label = label * (max_values[-1] - min_values[-1]) + avg_values[-1]\r\n",
    "\r\n",
    "print(\"Inference result is {}, the corresponding label is {}\".format(predict.numpy(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "首先定义运算场所 fluid.CPUPlace()和 fluid.CUDAPlace(0)分别表示运算场所为CPU和GPU\n",
    "\n",
    "Executor:接收传入的program，通过run()方法运行program。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_cuda = False                         #use_cuda为False,表示运算场所为CPU;use_cuda为True,表示运算场所为GPU           \r\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n",
    "exe = fluid.Executor(place)              #创建一个Executor实例exe\r\n",
    "exe.run(fluid.default_startup_program()) #Executor的run()方法执行startup_program(),进行参数初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "DataFeeder负责将数据提供器（train_reader,test_reader）返回的数据转成一种特殊的数据结构，使其可以输入到Executor中。\n",
    "\n",
    "feed_list设置向模型输入的向变量表或者变量表名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入数据维度\r\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[x, y])#feed_list:向模型输入的变量表或变量表名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iter=0;\r\n",
    "iters=[]\r\n",
    "train_costs=[]\r\n",
    "\r\n",
    "def draw_train_process(iters,train_costs):\r\n",
    "    title=\"training cost\"\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    plt.xlabel(\"iter\", fontsize=14)\r\n",
    "    plt.ylabel(\"cost\", fontsize=14)\r\n",
    "    plt.plot(iters, train_costs,color='red',label='training cost') \r\n",
    "    plt.grid()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "训练并保存模型\n",
    "\n",
    "Executor接收传入的program,并根据feed map(输入映射表)和fetch_list(结果获取表) 向program中添加feed operators(数据输入算子)和fetch operators（结果获取算子)。 feed map为该program提供输入数据。fetch_list提供program训练结束后用户预期的变量。\n",
    "\n",
    "注：enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-84b2a524c61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;31m#遍历train_reader迭代器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         train_cost = exe.run(program=fluid.default_main_program(),#运行主程序\n\u001b[0m\u001b[1;32m      9\u001b[0m                              \u001b[0mfeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeeder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0;31m#喂入一个batch的训练数据，根据feed_list和data提供的信息，将输入数据转成一种特殊的数据结构\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                              fetch_list=[avg_cost])    \n",
      "\u001b[0;31mNameError\u001b[0m: name 'exe' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM=50\r\n",
    "model_save_dir = \"/home/aistudio/work/fit_a_line.inference.model\"\r\n",
    "\r\n",
    "for pass_id in range(EPOCH_NUM):                                  #训练EPOCH_NUM轮\r\n",
    "    # 开始训练并输出最后一个batch的损失值\r\n",
    "    train_cost = 0\r\n",
    "    for batch_id, data in enumerate(train_reader()):              #遍历train_reader迭代器\r\n",
    "        train_cost = exe.run(program=fluid.default_main_program(),#运行主程序\r\n",
    "                             feed=feeder.feed(data),              #喂入一个batch的训练数据，根据feed_list和data提供的信息，将输入数据转成一种特殊的数据结构\r\n",
    "                             fetch_list=[avg_cost])    \r\n",
    "        if batch_id % 40 == 0:\r\n",
    "            print(\"Pass:%d, Cost:%0.5f\" % (pass_id, train_cost[0][0]))    #打印最后一个batch的损失值\r\n",
    "        iter=iter+BATCH_SIZE\r\n",
    "        iters.append(iter)\r\n",
    "        train_costs.append(train_cost[0][0])\r\n",
    "       \r\n",
    "   \r\n",
    "    # 开始测试并输出最后一个batch的损失值\r\n",
    "    test_cost = 0\r\n",
    "    for batch_id, data in enumerate(test_reader()):               #遍历test_reader迭代器\r\n",
    "        test_cost= exe.run(program=test_program, #运行测试cheng\r\n",
    "                            feed=feeder.feed(data),               #喂入一个batch的测试数据\r\n",
    "                            fetch_list=[avg_cost])                #fetch均方误差\r\n",
    "    print('Test:%d, Cost:%0.5f' % (pass_id, test_cost[0][0]))     #打印最后一个batch的损失值\r\n",
    "    \r\n",
    "    #保存模型\r\n",
    "    # 如果保存路径不存在就创建\r\n",
    "if not os.path.exists(model_save_dir):\r\n",
    "    os.makedirs(model_save_dir)\r\n",
    "print ('save models to %s' % (model_save_dir))\r\n",
    "#保存训练参数到指定路径中，构建一个专门用预测的program\r\n",
    "fluid.io.save_inference_model(model_save_dir,   #保存推理model的路径\r\n",
    "                                  ['x'],            #推理（inference）需要 feed 的数据\r\n",
    "                                  [y_predict],      #保存推理（inference）结果的 Variables\r\n",
    "                                  exe)              #exe 保存 inference model\r\n",
    "draw_train_process(iters,train_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **算法比较**\n",
    "\n",
    "自己写的算法的效果较差，使用paddle的效果比较好\n",
    "\n",
    "自己写的损失函数变化情况：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/bd45e68f9729494f916db902010f983ba55a1cee9e754c63a7728b05d5841381)\n",
    "\n",
    "y值特别小的原因是因为我对数据作了归一化处理\n",
    "\n",
    "paddle自带的函数写的损失函数变化情况：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/39cb390e870b48faaaf7487eb000dedf0f848d7d7e044fbfb41cdbe76fa19b4d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
