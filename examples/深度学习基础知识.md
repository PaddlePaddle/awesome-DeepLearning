## 1.深度学习发展历史 ##
总的来说，深度学习经历了两次低谷，三次增长。从简单神经元模型、专家系统到如今的较为成熟，可以落地应用。

1958年，Rosenblatt发明感知器算法，该方法后被证明为能够收敛，理论与实践效果引起第一次神经网络的浪潮；但单层感知器只能处理线性分类问题，解决不了异或问题。

1986年，Hinton发明了适用于多层感知器（MLP）的BP算法，并采用Sigmoid进行非线性映射，有效解决了非线性分类和学习的问题。该方法引起了神经网络的第二次热潮，SVM、AdaBoost。决策树、随机森林、图模型相继出现。

2006年，Hinton提出了梯度消失解决方案：无监督预训练对权值进行初始化+有监督训练微调，且ReLU激活函数可以极大增大收敛速度并从根本上解决了梯度消失问题，再加上计算机计算能力与数据存储能力的提升，深度学习进入快速发展期，直到2012年至今的爆发期。
## 2.人工智能、机器学习、深度学习有什么区别和联系 ##
概括来说，人工智能、机器学习和深度学习覆盖的技术范畴是逐层递减的。人工智能是最宽泛的概念。机器学习是当前比较有效的一种实现人工智能的方式。深度学习是机器学习算法中最热门的一个分支，近些年取得了显著的进展，并替代了大多数传统机器学习算法。

三者的关系即：人工智能 > 机器学习 > 深度学习。

人工智能是研发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。由于这个定义只阐述了目标，而没有限定方法，因此实现人工智能存在的诸多方法和分支，导致其变成一个“大杂烩”式的学科。

机器学习，区别于人工智能，机器学习、尤其是监督学习则有更加明确的指代。机器学习是专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构，使之不断改善自身的性能。机器学习的实现可以分成两步：训练和预测，类似于我们熟悉的归纳和演绎。

2010年左右，随着大数据的涌现和计算机算力提升，深度学习模型异军突起，极大改变了机器学习的应用格局。今天，多数机器学习任务都可以使用深度学习模型解决，尤其在语音、计算机视觉和自然语言处理等领域，深度学习模型的效果比传统机器学习算法有显著提升。深度学习与机器学习，两者在理论结构上是一致的，即：模型假设、评价函数和优化算法，其根本差别在于假设的复杂度。
## 3.神经元、单层感知机、多层感知机 ##
神经元：神经网络中每个节点称为神经元，由两部分组成：加权和（将所有输入加权求和）与非线性变换（激活函数），加权和的结果经过一个非线性函数变换，让神经元计算具备非线性的能力。

单层感知机：二分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别（+1和-1）。感知机学习的目的在于求出将训练数据进行线性划分的分离超平面。感知机预测是通过学习得到的感知器模型对新的输入实例进行分类，它是神经网络与支持向量机的基础。算法具有简单，易于实现等特点。用感知器做二分类的基本思想是：假设训练数据是线性可分的，我们将大于0的分为+1类，小于0的分为-1类，感知器的学习目标是求得一个能够将数据集中正实例点和负实例点完全正确分开的超平面。
为找出这样的超平面，需要确定感知机的模型参数w，b，定义一个损失函数并将其最小化。

多层感知机：多层感知机由感知机推广而来，层与层之间是全连接的：最底层是输入层,中间是隐藏层,最后是输出层，其最主要的特点是有多个神经元层，可以处理线性不可分的的训练数据。

## 4.什么是前向传播 ##
前向传播指的是信息在网络中从第一层逐渐地向高层进行传递的过程，如下图所示：
![前向传播](https://images2015.cnblogs.com/blog/853467/201606/853467-20160630140644406-409859737.png)
## 5.什么是后向传播 ##
反向传播算法是目前用来训练人工神经网络的最常用且有效的算法。

其主要思想是：计算神经网络的输出结果与实际结果的误差，将该误差从输出层向隐藏层反向传播，直至传播到输入层，同时在反向传播过程中，根据误差调整各参数值，不断迭代至收敛，如下图：
![](https://images2015.cnblogs.com/blog/853467/201606/853467-20160630152018906-1524325812.png)





