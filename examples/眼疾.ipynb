{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#picture->path train_data\n",
    "def init_process(path, lens):\n",
    "    data = []\n",
    "    name = find_label(path)\n",
    "    for i in range(lens[0], lens[1]+1):\n",
    "        data.append([path % i, name])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label(str):\n",
    "    first, last = 0, 0\n",
    "    for i in range(len(str) - 1, -1, -1):\n",
    "        if str[i] == '%' :\n",
    "            last = i - 1\n",
    "        if (str[i] == 'H' or str[i] == 'N' or str[i] == 'P') and str[i - 1] == '/':\n",
    "            first = i\n",
    "            break\n",
    "\n",
    "    name = str[first:last+1]\n",
    "    if name == 'H' or name == 'N':\n",
    "        return 0 #正常\n",
    "    else:\n",
    "        return 1 #异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Myloader(path):\n",
    "    return Image.open(path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):#重写dataset类\n",
    "    def __init__(self, data, transform, loder):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.loader = loder\n",
    "    def __getitem__(self, item):\n",
    "        img, label = self.data[item]\n",
    "        img = self.loader(img)\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR2='C:/Users/Lhh/pycharmProjects/pythonProject/data2/Training400/validation400/'\n",
    "CSVFILE = 'C:/Users/Lhh/pycharmProjects/pythonProject/data2/Validation-GT/labels.csv'\n",
    "filelists = open(CSVFILE).readlines()\n",
    "testimgs = []\n",
    "for line in filelists[1:]:\n",
    "    line = line.strip().split(',')\n",
    "    name = line[1]\n",
    "    label = int(line[2])\n",
    "    # 存放验证集的路径及结果\n",
    "    filepath = os.path.join(DATADIR2, name)\n",
    "    testimgs.append([filepath,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # 归一化\n",
    "    ])\n",
    "    \n",
    "    path1 = 'C:/Users/Lhh/pycharmProjects/pythonProject/data2/Training400/Training400/H%d.jpg'\n",
    "    data1 = init_process(path1, [1, 26])\n",
    "    path2 = 'C:/Users/Lhh/pycharmProjects/pythonProject/data2/Training400/Training400/N%d.jpg'\n",
    "    data2 = init_process(path2, [1, 161])\n",
    "    path3 = 'C:/Users/Lhh/pycharmProjects/pythonProject/data2/Training400/Training400/P%d.jpg'\n",
    "    data3 = init_process(path3, [1, 213])\n",
    "\n",
    "    train_data = data1 + data2 + data3\n",
    "\n",
    "    train = MyDataset(train_data, transform=transform, loder=Myloader)\n",
    "\n",
    "    test_data = testimgs\n",
    "    test= MyDataset(test_data, transform=transform, loder=Myloader)\n",
    "\n",
    "    train_data = DataLoader(dataset=train, batch_size=4, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    test_data = DataLoader(dataset=test, batch_size=4, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model=models.inception_v3(pretrained=True)\n",
    "model.fc=torch.nn.Sequential(torch.nn.Linear(2048,2,bias=True))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Loss:57.0212,Train Accuracy:76.50%,Valid Accuracy:65.25%\n",
      "Epoch 2/10\n",
      "----------\n",
      "Loss:54.4661,Train Accuracy:78.25%,Valid Accuracy:80.00%\n",
      "Epoch 3/10\n",
      "----------\n",
      "Loss:47.4059,Train Accuracy:79.00%,Valid Accuracy:83.75%\n",
      "Epoch 4/10\n",
      "----------\n",
      "Loss:47.4796,Train Accuracy:79.75%,Valid Accuracy:75.25%\n",
      "Epoch 5/10\n",
      "----------\n",
      "Loss:50.2228,Train Accuracy:75.25%,Valid Accuracy:84.00%\n",
      "Epoch 6/10\n",
      "----------\n",
      "Loss:53.3631,Train Accuracy:79.00%,Valid Accuracy:86.00%\n",
      "Epoch 7/10\n",
      "----------\n",
      "Loss:46.7304,Train Accuracy:80.75%,Valid Accuracy:84.25%\n",
      "Epoch 8/10\n",
      "----------\n",
      "Loss:40.6273,Train Accuracy:85.50%,Valid Accuracy:82.75%\n",
      "Epoch 9/10\n",
      "----------\n",
      "Loss:43.7127,Train Accuracy:83.75%,Valid Accuracy:85.75%\n",
      "Epoch 10/10\n",
      "----------\n",
      "Loss:41.6089,Train Accuracy:82.50%,Valid Accuracy:85.50%\n"
     ]
    }
   ],
   "source": [
    "n_epochs=10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr=0.0001\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)#lr随着训练不断衰减\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss=0.0\n",
    "    correct=0\n",
    "    print(\"Epoch {}/{}\".format(epoch+1,n_epochs))\n",
    "    print(\"-\"*10)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader, 0):\n",
    "        data, target = Variable(data).to(device), Variable(target.long()).to(device)\n",
    "        optimizer.zero_grad()  # 梯度清0\n",
    "        outputs = model(data)[0]  # 取0即不考虑辅助分类器的结果\n",
    "        pred = torch.max(outputs.data, 1)[1].data\n",
    "        loss = criterion(outputs, target)  # 计算误差\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        running_loss+=loss.data\n",
    "        correct += (pred== target).sum()\n",
    "        \n",
    "    current=0\n",
    "    total=0\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)[0]\n",
    "\n",
    "        predicted = torch.max(outputs.data, 1)[1].data\n",
    "        total += labels.size(0)\n",
    "        current += (predicted == labels).sum()\n",
    "        \n",
    "    print(\"Loss:{:.4f},Train Accuracy:{:.2f}%,Valid Accuracy:{:.2f}%\".format(running_loss,100*correct/400,100*current/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
