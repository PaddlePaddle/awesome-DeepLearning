## 1&2.损失函数方法补充及代码实现 ##
在原本的train代码中，损失函数为交叉熵损失函数。这里补充一种简单的均方差损失函数：即预测数据和原始数据对应点误差的平方和的均值，代码如下：

		import numpy as np
		def loss(self, y, z):
        	loss = np.mean(np.square(z-y))
        	return loss```
## 3.池化方法补充 ##
常用的池化方法有均值池化和最大池化。
假设池化范围为4*4。

均值池化：对池化区域内的像素点取均值，这种方法得到的特征数据对背景信息更敏感；
![](https://img-blog.csdn.net/20180801120929274?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzI1MTA0NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/0)

最大池化：对池化区域的所有像素值取最大值，这种方法得到的特征数据对纹理信息更加敏感。
![](https://img-blog.csdn.net/20180801120719351?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzI1MTA0NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/0)
## 4.数据增强方法补充 ##
数据增强主要是为了减少网络的过拟合现象，通过对训练图片进行变换可以得到泛化能力更强的网络，更好的适应应用场景。

常用的数据增强方法有：



- 旋转/反射变换: 随机旋转图像一定角度; 改变图像内容的朝向;



- 翻转变换：沿着水平或者垂直方向翻转图像;



- 缩放变换：按照一定的比例放大或者缩小图像;



- 平移变换：在图像平面上对图像以一定方式进行平移，可以采用随机或人为定义的方式指定平移范围和平移步长, 沿水平或竖直方向进行平移. 改变图像内容的位置;


- 尺度变换：对图像按照指定的尺度因子, 进行放大或缩小; 或者参照SIFT特征提取思想, 利用指定的尺度因子对图像滤波构造尺度空间. 改变图像内容的大小或模糊程度;



- 对比度变换：在图像的HSV颜色空间，改变饱和度S和V亮度分量，保持色调H不变. 对每个像素的S和V分量进行指数运算(指数因子在0.25到4之间), 增加光照变化；



- 噪声扰动：对图像的每个像素RGB进行随机扰动, 常用的噪声模式是椒盐噪声和高斯噪声；



- 颜色变化：在图像通道上添加随机扰动。


- 重新生成：通过生成对抗网络GAN生成同类型的数据

## 5.图像分类方法综述 ##
图像分类的任务就是给定一个图像，让计算机能够正确给出该图像所属的类别。图像分类算法可以分为传统与深度学习两大类。传统的图像分类模型通常包括底层特征学习、特征编码、空间约束、分类器设计、模型融合等几个阶段。深度学习算法主要通过大量的数据传入网络训练机器学习分类，常见的卷积网络模型有LeNet、Alexnet、VGG、GoogLeNet、ResNet。









