# 深度学习基础知识 #
## 1.损失函数方法补充 ##
### 0-1损失函数(zero-one loss)
0-1损失是指预测值和目标值不相等为1， 否则为0:
特点：

(1)0-1损失函数直接对应分类判断错误的个数，但是它是一个非凸函数，不太适用.

(2)感知机就是用的这种损失函数。但是相等这个条件太过严格，因此可以放宽条件，即满足 |Y-f(x)|<t时认为相等，

### Hinge Loss 

在机器学习中，**Hinge loss**（铰链损失函数）作为损失函数，通常被用于最大间隔算法(maximum-margin)，而最大间隔算法又是SVM(支持向量机support vector machines)用到的重要算法。

Hinge loss专用于二分类问题，标签值y=±1，预测值$\hat{y}$∈R。该二分类问题的目标函数的要求如下：当$\hat{y}$等于+1或者小于等于-1时，都是分类器确定的分类结果，此时的损失函数loss为0；而当$\hat{y}$预测值∈(−1,1)时，分类器对分类结果不确定，loss不为0。显然，当y^=0时，loss达到最大值。


## 2.损失函数python代码实现 ##
Hinge Loss
  
    def update_weights_Hinge(m1, m2, b, X1, X2, Y, learning_rate):   
    
    m1_deriv = 0
    m2_deriv = 0
    b_deriv = 0
    N = len(X1)
    for i in range(N):
    # 计算偏导数
    if Y[i]*(m1*X1[i] + m2*X2[i] + b) <= 1:
    m1_deriv += -X1[i] * Y[i]
    m2_deriv += -X2[i] * Y[i]
    b_deriv += -Y[i]
    # 否则偏导数为0
    # 我们减去它，因为导数指向最陡的上升方向
    m1 -= (m1_deriv / float(N)) * learning_rate
    m2 -= (m2_deriv / float(N)) * learning_rate
    b -= (b_deriv / float(N)) * learning_rate
    return m1, m2, b

## 3.池化方法补充 ##
Stochastic-pooling（随机池化）：只需对feature map中的元素按照其概率值大小随机选择，即元素值大的被选中的概率也大。而不像max-pooling那样，永远只取那个最大值元素。
## 4.数据增强方法修改及补充 ##
### 色彩抖动

在实际工程中为了消除图像在不同背景中存在的差异性，通常会做一些色彩抖动操作，扩充数据集合。色彩抖动主要是在图像的颜色方面做增强，主要调整的是图像的亮度，饱和度和对比度。工程中不是任何数据集都适用，通常如果不同背景的图像较多，加入色彩抖动操作会有很好的提升。

### 几何变换类

几何变换类即对图像进行几何变换，包括翻转，旋转，裁剪，变形，缩放等各类操作。

### 颜色变换

包括噪声、模糊、颜色变换、擦除、填充等等。

### GAN

通过生成对抗网络生成同类型的数据。比如生成汽车、人脸图片。通过图像风格迁移的手段，还可以生成同一物体再不同环境下的图片。

## 5.图像分类方法综述 ##
### 传统方法

#### SVM支持向量机<br></br>
支持向量机（SVM）是一种强大而灵活的有监督机器学习算法是多维空间中超平面上不同类的表示。目标是分裂
将数据集分成类，寻找最大边缘超平面。它建立了一个超平面或一组
高维空间中的超平面和两类之间的良好分离是通过
到任何类中最近的训练数据点距离最大的超平面。真正的力量
该算法的性能取决于所使用的核函数。  

一.线性SVM

SVM的主要思想是建立一个超平面作为决策曲面，是的正例和反例之间的隔离边缘被最大化。对于二维线性可分情况，令H为把两类训练样本没有错误地分开的分类县，H1、H2分别为过各类中离分类线最近的样本且平行于分类线的直线，它们之间的距离讲座分类间隔。所谓最优分类线就是要求分类线不但能将两类正确分开，而且使分类间隔最大。在高维空间，最优分类线就成为最优分类线。

1.线性分类器。
即用一个超平面将正负样本分离开。

2.最优分类面
对于SVM，存在一个分类面，两点集到此平面的最小距离最大，两个点集中的边缘点到此平面的距离最大

二.非线性SVM与核函数

在学习样本是线性不可分，但却是非线性可分的情况下，可以通过非线性变换吧学习样本变换到高维空间，使其咋高维空间里是线性可分的。用K(x,y)代替原来的点积(x,y)，Mercer定理(任何半正定的函数都可以作为核函数)指出，核函数K(x,y)通过与其想联系的非线性变换φ隐含地把特征向量映射到高维特征空间，使得系学习样本成为线性可分的。常用核函数有：

(1).多项式核函数；

(2).径向基函数；

(3).Sigmoid函数；

#### KNN ####
那么KNN算法如何应用到图像分类问题中，其实问题也就是如何评价一张待分类的图像A与P个训练样本图像中间的距离呢？
其中关键的问题就是图像的特征选择成什么，把问题往更大的方面考虑下，对于图像而言，（传统）机器学习与深度学习的一个很大区别是后者的自动特征抽取，所以深度学习的问世在一定程度上改变了人们对图像处理问题的侧重点，从特征描述到网络结构。所以在下面我们可以不严格的分为两类考虑，直接使用图像与使用一种图像特征提取方法。

1.直接分类

所谓的直接分类本质上是将图像的每个像素点的像素值作为特征，那么此时两种图像的距离（假设使用L1）就是每个对应位置的像素点的像素值差值的绝对值的和。

2.对特征分类

然后很多时候我们不会直接使用像素值作为图像的特征来使用，因为它并不能从本质上反映了人对图像的认知，比如我们将一张图稍稍向一个方向平移一段距离，在人眼看来他们应该是一类，甚至就是同一张，但是如果用像素值计算距离的话，距离确很大。
所以在更多的时候，要计算距离的对象是一些描述子生成的特征，举个例子，HOG+SVM的方法在行人检测中有很好的效果，而SVM的作用也是个分类器，如果换成KNN的话也是可行的（可行指的是原理上可行，效果如何并未考证），所以此时KNN计算的对象其实是HOG生成的描述子，而不再是图像的像素。

但是很不幸的是，KNN在图像问题中几乎不会使用，这个观点来源于斯坦福CS231n，它的原话是 K-Nearest Neighbor on images never used.
原因有两个：
1.很差的测试效率；
2.整个图像水平的距离度量可能非常不直观。
如说第二个原因可以靠着一些特征描述子来解决的话，那么第一个问题就是KNN算法的硬伤，在机器学习中其实我们对测试阶段的时间容忍要远远高于训练阶段，因为最终使用模型解决问题时足够快就可以了，CNN普遍是这样。但是这个问题在KNN中就会无限的暴露出来，“在线”学习的方式决定了样本量越大，分类过程就会越慢。

总结

1.对于样本不平均问题，KNN相比于其他监督学习算法容忍度更差。

2.KNN的计算量和数据存储量都很大。

3.但是KNN的思想简单，在某些方便可以带来很高的准确率，比如在经典的手写数字识别问题上，KNN的准确率可以排在第二位。

4.KNN是一种在线的学习方式，效率低，而且样本量越大效率就越低。
### 深度学习方法

#### 卷积神经网络<br></br>
卷积神经网络（CNN，或ConvNet）是一种多层神经网络，旨在通过最少的预处理直接从像素图像中识别视觉模式。这是一个特殊的人工神经网络结构。它包括两个重要的元素，即卷积层和池化层。
<br></br>

