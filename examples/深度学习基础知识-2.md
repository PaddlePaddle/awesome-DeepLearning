# 深度学习基础知识-2

##  损失函数方法补充

一般来说，我们在进行机器学习任务时，使用的每一个算法都有一个目标函数，算法便是对这个目标函数进行优化，特别是在分类或者回归任务中，便是使用损失函数（Loss Function）作为其目标函数，又称为代价函数(Cost Function)。

损失函数是用来评价模型的预测值$\widetilde{y}=f(X)$与真实值$Y$的不一致程度，它是一个非负实值函数。通常使用 $L(\widetilde{y},Y)$来表示，损失函数越小，模型的性能就越好。

设一共有N个样本的样本集为$(X,Y)=(x_i,y_i)$， $y_i$为样本ii的真实值，$\widetilde{y_i}$ 为样本ii的预测值，$f$为分类或者回归函数。

那么总的损失函数为：
$$
L=\sum\limits_{i=1}^{N}l(y_i,\widetilde{y_i})
$$

### 1.1 $L_1\_Loss$

$L_1\_Loss $ 同 MSE 损失是分类问题中出现的最频繁的 Loss。首先计算方法上$L_1\_Loss $是求所有预测值和标签距离的平均数，MSE 损失是求预测值和标签距离平方的平均数。二者的结构很类似，区别就是一个用了绝对值一个用了平方。
$$
L_1\_Loss = \frac{1}{N} \sum|y - p|
$$




###  1.2 $L_1\_Loss$函数Python实现

```python
def l1_loss(pred, label):
    loss = np.abs(pred - label)
    loss = np.mean(loss)
    return loss
pred = np.array([[1], [4], [2] ],dtype="float32")#随便编两个点代入损失函数
label = np.array([[1], [3], [4] ],dtype="float32")
loss_value=l1_loss(pred, label)
print("L1 Loss的值是:", loss_value)
```



### 2.1 Huber Loss 

Huber是 $L_1\_Loss $ 和 MSE Loss 的分段组合。在零点附近用MSE，其余位置用 $L_1\_Loss $ 就形成了 Huber Loss。具体的选择范围用 $\delta$ 划分。
$$
HuberLoss = \left \{ \begin{matrix}
\frac{1}{2}(y - p)^{2} & |y-p| \leq\delta \\ 
\delta|y-p|-\frac{1}{2}\delta^{2} & otherwise
\end{matrix}\right.
$$


###  2.1 Huber Loss 函数Python实现

```python
def huber_loss(pred, lable, delta):
    loss = np.where(np.abs(lable-pred) <= delta , 0.5*((lable-pred)**2), delta*np.abs(lable - pred) - 0.5*(delta**2))
    loss = np.mean(loss)
    return loss

pred = np.array([[1], [4], [2] ],dtype="float32")#随便编两个点代入损失函数
label = np.array([[1], [3], [4] ],dtype="float32")
loss_value=huber_loss(pred, label, 1)
print("Huber Loss的值是:", loss_value)
```

### 3.1 Hinge loss

在机器学习中，**Hinge loss**是一种损失函数，它通常用于**"maximum-margin"**的分类任务中，如支持向量机。数学表达式为：
$$
L=\max \{0,1-y\widetilde{y}\}
$$
其中$\widetilde{y}$表示预测输出，通常是模糊的（介于0到1之间）， $y$表示正确的类别。

- 如果**$y\widetilde{y}<1$**，则损失为： $1-y\widetilde{y}$
- 如果**$y\widetilde{y}\ge1$** ，则损失为：0


###  3.2 Hinge loss函数Python实现

```python
def hinge_loss(pred, label):
    zeros = np.zeros_like(pred)
    loss = np.maximum(zeros,1-(pred*label))
    loss = np.mean(loss)
    return loss

pred = np.array([[1], [4], [2] ],dtype="float32")#随便编两个点代入损失函数
label = np.array([[1], [3], [4] ],dtype="float32")
loss_value=l1_loss(pred, label)
print("L1 Loss的值是:", loss_value)
```





## 池化方法补充

**池化的作用则体现在降采样：保留显著特征、降低特征维度，增大kernel的感受野**。深度网络越往后面越能捕捉到物体的语义信息，这种语义信息是建立在较大的感受野基础上。



### 1、一般池化(General Pooling)

<img src="https://www.pianshen.com/images/30/bb4dd12d2c1247f5c18e063efd3fdbce.gif" alt="img" style="zoom:80%;" />

池化作用于图像中不重合的区域（与卷积操作不同），定义池化窗口的大小为**size_X**，即图中红色正方形的边长，定义两个相邻池化窗口的水平位移 / 竖直位移为stride。一般池化由于每一池化窗口都是不重复的，所以**sizeX=stride**。



### 2、均值池化(Mean / Average Pooling)

<img src="https://www.pianshen.com/images/15/7700c08ad172406406f2fa52a224d3af.png" alt="img" style="zoom:67%;" />

一般池化的基础上，计算每个池化窗口对应图像区域的**平均值**，作为该区域池化后的值。



### 3、最大池化(Max Pooling)

<img src="https://www.pianshen.com/images/58/9da3612d1ca10124c401819c6c3af8ea.png" alt="img" style="zoom: 33%;" />

一般池化的基础上，选取每个池化窗口对应图像区域的**最大值**，作为该区域池化后的值。



### 4、随机池化(Stochastic Pooling)

<img src="https://www.pianshen.com/images/219/0d809e4b3b01f89ef683b21e5644d723.png" alt="img" style="zoom: 50%;" />

Stochastic pooling是**一种简单有效的正则化CNN的方法，能够降低max pooling的过拟合现象，提高泛化能力**。对于pooling层的输入，根据输入的多项式分布随机选择一个值作为输出。训练阶段和测试阶段的操作略有不同。

**训练阶段：**

1）前向传播：先将池化窗口中的元素全部除以它们的和，得到概率矩阵；再按照概率随机选中的方格的值，作为该区域池化后的值。

2）反向传播：求导时，只需保留前向传播中已经被选中节点的位置的值，其它值都为0，类似max-pooling的反向传播。

**测试阶段：**

在测试时也使用Stochastic Pooling会对预测值引入噪音，降低性能。取而代之的是使用概率矩阵加权平均。比使用Average Pooling表现要好一些。在平均意义上，与Average Pooling近似，在局部意义上，服从Max Pooling准则。

### 5、重叠池化(Overlapping Pooling)

重叠池化，即相邻池化窗口之间会有重叠区域。如果定义池化窗口的大小为sizeX，定义两个相邻池化窗口的水平位移 / 竖直位移为stride，此时**sizeX>stride**。

Alexnet中提出和使用，不仅可以提升预测精度，同时一定程度上可以减缓过拟合。相比于正常池化（步长s=2，窗口x=2），重叠池化(步长s=2，窗口x=3) 可以减少top-1, top-5的错误率分别为0.4% 和0.3%。

### 6、全局池化(Global Pooling)

Global Pooling就是**池化窗口的大小 = 整张特征图的大小**。这样，每个 W×H×C 的特征图输入就会被转化为 1×1×C 的输出，也等同于每个位置权重都为 1/(W×H) 的全连接层操作。




##  数据增强方法补充

有监督数据增强，即**采用预设的数据变换规则，在已有数据的基础上**进行数据的扩增，包含单样本数据增强和多样本数据增强，其中单样本又包括几何操作类，颜色变换类。

### **1. 单样本数据增强**

所谓单样本数据增强，即增强一个样本的时候，全部围绕着该样本本身进行操作，包括**几何变换类，颜色变换类**等。

**(1) 几何变换类**

几何变换类即对图像进行几何变换，包括**翻转，旋转，裁剪，变形，缩放**等各类操作。

**(2) 颜色变换类**

上面的几何变换类操作，没有改变图像本身的内容，它可能是选择了图像的一部分或者对像素进行了重分布。如果要改变图像本身的内容，就属于颜色变换类的数据增强了，常见的包括**噪声、模糊、颜色变换、擦除、填充**等等。

基于噪声的数据增强就是在原来的图片的基础上，随机叠加一些噪声，最常见的做法就是高斯噪声。更复杂一点的就是在面积大小可选定、位置随机的矩形区域上丢弃像素产生黑色矩形块，从而产生一些彩色噪声，以Coarse Dropout方法为代表，甚至还可以对图片上随机选取一块区域并擦除图像信息。

颜色变换的另一个重要变换是颜色扰动，就是在某一个颜色空间通过增加或减少某些颜色分量，或者更改颜色通道的顺序。

### **2. 多样本数据增强**

不同于单样本数据增强，多样本数据增强方法利用多个样本来产生新的样本，下面介绍几种方法。

**(1) SMOTE**

SMOTE通过人工合成新样本来处理样本不平衡问题，从而提升分类器性能。

类不平衡现象是很常见的，它指的是数据集中各类别数量不近似相等。如果样本类别之间相差很大，会影响分类器的分类效果。假设小样本数据数量极少，如仅占总体的1%，则即使小样本被错误地全部识别为大样本，在经验风险最小化策略下的分类器识别准确率仍能达到99%，但由于没有学习到小样本的特征，实际分类效果就会很差。

SMOTE方法是基于插值的方法，它可以为小样本类合成新的样本。

**(2) SamplePairing**

SamplePairing方法的原理非常简单，从训练集中随机抽取两张图片分别经过基础数据增强操作(如随机翻转等)处理后经像素以取平均值的形式叠加合成一个新的样本，标签为原样本标签中的一种。这两张图片甚至不限制为同一类别，这种方法对于医学图像比较有效。

经SamplePairing处理后可使训练集的规模从N扩增到N×N。实验结果表明，因SamplePairing数据增强操作可能引入不同标签的训练样本，导致在各数据集上使用SamplePairing训练的误差明显增加，而在验证集上误差则有较大幅度降低。

尽管SamplePairing思路简单，性能上提升效果可观，符合奥卡姆剃刀原理，但遗憾的是可解释性不强。

**(3) mixup**

mixup是Facebook人工智能研究院和MIT在“Beyond Empirical Risk Minimization”中提出的基于邻域风险最小化原则的数据增强方法，它使用线性插值得到新样本数据。

**SMOTE，SamplePairing，mixup三者思路上有相同之处，都是试图将离散样本点连续化来拟合真实样本分布**，不过所增加的样本点在特征空间中仍位于已知小样本点所围成的区域内。如果能够在给定范围之外适当插值，也许能实现更好的数据增强效果。

### **3. 无监督的数据增强**

无监督的数据增强方法包括两类：

(1) 通过模型学习数据的分布，随机生成与训练数据集分布一致的图片，代表方法GAN[4]。

(2) 通过模型，学习出适合当前任务的数据增强方法，代表方法AutoAugment。

**3.1 GAN**

关于GAN(generative adversarial networks)，我们已经说的太多了。它包含两个网络，一个是生成网络，一个是对抗网络，基本原理如下：

(1) G是一个生成图片的网络，它接收随机的噪声z，通过噪声生成图片，记做G(z) 。

(2) D是一个判别网络，判别一张图片是不是“真实的”，即是真实的图片，还是由G生成的图片。

**3.2 Autoaugmentation**

AutoAugment是Google提出的自动选择最优数据增强方案的研究，这是无监督数据增强的重要研究方向。它的基本思路是使用增强学习从数据本身寻找最佳图像变换策略。学习已有数据增强的组合策略，对于门牌数字识别等任务，研究表明剪切和平移等几何变换能够获得最佳效果。

##  图像分类方法综述

### **基于色彩特征的索引技术**

色彩是物体表面的一种视觉特性,每种物体都有其特有的色彩特征,譬如人们说到绿色往往是和树木或草原相关,谈到蓝色往往是和大海或蓝天相关,同一类物体往拍几有着相似的色彩特征,因此我们可以根据色彩特征来区分物体.用色彩特特征进行图像分类一可以追溯到**Swain和Ballard**提出的**色彩直方图**的方法.由于色彩直方图具有简单且随图像的大小、旋转变化不敏感等特点,得到了研究人员的厂泛关注,目前几乎所有基于内容分类的图像数据库系统都把色彩分类方法作为分类的一个重要手段,并提出了许多改进方法,归纳起主要可以分为两类：**全局色彩特征索引**和**局部色彩特征索引**。

### **基于纹理的图像分类技术**

纹理特征也是图像的重要特征之一,其本质是**刻画象素的邻域灰度空间分布规律**。由于它在模式识别和计算机视觉等领域已经取得了丰富的研究成果,因此可以借用到图像分类中。

在70年代早期,**Haralick**等人提出纹理特征的**灰度共生矩阵**表示法,这个方法提取的是纹理的灰度级空间相关性,它首先基于象素之间的距离和方向建立灰度共生矩阵,再由这个矩阵提取有意义的统计量作为纹理特征向量。基于一项人眼对纹理的视觉感知的心理研究,Tamuar等人提出可以模拟纹理视觉模型的6个纹理属性,分别是粒度,对比度,方向性,线型,均匀性和粗糙度。

### **基于形状的图像分类技术**

形状是图像的重要可视化内容之一。在二维图像空间中，形状通常被认为是一条封闭的轮廓曲线所包围的区域，所以对形状的描述涉及到对轮廓边界的描述以及对这个边界所包围区域的描述。目前的基于形状分类方法大多围绕着从形状的轮廓特征和形状的区域特征建立图像索引。关于对形状轮廓特征的描述主要有：直线段描述、样条拟合曲线、傅立叶描述子以及高斯参数曲线等等。

实际上更常用的办法是采用**区域特征**和**边界特征**相**结合**来进行形状的相似分类。如Eakins等人提出了一组重画规则并对形状轮廓用线段和圆弧进行简化表达，然后定义形状的邻接族和形族两种分族函数对形状进行分类。邻接分族主要采用了形状的边界信息,而形状形族主要采用了形状区域信息。在形状进行匹配时,除了每个族中形状差异外，还比较每个族中质心和周长的差异，以及整个形状的位置特征矢量的差异，查询判别距离是这些差异的加权和。

