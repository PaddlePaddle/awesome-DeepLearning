# 深度学习基础知识（一）

## 深度学习发展历史

深度学习的发展经过了半个多世纪才逐渐成熟，其历程可以分为以下几个阶段。

大概1943年，神经网络和数学模型，即MCP模型建立起来，这就是一个简化了的模型，它奠定了人工神经网络的基础，对多路的信号输入进行线性加权，求和，并使用阈值进行非线性激活。首次提出的神经元结构，但权重是不可学习的。

1958年，感知机perceptron 被提出，并使用进行分类，权重学习理论被提出，神经元的结构也逐渐趋于完善，神经网络的第一个快速发展的阶段。

在1969年，线性模型被提出，但只能处理线性分类问题，无法解决最基本的异或问题，神经网络的研究陷入了近20年的停滞阶段。

随后在1986年，神经网络之父发明了多层感知器的BP算法，使用Sigmoid进行非线性映射，解决了非线性的问题，这引起了神经网络的第二波热潮。随后由于机器学习的算法快速发展，如支持向量机SVM的使用，对于少量数据的优势，因此此阶段神经网络并不突出。

而到了21世纪之后，人们发现神经网络在图像以及自然语言处理等方面有很大的优势，表现良好，同时近些年来数据的激增以及硬件设备的快速发展，因此神经网络模型得到了很好的发展，并称为“深度学习”，从此深度学习进入了新的时代，成为了最热门的领域。

## 人工智能、机器学习、深度学习有什么区别和联系？

从概念上来说，人工智能、机器学习和深度学习是逐渐由大到小的关系，人工智能的概念最为广泛，但一般使用这个概念的时候比较宽泛，不涉及实际的应用。机器学习是目前实现人工智能一种比较有效的方法。深度学习是目前机器学习种最热门的分支，近些年机器学习的发展主要集中在深度学习领域。简单来说，人工智能>机器学习>深度学习。

人工智能只是说明了模拟、延伸扩展人的智能的理论办法与技术的新技术，只是定义目标，并未限定方法，因此存在很多方法与分支。

机器学习是由明确指代的学科，研究计算机如何模拟实现人类的学习行为，其实现主要分为两步：训练和预测，即归纳和演绎，通过具体的案例中抽象出一般的规律，然后进行预测，如果和实际一致，就说明模型是有效的。目前的模型主要包含三个部分：模型假设、评价函数、优化算法。模型假设决定了前提，即假定了一个模型可能的关系，评价函数用于评价一个数据X~Y预测结果两者关系的好坏，可以衡量关系是否能好的拟合现有的观测样本，将拟合的误差最小作为优化的目标。在假设的范围内找到使得评价指标尽可能的最优的关系，这个寻找的方法就是优化算法。

深度学习与传统的机器学习算法在理论结构上是一致的，差别在于假设的复杂度。深度学习模型是输入到输出的映射函数，足够深的神经网络可以拟合任意复杂的函数。

## 神经元、单层感知机、多层感知机

神经元细胞，是神经系统最基本的结构和功能单位。 分为细胞体和突起两部分。 细胞体由细胞核、细胞膜、细胞质组成，具有联络和整合输入信息并传出信息的作用。 突起有树突和轴突两种，这是深度学习的基础。

对生物的神经元细胞的结构进行模拟，则得到了一个类似神经元的运算模型，即M-P模型。

结合M-P模型和Hebb学习规则，感知机出现了，单层感知机和多层感知机是最基础的神经网络结构，属于前馈型网络，单层感知机是二分类的线性分类模型，输入是被感知数据集的特征向量，输出时数据集的类别{+1,-1}。单层感知机的函数近似非常有限，其决策边界必须是一个超平面，严格要求数据是线性可分的。支持向量机，用核函数修正了感知器的不足，将特征向量有效的映射到更高维的空间使得样本成为线性可分的数据集。

多层感知机在单层神经网络的基础上引入了一到多个隐藏层(hidden layer)。隐藏层位于输入层和输出层之间。

## 什么是前向传播

前向传播就是将上一层的输出作为下一层的输入，经过线性求和之后经过$\sigma$激活函数，并计算下一层的输出，一直到运算到输出层为止，用公式来表示即为如下的过程。
$$
z^{(l)}=W^{(l-1)}+b^{(l)}
$$

$$
a^{(l)}=\sigma(z^{(l)})
$$

用图像表示即为如下过程：

![1](.\images\1.png)



## 什么是反向传播

**反向传播**（back propagation, **BP**）算法是 "误差反向传播" 的简称，也称为**backprop**，允许来自代价函数的信息通过网络向后流动，以便计算梯度。

反向传播是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。该方法对网络中所有权重计算损失函数的梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。

用图像表示为以下过程：

![2](.\images\2.png)



