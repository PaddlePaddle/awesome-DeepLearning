{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.vision.transforms import Compose, Normalize\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "from paddle.metric import Accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download training data and load training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "..\n",
      "Download finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load finished\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([Normalize(mean=[127.5],\n",
    "                               std=[127.5],\n",
    "                               data_format='CHW')])\n",
    "# 使用transform对数据集做归一化\n",
    "print('download training data and load training data')\n",
    "#读取训练集 测试集数据\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "print('load finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LeNet(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\n",
    "        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2,  stride=2)\n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)\n",
    "        self.linear1 = paddle.nn.Linear(in_features=16*5*5, out_features=120)\n",
    "        self.linear2 = paddle.nn.Linear(in_features=120, out_features=84)\n",
    "        self.linear3 = paddle.nn.Linear(in_features=84, out_features=10)\n",
    "    #前馈网络\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = paddle.flatten(x, start_axis=1,stop_axis=-1)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = paddle.Model(LeNet())   # 封装模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#训练\n",
    "def train(model,Batch_size=64):\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    iterator = 0\n",
    "    epochs = 5\n",
    "    total_steps = (int(50000//Batch_size)+1)*epochs\n",
    "    lr = paddle.optimizer.lr.PolynomialDecay(learning_rate=0.01,decay_steps=total_steps,end_lr=0.001)\n",
    "    optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    # 用Adam作为优化函数\n",
    "    for epoch in range(epochs):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            x_data = data[0]\n",
    "            y_data = data[1]\n",
    "            predicts = model(x_data)\n",
    "            loss = F.cross_entropy(predicts, y_data)\n",
    "            # 计算损失\n",
    "            acc = paddle.metric.accuracy(predicts, y_data)\n",
    "            loss.backward()\n",
    "            if batch_id % 200 == 0:\n",
    "                iterator+=200\n",
    "            optim.step()\n",
    "            optim.clear_grad()\n",
    "        paddle.save(model.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdparams') #保存模型权重\n",
    "        paddle.save(optim.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdopt')#保存优化器参数权重\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#测试\r\n",
    "def test(model):\r\n",
    "    # 加载测试数据集\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\r\n",
    "    model.eval()\r\n",
    "    batch_size = 64\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data = data[0]\r\n",
    "        y_data = data[1]\r\n",
    "        predicts = model(x_data)\r\n",
    "        # 获取预测结果\r\n",
    "        loss = F.cross_entropy(predicts, y_data)\r\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\r\n",
    "        if batch_id % 20 == 0:\r\n",
    "            print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#随机抽取100张图片进行测试\r\n",
    "def random_test(model,num=100):\r\n",
    "    # select_id = random.sample(range(1, 10000), 100) #生成一百张测试图片的下标\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data = data[0]\r\n",
    "        label = data[1]\r\n",
    "    predicts = model(x_data)\r\n",
    "    #返回正确率\r\n",
    "    acc = paddle.metric.accuracy(predicts, label)\r\n",
    "    print(\"随机抽样100张图片正确率为：{}\".format(acc.numpy()))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#调用模型\r\n",
    "model = LeNet()\r\n",
    "train(model)\r\n",
    "test(model)\r\n",
    "random_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
