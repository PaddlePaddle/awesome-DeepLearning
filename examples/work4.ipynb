{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#数据集介绍\n",
    "iChallenge-PM是百度大脑和中山大学中山眼科中心联合举办的iChallenge比赛中，提供的关于病理性近视（Pathologic Myopia，PM）的医疗类数据集，包含1200个受试者的眼底视网膜图片，训练、验证和测试数据集各400张。\n",
    "此数据集的设计初衷是可以完成分类、分割、检测等多种任务，这里我们只关注其中的分类任务.\n",
    "H:高度近视High Myopia\n",
    "N:正常视力Normal\n",
    "P:病理性近视Pathologic\n",
    "P是病理性近似，正样本，类别为1\n",
    "H和N不是病理性近似，负样本，类别为0\n",
    "读入数据的时候根据文件名确定样本标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#ResNet网络结构\n",
    "2015 年，ResNet 横空出世，一举斩获 CVPR 2016 最佳论文奖，而且在 Imagenet 比赛的三个任务以及 COCO 比赛的检测和分割任务上都获得了第一名。四年过去，这一论文的被引量已超 40000 次.。\n",
    "\n",
    "我们知道，增加网络深度后，网络可以进行更加复杂的特征提取，因此更深的模型可以取得更好的结果。但事实并非如此，人们发现随着网络深度的增加，模型精度并不总是提升，并且这个问题显然不是由过拟合（overfitting）造成的，因为网络加深后不仅测试误差变高了，它的训练误差竟然也变高了。作者提出，这可能是因为更深的网络会伴随梯度消失/爆炸问题，从而阻碍网络的收敛。作者将这种加深网络深度但网络性能却下降的现象称为退化问题（degradation problem）。\n",
    "\n",
    "ResNet中的Bottleneck结构和11卷积\n",
    "\n",
    "ResNet50起，就采用Bottleneck结构，主要是引入1x1卷积。我们来看一下这里的1x1卷积有什么作用：\n",
    "\n",
    "对通道数进行升维和降维（跨通道信息整合），实现了多个特征图的线性组合，同时保持了原有的特征图大小；\n",
    "\n",
    "相比于其他尺寸的卷积核，可以极大地降低运算复杂度；\n",
    "\n",
    "如果使用两个3x3卷积堆叠，只有一个relu，但使用1x1卷积就会有两个relu，引入了更多的非线性映射；\n",
    "Basicblock和Bottleneck结构\n",
    "我们来计算一下11卷积的计算量优势：首先看上图右边的bottleneck结构，对于256维的输入特征，参数数目：1x1x256x64+3x3x64x64+1x1x64x256=69632，如果同样的输入输出维度但不使用1x1卷积，而使用两个3x3卷积的话，参数数目为(3x3x256x256)x2=1179648。简单计算下就知道了，使用了1x1卷积的bottleneck将计算量简化为原有的5.9%，收益超高。\n",
    "整个ResNet不使用dropout，全部使用BN。此外，回到最初的这张细节图，我们不难发现一些规律和特点：\n",
    "\n",
    "受VGG的启发，卷积层主要是3×3卷积；\n",
    "\n",
    "对于相同的输出特征图大小的层，即同一stage，具有相同数量的3x3滤波器;\n",
    "\n",
    "如果特征地图大小减半，滤波器的数量加倍以保持每层的时间复杂度；（这句是论文和现场演讲中的原话，虽然我并不理解是什么意思）\n",
    "\n",
    "每个stage通过步长为2的卷积层执行下采样，而却这个下采样只会在每一个stage的第一个卷积完成，有且仅有一次。\n",
    "\n",
    "网络以平均池化层和softmax的1000路全连接层结束，实际上工程上一般用自适应全局平均池化 (Adaptive Global Average Pooling)；\n",
    "\n",
    "从图中的网络结构来看，在卷积之后全连接层之前有一个全局平均池化 (Global Average Pooling, GAP) 的结构。\n",
    "\n",
    "总结如下：\n",
    "\n",
    "相比传统的分类网络，这里接的是池化，而不是全连接层。池化是不需要参数的，相比于全连接层可以砍去大量的参数。对于一个7x7的特征图，直接池化和改用全连接层相比，可以节省将近50倍的参数，作用有二：一是节省计算资源，二是防止模型过拟合，提升泛化能力；\n",
    "\n",
    "这里使用的是全局平均池化，但我觉得大家都有疑问吧，就是为什么不用最大池化呢？这里解释很多，我查阅到的一些论文的实验结果表明平均池化的效果略好于最大池化，但最大池化的效果也差不到哪里去。实际使用过程中，可以根据自身需求做一些调整，比如多分类问题更适合使用全局最大池化（道听途说，不作保证）。如果不确定话还有一个更保险的操作，就是最大池化和平均池化都做，然后把两个张量拼接，让后续的网络自己学习权重使用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "from PIL import Image\r\n",
    "import cv2\r\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /home/aistudio/data/data90836/training.zip, /home/aistudio/data/data90836/training.zip.zip or /home/aistudio/data/data90836/training.zip.ZIP.\n",
      "[Errno 13] Permission denied: '/home/aistudio/work/palm/PALM-Training400/'\n",
      "/home/aistudio\n",
      "unzip:  cannot find or open PALM-Training400.zip, PALM-Training400.zip.zip or PALM-Training400.zip.ZIP.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0001.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0002.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0003.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0004.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0005.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0006.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0007.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0008.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0009.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0010.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0011.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0012.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0013.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0014.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0015.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0016.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0017.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0018.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0019.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0020.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0021.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0022.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0023.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0024.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0025.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0026.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0027.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0028.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0029.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0030.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0031.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0032.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0033.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0034.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0035.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0036.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0037.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0038.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0039.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0040.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0041.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0042.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0043.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0044.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0045.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0046.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0047.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0048.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0049.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0050.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0051.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0052.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0053.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0054.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0055.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0056.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0057.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0058.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0059.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0060.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0061.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0062.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0063.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0064.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0065.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0066.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0067.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0068.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0069.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0070.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0071.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0072.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0073.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0074.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0075.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0076.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0077.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0078.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0079.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0080.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0081.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0082.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0083.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0084.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0085.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0086.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0087.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0088.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0089.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0090.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0091.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0092.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0093.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0094.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0095.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0096.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0097.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0098.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0099.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0100.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0101.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0102.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0103.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0104.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0105.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0106.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0107.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0108.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0109.jpg.\n",
      "checkdir error:  cannot create /home/aistudio/work/palm/PALM-Validation400\n",
      "                 Permission denied\n",
      "                 unable to process PALM-Validation400/V0110.jpg.\n",
      "/home/aistudio\n"
     ]
    }
   ],
   "source": [
    "#解压数据\r\n",
    "!unzip -o -q -d /home/aistudio/work/palm /home/aistudio/data/data90836/training.zip\r\n",
    "%cd /home/aistudio/work/palm/PALM-Training400/\r\n",
    "!unzip -o -q PALM-Training400.zip\r\n",
    "!unzip -o -q -d /home/aistudio/work/palm /home/aistudio/data/data90836/validation.zip\r\n",
    "!unzip -o -q -d /home/aistudio/work/palm /home/aistudio/data/data90836/valid_gt.zip\r\n",
    "#返回家目录，生成模型文件位于/home/aistudio/\r\n",
    "%cd /home/aistudio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将数据集转换为csv格式并放到home文件夹中\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "data_xls = pd.read_excel('/home/aistudio/work/palm/PALM-Validation-GT/PM_Label_and_Fovea_Location.xlsx', index_col=0)\r\n",
    "data_xls.to_csv('/home/aistudio/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#训练集路径\r\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\r\n",
    "#加载数据集，将数据集划分为训练集和测试集\r\n",
    "def load_data(ratio=0.8):\r\n",
    "    filenames = os.listdir(DATADIR)\r\n",
    "    testdata=filenames[int(len(filenames)*ratio):-1]\r\n",
    "    traindata=filenames[:int(len(filenames)*ratio)]\r\n",
    "    return traindata,testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对读入的图像数据进行预处理\r\n",
    "def transform_img(img):\r\n",
    "    # 将图片尺寸缩放道 224x224\r\n",
    "    img = cv2.resize(img, (224, 224))\r\n",
    "    # 读入的图像数据格式是[H, W, C]\r\n",
    "    # 使用转置操作将其变成[C, H, W]\r\n",
    "    img = np.transpose(img, (2,0,1))\r\n",
    "    img = img.astype('float32')\r\n",
    "    # 将数据范围调整到[-1.0, 1.0]之间\r\n",
    "    img = img / 255.\r\n",
    "    img = img * 2.0 - 1.0\r\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义训练集数据读取器\r\n",
    "def data_loader(datadir,filenames, batch_size=10, mode = 'train'):\r\n",
    "    # 将datadir目录下的文件列出来，每条文件都要读入\r\n",
    "    def reader():\r\n",
    "        if mode == 'train':\r\n",
    "            # 训练时随机打乱数据顺序\r\n",
    "            random.shuffle(filenames)\r\n",
    "        batch_imgs = []\r\n",
    "        batch_labels = []\r\n",
    "        for name in filenames:\r\n",
    "            filepath = os.path.join(datadir, name)\r\n",
    "            img = cv2.imread(filepath)\r\n",
    "            img = transform_img(img)\r\n",
    "            if name[0] == 'H' or name[0] == 'N':\r\n",
    "                # H开头的文件名表示高度近似，N开头的文件名表示正常视力\r\n",
    "                # 高度近视和正常视力的样本，都不是病理性的，属于负样本，标签为0\r\n",
    "                label = 0\r\n",
    "            elif name[0] == 'P':\r\n",
    "                # P开头的是病理性近视，属于正样本，标签为1\r\n",
    "                label = 1\r\n",
    "            else:\r\n",
    "                raise('Not excepted file name')\r\n",
    "            # 每读取一个样本的数据，就将其放入数据列表中\r\n",
    "            batch_imgs.append(img)\r\n",
    "            batch_labels.append(label)\r\n",
    "            if len(batch_imgs) == batch_size:\r\n",
    "                # 当数据列表的长度等于batch_size的时候，\r\n",
    "                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出\r\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "                yield imgs_array, labels_array\r\n",
    "                batch_imgs = []\r\n",
    "                batch_labels = []\r\n",
    "\r\n",
    "        if len(batch_imgs) > 0:\r\n",
    "            # 剩余样本数目不足一个batch_size的数据，一起打包成一个mini-batch\r\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "            yield imgs_array, labels_array\r\n",
    "\r\n",
    "    return reader\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义验证集数据读取器\r\n",
    "def valid_data_loader(datadir, csvfile, batch_size=10, mode='valid'):\r\n",
    "    # 训练集读取时通过文件名来确定样本标签，验证集则通过csvfile来读取每个图片对应的标签\r\n",
    "    # 请查看解压后的验证集标签数据，观察csvfile文件里面所包含的内容\r\n",
    "    # csvfile文件所包含的内容格式如下，每一行代表一个样本，\r\n",
    "    # 其中第一列是图片id，第二列是文件名，第三列是图片标签，\r\n",
    "    # 第四列和第五列是Fovea的坐标，与分类任务无关\r\n",
    "    # ID,imgName,Label,Fovea_X,Fovea_Y\r\n",
    "    # 1,V0001.jpg,0,1157.74,1019.87\r\n",
    "    # 2,V0002.jpg,1,1285.82,1080.47\r\n",
    "    # 打开包含验证集标签的csvfile，并读入其中的内容\r\n",
    "    filelists = open(csvfile).readlines()\r\n",
    "    def reader():\r\n",
    "        batch_imgs = []\r\n",
    "        batch_labels = []\r\n",
    "        for line in filelists[1:]:\r\n",
    "            line = line.strip().split(',')\r\n",
    "            name = line[1]\r\n",
    "            label = int(line[2])\r\n",
    "            # 根据图片文件名加载图片，并对图像数据作预处理\r\n",
    "            filepath = os.path.join(datadir, name)\r\n",
    "            img = cv2.imread(filepath)\r\n",
    "            img = transform_img(img)\r\n",
    "            # 每读取一个样本的数据，就将其放入数据列表中\r\n",
    "            batch_imgs.append(img)\r\n",
    "            batch_labels.append(label)\r\n",
    "            if len(batch_imgs) == batch_size:\r\n",
    "                # 当数据列表的长度等于batch_size的时候，\r\n",
    "                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出\r\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "                yield imgs_array, labels_array\r\n",
    "                batch_imgs = []\r\n",
    "                batch_labels = []\r\n",
    "\r\n",
    "        if len(batch_imgs) > 0:\r\n",
    "            # 剩余样本数目不足一个batch_size的数据，一起打包成一个mini-batch\r\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "            yield imgs_array, labels_array\r\n",
    "\r\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义神经网络的训练\r\n",
    "import os\r\n",
    "import random\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\r\n",
    "DATADIR2 = '/home/aistudio/work/palm/PALM-Validation400'\r\n",
    "CSVFILE = '/home/aistudio/labels.csv'\r\n",
    "\r\n",
    "# 定义训练过程\r\n",
    "def train_pm(model, optimizer,filenames):\r\n",
    "    # 开启0号GPU训练\r\n",
    "    use_gpu = True\r\n",
    "    paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\r\n",
    "\r\n",
    "    print('start training ... ')\r\n",
    "    model.train()\r\n",
    "    epoch_num = 5\r\n",
    "    # 定义数据读取器，训练数据读取器和验证数据读取器\r\n",
    "    train_loader = data_loader(DATADIR,filenames, batch_size=10, mode='train')\r\n",
    "    valid_loader = valid_data_loader(DATADIR2, CSVFILE)\r\n",
    "    for epoch in range(epoch_num):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            x_data, y_data = data\r\n",
    "            img = paddle.to_tensor(x_data)\r\n",
    "            label = paddle.to_tensor(y_data)\r\n",
    "            # 运行模型前向计算，得到预测值\r\n",
    "            logits = model(img)\r\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label)\r\n",
    "            avg_loss = paddle.mean(loss)\r\n",
    "\r\n",
    "            if batch_id % 10 == 0:\r\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\r\n",
    "            # 反向传播，更新权重，清除梯度\r\n",
    "            avg_loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.clear_grad()\r\n",
    "\r\n",
    "        model.eval()\r\n",
    "        accuracies = []\r\n",
    "        losses = []\r\n",
    "        for batch_id, data in enumerate(valid_loader()):\r\n",
    "            x_data, y_data = data\r\n",
    "            img = paddle.to_tensor(x_data)\r\n",
    "            label = paddle.to_tensor(y_data)\r\n",
    "            # 运行模型前向计算，得到预测值\r\n",
    "            logits = model(img)\r\n",
    "            # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\r\n",
    "            # 计算sigmoid后的预测概率，进行loss计算\r\n",
    "            pred = F.sigmoid(logits)\r\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label)\r\n",
    "            # 计算预测概率小于0.5的类别\r\n",
    "            pred2 = pred * (-1.0) + 1.0\r\n",
    "            # 得到两个类别的预测概率，并沿第一个维度级联\r\n",
    "            pred = paddle.concat([pred2, pred], axis=1)\r\n",
    "            acc = paddle.metric.accuracy(pred, paddle.cast(label, dtype='int64'))\r\n",
    "\r\n",
    "            accuracies.append(acc.numpy())\r\n",
    "            losses.append(loss.numpy())\r\n",
    "        print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\r\n",
    "        model.train()\r\n",
    "\r\n",
    "        paddle.save(model.state_dict(), 'palm.pdparams')\r\n",
    "        paddle.save(optimizer.state_dict(), 'palm.pdopt')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义评估过程\r\n",
    "def evaluation(model, filenames,params_file_path):\r\n",
    "\r\n",
    "    # 开启0号GPU预估\r\n",
    "    use_gpu = True\r\n",
    "    paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\r\n",
    "\r\n",
    "    print('start evaluation .......')\r\n",
    "\r\n",
    "    #加载模型参数\r\n",
    "    model_state_dict = paddle.load(params_file_path)\r\n",
    "    model.load_dict(model_state_dict)\r\n",
    "    model.eval()\r\n",
    "    eval_loader = data_loader(DATADIR, filenames,\r\n",
    "                        batch_size=10, mode='eval')\r\n",
    "\r\n",
    "    acc_set = []\r\n",
    "    avg_loss_set = []\r\n",
    "    \r\n",
    "    for batch_id, data in enumerate(eval_loader()):\r\n",
    "        x_data, y_data = data\r\n",
    "        img = paddle.to_tensor(x_data)\r\n",
    "        label = paddle.to_tensor(y_data)\r\n",
    "        # 运行模型前向计算，得到预测值\r\n",
    "        logits = model(img)\r\n",
    "        # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\r\n",
    "        # 计算sigmoid后的预测概率，进行loss计算\r\n",
    "        pred = F.sigmoid(logits)\r\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, label)\r\n",
    "        # 计算预测概率小于0.5的类别\r\n",
    "        pred2 = pred * (-1.0) + 1.0\r\n",
    "        # 得到两个类别的预测概率，并沿第一个维度级联\r\n",
    "        pred = paddle.concat([pred2, pred], axis=1)\r\n",
    "        acc = paddle.metric.accuracy(pred, paddle.cast(label, dtype='int64'))\r\n",
    "\r\n",
    "        acc_set.append(acc.numpy())\r\n",
    "        avg_loss_set.append(loss.numpy())\r\n",
    "    print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(acc_set), np.mean(avg_loss_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加载测试数据\r\n",
    "def load_p_data(datadir,filenames,num_begin,num_end):\r\n",
    "        # 将datadir目录下的文件列出来，每条文件都要读入\r\n",
    "        def reader():\r\n",
    "            batch_imgs = []\r\n",
    "            batch_labels = []\r\n",
    "            name_set=[]\r\n",
    "            for name in filenames[num_begin:num_end]:\r\n",
    "                filepath = os.path.join(datadir, name)\r\n",
    "                img = cv2.imread(filepath)\r\n",
    "                img = transform_img(img)\r\n",
    "                if name[0] == 'H' or name[0] == 'N':\r\n",
    "                    # H开头的文件名表示高度近似，N开头的文件名表示正常视力\r\n",
    "                    # 高度近视和正常视力的样本，都不是病理性的，属于负样本，标签为0\r\n",
    "                    label = 0\r\n",
    "                elif name[0] == 'P':\r\n",
    "                    # P开头的是病理性近视，属于正样本，标签为1\r\n",
    "                    label = 1\r\n",
    "                else:\r\n",
    "                    raise('Not excepted file name')\r\n",
    "                # 每读取一个样本的数据，就将其放入数据列表中\r\n",
    "                batch_imgs.append(img)\r\n",
    "                batch_labels.append(label)\r\n",
    "                name_set.append(name)\r\n",
    "\r\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "            yield imgs_array, labels_array,name_set\r\n",
    "        return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#在数据集中抽取选中的数据作预测\r\n",
    "def predict(model,datadir,filenames,num_begin,num_end,params_file_path):\r\n",
    "    # 开启0号GPU预估\r\n",
    "    use_gpu = True\r\n",
    "    paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\r\n",
    "\r\n",
    "    print('start test .......')\r\n",
    "\r\n",
    "    #加载模型参数\r\n",
    "    model_state_dict = paddle.load(params_file_path)\r\n",
    "    model.load_dict(model_state_dict)\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    test_loader=load_p_data(datadir,filenames,num_begin,num_end)\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data, y_data, name_data = data\r\n",
    "        img = paddle.to_tensor(x_data)\r\n",
    "        label = paddle.to_tensor(y_data)\r\n",
    "        # 运行模型前向计算，得到预测值\r\n",
    "        logits = model(img)\r\n",
    "        # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\r\n",
    "        pred = F.sigmoid(logits)\r\n",
    "        t = np.array(pred)\r\n",
    "        t=np.around(t)\r\n",
    "        t=t.reshape(1,-1)\r\n",
    "        print(name_data)\r\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义神经网络 ResNet50\r\n",
    "# -*- coding:utf-8 -*-\r\n",
    "# ResNet模型代码\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "# ResNet中使用了BatchNorm层，在卷积层的后面加上BatchNorm以提升数值稳定性\r\n",
    "# 定义卷积批归一化块\r\n",
    "class ConvBNLayer(paddle.nn.Layer):\r\n",
    "    def __init__(self,\r\n",
    "                 num_channels,\r\n",
    "                 num_filters,\r\n",
    "                 filter_size,\r\n",
    "                 stride=1,\r\n",
    "                 groups=1,\r\n",
    "                 act=None):\r\n",
    "       \r\n",
    "        \"\"\"\r\n",
    "        num_channels, 卷积层的输入通道数\r\n",
    "        num_filters, 卷积层的输出通道数\r\n",
    "        stride, 卷积层的步幅\r\n",
    "        groups, 分组卷积的组数，默认groups=1不使用分组卷积\r\n",
    "        \"\"\"\r\n",
    "        super(ConvBNLayer, self).__init__()\r\n",
    "\r\n",
    "        # 创建卷积层\r\n",
    "        self._conv = nn.Conv2D(\r\n",
    "            in_channels=num_channels,\r\n",
    "            out_channels=num_filters,\r\n",
    "            kernel_size=filter_size,\r\n",
    "            stride=stride,\r\n",
    "            padding=(filter_size - 1) // 2,\r\n",
    "            groups=groups,\r\n",
    "            bias_attr=False)\r\n",
    "\r\n",
    "        # 创建BatchNorm层\r\n",
    "        self._batch_norm = paddle.nn.BatchNorm2D(num_filters)\r\n",
    "        \r\n",
    "        self.act = act\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        y = self._conv(inputs)\r\n",
    "        y = self._batch_norm(y)\r\n",
    "        if self.act == 'leaky':\r\n",
    "            y = F.leaky_relu(x=y, negative_slope=0.1)\r\n",
    "        elif self.act == 'relu':\r\n",
    "            y = F.relu(x=y)\r\n",
    "        return y\r\n",
    "\r\n",
    "# 定义残差块\r\n",
    "# 每个残差块会对输入图片做三次卷积，然后跟输入图片进行短接\r\n",
    "# 如果残差块中第三次卷积输出特征图的形状与输入不一致，则对输入图片做1x1卷积，将其输出形状调整成一致\r\n",
    "class BottleneckBlock(paddle.nn.Layer):\r\n",
    "    def __init__(self,\r\n",
    "                 num_channels,\r\n",
    "                 num_filters,\r\n",
    "                 stride,\r\n",
    "                 shortcut=True):\r\n",
    "        super(BottleneckBlock, self).__init__()\r\n",
    "        # 创建第一个卷积层 1x1\r\n",
    "        self.conv0 = ConvBNLayer(\r\n",
    "            num_channels=num_channels,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=1,\r\n",
    "            act='relu')\r\n",
    "        # 创建第二个卷积层 3x3\r\n",
    "        self.conv1 = ConvBNLayer(\r\n",
    "            num_channels=num_filters,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=3,\r\n",
    "            stride=stride,\r\n",
    "            act='relu')\r\n",
    "        # 创建第三个卷积 1x1，但输出通道数乘以4\r\n",
    "        self.conv2 = ConvBNLayer(\r\n",
    "            num_channels=num_filters,\r\n",
    "            num_filters=num_filters * 4,\r\n",
    "            filter_size=1,\r\n",
    "            act=None)\r\n",
    "\r\n",
    "        # 如果conv2的输出跟此残差块的输入数据形状一致，则shortcut=True\r\n",
    "        # 否则shortcut = False，添加1个1x1的卷积作用在输入数据上，使其形状变成跟conv2一致\r\n",
    "        if not shortcut:\r\n",
    "            self.short = ConvBNLayer(\r\n",
    "                num_channels=num_channels,\r\n",
    "                num_filters=num_filters * 4,\r\n",
    "                filter_size=1,\r\n",
    "                stride=stride)\r\n",
    "\r\n",
    "        self.shortcut = shortcut\r\n",
    "\r\n",
    "        self._num_channels_out = num_filters * 4\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        y = self.conv0(inputs)\r\n",
    "        conv1 = self.conv1(y)\r\n",
    "        conv2 = self.conv2(conv1)\r\n",
    "\r\n",
    "        # 如果shortcut=True，直接将inputs跟conv2的输出相加\r\n",
    "        # 否则需要对inputs进行一次卷积，将形状调整成跟conv2输出一致\r\n",
    "        if self.shortcut:\r\n",
    "            short = inputs\r\n",
    "        else:\r\n",
    "            short = self.short(inputs)\r\n",
    "\r\n",
    "        y = paddle.add(x=short, y=conv2)\r\n",
    "        y = F.relu(y)\r\n",
    "        return y\r\n",
    "\r\n",
    "# 定义ResNet模型\r\n",
    "class ResNet(paddle.nn.Layer):\r\n",
    "    def __init__(self, layers=50, class_dim=1):\r\n",
    "        \"\"\"\r\n",
    "        \r\n",
    "        layers, 网络层数，可以是50, 101或者152\r\n",
    "        class_dim，分类标签的类别数\r\n",
    "        \"\"\"\r\n",
    "        super(ResNet, self).__init__()\r\n",
    "        self.layers = layers\r\n",
    "        supported_layers = [50, 101, 152]\r\n",
    "        assert layers in supported_layers, \\\r\n",
    "            \"supported layers are {} but input layer is {}\".format(supported_layers, layers)\r\n",
    "\r\n",
    "        if layers == 50:\r\n",
    "            #ResNet50包含多个模块，其中第2到第5个模块分别包含3、4、6、3个残差块\r\n",
    "            depth = [3, 4, 6, 3]\r\n",
    "        elif layers == 101:\r\n",
    "            #ResNet101包含多个模块，其中第2到第5个模块分别包含3、4、23、3个残差块\r\n",
    "            depth = [3, 4, 23, 3]\r\n",
    "        elif layers == 152:\r\n",
    "            #ResNet152包含多个模块，其中第2到第5个模块分别包含3、8、36、3个残差块\r\n",
    "            depth = [3, 8, 36, 3]\r\n",
    "        \r\n",
    "        # 残差块中使用到的卷积的输出通道数\r\n",
    "        num_filters = [64, 128, 256, 512]\r\n",
    "\r\n",
    "        # ResNet的第一个模块，包含1个7x7卷积，后面跟着1个最大池化层\r\n",
    "        self.conv = ConvBNLayer(\r\n",
    "            num_channels=3,\r\n",
    "            num_filters=64,\r\n",
    "            filter_size=7,\r\n",
    "            stride=2,\r\n",
    "            act='relu')\r\n",
    "        self.pool2d_max = nn.MaxPool2D(\r\n",
    "            kernel_size=3,\r\n",
    "            stride=2,\r\n",
    "            padding=1)\r\n",
    "\r\n",
    "        # ResNet的第二到第五个模块c2、c3、c4、c5\r\n",
    "        self.bottleneck_block_list = []\r\n",
    "        num_channels = 64\r\n",
    "        for block in range(len(depth)):\r\n",
    "            shortcut = False\r\n",
    "            for i in range(depth[block]):\r\n",
    "                bottleneck_block = self.add_sublayer(\r\n",
    "                    'bb_%d_%d' % (block, i),\r\n",
    "                    BottleneckBlock(\r\n",
    "                        num_channels=num_channels,\r\n",
    "                        num_filters=num_filters[block],\r\n",
    "                        stride=2 if i == 0 and block != 0 else 1, # c3、c4、c5将会在第一个残差块使用stride=2；其余所有残差块stride=1\r\n",
    "                        shortcut=shortcut))\r\n",
    "                num_channels = bottleneck_block._num_channels_out\r\n",
    "                self.bottleneck_block_list.append(bottleneck_block)\r\n",
    "                shortcut = True\r\n",
    "\r\n",
    "        # 在c5的输出特征图上使用全局池化\r\n",
    "        self.pool2d_avg = paddle.nn.AdaptiveAvgPool2D(output_size=1)\r\n",
    "\r\n",
    "        # stdv用来作为全连接层随机初始化参数的方差\r\n",
    "        import math\r\n",
    "        stdv = 1.0 / math.sqrt(2048 * 1.0)\r\n",
    "        \r\n",
    "        # 创建全连接层，输出大小为类别数目，经过残差网络的卷积和全局池化后，\r\n",
    "        # 卷积特征的维度是[B,2048,1,1]，故最后一层全连接的输入维度是2048\r\n",
    "        self.out = nn.Linear(in_features=2048, out_features=class_dim,\r\n",
    "                      weight_attr=paddle.ParamAttr(\r\n",
    "                          initializer=paddle.nn.initializer.Uniform(-stdv, stdv)))\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        y = self.conv(inputs)\r\n",
    "        y = self.pool2d_max(y)\r\n",
    "        for bottleneck_block in self.bottleneck_block_list:\r\n",
    "            y = bottleneck_block(y)\r\n",
    "        y = self.pool2d_avg(y)\r\n",
    "        y = paddle.reshape(y, [y.shape[0], -1])\r\n",
    "        y = self.out(y)\r\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "start training ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 0, loss is: [0.67699844]\n",
      "epoch: 0, batch_id: 10, loss is: [0.7729627]\n",
      "epoch: 0, batch_id: 20, loss is: [0.7365789]\n",
      "epoch: 0, batch_id: 30, loss is: [0.59878033]\n",
      "[validation] accuracy/loss: 0.7599999308586121/0.5259617567062378\n",
      "epoch: 1, batch_id: 0, loss is: [0.434448]\n",
      "epoch: 1, batch_id: 10, loss is: [0.40699005]\n",
      "epoch: 1, batch_id: 20, loss is: [0.49765036]\n",
      "epoch: 1, batch_id: 30, loss is: [0.33471498]\n",
      "[validation] accuracy/loss: 0.8100000619888306/0.4256131052970886\n",
      "epoch: 2, batch_id: 0, loss is: [0.28392982]\n",
      "epoch: 2, batch_id: 10, loss is: [0.6830715]\n",
      "epoch: 2, batch_id: 20, loss is: [0.5263477]\n",
      "epoch: 2, batch_id: 30, loss is: [0.7211212]\n",
      "[validation] accuracy/loss: 0.8999999761581421/0.27760475873947144\n",
      "epoch: 3, batch_id: 0, loss is: [0.30452743]\n",
      "epoch: 3, batch_id: 10, loss is: [0.1176555]\n",
      "epoch: 3, batch_id: 20, loss is: [1.0202836]\n",
      "epoch: 3, batch_id: 30, loss is: [0.10208807]\n",
      "[validation] accuracy/loss: 0.9024999737739563/0.2556475102901459\n",
      "epoch: 4, batch_id: 0, loss is: [0.22765188]\n",
      "epoch: 4, batch_id: 10, loss is: [0.29931164]\n",
      "epoch: 4, batch_id: 20, loss is: [0.3710094]\n",
      "epoch: 4, batch_id: 30, loss is: [0.6657139]\n",
      "[validation] accuracy/loss: 0.8975000381469727/0.2646353244781494\n",
      "start evaluation .......\n",
      "[validation] accuracy/loss: 0.7847222089767456/0.4193152189254761\n",
      "start test .......\n",
      "['P0191.jpg', 'N0015.jpg', 'P0162.jpg', 'P0008.jpg', 'P0159.jpg', 'N0121.jpg', 'P0103.jpg', 'H0007.jpg', 'P0098.jpg', 'P0122.jpg', 'P0209.jpg', 'P0207.jpg', 'P0152.jpg', 'P0113.jpg', 'N0111.jpg', 'N0047.jpg', 'P0056.jpg', 'P0195.jpg', 'N0113.jpg', 'P0198.jpg', 'N0080.jpg', 'P0104.jpg', 'N0049.jpg', 'P0053.jpg', 'H0006.jpg', 'N0061.jpg', 'P0023.jpg', 'N0114.jpg', 'N0091.jpg', 'N0096.jpg', 'P0072.jpg', 'P0035.jpg', 'N0019.jpg', 'P0030.jpg', 'N0064.jpg', 'P0066.jpg', 'P0026.jpg', 'P0102.jpg', 'P0045.jpg', 'P0076.jpg', 'P0090.jpg', 'P0042.jpg', 'N0032.jpg', 'P0029.jpg', 'H0003.jpg', 'P0044.jpg', 'N0068.jpg', 'P0146.jpg', 'P0194.jpg', 'P0106.jpg', 'P0108.jpg', 'P0143.jpg', 'N0093.jpg', 'N0125.jpg', 'N0054.jpg', 'N0140.jpg', 'H0026.jpg', 'N0076.jpg', 'P0184.jpg', 'P0006.jpg', 'N0018.jpg', 'N0055.jpg', 'N0025.jpg', 'P0073.jpg', 'N0031.jpg', 'N0071.jpg', 'P0173.jpg', 'P0149.jpg', 'P0144.jpg', 'P0063.jpg', 'P0175.jpg', 'P0069.jpg', 'P0022.jpg', 'P0074.jpg', 'P0211.jpg', 'H0009.jpg', 'N0006.jpg', 'P0027.jpg']\n",
      "[[1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1.\n",
      "  0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      "  0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      "  0. 1. 1. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#进入保存参数的目录\r\n",
    "%cd /home/aistudio/\r\n",
    "#训练网络\r\n",
    "#加载数据\r\n",
    "traindata,testdata=load_data()\r\n",
    "model = ResNet()\r\n",
    "# 定义优化器\r\n",
    "opt = paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=model.parameters(), weight_decay=0.001)\r\n",
    "# 启动训练过程\r\n",
    "train_pm(model, opt,traindata)\r\n",
    "#启动评估过程\r\n",
    "evaluation(model,testdata, params_file_path=\"palm.pdparams\")\r\n",
    "#模型预测，取指定的测试集预测\r\n",
    "predict(model,DATADIR,testdata,num_begin=0,num_end=-1,params_file_path=\"palm.pdparams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
