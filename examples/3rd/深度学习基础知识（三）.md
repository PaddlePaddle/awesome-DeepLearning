# 深度学习基础知识（三）
标签（空格分隔）： 未分类

---
##归一化方法详解
###batch normalization（批归一化） 

 对于前馈神经网络第 l 隐层，神经元的输入为 a, 激活函数为 f, 激活函数输出为 h。权值 w 通过 SGD学习得到
![此处输入图片的描述][1]
 深度学习中的一个挑战就是对于上面公式中 一层的权值 w 的梯度 高度依赖于前一层神经元的输出，特别是当这些输出的改变高度相关的时候。这个问题有个名字，叫 covariate shift）。 针对此问题 [Ioffe and Szegedy, 2015] 提出了 Batch normalization 来降低这个 covariate shift 的影响。对于每个隐层的神经元，我们在所有的训练样本上归一化该神经元的输入。 
![此处输入图片的描述][2]
在整个训练样本上计算均值方差，然后对神经元的输入进行归一化。由于对整个训练样本计算均值方差不太有效率（对于训练来说），所以提出了 在最小训练批次上估计 均值方差。这个约束导致Batch normalization 难以应用于 recurrent neural networks。

###Layer normalization
针对前面提到的 Batch normalization 的问题，我们提出了 Layer normalization。

我们知道BN的两个缺点的产生原因均是因为计算归一化统计量时计算的样本数太少。LN是一个独立于batch size的算法，所以无论样本数多少都不会影响参与LN计算的数据量，从而解决BN的两个问题。LN的做法如下图左侧所示：根据样本的特征数做归一化。

先看MLP中的LN。设 H 是一层中隐层节点的数量， l 是MLP的层数，我们可以计算LN的归一化统计量 μ 和 σ  ： 
![此处输入图片的描述][3]
注意上面统计量的计算是和样本数量没有关系的，它的数量只取决于隐层节点的数量，所以只要隐层节点的数量足够多，我们就能保证LN的归一化统计量足够具有代表性。通过 μ 和 σ 可以得到归一化后的值  ：
![此处输入图片的描述][4]
其中 ![\[公式\]][5] 是一个很小的小数，防止除0（论文中忽略了这个参数）。

在LN中我们也需要一组参数来保证归一化操作不会破坏之前的信息，在LN中这组参数叫做增益（gain） g 和偏置（bias） b （等同于BN中的 γ和 β ）。假设激活函数为 f ，最终LN的输出为：
![此处输入图片的描述][6]
合并公式(2)，(3)并忽略参数 l ，我们有

![此处输入图片的描述][7]

###LN模型
![此处输入图片的描述][8]

###LN作用
LN的操作类似于将BN做了一个“转置”，对同一层网络的输出做一个标准化。注意，同一层的输出是单个图片的输出，比如对于一个batch为32的神经网络训练，会有32个均值和方差被得出，每个均值和方差都是由单个图片的所有channel之间做一个标准化。这么操作，就使得LN不受batch size的影响。同时，LN可以很好地用到序列型网络如RNN中。同时，LR在训练过程和inference过程都会有，这就是和BN很大的差别了。

在Kaiming ECCV2018的paper里拿LN和BN做了比较，结果是在较大batch size的时候BN的表现比LN好很多。大大小小的主流网络都在用BN也证明了这一点。

LN拼性能暂时不是BN的对手，但LN的应用范围更广，受限小。这是BN也无法比拟的

###LN应用场景


在RNN中随着t的增长，通常会出现梯度消失和梯度爆炸的问题，这是由于时间维展开，梯度不稳定，或者出现小于1的情况，或者出现大于1的情况，在链式法则的作用下而导致的。而如果采用layer normalized RNN,归一化项会re-scaling inputs to a layer, 使得隐层和隐层之间的梯度计算更稳定。


##可变形卷积方法详解（Deformable Convolutional Networks）
###DCN V1

###背景

在计算机视觉领域，同一物体在不同场景，角度中未知的几何变换是检测/识别的一大挑战，通常来说我们有两种做法:

(1)通过充足的数据增强，扩充足够多的样本去增强模型适应尺度变换的能力。

(2)设置一些针对几何变换不变的特征或者算法，比如SIFT和sliding windows。

两种方法都有缺陷，第一种方法因为样本的局限性显然模型的泛化能力比较低，无法泛化到一般场景中，第二种方法则因为手工设计的不变特征和算法对于过于复杂的变换是很难的而无法设计。所以作者提出了Deformable Conv（可变形卷积）和 Deformable Pooling（可变形池化）来解决这个问题。

###可变形卷积
可变形卷积顾名思义就是卷积的位置是可变形的，并非在传统的N × N的网格上做卷积，这样的好处就是更准确地提取到我们想要的特征（传统的卷积仅仅只能提取到矩形框的特征），通过一张图我们可以更直观地了解：
![此处输入图片的描述][9]

在上面这张图里面，左边传统的卷积显然没有提取到完整绵羊的特征，而右边的可变形卷积则提取到了完整的不规则绵羊的特征。

那可变卷积实际上是怎么做的呢？其实就是在每一个卷积采样点加上了一个偏移量，如下图所示：
![此处输入图片的描述][10]

(a) 所示的正常卷积规律的采样 9 个点（绿点），(b)©(d) 为可变形卷积，在正常的采样坐标上加上一个位移量（蓝色箭头），其中 ©(d) 作为 (b) 的特殊情况，展示了可变形卷积可以作为尺度变换，比例变换和旋转变换等特殊情况。

我们先看普通的卷积，以3x3卷积为例对于每个输出y(p0)，都要从x上采样9个位置，这9个位置都在中心位置x(p0)向四周扩散，(-1,-1)代表x(p0)的左上角，(1,1)代表x(p0)的右下角。
![此处输入图片的描述][11]
所以传统的卷积输出就是（其中 P n P_n Pn​就是网格中的n个点）：

![此处输入图片的描述][12]
正如我们上面阐述的可变形卷积，他就是在传统的卷积操作上加入了一个偏移量，正是这个偏移量才让卷积变形为不规则的卷积，这里要注意这个偏移量可以是小数，所以下面的式子的特征值需要通过双线性插值的方法来计算。：
![此处输入图片的描述][13]
那这个偏移量如何算呢？我们来看：
![此处输入图片的描述][14]
对于输入的一张feature map，假设原来的卷积操作是3×3的，那么为了学习偏移量offset，我们定义另外一个3×3的卷积层（图中上面的那层），输出的维度其实就是原来feature map大小，channel数等于2N（分别表示x,y方向的偏移）。下面的可变形卷积可以看作先基于上面那部分生成的offset做了一个插值操作，然后再执行普通的卷积。

###可变形卷积的可视化
![此处输入图片的描述][15]
我们可以从上图看到，可以看到当绿色点在目标上时，红色点所在区域也集中在目标位置，并且基本能够覆盖不同尺寸的目标，因此经过可变形卷积，我们可以更好地提取出感兴趣物体的完整特征，效果是非常不错的。

##DCN V2
DCN v1听起来不错，但其实也有问题：我们的可变形卷积有可能引入了无用的上下文（区域）来干扰我们的特征提取，这显然会降低算法的表现
![此处输入图片的描述][16]

我们可以看到虽然DCN v1更能覆盖整个物体，但是同时也会引入一些无关的背景，这造成了干扰，所以作者提出了三个解决方法：

（1）More Deformable Conv Layers（使用更多的可变形卷积）。

（2）Modulated Deformable Modules（在DCNv1基础（添加offset）上添加每个采样点的权重）

（3）R-CNN Feature Mimicking（模拟R-CNN的feature）。

在DCN v1中只在conv 5中使用了三个可变形卷积，在DCN v2中把conv3到conv5都换成了可变形卷积，提高算法对几何形变的建模能力。![此处输入图片的描述][17]

###在DCNv1基础（添加offset）上添加每个采样点的权重
我们知道在DCN v1中的卷积是添加了一个offset Δ P 
![此处输入图片的描述][18]
为了解决引入了一些无关区域的问题，在DCN v2中我们不只添加每一个采样点的偏移，还添加了一个权重系数 Δ m k \Delta{m_k} Δmk​，来区分我们引入的区域是否为我们感兴趣的区域，假如这个采样点的区域我们不感兴趣，则把权重学习为0即可：
![此处输入图片的描述][19]
总的来说，DCN v1中引入的offset是要寻找有效信息的区域位置，DCN v2中引入权重系数是要给找到的这个位置赋予权重，这两方面保证了有效信息的准确提取。

###DCN v2可视化

通过实验结果我们也可以看到DCN v2更能集中在物体的完整有效的区域：
![此处输入图片的描述][20]


  [1]: https://user-images.githubusercontent.com/86996619/125740175-a4ebecf9-9650-43a9-9795-7c4ba4ff49d6.png
  [2]: https://user-images.githubusercontent.com/86996619/125740182-f0eeeac7-e895-4680-aca6-d20d0ad2aa0f.png
  [3]: https://user-images.githubusercontent.com/86996619/125740192-17532ce4-a1b7-4cff-ac56-c37bcbcbb0db.png
  [4]: https://www.zhihu.com/equation?tex=%20%5Chat%7B%5Cmathbf%7Ba%7D%7D%5El%20=%20%5Cfrac%7B%5Cmathbf%7Ba%7D%5El%20-%20%5Cmu%5El%7D%7B%5Csqrt%7B%28%5Csigma%5El%29%5E2%20%2b%20%5Cepsilon%7D%7D%20%5Ctag2
  [5]: https://www.zhihu.com/equation?tex=%5Cepsilon
  [6]: https://www.zhihu.com/equation?tex=%5Cmathbf%7Bh%7D%5El%20=%20f%28%5Cmathbf%7Bg%7D%5El%20%5Codot%20%5Chat%7B%5Cmathbf%7Ba%7D%7D%5El%20%2b%20%5Cmathbf%7Bb%7D%5El%29%20%5Ctag3
  [7]: https://www.zhihu.com/equation?tex=%5Cmathbf%7Bh%7D%20=%20f%28%5Cfrac%7B%5Cmathbf%7Bg%7D%7D%7B%5Csqrt%7B%5Csigma%5E2%20%2b%20%5Cepsilon%7D%7D%20%5Codot%20%28%5Cmathbf%7Ba%7D%20-%20%5Cmu%29%2b%20%5Cmathbf%7Bb%7D%29%20%5Ctag4
  [8]: https://user-images.githubusercontent.com/86996619/125741499-7f211fc3-e4d4-4e4b-8f48-5e1f8209007c.png
  [9]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS00Y2YzYWFmNDdjYjhhNDFkLnBuZw?x-oss-process=image/format,png
  [10]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS1lYjQ2MWRjZDk2MWE3MzllLnBuZw?x-oss-process=image/format,png
  [11]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS0yZWM5OGUyZWE1OTQzYTQ3LnBuZw?x-oss-process=image/format,png
  [12]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS1mYWU4ZmZkM2M2MjUzMDVmLnBuZw?x-oss-process=image/format,png
  [13]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS0xZWFlYTgzYjdmNjJjMDcyLnBuZw?x-oss-process=image/format,png
  [14]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS1kN2FmYTZkYzA2NjU4NzkzLnBuZw?x-oss-process=image/format,png
  [15]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS1kZTNkOTkzZDAxNzI3ZmUxLnBuZw?x-oss-process=image/format,png
  [16]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS0zOTNiMGMyYzExMDg3YTViLnBuZw?x-oss-process=image/format,png
  [17]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS01NTFiNWNiYTZjNjQwYjU4LnBuZw?x-oss-process=image/format,png
  [18]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS02NGVkNmM3NDkwZGI2YTc3LnBuZw?x-oss-process=image/format,png
  [19]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS0yYTZjZDMyOTZiMzZlYTVkLnBuZw?x-oss-process=image/format,png
  [20]: https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTcxMzExNS02NTQxZmZkNzliMjc4ZTBhLnBuZw?x-oss-process=image/format,png