{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**1.深度学习的基础知识**\n",
    "**①深度学习发展历史**\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2f48157518b443488f2e1404ed96cb0832fd0d86424f4374ae8bbf8274b3ff49)\n",
    "   由图可以明显看出DL在从06年崛起之前经历了两个低谷，这两个低谷也将神经网络的发展分为了三个不同的阶段，下面就分别讲述这三个阶段。\n",
    "**第一代神经网络（1958~1969）**\n",
    "\n",
    "最早的神经网络的思想起源于1943年的MCP人工神经元模型，当时是希望能够用计算机来模拟人的神经元反应的过程，该模型将神经元简化为了三个过程：输入信号线性加权，求和，非线性激活（阈值法）。如下图所示：![](https://ai-studio-static-online.cdn.bcebos.com/65170df3624d4f2d83e947913c0ba9ad5f90eda75cf6410db3596c2ef966d463)\n",
    "第一次将MCP用于机器学习（分类）的当属1958年Rosenblatt发明的感知器（perceptron）算法。该算法使用MCP模型对输入的多维数据进行二分类，且能够使用梯度下降法从训练样本中自动学习更新权值。1962年，该方法被证明为能够收敛，理论与实践效果引起第一次神经网络的浪潮。\n",
    "\n",
    "然而学科发展的历史不总是一帆风顺的。\n",
    "\n",
    "1969年，美国数学家及人工智能先驱Minsky在其著作中证明了感知器本质上是一种线性模型，只能处理线性分类问题，就连最简单的XOR（亦或）问题都无法正确分类。这等于直接宣判了感知器的死刑，神经网络的研究也陷入了近20年的停滞。\n",
    "\n",
    "**第二代神经网络（1986~1998）**\n",
    "\n",
    "第一次打破非线性诅咒的当属现代DL大牛Hinton，其在1986年发明了适用于多层感知器（MLP）的BP算法，并采用Sigmoid进行非线性映射，有效解决了非线性分类和学习的问题。该方法引起了神经网络的第二次热潮。\n",
    "\n",
    "1989年，Robert Hecht-Nielsen证明了MLP的万能逼近定理，即对于任何闭区间内的一个连续函数f，都可以用含有一个隐含层的BP网络来逼近该定理的发现极大的鼓舞了神经网络的研究人员。\n",
    "\n",
    "也是在1989年，LeCun发明了卷积神经网络-LeNet，并将其用于数字识别，且取得了较好的成绩，不过当时并没有引起足够的注意。\n",
    "\n",
    "值得强调的是在1989年以后由于没有特别突出的方法被提出，且NN一直缺少相应的严格的数学理论支持，神经网络的热潮渐渐冷淡下去。冰点来自于1991年，BP算法被指出存在梯度消失问题，即在误差梯度后向传递的过程中，后层梯度以乘性方式叠加到前层，由于Sigmoid函数的饱和特性，后层梯度本来就小，误差梯度传到前层时几乎为0，因此无法对前层进行有效的学习，该发现对此时的NN发展雪上加霜。\n",
    "\n",
    "1997年，LSTM模型被发明，尽管该模型在序列建模上的特性非常突出，但由于正处于NN的下坡期，也没有引起足够的重视。\n",
    "\n",
    "**统计学习方法的春天（1986~2006）**\n",
    "\n",
    "1986年，决策树方法被提出，很快ID3，ID4，CART等改进的决策树方法相继出现，到目前仍然是非常常用的一种机器学习方法。该方法也是符号学习方法的代表。 \n",
    "\n",
    "1995年，线性SVM被统计学家Vapnik提出。该方法的特点有两个：由非常完美的数学理论推导而来（统计学与凸优化等），符合人的直观感受（最大间隔）。不过，最重要的还是该方法在线性分类的问题上取得了当时最好的成绩。 \n",
    "\n",
    "1997年，AdaBoost被提出，该方法是PAC（Probably Approximately Correct）理论在机器学习实践上的代表，也催生了集成方法这一类。该方法通过一系列的弱分类器集成，达到强分类器的效果。 \n",
    "\n",
    "2000年，KernelSVM被提出，核化的SVM通过一种巧妙的方式将原空间线性不可分的问题，通过Kernel映射成高维空间的线性可分问题，成功解决了非线性分类的问题，且分类效果非常好。至此也更加终结了NN时代。 \n",
    "\n",
    "2001年，随机森林被提出，这是集成方法的另一代表，该方法的理论扎实，比AdaBoost更好的抑制过拟合问题，实际效果也非常不错。 \n",
    "\n",
    "2001年，一种新的统一框架-图模型被提出，该方法试图统一机器学习混乱的方法，如朴素贝叶斯，SVM，隐马尔可夫模型等，为各种学习方法提供一个统一的描述框架。\n",
    "\n",
    "**第三代神经网络-DL（2006-至今）**\n",
    "\n",
    "该阶段又分为两个时期：快速发展期（2006~2012）与爆发期（2012~至今）\n",
    "\n",
    "*快速发展期（2006~2012）*\n",
    "\n",
    "2006年，DL元年。是年，Hinton提出了深层网络训练中梯度消失问题的解决方案：无监督预训练对权值进行初始化+有监督训练微调。其主要思想是先通过自学习的方法学习到训练数据的结构（自动编码器），然后在该结构上进行有监督训练微调。但是由于没有特别有效的实验验证，该论文并没有引起重视。\n",
    "\n",
    "2011年，ReLU激活函数被提出，该激活函数能够有效的抑制梯度消失问题。\n",
    "\n",
    "2011年，微软首次将DL应用在语音识别上，取得了重大突破。\n",
    "\n",
    "*爆发期（2012~至今）*\n",
    "\n",
    "2012年，Hinton课题组为了证明深度学习的潜力，首次参加ImageNet图像识别比赛，其通过构建的CNN网络AlexNet一举夺得冠军，且碾压第二名（SVM方法）的分类性能。也正是由于该比赛，CNN吸引到了众多研究者的注意。 \n",
    "\n",
    "AlexNet的创新点： \n",
    "\n",
    "（1）首次采用ReLU激活函数，极大增大收敛速度且从根本上解决了梯度消失问题；（2）由于ReLU方法可以很好抑制梯度消失问题，AlexNet抛弃了“预训练+微调”的方法，完全采用有监督训练。也正因为如此，DL的主流学习方法也因此变为了纯粹的有监督学习；（3）扩展了LeNet5结构，添加Dropout层减小过拟合，LRN层增强泛化能力/减小过拟合；（4）首次采用GPU对计算进行加速；\n",
    "\n",
    "2013,2014,2015年，通过ImageNet图像识别比赛，DL的网络结构，训练方法，GPU硬件的不断进步，促使其在其他领域也在不断的征服战场\n",
    "\n",
    "2015年，Hinton，LeCun，Bengio论证了局部极值问题对于DL的影响，结果是Loss的局部极值问题对于深层网络来说影响可以忽略。该论断也消除了笼罩在神经网络上的局部极值问题的阴霾。具体原因是深层网络虽然局部极值非常多，但是通过DL的BatchGradientDescent优化方法很难陷进去，而且就算陷进去，其局部极小值点与全局极小值点也是非常接近，但是浅层网络却不然，其拥有较少的局部极小值点，但是却很容易陷进去，且这些局部极小值点与全局极小值点相差较大。论述原文其实没有证明，只是简单叙述，严密论证是猜的。。。\n",
    "\n",
    "2015，DeepResidualNet发明。分层预训练，ReLU和BatchNormalization都是为了解决深度神经网络优化时的梯度消失或者爆炸问题。但是在对更深层的神经网络进行优化时，又出现了新的Degradation问题，即”通常来说，如果在VGG16后面加上若干个单位映射，网络的输出特性将和VGG16一样，这说明更深次的网络其潜在的分类性能只可能>=VGG16的性能，不可能变坏，然而实际效果却是只是简单的加深VGG16的话，分类性能会下降（不考虑模型过拟合问题）“Residual网络认为这说明DL网络在学习单位映射方面有困难，因此设计了一个对于单位映射（或接近单位映射）有较强学习能力的DL网络，极大的增强了DL网络的表达能力。此方法能够轻松的训练高达150层的网络。\n",
    "\n",
    "**②人工智能、机器学习、深度学习有什么区别和联系？**\n",
    "**人工智能：从概念提出到走向繁荣**\n",
    "   1956年，几个计算机科学家相聚在达特茅斯会议，提出了“人工智能”的概念，梦想着用当时刚刚出现的计算机来构造复杂的、拥有与人类智慧同样本质特性的机器。其后，人工智能就一直萦绕于人们的脑海之中，并在科研实验室中慢慢孵化。之后的几十年，人工智能一直在两极反转，或被称作人类文明耀眼未来的预言，或被当成技术疯子的狂想扔到垃圾堆里。直到2012年之前，这两种声音还在同时存在。\n",
    "   2012年以后，得益于数据量的上涨、运算力的提升和机器学习新算法（深度学习）的出现，人工智能开始大爆发。据领英近日发布的《全球AI领域人才报告》显示，截至2017年一季度，基于领英平台的全球AI（人工智能）领域技术人才数量超过190万，仅国内人工智能人才缺口达到500多万。\n",
    "   人工智能的研究领域也在不断扩大，图二展示了人工智能研究的各个分支，包括专家系统、机器学习、进化计算、模糊逻辑、计算机视觉、自然语言处理、推荐系统等。\n",
    "   但目前的科研工作都集中在弱人工智能这部分，并很有希望在近期取得重大突破，电影里的人工智能多半都是在描绘强人工智能，而这部分在目前的现实世界里难以真正实现（通常将人工智能分为弱人工智能和强人工智能，前者让机器具备观察和感知的能力，可以做到一定程度的理解和推理，而强人工智能让机器获得自适应能力，解决一些之前没有遇到过的问题）。弱人工智能有希望取得突破，是如何实现的，“智能”又从何而来呢？这主要归功于一种实现人工智能的方法——机器学习。\n",
    "\n",
    "**机器学习：一种实现人工智能的方法**\n",
    "   机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来“训练”，通过各种算法从数据中学习如何完成任务。\n",
    "   举个简单的例子，当我们浏览网上商城时，经常会出现商品推荐的信息。这是商城根据你往期的购物记录和冗长的收藏清单，识别出这其中哪些是你真正感兴趣，并且愿意购买的产品。这样的决策模型，可以帮助商城为客户提供建议并鼓励产品消费。\n",
    "   机器学习直接来源于早期的人工智能领域，传统的算法包括决策树、聚类、贝叶斯分类、支持向量机、EM、Adaboost等等。从学习方法上来分，机器学习算法可以分为监督学习（如分类问题）、无监督学习（如聚类问题）、半监督学习、集成学习、深度学习和强化学习。\n",
    "   传统的机器学习算法在指纹识别、基于Haar的人脸检测、基于HoG特征的物体检测等领域的应用基本达到了商业化的要求或者特定场景的商业化水平，但每前进一步都异常艰难，直到深度学习算法的出现。\n",
    "   \n",
    "**深度学习：一种实现机器学习的技术**\n",
    "   深度学习本来并不是一种独立的学习方法，其本身也会用到有监督和无监督的学习方法来训练深度神经网络。但由于近几年该领域发展迅猛，一些特有的学习手段相继被提出（如残差网络），因此越来越多的人将其单独看作一种学习的方法。\n",
    "   最初的深度学习是利用深度神经网络来解决特征表达的一种学习过程。深度神经网络本身并不是一个全新的概念，可大致理解为包含多个隐含层的神经网络结构。为了提高深层神经网络的训练效果，人们对神经元的连接方法和激活函数等方面做出相应的调整。其实有不少想法早年间也曾有过，但由于当时训练数据量不足、计算能力落后，因此最终的效果不尽如人意。\n",
    "   深度学习摧枯拉朽般地实现了各种任务，使得似乎所有的机器辅助功能都变为可能。无人驾驶汽车，预防性医疗保健，甚至是更好的电影推荐，都近在眼前，或者即将实现。\n",
    "\n",
    "**三者的区别和联系**\n",
    "   机器学习是一种实现人工智能的方法，深度学习是一种实现机器学习的技术。我们就用最简单的方法——同心圆，可视化地展现出它们三者的关系。\n",
    "   目前，业界有一种错误的较为普遍的意识，即“深度学习最终可能会淘汰掉其他所有机器学习算法”。这种意识的产生主要是因为，当下深度学习在计算机视觉、自然语言处理领域的应用远超过传统的机器学习方法，并且媒体对深度学习进行了大肆夸大的报道。\n",
    "   深度学习，作为目前最热的机器学习方法，但并不意味着是机器学习的终点。起码目前存在以下问题：\n",
    "   1. 深度学习模型需要大量的训练数据，才能展现出神奇的效果，但现实生活中往往会遇到小样本问题，此时深度学习方法无法入手，传统的机器学习方法就可以处理；\n",
    "   2. 有些领域，采用传统的简单的机器学习方法，可以很好地解决了，没必要非得用复杂的深度学习方法；\n",
    "   3. 深度学习的思想，来源于人脑的启发，但绝不是人脑的模拟，举个例子，给一个三四岁的小孩看一辆自行车之后，再见到哪怕外观完全不同的自行车，小孩也十有八九能做出那是一辆自行车的判断，也就是说，人类的学习过程往往不需要大规模的训练数据，而现在的深度学习方法显然不是对人脑的模拟。\n",
    "\n",
    "**③神经元、单层感知机、多层感知机**\n",
    "**神经元**\n",
    "一个神经元通常具有多个树突，主要用来接受传入信息；而轴突只有一条，轴突尾端有许多轴突末梢可以给其他多个神经元传递信息。轴突末梢跟其他神经元的树突产生连接，从而传递信号。这个连接的位置在生物学上叫做“突触”。突触之间的交流通过神经递质实现。\n",
    "下面对上面的这个模型进行抽象处理。首先考虑到神经元结构有多个树突，一个轴突可将其抽象为下图的黑箱结构：![](https://ai-studio-static-online.cdn.bcebos.com/04ef3c87c76943068678b884ce3299013703cefc5f4e441884472f3af4d5a383)\n",
    "但是黑箱结构有诸多不便，首先是不知道黑箱中的函数结构就不能为我们所用，其次是输入输出与黑箱的关系也无法量化。因此考虑将上述结构简化，首先把树突到细胞核的阶段简化为线性加权的过程（当然了，该过程也有可能是非线性的，但是我们可以把其非线性过程施加到后面的非线性函数以及多层网络结构中），其次把突触之间的信号传递简化为对求和结果的非线性变换，那么上述模型就变得清晰了：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1fb1cff3a5ed496ca381202fe35e09acad168822a11840b0956800994fb7cf95)\n",
    "\n",
    "**单层感知机**\n",
    "面我们介绍的神经元的基本模型实际就是一个感知机的模型，该词最早出现于1958年，计算科学家Rosenblatt提出的由两层神经元组成的神经网络。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/bb14be1dbf294204a9975b5b66d034652cbea2638ea84e7ca0ca95352622d4fa)对前面的模型进一步符号化，如下图所示：\n",
    "\n",
    "可以看到，感知机的基本模型包括：\n",
    "输入：x1,x2...xn,实际可能回比这更多,此处添加了一个偏置1，是为了平衡线性加权函数总是过零点的问题;\n",
    "权值：对应于每个输入都有一个加权的权值w1,w2...wN;\n",
    "激活函数：激活函数f对应于一个非线性函数，其选择有很多，本文后面会详细介绍;\n",
    "输出y：由激活激活函数进行处理后的结果，往往是区分度较大的非连续值用于分类;\n",
    "\n",
    "激活函数\n",
    "   首先我们来了解一下激活函数有什么意义，我们前面提到，我们把权重加权的过程看作线性加权，此时该系统为一线性系统，能够解决的问题有限，其非线性部分在激活函数中体现。使用激活函数能够使神经网络更加适应生活实际中的非线性问题。\n",
    "   \n",
    "**多层感知机**\n",
    " 多层感知机（MLP，Multilayer Perceptron）也叫人工神经网络（ANN，Artificial Neural Network），除了输入输出层，它中间可以有多个隐层，最简单的MLP只含一个隐层，即三层的结构，如下图：![](https://ai-studio-static-online.cdn.bcebos.com/412dc6d7699541d1aa7dbca21a31bca0352008cdcf3345e5b8e78306e4ec3f37)\n",
    "   从上图可以看到，多层感知机层与层之间是全连接的。多层感知机最底层是输入层，中间是隐藏层，最后是输出层。 \n",
    "   隐藏层的神经元怎么得来？首先它与输入层是全连接的，假设输入层用向量X表示，则隐藏层的输出就是 f (W1X+b1)，W1是权重（也叫连接系数），b1是偏置，函数f 可以是常用的sigmoid函数或者tanh函数：\n",
    "\n",
    "**④什么是前向传播**\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9d48986be2d44ea5aef3a312a97f63c51847b839ad73430eb11e21ee0aab5bc9)\n",
    "   如图所示，这里讲得已经很清楚了，前向传播的思想比较简单。\n",
    "举个例子，假设上一层结点i,j,k,…等一些结点与本层的结点w有连接，那么结点w的值怎么算呢？就是通过上一层的i,j,k等结点以及对应的连接权值进行加权和运算，最终结果再加上一个偏置项（图中为了简单省略了），最后在通过一个非线性函数（即激活函数），如ReLu，sigmoid等函数，最后得到的结果就是本层结点w的输出。\n",
    "最终不断的通过这种方法一层层的运算，得到输出层结果。\n",
    "\n",
    "**⑤什么是反向传播**\n",
    "BackPropagation算法是多层神经网络的训练中举足轻重的算法。简单的理解，它的确就是复合函数的链式法则，但其在实际运算中的意义比链式法则要大的多。要回答题主这个问题“如何直观的解释back propagation算法？” 需要先直观理解多层神经网络的训练。\n",
    "\n",
    "机器学习可以看做是数理统计的一个应用，在数理统计中一个常见的任务就是拟合，也就是给定一些样本点，用合适的曲线揭示这些样本点随着自变量的变化关系.\n",
    "\n",
    "深度学习同样也是为了这个目的，只不过此时，样本点不再限定为(x, y)点对，而可以是由向量、矩阵等等组成的广义点对(X,Y)。而此时，(X,Y)之间的关系也变得十分复杂，不太可能用一个简单函数表示。然而，人们发现可以用多层神经网络来表示这样的关系，而多层神经网络的本质就是一个多层复合的函数。借用网上找到的一幅图[1]，来直观描绘一下这种复合关系。![](https://ai-studio-static-online.cdn.bcebos.com/43390b4a59734ae2b1881a9a195bd98d74758588142e4ffaa9c1cb9a57535976)\n",
    "其对应的表达式如下：![](https://ai-studio-static-online.cdn.bcebos.com/33bb98133d58489c86508eced99d10f10dab9bfaffb24585bce1effaad4b739c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**房价预测的python+numpy实现**\n",
    "**1. 解压数据集，并且查看打印数据集内容**\n",
    "房价数据集只有两个标签，分别是房屋的面积和房价，为了便于处理，我们对数据进行归一化处理操作。 归一化的方式有多种，此次我们采用max-min归一化操作。\n",
    "\n",
    "基本上所有的数据在拿到后都必须进行归一化，至少有以下3条原因：\n",
    "\n",
    "1.过大或过小的数值范围会导致计算时的浮点上溢或下溢。\n",
    "\n",
    "2.不同的数值范围会导致不同属性对模型的重要性不同（至少在训练的初始阶段如此），而这个隐含的假设常常是不合理的。这会对优化的过程造成困难，使训练时间大大加长。\n",
    "\n",
    "3.很多的机器学习技巧/模型（例如L1，L2正则项，向量空间模型-Vector Space Model）都基于这样的假设：所有的属性取值都差不多是以0为均值且取值范围相近的。\n",
    "\n",
    "**数据集分割**\n",
    "\n",
    "将原始数据处理为可用数据后，为了评估模型的好坏，我们将数据分成两份：训练集和测试集。\n",
    "\n",
    "训练集数据用于调整模型的参数，即进行模型的训练，模型在这份数据集上的误差被称为训练误差； 测试集数据被用来测试，模型在这份数据集上的误差被称为测试误差。 我们训练模型的目的是为了通过从训练数据中找到规律来预测未知的新数据，所以测试误差是更能反映模型表现的指标。分割数据的比例要考虑到两个因素：更多的训练数据会降低参数估计的方差，从而得到更可信的模型；而更多的测试数据会降低测试误差的方差，从而得到更可信的测试误差。我们这个例子中设置的分割比例为8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>房屋面积</th>\n",
       "      <th>房价</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.87</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.74</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.24</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.19</td>\n",
       "      <td>780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.64</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     房屋面积     房价\n",
       "0   98.87  599.0\n",
       "1   68.74  450.0\n",
       "2   89.24  440.0\n",
       "3  129.19  780.0\n",
       "4   61.64  450.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "data_path='./房价预测/data/data.txt'\r\n",
    "colnames = ['房屋面积']+['房价']\r\n",
    "print_data = pd.read_csv(data_path, names = colnames)\r\n",
    "data=np.loadtxt(data_path,delimiter = ',')\r\n",
    "print_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the raw area : 199.96\n",
      "按列最大值，最小值，平均值： [ 199.96 2000.  ] [ 40.09 202.  ] [ 94.64454023 608.25057471]\n",
      "normalizatin: [0.65875686 0.77405419]\n"
     ]
    }
   ],
   "source": [
    "#axis=0,表示按列计算\r\n",
    "#data.shape[0]表示data中一共有多少列\r\n",
    "maximums, minimums, avgs = data.max(axis=0), data.min(axis=0), data.sum(axis=0)/data.shape[0]\r\n",
    "print(\"the raw area :\",data[:,0].max(axis = 0))\r\n",
    "print(\"按列最大值，最小值，平均值：\",maximums,minimums,avgs)\r\n",
    "data=(data-avgs)/(maximums-minimums)\r\n",
    "print('normalizatin:',data.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870\n",
      "696\n"
     ]
    }
   ],
   "source": [
    "### 数据集的分割，ratio为分割比例\r\n",
    "ratio = 0.8\r\n",
    "offset = int(data.shape[0]*ratio)\r\n",
    "train_data = data[:offset].copy()\r\n",
    "test_data = data[offset:].copy()\r\n",
    "print(len(data))\r\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对上述函数进行封装\r\n",
    "def data_load(data_path,ratio=0.8):\r\n",
    "    data=np.loadtxt(data_path,delimiter = ',',dtype='float32')\r\n",
    "    maximums, minimums, avgs = data.max(axis=0), data.min(axis=0), data.sum(axis=0)/data.shape[0]\r\n",
    "    #归一化\r\n",
    "    data=(data-avgs)/(maximums-minimums)\r\n",
    "    #数据集分割\r\n",
    "    ratio = 0.8\r\n",
    "    offset = int(data.shape[0]*ratio)\r\n",
    "    train_data = data[:offset].copy()\r\n",
    "    test_data = data[offset:].copy()\r\n",
    "    train_feature,train_label=train_data[:,:-1],train_data[:,-1]\r\n",
    "    test_feature,test_label=test_data[:,:-1],test_data[:,-1]\r\n",
    "    return train_feature,train_label,test_feature,test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**2.模型设计**\n",
    "假设房价和各影响因素之间能够用线性关系来描述：![](https://ai-studio-static-online.cdn.bcebos.com/7cc5a55596704e408e6a7cd917e6dac2d0529f02403b45b59832f32e78d90608)\n",
    "我们可以直接给定一组初始化的系数W，然后进行模型的拟合。 损失函数我们采用MSE损失函数，方程式如下所示。为了计算方便，我们更改系数为1/2n![](https://ai-studio-static-online.cdn.bcebos.com/3f167047b6f544679f0278e597b0969f0228f649395840b69c2db28918e5a754)\n",
    "本次实验所采用的线性模型的结构如下所示。由于numpy实现两层的过于复杂，时间关系，仅通过一层来实现作为说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predict：[ 0.04662517 -0.2858381  -0.05963511  0.38118489 -0.36418156]\n",
      " Ture label:[-0.00514491 -0.08801477 -0.0935765   0.0955225  -0.08801477]\n",
      " loss: 0.0757117481668684\n"
     ]
    }
   ],
   "source": [
    "# 自定义网络框架\r\n",
    "class Network(object):\r\n",
    "    def __init__(self, num_of_weights):\r\n",
    "        # 随机产生w的初始值\r\n",
    "        # 为了保持程序每次运行结果的一致性，\r\n",
    "        # 此处设置固定的随机数种子\r\n",
    "        np.random.seed(0)\r\n",
    "        self.w = np.random.randn(num_of_weights, 1)\r\n",
    "        self.b = 0.\r\n",
    "    # 前向计算过程    \r\n",
    "    def forward(self, x):\r\n",
    "        z = np.dot(x, self.w) + self.b\r\n",
    "        return z\r\n",
    "    # MSE函数实现\r\n",
    "    def loss(self, z, y):\r\n",
    "            error = z - y\r\n",
    "            cost = error * error\r\n",
    "            cost = np.mean(cost)\r\n",
    "            return cost\r\n",
    "x,y,_,_=data_load(data_path)\r\n",
    "\r\n",
    "net=Network(1)\r\n",
    "z=net.forward(x[:5])\r\n",
    "loss=net.loss(z,y[:5])\r\n",
    "print(f' predict：{z[:,0]}\\n',\r\n",
    "f\"Ture label:{y[:5]}\\n\",\r\n",
    "\"loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**3.训练过程**\n",
    "我们采用梯度下降法来对我们的算法参数进行优化求解![](https://ai-studio-static-online.cdn.bcebos.com/64da0182091342f1a13e5d076d78510f50f60ae8e7ee4afeab696a7058e3040a)\n",
    "对上图我们还可以进行一系列的优化，例如我们可以在X所有项加上一个指定参数1，使之变成X=[1,x1,x2,x3,...xn]T,那么我们对应的可以更改W为[b,w1,w2,w,3,...,wn]T,那么我们的自变量和参数都可以变为nx1的变量。所以线性方程变为y=W_T*X，其中W_T是W的转置，X是表示输入样本。那么我们对于W的修改就可以通过矩阵操作统一实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对x进行修正\r\n",
    "def modify_x(x):\r\n",
    "    x=np.column_stack((np.ones((x.shape[0],1)),x))\r\n",
    "    return x\r\n",
    "# 自定义网络框架的修改版\r\n",
    "class Network(object):\r\n",
    "    def __init__(self, num_of_weights):\r\n",
    "        # 随机产生w的初始值\r\n",
    "        # 为了保持程序每次运行结果的一致性，\r\n",
    "        # 此处设置固定的随机数种子\r\n",
    "        np.random.seed(0)\r\n",
    "        self.w = np.random.randn(num_of_weights, 1)\r\n",
    "    # 前向计算过程    \r\n",
    "    def forward(self, x):\r\n",
    "        self.w[0]=0.\r\n",
    "        z = np.dot(x, self.w)\r\n",
    "        return z\r\n",
    "    # MSE函数实现\r\n",
    "    def loss(self, z, y):\r\n",
    "            error = z - y\r\n",
    "            cost = error * error\r\n",
    "            cost = np.mean(cost)\r\n",
    "            return cost\r\n",
    "#计算当前的梯度值\r\n",
    "def gradient(x,y,z):\r\n",
    "    gradient_w=np.dot(x.T,(z-y))/x.shape[0]\r\n",
    "    return gradient_w[:,0]\r\n",
    "# x=modify_x(x)\r\n",
    "# y=y.reshape(y.shape[0],1)\r\n",
    "# net=Network(x.shape[1])\r\n",
    "# z=net.forward(x)\r\n",
    "# print(x.shape)\r\n",
    "# print(y.shape)\r\n",
    "# print(z.shape)\r\n",
    "# gradient_w=gradient(x,y,z)\r\n",
    "# print(gradient_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\r\n",
    "    def __init__(self, num_of_weights):\r\n",
    "        # 随机产生w的初始值\r\n",
    "        # 为了保持程序每次运行结果的一致性，\r\n",
    "        # 此处设置固定的随机数种子\r\n",
    "        np.random.seed(0)\r\n",
    "        self.w = np.random.randn(num_of_weights+1, 1)\r\n",
    "    # 前向计算过程    \r\n",
    "    def forward(self, x):\r\n",
    "        self.w[0]=0.\r\n",
    "        z = np.dot(x, self.w)\r\n",
    "        return z\r\n",
    "    # MSE函数实现\r\n",
    "    def loss(self, z, y):\r\n",
    "            error = z - y\r\n",
    "            cost = error * error\r\n",
    "            cost = np.mean(cost)\r\n",
    "            return cost\r\n",
    "    def modify_x(self,x):\r\n",
    "        x=np.column_stack((np.ones((x.shape[0],1)),x))\r\n",
    "        return x\r\n",
    "    def gradient(self,x,y):\r\n",
    "        y=y.reshape(y.shape[0],1)\r\n",
    "        z=self.forward(x)\r\n",
    "        gradient_w=np.dot(x.T,(z-y))/x.shape[0]\r\n",
    "        return gradient_w\r\n",
    "    def step(self,gradient_w,lr):\r\n",
    "        self.w=self.w-lr*gradient_w\r\n",
    "    def train(self,x,y,iteration=1000,lr=0.5):\r\n",
    "        points=[]\r\n",
    "        losses=[]\r\n",
    "        for i in range(iteration):\r\n",
    "            points.append(self.w)\r\n",
    "            z=self.forward(x)\r\n",
    "            loss=self.loss(z,y)\r\n",
    "            gradient_w=self.gradient(x,y)\r\n",
    "            losses.append(loss)\r\n",
    "            net.step(gradient_w,lr)\r\n",
    "            if (i)%50==0:\r\n",
    "                print(f'iter: {i}, point: {self.w[:,0]}, loss: {loss}')\r\n",
    "            # print(f'iter: {i}, point: {self.w.shape}, loss: {loss}')\r\n",
    "            \r\n",
    "        return points, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**3.模型的训练和可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, point: [0.0005321  0.40503304], loss: 0.009834716345136362\n",
      "iter: 50, point: [0.00086141 0.55375317], loss: 0.007840170584324837\n",
      "iter: 100, point: [0.0009755  0.60527637], loss: 0.0076007783574149265\n",
      "iter: 150, point: [0.00101502 0.62312627], loss: 0.007572045680817139\n",
      "iter: 200, point: [0.00102872 0.62931026], loss: 0.007568597086369735\n",
      "iter: 250, point: [0.00103346 0.63145267], loss: 0.007568183174229592\n",
      "iter: 300, point: [0.0010351  0.63219489], loss: 0.007568133495074106\n",
      "iter: 350, point: [0.00103567 0.63245203], loss: 0.0075681275324113815\n",
      "iter: 400, point: [0.00103587 0.63254112], loss: 0.007568126816752138\n",
      "iter: 450, point: [0.00103594 0.63257198], loss: 0.00756812673085626\n",
      "iter: 500, point: [0.00103596 0.63258267], loss: 0.007568126720546742\n",
      "iter: 550, point: [0.00103597 0.63258637], loss: 0.007568126719309357\n",
      "iter: 600, point: [0.00103597 0.63258766], loss: 0.007568126719160844\n",
      "iter: 650, point: [0.00103597 0.6325881 ], loss: 0.007568126719143018\n",
      "iter: 700, point: [0.00103597 0.63258826], loss: 0.007568126719140878\n",
      "iter: 750, point: [0.00103597 0.63258831], loss: 0.007568126719140622\n",
      "iter: 800, point: [0.00103597 0.63258833], loss: 0.0075681267191405905\n",
      "iter: 850, point: [0.00103597 0.63258833], loss: 0.007568126719140587\n",
      "iter: 900, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 950, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1000, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1050, point: [0.00103597 0.63258834], loss: 0.007568126719140585\n",
      "iter: 1100, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1150, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1200, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1250, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1300, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1350, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1400, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1450, point: [0.00103597 0.63258834], loss: 0.007568126719140587\n",
      "iter: 1500, point: [0.00103597 0.63258834], loss: 0.007568126719140585\n",
      "iter: 1550, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n",
      "iter: 1600, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n",
      "iter: 1650, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n",
      "iter: 1700, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n",
      "iter: 1750, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n",
      "iter: 1800, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n",
      "iter: 1850, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n",
      "iter: 1900, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n",
      "iter: 1950, point: [0.00103597 0.63258834], loss: 0.007568126719140584\n"
     ]
    }
   ],
   "source": [
    "net=Network(x.shape[1])\r\n",
    "x_=net.modify_x(x)\r\n",
    "y=y.reshape(y.shape[0],1)\r\n",
    "iteration=2000\r\n",
    "points, losses=net.train(x_,y,iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "from pylab import mpl  \r\n",
    "mpl.rcParams['font.sans-serif']=['SimHei'] # 指定默认字体 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\r\n",
    "plt.plot(losses)\r\n",
    "plt.xlabel('iteration')\r\n",
    "plt.ylabel('loss')\r\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\r\n",
    "z=net.forward(x_)\r\n",
    "x__=x*(maximums[0]-minimums[0])+avgs[0]\r\n",
    "y_=y*(maximums[1]-minimums[1])+avgs[1]\r\n",
    "z_=z*(maximums[1]-minimums[1])+avgs[1]\r\n",
    "plt.scatter(x__,y_)\r\n",
    "plt.plot(x__,z_,c='r')\r\n",
    "plt.xlabel('Area')\r\n",
    "plt.ylabel('Price')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**房价预测的Paddle框架实现**\n",
    "原理部分与上相同，但此次采用的是双层的神经网络模型，隐层数量为5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddle.nn import Linear\r\n",
    "import paddle.nn.functional as F\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(paddle.nn.Layer):\r\n",
    "\r\n",
    "    # self代表类的实例自身\r\n",
    "    def __init__(self,num):\r\n",
    "        # 初始化父类中的一些参数\r\n",
    "        super(Network, self).__init__()\r\n",
    "        \r\n",
    "        # 定义一层全连接层，输入维度是num，输出维度是1\r\n",
    "        self.fc1 = Linear(in_features=num, out_features=5)\r\n",
    "        self.a=paddle.nn.Sigmoid()\r\n",
    "        self.fc2 = Linear(5,out_features=1)\r\n",
    "    \r\n",
    "    # 网络的前向计算\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.fc1(inputs)\r\n",
    "        x=self.a(x)\r\n",
    "        x=self.fc2(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对上述函数进行封装\r\n",
    "def data_load_new(data_path,ratio=0.8):\r\n",
    "    data=np.loadtxt(data_path,delimiter = ',',dtype='float32')\r\n",
    "    maximums, minimums, avgs = data.max(axis=0), data.min(axis=0), data.sum(axis=0)/data.shape[0]\r\n",
    "    #归一化\r\n",
    "    data=(data-avgs)/(maximums-minimums)\r\n",
    "    #数据集分割\r\n",
    "    ratio = 0.8\r\n",
    "    offset = int(data.shape[0]*ratio)\r\n",
    "    train_data = data[:offset].copy()\r\n",
    "    test_data = data[offset:].copy()\r\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 2) (174, 2)\n"
     ]
    }
   ],
   "source": [
    "# 声明定义好的线性回归模型\r\n",
    "model = Network(x.shape[1])\r\n",
    "# 开启模型训练模式\r\n",
    "model.train()\r\n",
    "# 加载数据\r\n",
    "training_data, test_data = data_load_new(data_path)\r\n",
    "# 定义优化算法，使用随机梯度下降SGD\r\n",
    "# 学习率设置为0.01\r\n",
    "opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\r\n",
    "print(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 0, loss is: [0.09917273]\n",
      "epoch: 0, iter: 20, loss is: [0.0737596]\n",
      "epoch: 0, iter: 40, loss is: [0.01595156]\n",
      "epoch: 0, iter: 60, loss is: [0.02178749]\n",
      "epoch: 1, iter: 0, loss is: [0.02515522]\n",
      "epoch: 1, iter: 20, loss is: [0.02730075]\n",
      "epoch: 1, iter: 40, loss is: [0.00904213]\n",
      "epoch: 1, iter: 60, loss is: [0.01497635]\n",
      "epoch: 2, iter: 0, loss is: [0.02712169]\n",
      "epoch: 2, iter: 20, loss is: [0.0274705]\n",
      "epoch: 2, iter: 40, loss is: [0.04888221]\n",
      "epoch: 2, iter: 60, loss is: [0.01234901]\n",
      "epoch: 3, iter: 0, loss is: [0.00879118]\n",
      "epoch: 3, iter: 20, loss is: [0.02383676]\n",
      "epoch: 3, iter: 40, loss is: [0.03809622]\n",
      "epoch: 3, iter: 60, loss is: [0.00925345]\n",
      "epoch: 4, iter: 0, loss is: [0.01290477]\n",
      "epoch: 4, iter: 20, loss is: [0.02234135]\n",
      "epoch: 4, iter: 40, loss is: [0.02070921]\n",
      "epoch: 4, iter: 60, loss is: [0.01241408]\n",
      "epoch: 5, iter: 0, loss is: [0.02910613]\n",
      "epoch: 5, iter: 20, loss is: [0.01874577]\n",
      "epoch: 5, iter: 40, loss is: [0.01416044]\n",
      "epoch: 5, iter: 60, loss is: [0.09141838]\n",
      "epoch: 6, iter: 0, loss is: [0.02658093]\n",
      "epoch: 6, iter: 20, loss is: [0.02040408]\n",
      "epoch: 6, iter: 40, loss is: [0.03866465]\n",
      "epoch: 6, iter: 60, loss is: [0.02139562]\n",
      "epoch: 7, iter: 0, loss is: [0.02232074]\n",
      "epoch: 7, iter: 20, loss is: [0.03333586]\n",
      "epoch: 7, iter: 40, loss is: [0.02530864]\n",
      "epoch: 7, iter: 60, loss is: [0.01014854]\n",
      "epoch: 8, iter: 0, loss is: [0.01676147]\n",
      "epoch: 8, iter: 20, loss is: [0.02722653]\n",
      "epoch: 8, iter: 40, loss is: [0.01120919]\n",
      "epoch: 8, iter: 60, loss is: [0.00752459]\n",
      "epoch: 9, iter: 0, loss is: [0.01959429]\n",
      "epoch: 9, iter: 20, loss is: [0.03472038]\n",
      "epoch: 9, iter: 40, loss is: [0.02280031]\n",
      "epoch: 9, iter: 60, loss is: [0.01171026]\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 10   # 设置外层循环次数\r\n",
    "BATCH_SIZE = 10  # 设置batch大小\r\n",
    "\r\n",
    "# 定义外层循环\r\n",
    "for epoch_id in range(EPOCH_NUM):\r\n",
    "    # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\r\n",
    "    np.random.shuffle(training_data)\r\n",
    "    # 将训练数据进行拆分，每个batch包含16条数据\r\n",
    "    mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\r\n",
    "    # 定义内层循环\r\n",
    "    for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "        x = np.array(mini_batch[:, :-1]) # 获得当前批次训练数据\r\n",
    "        y = np.array(mini_batch[:, -1]) # 获得当前批次训练标签（真实房价）\r\n",
    "        # 将numpy数据转为飞桨动态图tensor形式\r\n",
    "        features = paddle.to_tensor(x)\r\n",
    "        prices = paddle.to_tensor(y)\r\n",
    "        \r\n",
    "        # print(features)\r\n",
    "\r\n",
    "        # 前向计算\r\n",
    "        predicts = model(features)\r\n",
    "        \r\n",
    "        # 计算损失\r\n",
    "        loss = F.square_error_cost(predicts, label=prices)\r\n",
    "        avg_loss = paddle.mean(loss)\r\n",
    "        if iter_id%20==0:\r\n",
    "            print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, iter_id, avg_loss.numpy()))\r\n",
    "        # print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, iter_id, avg_loss.numpy()))\r\n",
    "        \r\n",
    "        # 反向传播\r\n",
    "        avg_loss.backward()\r\n",
    "        # 最小化loss,更新参数\r\n",
    "        opt.step()\r\n",
    "        # 清除梯度\r\n",
    "        opt.clear_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**两种方法的比较**\n",
    "使用测试集计算两种方法的均方误差，比较两者的误差大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss    way1:0.04192041453699585  way2:0.02530328556895256\n"
     ]
    }
   ],
   "source": [
    "_,_,test_feature,test_label=data_load(data_path)\r\n",
    "test_feature_1=modify_x(test_feature)\r\n",
    "way1_out=net.forward(test_feature_1)\r\n",
    "\r\n",
    "#转换为预测模式，更加节省内存速度更快性能更高\r\n",
    "model.eval()\r\n",
    "test_feature_2=paddle.to_tensor(test_feature)\r\n",
    "way2_out=model(test_feature_2)\r\n",
    "\r\n",
    "\r\n",
    "# way1_out=way1_out*(maximums[1]-minimums[1])+avgs[1]\r\n",
    "# way2_out=way2_out*(maximums[1]-minimums[1])+avgs[1]\r\n",
    "# test_label=test_label*(maximums[1]-minimums[1])+avgs[1]\r\n",
    "test_label_2=paddle.to_tensor(test_label)\r\n",
    "loss1=net.loss(way1_out,test_label)\r\n",
    "loss2=F.square_error_cost(way2_out,label=test_label_2)\r\n",
    "loss2=np.mean(loss2.numpy())\r\n",
    "\r\n",
    "print(f'loss    way1:{loss1}  way2:{loss2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss    way1:135520.48384232534  way2:81800.5546875\n"
     ]
    }
   ],
   "source": [
    "way1_out=way1_out*(maximums[1]-minimums[1])+avgs[1]\r\n",
    "way2_out=way2_out*(maximums[1]-minimums[1])+avgs[1]\r\n",
    "test_label=test_label*(maximums[1]-minimums[1])+avgs[1]\r\n",
    "test_label_2=paddle.to_tensor(test_label)\r\n",
    "loss1=net.loss(way1_out,test_label)\r\n",
    "loss2=F.square_error_cost(way2_out,label=test_label_2)\r\n",
    "loss2=np.mean(loss2.numpy())\r\n",
    "\r\n",
    "print(f'loss    way1:{loss1}  way2:{loss2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
