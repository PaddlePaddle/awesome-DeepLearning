# 零基础入门深度学习-7.6

## 1 深度学习发展历史
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/8212741e9a70495ea467a2d2a861baff9ecd964aa67447e8a415b162dd5d01a4" width="900" hegiht="" ></center>
<center><br>图1：深度学习发展历程</br></center>
<br></br>

* **1940年代**：首次提出神经元的结构，但权重是不可学的。
* **50-60年代**：提出权重学习理论，神经元结构趋于完善，开启了神经网络的第一个黄金时代。
* **1969年**：提出异或问题（人们惊讶的发现神经网络模型连简单的异或问题也无法解决，对其的期望从云端跌落到谷底），神经网络模型进入了被束之高阁的黑暗时代。
* **1986年**：新提出的多层神经网络解决了异或问题，但随着90年代后理论更完备并且实践效果更好的SVM等机器学习模型的兴起，神经网络并未得到重视。
* **2010年左右**：深度学习进入真正兴起时期。随着神经网络模型改进的技术在语音和计算机视觉任务上大放异彩，也逐渐被证明在更多的任务，如自然语言处理以及海量数据的任务上更加有效。至此，神经网络模型重新焕发生机，并有了一个更加响亮的名字：深度学习。

神经网络到2010年后才焕发生机，这与深度学习成功所依赖的先决条件：大数据涌现、硬件发展和算法优化有关。

* **大数据是神经网络发展的有效前提**。神经网络和深度学习是非常强大的模型，需要足够量级的训练数据。时至今日，之所以很多传统机器学习算法和人工特征依然是足够有效的方案，原因在于很多场景下没有足够的标记数据来支撑深度学习。深度学习的能力特别像科学家阿基米德的豪言壮语：“给我一根足够长的杠杆，我能撬动地球！”。深度学习也可以发出类似的豪言：“给我足够多的数据，我能够学习任何复杂的关系”。但在现实中，足够长的杠杆与足够多的数据一样，往往只能是一种美好的愿景。直到近些年，各行业IT化程度提高，累积的数据量爆发式地增长，才使得应用深度学习模型成为可能。

* **依靠硬件的发展和算法的优化**。现阶段，依靠更强大的计算机、GPU、autoencoder预训练和并行计算等技术，深度学习在模型训练上的困难已经被逐渐克服。其中，数据量和硬件是更主要的原因。没有前两者，科学家们想优化算法都无从进行。

## 2 人工智能、机器学习、深度学习有什么区别和联系

人工智能、机器学习和深度学习覆盖的技术范畴是逐层递减的。人工智能是最宽泛的概念。机器学习是当前比较有效的一种实现人工智能的方式。深度学习是机器学习算法中最热门的一个分支，近些年取得了显著的进展，并替代了大多数传统机器学习算法。三者的关系如 **图2** 所示，即：人工智能 > 机器学习 > 深度学习。
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/594606d16fca46a38b6d9ec17a1fc15862d1ac31bf354c52a0cf504f5bcae785" width="300" hegiht="" ></center>
<center><br>图2：人工智能、机器学习和深度学习三者关系示意</br></center>
<br></br>

* 人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。通常将人工智能分为弱人工智能和强人工智能：前者让机器具备观察和感知的能力，可以做到一定程度的理解和推理，而强人工智能让机器获得自适应能力，解决一些之前没有遇到过的问题；
* 机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。“机器学习”是“模拟、延伸和扩展人的智能”的一条路径，所以是人工智能的一个子集；
* 相较而言，深度学习是一个比较新的概念，严格地说是2006年提出的。深度学习是用于建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据的一种机器学习技术。

## 3 神经元  单层感知机  多层感知机
### 神经网络、神经元

人工神经网络包括多个神经网络层，如卷积层、全连接层、LSTM等，每一层又包括很多神经元，超过三层的非线性神经网络都可以被称为深度神经网络。通俗的讲，深度学习的模型可以视为是输入到输出的映射函数，如图像到高级语义（美女）的映射，足够深的神经网络理论上可以拟合任何复杂的函数。因此神经网络非常适合学习样本数据的内在规律和表示层次，对文字、图像和语音任务有很好的适用性。因为这几个领域的任务是人工智能的基础模块，所以深度学习被称为实现人工智能的基础也就不足为奇了。

神经网络结构如 **图3** 所示。

<center><img src="https://ai-studio-static-online.cdn.bcebos.com/af79017f3e1143fab258386460c324c4adf7ab0a51364fa98474d04798721752" width="700" hegiht="" ></center>
<center><br>图3：神经网络结构示意图</br></center>
<br></br>

* **神经元：** 神经网络中每个节点称为神经元，由两部分组成：
  - 加权和：将所有输入加权求和。
  - 非线性变换（激活函数）：加权和的结果经过一个非线性函数变换，让神经元计算具备非线性的能力。
* **多层连接：** 大量这样的节点按照不同的层次排布，形成多层的结构连接起来，即称为神经网络。
* **前向计算：** 从输入计算输出的过程，顺序从网络前至后。
* **计算图：** 以图形化的方式展现神经网络的计算逻辑又称为计算图。我们也可以将神经网络的计算图以公式的方式表达，如下：
$$Y =f_3 ( f_2 ( f_1 ( w_1\cdot x_1+w_2\cdot x_2+w_3\cdot x_3+b ) + … ) … ) … )$$

### 单层感知机
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/e3a116af4d7e47febdae3b02c31c7f905d0914a9b6df431a8df4e0a8b9ffe844" width="700" hegiht="" ></center>
<center><br>图4：单神经元感知机结构</br></center>
<br></br>

单神经元感知机——判定边界
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/bc148885a9664b0e92df891edec92faba8ec67b84c8a4d99b22bef2c76e9e648" width="700" hegiht="" ></center>
<center><br>图5：单神经元感知机—判定边界</br></center>
<br></br>

* 判定边界由那些使得净输入n为零的输入向量确定；
* 对于边界上的所有点而言，输入向量与权值向量的内积都是一样的，输入向量在权值向量上都有相同的投影
* 权值向量总是指向神经元输出为1的区域

### 多层感知机
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/eb57265af39d4682aacfa67964513e63096edd2670604371b0353897ed7cf850" width="700" hegiht="" ></center>
<center><br>图6：多神经元感知机结构</br></center>
<br></br>
多层感知机（MLP，Multilayer Perceptron）也叫人工神经网络（ANN，Artificial Neural Network），除了输入输出层，它中间可以有多个隐层，最简单的MLP只含一个隐层，即三层的结构.从上图可以看到，多层感知机层与层之间是全连接的。多层感知机最底层是输入层，中间是隐藏层，最后是输出层。

## 4 什么是前向传播

<center><img src="https://ai-studio-static-online.cdn.bcebos.com/7431d25c10d94beeaed4850fb85ffd5ade2e9622b8c2487888301fb1ca8e6c43" width="700" hegiht="" ></center>
<center><br>图7：前向传播算法</br></center>
<br></br>


## 5 什么是反向传播

<center><img src="https://ai-studio-static-online.cdn.bcebos.com/e2ceb12a88be40fb937f976069fa456e8f0e25803a0f4bb1b30ce60c941b0596" width="700" hegiht="" ></center>
<center><br>图8：反向传播算法</br></center>
<br></br>
