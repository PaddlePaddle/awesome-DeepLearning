# 解决样本不均衡问题

​	当前基于深度学习的目标检测主要包括：基于two-stage的目标检测和基于one-stage的目标检测。two-stage的目标检测框架一般检测精度相对较高，但检测速度慢；而one-stage的目标检测速度相对较快，但是检测精度相对较低。one-stage的精度不如two-stage的精度，一个主要的原因是训练过程中样本极度不均衡造成的。

## 样本类别

正样本：标签区域内的图像区域，即目标图像块

负样本：标签区域以外的图像区域，即图像背景区域

易分正样本：容易正确分类的正样本，在实际训练过程中，该类占总体样本的比重非常高，单个样本的损失函数较小，但是累计的损失函数会主导损失函数

易分负样本：容易正确分类的负样本，在实际训练过程中，该类占的比重非常高，单个样本的损失函数较小，但是累计的损失函数会主导损失函数

难分正样本：错分成负样本的正样本，这部分样本在训练过程中单个样本的损失函数较高，但是该类占总体样本的比例较小

难分负样本：错分成正样本的负样本，这部分样本在训练过程中单个样本的损失函数教高，但是该类占总体样本的比例教小

## 样本不均衡问题

​	样本不均衡问题：指在训练的时候各个类别的样本数量不均衡，由于检测算法各不相同，以及数据集之间的差异，可能会存在正负样本、难易样本、类别间样本这3种不均衡问题。一般在目标检测任务框架中，保持正负样本的比例为1:3（经验值）。

​	样本不平衡实际上是一种非常常见的现象。比如：在欺诈交易检测，欺诈交易的订单应该是占总交易数量极少部分；工厂中产品质量检测问题，合格产品的数量应该是远大于不合格产品的；信用卡的征信问题中往往就是正样本居多。

## **1.正负样本不均衡**

以Faster RCNN为例，在RPN部分会生成20000个左右的Anchor，由于一张图中通常有10个左右的物体，导致可能只有100个左右的Anchor会是正样本，正负样本比例约为1∶200，存在严重的不均衡。

对于目标检测算法，主要需要关注的是对应着真实物体的正样本，在训练时会根据其loss来调整网络参数。相比之下，负样本对应着图像的背景，如果有大量的负样本参与训练，则会淹没正样本的损失，从而降低网络收敛的效率与检测精度。

### **2.难易样本不均衡**

难样本指的是分类不太明确的边框，处在前景与背景的过渡区域上，在网络训练中难样本损失会较大，也是我们希望模型去学习优化的样本，利用这部分训练可以提升检测的准确率。

然而，大量的样本并非处在前景与背景的过渡区，而是与真实物体没有重叠区域的负样本，或者与真实物体重叠程度很高的正样本，这部分被称为简单样本，单个损失会较小，对参数收敛的作用有限。

虽然简单样本单个损失小，但由于数量众多，因此如果全都计算损失的话，其损失也会比难样本大很多，这种难易样本的不均衡也会影响模型的收敛与精度。

值得注意的是，由于负样本中大量的是简单样本，导致难易样本与正负样本这两个不均衡问题有一定的重叠，解决方法往往能同时对这两个问题起作用。

### **3.类别间样本不均衡**

在有些目标检测的数据集中，还会存在类别间的不均衡问题。举个例子，数据集中有100万个车辆、1000个行人的实例标签，样本比例为1000∶1，属于典型的类别不均衡。

这种情况下，如果不做任何处理，使用该数据集进行训练，由于行人这一类别可参考标签太少，会使得模型主要关注车这一类别的检测，网络中的参数主要根据车辆的损失进行优化，导致行人的检测精度大大下降。

## 解决样本不均衡问题的方法

机器学习中，解决样本不均衡问题主要有2种思路：数据角度和算法角度。从数据角度出发，有扩大数据集、数据类别均衡采样等方法。在算法层面，目标检测方法使用的方法主要有：

Faster RCNN、SSD等算法在正负样本的筛选时，根据样本与真实物体的IoU大小，设置了3∶1的正负样本比例，这一点缓解了正负样本的不均衡，同时也对难易样本不均衡起到了作用。

Faster RCNN在RPN模块中，通过前景得分排序筛选出了2000个左右的候选框，这也会将大量的负样本与简单样本过滤掉，缓解了前两个不均衡问题。

权重惩罚：对于难易样本与类别间的不均衡，可以增大难样本与少类别的损失权重，从而增大模型对这些样本的惩罚，缓解不均衡问题。

数据增强：从数据侧入手，可以在当前数据集上使用随机生成和添加扰动的方法，也可以利用网络爬虫数据等增加数据集的丰富性，从而缓解难易样本和类别间样本等不均衡问题，可以参考SSD的数据增强方法。
目前解决这类问题主要是两种方案：一是hard sampling方法，从所有样本中选择一定量的正样本和负样本，只有被选择的样本才计算loss，一般会倾向选择一些难负例样本，比如OHEM；另外一类方法是soft sampling方法，选择所有样本计算loss，但是不同的样本赋给不同的权重值，比如focal loss。这些基于采样的策略虽然有效，但是需要超参数调节。下面我们介绍一种无采样方法。

# 解决目标检测中样本不平衡的无采样方法

我们介绍的论文是**[Is Sampling Heuristics Necessary in Training Deep Object Detectors?](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1909.04868.pdf)*，论文提出了一种无采样方案，无采样方法使用所有的样本进行训练，下面我们具体来看它如何训练出比较好的检测效果，它的策略非常简单。

## **从RetinaNet和Focal loss引入**

RetinaNet是目前比较好的one-stage目标检测算法，它采用focal loss来解决正负样本不均衡问题。这里我们探讨focal loss对RetinaNet的影响。我们将采用focal loss的算法称为RetinaNet-FL，而简单采用标准交叉熵的算法称为RetinaNet-None。两种loss的计算如下所示：

![](.\image\v2-424425b0896cb0e3a8fbe412204e9597_720w.jpg)

其中![[公式]](https://www.zhihu.com/equation?tex=L%5E%7BFL%7D)表示focal loss，而![[公式]](https://www.zhihu.com/equation?tex=L%5E%7BCE%7D)表示普通交叉熵。![[公式]](https://www.zhihu.com/equation?tex=p_%7Bij%7D)表示的是对第![[公式]](https://www.zhihu.com/equation?tex=i)个anchor（一个anchor对应一个训练实例）的第![[公式]](https://www.zhihu.com/equation?tex=j)的类的预测概率。正负样本的loss就是负对数loss：

![](.\image\equation.svg)

对于focal loss其实就是在交叉熵基础上为不同样本分配权重。对于RetinaNet-FL，比较容易训练并取得很好的效果。那么，对于RetinaNet-None，如果只是按同样的设置训练，会发现分类的梯度很快爆炸，如图2a所示，当我们尝试减少分类loss的权重直到除以5000才可以解决梯度爆炸，但是最终的效果很差，AP值仅为6.9。我们来分析这个问题，首先由于负样本太多，模型训练刚开始负样本的loss会很大，而且不稳定，所以很容易出现梯度爆炸。然后我们可以通过降低分类权重避免梯度爆炸，但是从loss曲线上看，分类loss会从一个较大的值迅速降为一个极小值，后面就在此附近来回震荡，这说明模型的分类loss很快被负样本所主导，模型倾向于预测负样本，所以最终模型效果依然很差。这是一个进退难题。

其实梯度容易爆炸的一个原因在于模型初始化策略，一般情况下我们会倾向让初始化的模型对于各类的预测是相同概率的，但是对于我们这个正负样本极度不平衡问题，这其实是非常不利的，因为负样本的loss会很大。所以RetinaNet论文中建议在对分类分支初始化时，对负样本设置一个先验概率值![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)，具体实施是改变分类分支的bias初始化值，对bias设置如下：

![](.\image\equation1.svg)

RetinaNet中采用的![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)为0.01，那么初始化后的分类分支sigmod处理后的预测概率倾向于0.01，而不是0.5，这会大大减少负样本的初始loss。如图2b所示，但是依然还是出现了梯度爆炸，将分类loss除以500后可以避免，最终的AP值为17.9，从曲线上loss还是有一个突变，说明模型还是陷入负样本中。进一步地调整![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)，当设置为1e-5时，并且分类loss除以10，发现模型可以较好地收敛，最终的AP为35.6，基本达到RetinaNet-FL的效果（AP为36.4）。再进一步地降低![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)为1e-10，发现模型效果反而有稍微下降，AP值为33.8。另外，作者发现RetinaNet-None预测的概率平均值是远远低于RetinaNet-FL，为了提升召回，可以设置较低的阈值，若将阈值从0.05降低至0.005，AP值从35.6提升到36.2，而这对RetinaNet-FL无影响。

这说明只要适当调整模型的初始化以及loss，采用普通交叉熵是可以达到与focal loss类似的效果的。这是此论文最重要的发现，据此给出了无采样的训练机制，主要包括三点，让我们一一道来。

## **最优bias初始化**

前面已经说到，分类分支的初始化对模型训练很关键，这里我们理论分析最优的![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)如何确定。假定数据集中共有![[公式]](https://www.zhihu.com/equation?tex=C)个类别，样本量为![[公式]](https://www.zhihu.com/equation?tex=N)，其中正例为![[公式]](https://www.zhihu.com/equation?tex=N_f)

在论文的实验中，![[公式]](https://www.zhihu.com/equation?tex=C)为80，而![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7BN%7D%7BN_f%7D)大约为1000。给定一系列![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)值，我们可以计算出正负例的分类loss 。

在前面的分析中，我们发现![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)取1e-5时，模型效果最好。从表中我们可以看到，此时的整体loss是最小，这大大降低了训练初期的梯度爆炸的风险，而且负样本的loss也较小，模型训练过程中更容易学习到正样本。而当![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)为0.5或者0.01时，负样本的loss很大，模型很容易陷入负样本的陷阱中。若![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)取1e-10，虽然负样本loss更低，但是正样本loss增加了，这反而不利于模型的稳定训练。基于上面的分析，最优的设置应该是要使整体loss最低，我们可以求导数来确定![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)

很容易计算出最优![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)为![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7BN_f%7D%7BN%7D+%5Ccdot+%5Cfrac%7B1%7D%7BC%7D)，此时![[公式]](https://www.zhihu.com/equation?tex=L%5E%7BCE%7D)最低。这里我们认为模型训练之初，![[公式]](https://www.zhihu.com/equation?tex=%5Csigma%28wx%2Bb%29%5Capprox%5Csigma%28b%29%3D%5Cpi)。那么可以计算出bias的最优初始化值为：

![](.\image\equation (1).svg)

按照上面参数计算，最优的![[公式]](https://www.zhihu.com/equation?tex=%5Cpi)为1.113e-5，和我们的实验值是吻合的。

## **Guided Loss**

前面实验的另外一个结论是要降低分类loss，但是降低比例很难确定。但是对于回归loss，其只计算正样本，不会受到正负样本不平衡的影响，所以我们可以通过回归loss来确定分类loss的调整比例：

![](.\image\equation (2).svg)

那么最终的loss计算为：

![](.\image\equation (3).svg).

这里![[公式]](https://www.zhihu.com/equation?tex=w%5E%7Breg%7D)和![[公式]](https://www.zhihu.com/equation?tex=w%5E%7Bcls%7D)是回归和分类loss的权重系数，是检测模型所固有的参数。简单来说，我们用![[公式]](https://www.zhihu.com/equation?tex=L%5E%7Breg%7D)来引导![[公式]](https://www.zhihu.com/equation?tex=L%5E%7Bcls%7D)，以希望分类loss可以和回归loss维持相同的水平，这在论文中称为guided loss。值得注意的是，我们虽然在训练过程中实时确定r，但是这一过程是不经过BP的，所以这一机制没有带来任何负担，也不引入新的超参数。

## **类别自适应阈值**

前面已经提到，RetinaNet-None会出现置信度偏移现象，我们可以采用较低的阈值来进一步提升模型效果，但是其实对每个类别，我们可以采用不同的过滤阈值。

## **实验效果**

首先，要说明的是上面所提出的3种机制对大部分目标检测算法都是适用的，包括基于anchor的one-satge和two-stage方法，以及无anchor的目标检测方法。论文中选取了YOLOv3，RetinaNet，FoveaBox（无anchor），Faster R-CNN以及Cascade R-CNN进行实验，来测试所提出的无采样方法的效果，如下表所示：

![](.\image\v2-50b1c157b81a1eb690a942ae2a553982_720w.jpg)

从表中可以看到，采用无采样方法的模型相比baseline均有一定的提升，这说明这一机制不仅限于理论分析，在实际中确实可以取得较好的效果。

另外，作者也分别实验分析了三种策略，如下表所示：

![](.\image\v2-38e6789d278101a71379632e24cb8330_720w.png)

可以看到三种策略都是有一定的效果的，但是我觉得第3个策略是最无关紧要的，提升不大，只能算上一种辅助策略。

另外一点是，前两种策略应该是有一定的互补性质的，比如都是适当降低分类loss来避免梯度爆炸的问题。这里作者比较了第一策略的采用与否对第二策略guided loss的影响，结果如下图所示：

![](.\image\v2-3d9a29d134aa910feccb2cfda37321f8_720w.jpg)

这里可以看到只要有了guided loss，第一策略对最终模型效果的影响是微乎其微的。这也很容易理解，最早的实验我们发现最重要的是要降低分类loss，两个策略可以起到同样的效果。不过从收敛曲线上可以看到，加入第一策略，收敛速度稍微更快一些，所以还是推荐加入第一策略。

## **小结**

正负样本不平衡一直以来是目标检测中比较头疼的问题，这篇论文的主要贡献是分析了这个问题对训练的影响，并给出了可以解决该问题的无采样方法，思路还是非常清晰的，看起来也是行之有效。

## **参考**

1. [Is Sampling Heuristics Necessary in Training Deep Object Detectors?](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1909.04868.pdf)
2. [Imbalance Problems in Object Detection: A Review](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1909.00169)
3. [Focal Loss for Dense Object Detection](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1708.02002.pdf)

