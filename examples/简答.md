①损失函数方法补充

0-1损失函数(zero-one loss)

0-1损失是指预测值和目标值不相等为1， 否则为0:

特点：

(1)0-1损失函数直接对应分类判断错误的个数，但是它是一个非凸函数，不太适用.

(2)感知机就是用的这种损失函数。但是相等这个条件太过严格，因此可以放宽条件，即满足
\|Y-f(x)\|\<t时认为相等，

\`\`\`python

if out=y:

loss=0

else

loss=1

\`\`\`

File "\<ipython-input-1-ecbb2339ed87\>", line 1

if out=y:

\^

SyntaxError: invalid syntax

③池化方法补充

Stochastic-pooling（随机池化）：只需对feature
map中的元素按照其概率值大小随机选择，即元素值大的被选中的概率也大。而不像max-pooling那样，永远只取那个最大值元素。

④数据增强方法补充

色彩抖动

在实际工程中为了消除图像在不同背景中存在的差异性，通常会做一些色彩抖动操作，扩充数据集合。色彩抖动主要是在图像的颜色方面做增强，主要调整的是图像的亮度，饱和度和对比度。工程中不是任何数据集都适用，通常如果不同背景的图像较多，加入色彩抖动操作会有很好的提升。

几何变换类

几何变换类即对图像进行几何变换，包括\*\*翻转，旋转，裁剪，变形，缩放\*\*等各类操作。

颜色变换

包括\*\*噪声、模糊、颜色变换、擦除、填充\*\*等等。

GAN

通过生成对抗网络生成同类型的数据。比如生成汽车、人脸图片。通过图像风格迁移的手段，还可以生成同一物体再不同环境下的图片。

⑤图像分类方法综述

1.卷积神经网络

卷积神经网络（CNN，或ConvNet）是一种多层神经网络，旨在通过最少的预处理直接从像素图像中识别视觉模式。这是一个特殊的人工神经网络结构。它包括两个重要的元素，即卷积层和池化层。

2.迁移学习

转移学习是一种机器学习技术，首先在机器上训练神经网络模型与正在解决的问题类似的问题，并且存储在解决过程中获得的知识解决一个问题并将其应用于不同但相关的问题。

3.SVM支持向量机

支持向量机（SVM）是一种强大而灵活的有监督机器学习算法是多维空间中超平面上不同类的表示。目标是分裂

将数据集分成类，寻找最大边缘超平面。它建立了一个超平面或一组

高维空间中的超平面和两类之间的良好分离是通过

到任何类中最近的训练数据点距离最大的超平面。真正的力量

该算法的性能取决于所使用的核函数。

4.KNN

K-最近邻（K-NN）是一种非参数的惰性学习算法，用于分类和分类

回归。该算法简单地依赖于特征向量和分类器之间的距离

通过在k-最近的例子中找到最常见的类来获得未知的数据点。

5.随机森林

随机森林算法（RFA）是一种由多个决策树组成的有监督学习算法

树。该算法在数据样本上建立决策树，并对每个样本进行预测

最后通过投票的方式选出最优解。
