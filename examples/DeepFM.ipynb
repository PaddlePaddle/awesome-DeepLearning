{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#导入所需的库\n",
    "import tensorflow as tf\n",
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.framework import ops \n",
    "#ops.reset_default_graph()\n",
    "\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数设定\n",
    "#特征数量\n",
    "n_features = 8\n",
    "#label个数\n",
    "n_class = 2\n",
    "\n",
    "#定义训练轮数\n",
    "#training_steps = 1000\n",
    "#学习率\n",
    "learning_rate=0.01\n",
    "\n",
    "\n",
    "#定义训练轮数\n",
    "training_steps = 1000\n",
    "#学习率\n",
    "#learning_rate=0.1\n",
    "#隐层K\n",
    "fv=20\n",
    "\n",
    "dnn_layer=[64,32]\n",
    "dnn_active_fuc=['relu','relu','relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据和数据转换\n",
    "train = pd.read_csv(\"C:/Users/ASUS/Desktop/12/data/diabetes_train.txt\",header=None,index_col=False)\n",
    "test = pd.read_csv(\"C:/Users/ASUS/Desktop/12/data/diabetes_test.txt\",header=None,index_col=False)\n",
    "#数据转换\n",
    "\n",
    "label = train.loc[:,[8]].values.reshape(-1,1)\n",
    "data = train.drop(columns=8).values.reshape(-1,n_features)\n",
    "\n",
    "y_test =  test.loc[:,[8]].values.reshape(-1,1)\n",
    "X_test =  test.drop(columns=8).values.reshape(-1,n_features)\n",
    "\n",
    "#one-hot编码\n",
    "enc = OneHotEncoder()\n",
    "#训练\n",
    "enc.fit(label)\n",
    "enc.fit(y_test)\n",
    "#转换成array\n",
    "label=enc.transform(label).toarray() \n",
    "y_test =enc.transform(y_test).toarray() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_x Tensor(\"Input/Reshape:0\", shape=(?, 8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def udf_full_connect(Input,input_size,output_size,activation='relu'):\n",
    "    #生成或获取weights和biases\n",
    "    weights=tf.get_variable(\"weights\",[input_size,output_size],initializer=tf.glorot_normal_initializer(),trainable=True)\n",
    "    biases=tf.get_variable(\"biases\",[output_size],initializer=tf.glorot_normal_initializer(),trainable=True)\n",
    "    \n",
    "    #全链接 \n",
    "    layer=tf.matmul(Input,weights)+biases\n",
    "    if activation==\"relu\":\n",
    "        layer=tf.nn.relu(layer)\n",
    "    elif activation==\"tanh\":\n",
    "        layer=tf.nn.tanh(layer)\n",
    "        \n",
    "    return layer\n",
    "    \n",
    "    \n",
    "ops.reset_default_graph()\n",
    "with tf.name_scope(\"Input\"):\n",
    "    x = tf.placeholder(tf.float32, [None, n_features])\n",
    "    y = tf.placeholder(tf.float32, [None, n_class])\n",
    "    Input_x = tf.reshape(x, shape=[-1, n_features, 1]) # None * feature_size \n",
    "    print(\"Input_x\",Input_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "3 Deep层网络输出\n"
     ]
    }
   ],
   "source": [
    "# 模型参数parameter\n",
    "with tf.name_scope(\"Parameter\"):\n",
    "    W = tf.Variable(tf.zeros([n_features, n_class]),name=\"w\")\n",
    "    b = tf.Variable(tf.zeros([n_class]),name=\"b\")\n",
    "    v = tf.Variable(tf.zeros([n_features, fv]),name=\"V\")\n",
    "    embeddings = tf.multiply(v, Input_x) # None * V * X \n",
    "\n",
    "\n",
    "\n",
    "    # 定义模型，此处使用与线性回归一样的定义\n",
    "    # 因为在后面定义损失的时候会加上映射\n",
    "with tf.name_scope(\"Prediction\"):\n",
    "    \n",
    "    Y_liner = tf.matmul(x, W) + b\n",
    "    #0.5*((sum(v*x))^2 - sum((v*x)^2)) \n",
    "    summed_features_emb = tf.reduce_sum(embeddings, 1)  # sum(v*x)\n",
    "    summed_features_emb_square = tf.square(summed_features_emb)  # (sum(v*x))^2\n",
    "\n",
    "    # square_sum part\n",
    "    squared_features_emb = tf.square(embeddings) # (v*x)^2\n",
    "    squared_sum_features_emb = tf.reduce_sum(squared_features_emb, 1)   # sum((v*x)^2)\n",
    "\n",
    "    \n",
    "    Y_pair = 0.5 * tf.subtract(summed_features_emb_square, squared_sum_features_emb)  # 0.5*((sum(v*x))^2 - sum((v*x)^2))\n",
    "    \n",
    "    \n",
    "    pred= tf.concat([Y_liner, Y_pair], axis=1) \n",
    "    \n",
    "\"\"\" 3 Deep层网络输出 \"\"\"\n",
    "print(\"3 Deep层网络输出\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lay1, input_size: 160, output_size: 64, active_fuc: relu\n",
      "lay1, deep_inputs: Tensor(\"Deep/deep_layer1/Reshape:0\", shape=(?, 160), dtype=float32)\n",
      "lay1, deep_outputs: Tensor(\"Deep/deep_layer1/Relu:0\", shape=(?, 64), dtype=float32)\n",
      "lay2, input_size: 64, output_size: 32, active_fuc: relu\n",
      "lay2, deep_outputs: Tensor(\"Deep/deep_layer2/Relu:0\", shape=(?, 32), dtype=float32)\n",
      "lay_last, input_size: 32, output_size: 2, active_fuc: relu\n",
      "lay_last, deep_outputs: Tensor(\"Deep/deep_layer3/Relu:0\", shape=(?, 2), dtype=float32)\n",
      "Y_sum Tensor(\"Sum:0\", shape=(?,), dtype=float32)\n",
      "pred Tensor(\"losses/error_loss/Shape:0\", shape=(1,), dtype=int32)\n",
      "y Tensor(\"losses/error_loss/Shape_1:0\", shape=(2,), dtype=int32)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"Deep\"):\n",
    "    # 第一层计算\n",
    "    print(\"lay%s, input_size: %s, output_size: %s, active_fuc: %s\" % (1, n_features*fv, dnn_layer[0], dnn_active_fuc[0]))\n",
    "    with tf.variable_scope(\"deep_layer1\", reuse=tf.AUTO_REUSE):\n",
    "        input_size = n_features*fv\n",
    "        output_size = dnn_layer[0]\n",
    "        deep_inputs = tf.reshape(embeddings, shape=[-1, input_size]) # None * (F*K)\n",
    "        print(\"%s: %s\" % (\"lay1, deep_inputs\", deep_inputs))\n",
    "       \n",
    "        # 全连接计算    \n",
    "        deep_outputs = udf_full_connect(deep_inputs, input_size, output_size, dnn_active_fuc[0])\n",
    "        print(\"%s: %s\" % (\"lay1, deep_outputs\", deep_outputs))\n",
    "        # batch_norm\n",
    "        #if is_batch_norm:\n",
    "        #    deep_outputs = tf.layers.batch_normalization(deep_outputs, axis=-1, training=is_train) \n",
    "        # 输出dropout\n",
    "        #if is_train and is_dropout_dnn:\n",
    "        #    deep_outputs = tf.nn.dropout(deep_outputs, dropout_dnn[1])\n",
    "    # 中间层计算\n",
    "    \n",
    "    for i in range(len(dnn_layer) - 1):\n",
    "        with tf.variable_scope(\"deep_layer%d\"%(i+2), reuse=tf.AUTO_REUSE):\n",
    "            print(\"lay%s, input_size: %s, output_size: %s, active_fuc: %s\" % (i+2, dnn_layer[i], dnn_layer[i+1], dnn_active_fuc[i+1]))\n",
    "            # 全连接计算\n",
    "            deep_outputs = udf_full_connect(deep_outputs, dnn_layer[i], dnn_layer[i+1], dnn_active_fuc[i+1])\n",
    "            print(\"lay%s, deep_outputs: %s\" % (i+2, deep_outputs))\n",
    "            # batch_norm\n",
    "            #if is_batch_norm:\n",
    "            #    deep_outputs = tf.layers.batch_normalization(deep_outputs, axis=-1, training=is_train)\n",
    "            # 输出dropout  \n",
    "           # if is_train and is_dropout_dnn:\n",
    "             #   deep_outputs = tf.nn.dropout(deep_outputs, dropout_dnn[i+2])\n",
    "             \n",
    "    # 输出层计算\n",
    "    print(\"lay_last, input_size: %s, output_size: %s, active_fuc: %s\" % (dnn_layer[-1], 2, dnn_active_fuc[-1]))\n",
    "    with tf.variable_scope(\"deep_layer%d\"%(len(dnn_layer)+1), reuse=tf.AUTO_REUSE):\n",
    "        deep_outputs = udf_full_connect(deep_outputs, dnn_layer[-1],2, dnn_active_fuc[-1])\n",
    "        print(\"lay_last, deep_outputs: %s\" % (deep_outputs))\n",
    "\n",
    "    # 正则化，默认L2\n",
    "    dnn_regularization = 0.0\n",
    "    for j in range(len(dnn_layer)+1):        \n",
    "        with tf.variable_scope(\"deep_layer%d\"%(j+1), reuse=True):\n",
    "            weights = tf.get_variable(\"weights\")\n",
    "            dnn_regularization = dnn_regularization + tf.nn.l2_loss(weights)\n",
    "\n",
    "Y_deep=deep_outputs    \n",
    "concat_input = tf.concat([Y_liner, Y_pair, Y_deep], axis=1)    \n",
    "Y_sum = tf.reduce_sum(concat_input, 1)\n",
    "print(\"Y_sum\",Y_sum) \n",
    "score=tf.nn.sigmoid(Y_sum,name='score')\n",
    "#score=tf.reshape(score, shape=[-1, 1])\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# 定义损失函数\n",
    "with tf.name_scope(\"losses\"):\n",
    "    with tf.name_scope(\"error_loss\"):\n",
    "        print(\"pred\",tf.shape(Y_sum))\n",
    "        print(\"y\",tf.shape(y))\n",
    "        error_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.reshape(Y_sum, [-1]), labels=tf.reshape(tf.cast(tf.argmax(y,axis=1),tf.float32), [-1]))) \n",
    "\n",
    "    tf.add_to_collection(\"losses\", error_loss)      #加入集合的操作\n",
    "\n",
    "    #在权重参数上实现L2正则化\n",
    "    with tf.name_scope(\"regularization\"):\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(0.01)\n",
    "        regularization = regularizer(W)+regularizer(v)+dnn_regularization\n",
    "    tf.add_to_collection(\"losses\",regularization)     #加入集合的操作\n",
    "\n",
    "    #get_collection()函数获取指定集合中的所有个体，这里是获取所有损失值\n",
    "    #并在add_n()函数中进行加和运算\n",
    "    loss = tf.add_n(tf.get_collection(\"losses\"))\n",
    "\n",
    "#定义一个优化器，学习率为固定为0.01，注意在实际应用中这个学习率数值应该大于0.01\n",
    "with tf.name_scope(\"Train\"):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "# 准确率\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "\n",
    "    #correct_prediction = tf.equal(tf.argmax(score, axis=1), tf.argmax(y, axis=1))\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy = tf.metrics.auc(tf.argmax(y, axis=1), score)\n",
    "    tf.summary.histogram(\"accuracy\",accuracy)\n",
    "    #tf.summary.scalar(\"accuracy\",accuracy)\n",
    "\n",
    "merged=tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps, loss_value is: 59.627785\n",
      "After 0 trainging steps ,validation accuarcy is 0%\n",
      "After 1 steps, loss_value is: 49.402199\n",
      "After 1 trainging steps ,validation accuarcy is 43.7375%\n",
      "After 2 steps, loss_value is: 42.256989\n",
      "After 2 trainging steps ,validation accuarcy is 42.5602%\n",
      "After 3 steps, loss_value is: 36.127926\n",
      "After 3 trainging steps ,validation accuarcy is 48.3231%\n",
      "After 4 steps, loss_value is: 29.778040\n",
      "After 4 trainging steps ,validation accuarcy is 51.7685%\n",
      "After 5 steps, loss_value is: 24.882502\n",
      "After 5 trainging steps ,validation accuarcy is 53.0535%\n",
      "After 6 steps, loss_value is: 21.387726\n",
      "After 6 trainging steps ,validation accuarcy is 51.7847%\n",
      "After 7 steps, loss_value is: 18.029110\n",
      "After 7 trainging steps ,validation accuarcy is 50.2047%\n",
      "After 8 steps, loss_value is: 14.819665\n",
      "After 8 trainging steps ,validation accuarcy is 48.8077%\n",
      "After 9 steps, loss_value is: 12.274663\n",
      "After 9 trainging steps ,validation accuarcy is 48.6705%\n",
      "After 10 steps, loss_value is: 10.626306\n",
      "After 10 trainging steps ,validation accuarcy is 49.2883%\n",
      "After 11 steps, loss_value is: 9.134202\n",
      "After 11 trainging steps ,validation accuarcy is 50.2223%\n",
      "After 12 steps, loss_value is: 7.587296\n",
      "After 12 trainging steps ,validation accuarcy is 51.1434%\n",
      "After 13 steps, loss_value is: 7.018031\n",
      "After 13 trainging steps ,validation accuarcy is 51.903%\n",
      "After 14 steps, loss_value is: 11.329676\n",
      "After 14 trainging steps ,validation accuarcy is 52.6952%\n",
      "After 15 steps, loss_value is: 19.193584\n",
      "After 15 trainging steps ,validation accuarcy is 52.6303%\n",
      "After 16 steps, loss_value is: 4.717664\n",
      "After 16 trainging steps ,validation accuarcy is 52.4004%\n",
      "After 17 steps, loss_value is: 6.653134\n",
      "After 17 trainging steps ,validation accuarcy is 52.6924%\n",
      "After 18 steps, loss_value is: 7.146816\n",
      "After 18 trainging steps ,validation accuarcy is 52.3707%\n",
      "After 19 steps, loss_value is: 4.687700\n",
      "After 19 trainging steps ,validation accuarcy is 52.4446%\n",
      "After 20 steps, loss_value is: 6.799165\n",
      "After 20 trainging steps ,validation accuarcy is 52.9498%\n",
      "After 21 steps, loss_value is: 5.904737\n",
      "After 21 trainging steps ,validation accuarcy is 52.6765%\n",
      "After 22 steps, loss_value is: 6.579521\n",
      "After 22 trainging steps ,validation accuarcy is 52.8881%\n",
      "After 23 steps, loss_value is: 3.749629\n",
      "After 23 trainging steps ,validation accuarcy is 52.9442%\n",
      "After 24 steps, loss_value is: 2.964398\n",
      "After 24 trainging steps ,validation accuarcy is 53.1922%\n",
      "After 25 steps, loss_value is: 5.594093\n",
      "After 25 trainging steps ,validation accuarcy is 53.3979%\n",
      "After 26 steps, loss_value is: 3.805867\n",
      "After 26 trainging steps ,validation accuarcy is 53.6896%\n",
      "After 27 steps, loss_value is: 5.314148\n",
      "After 27 trainging steps ,validation accuarcy is 54.051%\n",
      "After 28 steps, loss_value is: 3.708628\n",
      "After 28 trainging steps ,validation accuarcy is 53.7674%\n",
      "After 29 steps, loss_value is: 6.217653\n",
      "After 29 trainging steps ,validation accuarcy is 53.6225%\n",
      "After 30 steps, loss_value is: 3.005560\n",
      "After 30 trainging steps ,validation accuarcy is 53.7825%\n",
      "After 31 steps, loss_value is: 5.278630\n",
      "After 31 trainging steps ,validation accuarcy is 54.2051%\n",
      "After 32 steps, loss_value is: 6.141223\n",
      "After 32 trainging steps ,validation accuarcy is 53.9834%\n",
      "After 33 steps, loss_value is: 4.007675\n",
      "After 33 trainging steps ,validation accuarcy is 53.7809%\n",
      "After 34 steps, loss_value is: 3.066894\n",
      "After 34 trainging steps ,validation accuarcy is 53.6875%\n",
      "After 35 steps, loss_value is: 3.450183\n",
      "After 35 trainging steps ,validation accuarcy is 54.0548%\n",
      "After 36 steps, loss_value is: 1.889232\n",
      "After 36 trainging steps ,validation accuarcy is 54.3722%\n",
      "After 37 steps, loss_value is: 2.772890\n",
      "After 37 trainging steps ,validation accuarcy is 54.5829%\n",
      "After 38 steps, loss_value is: 1.538576\n",
      "After 38 trainging steps ,validation accuarcy is 54.5197%\n",
      "After 39 steps, loss_value is: 2.193580\n",
      "After 39 trainging steps ,validation accuarcy is 54.8063%\n",
      "After 40 steps, loss_value is: 1.865592\n",
      "After 40 trainging steps ,validation accuarcy is 55.1346%\n",
      "After 41 steps, loss_value is: 1.406950\n",
      "After 41 trainging steps ,validation accuarcy is 55.467%\n",
      "After 42 steps, loss_value is: 1.649006\n",
      "After 42 trainging steps ,validation accuarcy is 55.6184%\n",
      "After 43 steps, loss_value is: 0.962318\n",
      "After 43 trainging steps ,validation accuarcy is 55.6627%\n",
      "After 44 steps, loss_value is: 1.487349\n",
      "After 44 trainging steps ,validation accuarcy is 55.9564%\n",
      "After 45 steps, loss_value is: 0.868446\n",
      "After 45 trainging steps ,validation accuarcy is 56.2213%\n",
      "After 46 steps, loss_value is: 1.323393\n",
      "After 46 trainging steps ,validation accuarcy is 56.4877%\n",
      "After 47 steps, loss_value is: 0.957411\n",
      "After 47 trainging steps ,validation accuarcy is 56.4904%\n",
      "After 48 steps, loss_value is: 1.275434\n",
      "After 48 trainging steps ,validation accuarcy is 56.5935%\n",
      "After 49 steps, loss_value is: 1.147494\n",
      "After 49 trainging steps ,validation accuarcy is 56.8109%\n",
      "After 50 steps, loss_value is: 0.885424\n",
      "After 50 trainging steps ,validation accuarcy is 57.0299%\n",
      "After 51 steps, loss_value is: 1.068095\n",
      "After 51 trainging steps ,validation accuarcy is 57.1151%\n",
      "After 52 steps, loss_value is: 0.742944\n",
      "After 52 trainging steps ,validation accuarcy is 57.1314%\n",
      "After 53 steps, loss_value is: 0.992727\n",
      "After 53 trainging steps ,validation accuarcy is 57.325%\n",
      "After 54 steps, loss_value is: 0.713558\n",
      "After 54 trainging steps ,validation accuarcy is 57.518%\n",
      "After 55 steps, loss_value is: 0.888916\n",
      "After 55 trainging steps ,validation accuarcy is 57.7088%\n",
      "After 56 steps, loss_value is: 0.777222\n",
      "After 56 trainging steps ,validation accuarcy is 57.7519%\n",
      "After 57 steps, loss_value is: 0.787945\n",
      "After 57 trainging steps ,validation accuarcy is 57.8331%\n",
      "After 58 steps, loss_value is: 0.800075\n",
      "After 58 trainging steps ,validation accuarcy is 58.0112%\n",
      "After 59 steps, loss_value is: 0.673943\n",
      "After 59 trainging steps ,validation accuarcy is 58.1875%\n",
      "After 60 steps, loss_value is: 0.760613\n",
      "After 60 trainging steps ,validation accuarcy is 58.295%\n",
      "After 61 steps, loss_value is: 0.625713\n",
      "After 61 trainging steps ,validation accuarcy is 58.3537%\n",
      "After 62 steps, loss_value is: 0.727696\n",
      "After 62 trainging steps ,validation accuarcy is 58.5111%\n",
      "After 63 steps, loss_value is: 0.612258\n",
      "After 63 trainging steps ,validation accuarcy is 58.6735%\n",
      "After 64 steps, loss_value is: 0.693940\n",
      "After 64 trainging steps ,validation accuarcy is 58.8233%\n",
      "After 65 steps, loss_value is: 0.599194\n",
      "After 65 trainging steps ,validation accuarcy is 58.8911%\n",
      "After 66 steps, loss_value is: 0.656974\n",
      "After 66 trainging steps ,validation accuarcy is 59.0121%\n",
      "After 67 steps, loss_value is: 0.597355\n",
      "After 67 trainging steps ,validation accuarcy is 59.1599%\n",
      "After 68 steps, loss_value is: 0.644768\n",
      "After 68 trainging steps ,validation accuarcy is 59.3047%\n",
      "After 69 steps, loss_value is: 0.587312\n",
      "After 69 trainging steps ,validation accuarcy is 59.3785%\n",
      "After 70 steps, loss_value is: 0.634715\n",
      "After 70 trainging steps ,validation accuarcy is 59.4841%\n",
      "After 71 steps, loss_value is: 0.574699\n",
      "After 71 trainging steps ,validation accuarcy is 59.6217%\n",
      "After 72 steps, loss_value is: 0.620632\n",
      "After 72 trainging steps ,validation accuarcy is 59.7606%\n",
      "After 73 steps, loss_value is: 0.563265\n",
      "After 73 trainging steps ,validation accuarcy is 59.8342%\n",
      "After 74 steps, loss_value is: 0.604562\n",
      "After 74 trainging steps ,validation accuarcy is 59.9464%\n",
      "After 75 steps, loss_value is: 0.562990\n",
      "After 75 trainging steps ,validation accuarcy is 60.0828%\n",
      "After 76 steps, loss_value is: 0.590158\n",
      "After 76 trainging steps ,validation accuarcy is 60.2189%\n",
      "After 77 steps, loss_value is: 0.547194\n",
      "After 77 trainging steps ,validation accuarcy is 60.3033%\n",
      "After 78 steps, loss_value is: 0.583881\n",
      "After 78 trainging steps ,validation accuarcy is 60.4188%\n",
      "After 79 steps, loss_value is: 0.540722\n",
      "After 79 trainging steps ,validation accuarcy is 60.5509%\n",
      "After 80 steps, loss_value is: 0.581467\n",
      "After 80 trainging steps ,validation accuarcy is 60.6833%\n",
      "After 81 steps, loss_value is: 0.531488\n",
      "After 81 trainging steps ,validation accuarcy is 60.7674%\n",
      "After 82 steps, loss_value is: 0.568694\n",
      "After 82 trainging steps ,validation accuarcy is 60.8919%\n",
      "After 83 steps, loss_value is: 0.528781\n",
      "After 83 trainging steps ,validation accuarcy is 61.0238%\n",
      "After 84 steps, loss_value is: 0.562613\n",
      "After 84 trainging steps ,validation accuarcy is 61.1509%\n",
      "After 85 steps, loss_value is: 0.528567\n",
      "After 85 trainging steps ,validation accuarcy is 61.2433%\n",
      "After 86 steps, loss_value is: 0.547019\n",
      "After 86 trainging steps ,validation accuarcy is 61.3732%\n",
      "After 87 steps, loss_value is: 0.529464\n",
      "After 87 trainging steps ,validation accuarcy is 61.5037%\n",
      "After 88 steps, loss_value is: 0.530923\n",
      "After 88 trainging steps ,validation accuarcy is 61.6175%\n",
      "After 89 steps, loss_value is: 0.538204\n",
      "After 89 trainging steps ,validation accuarcy is 61.7287%\n",
      "After 90 steps, loss_value is: 0.519215\n",
      "After 90 trainging steps ,validation accuarcy is 61.8566%\n",
      "After 91 steps, loss_value is: 0.538472\n",
      "After 91 trainging steps ,validation accuarcy is 61.983%\n",
      "After 92 steps, loss_value is: 0.520762\n",
      "After 92 trainging steps ,validation accuarcy is 62.0843%\n",
      "After 93 steps, loss_value is: 0.524507\n",
      "After 93 trainging steps ,validation accuarcy is 62.2119%\n",
      "After 94 steps, loss_value is: 0.526809\n",
      "After 94 trainging steps ,validation accuarcy is 62.3397%\n",
      "After 95 steps, loss_value is: 0.513360\n",
      "After 95 trainging steps ,validation accuarcy is 62.4479%\n",
      "After 96 steps, loss_value is: 0.522916\n",
      "After 96 trainging steps ,validation accuarcy is 62.5702%\n",
      "After 97 steps, loss_value is: 0.516553\n",
      "After 97 trainging steps ,validation accuarcy is 62.6963%\n",
      "After 98 steps, loss_value is: 0.511779\n",
      "After 98 trainging steps ,validation accuarcy is 62.8103%\n",
      "After 99 steps, loss_value is: 0.517935\n",
      "After 99 trainging steps ,validation accuarcy is 62.9291%\n",
      "After 100 steps, loss_value is: 0.511229\n",
      "After 100 trainging steps ,validation accuarcy is 63.0542%\n",
      "After 200 steps, loss_value is: 0.494221\n",
      "After 200 trainging steps ,validation accuarcy is 70.563%\n",
      "After 300 steps, loss_value is: 0.527839\n",
      "After 300 trainging steps ,validation accuarcy is 73.5724%\n",
      "After 400 steps, loss_value is: 0.525639\n",
      "After 400 trainging steps ,validation accuarcy is 75.0126%\n",
      "After 500 steps, loss_value is: 0.524823\n",
      "After 500 trainging steps ,validation accuarcy is 75.8984%\n",
      "After 600 steps, loss_value is: 0.527470\n",
      "After 600 trainging steps ,validation accuarcy is 76.5112%\n",
      "After 700 steps, loss_value is: 0.513806\n",
      "After 700 trainging steps ,validation accuarcy is 76.9607%\n",
      "After 800 steps, loss_value is: 24.016672\n",
      "After 800 trainging steps ,validation accuarcy is 76.7483%\n",
      "After 900 steps, loss_value is: 1.037642\n",
      "After 900 trainging steps ,validation accuarcy is 73.0583%\n",
      "Testing Accuracyis 73.4535%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(\"./log\",sess.graph)\n",
    "    #在for循环内进行30000训练\n",
    "    for i in range(training_steps):\n",
    "\n",
    "        sess.run(train_op, feed_dict={x: data, y: label})\n",
    "        \n",
    "        loss_value = sess.run(loss, feed_dict={x: data, y: label})\n",
    "        summary,voliadata_accuracy=sess.run([merged,accuracy],feed_dict={x: data, y: label})\n",
    "        writer.add_summary(summary,i)\n",
    "\n",
    "        #训练30000轮，但每隔2000轮就输出一次loss的值\n",
    "        if i % 100 == 0 or i <= 100:\n",
    "            loss_value = sess.run(loss, feed_dict={x: data, y: label})\n",
    "            \n",
    "            print(\"After %d steps, loss_value is: %f\" % (i,loss_value))\n",
    "            print(\"After %d trainging steps ,validation accuarcy is %g%%\"%(i,voliadata_accuracy[0]*100))\n",
    "        #xs,ys =data.train.next_batch(200)\n",
    "        #sess.run(train_op,feed_dict={x:xs,y:ys})\n",
    "  \n",
    "    print(\"Testing Accuracyis %g%%\"%(accuracy[0].eval({x: X_test, y:y_test})*100))\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
