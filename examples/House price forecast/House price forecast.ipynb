{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data269\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 16.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import paddle\r\n",
    "print(paddle.__version__)\r\n",
    "import matplotlib\r\n",
    "matplotlib.use('Agg')\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>房屋面积</th>\n",
       "      <th>房价</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.87</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.74</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.24</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.19</td>\n",
       "      <td>780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.64</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     房屋面积     房价\n",
       "0   98.87  599.0\n",
       "1   68.74  450.0\n",
       "2   89.24  440.0\n",
       "3  129.19  780.0\n",
       "4   61.64  450.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['房屋面积']+['房价']\r\n",
    "print_data = pd.read_csv('./房价预测/data/data.txt',names = colnames)\r\n",
    "print_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the raw area : 199.96\n",
      "normalization: 0.6587568635148239\n"
     ]
    }
   ],
   "source": [
    "global x_raw,train_data,test_data\r\n",
    "data = np.loadtxt('./房价预测/data/data.txt',delimiter=',')\r\n",
    "x_raw = data.T[0].copy() \r\n",
    "\r\n",
    "#axis=0,表示按列计算\r\n",
    "#data.shape[0]表示data中一共有多少列\r\n",
    "maximums,minimums,avgs = data.max(axis=0),data.min(axis=0),data.sum(axis=0)/data.shape[0]\r\n",
    "print(\"the raw area :\",data[:,0].max(axis = 0))\r\n",
    "#归一化\r\n",
    "data[:,0] = (data[:,0]-avgs[0])/(maximums[0]-minimums[0])\r\n",
    "print('normalization:',data[:,0].max(axis = 0))\r\n",
    "plt.plot(data[:,0],data[:,1])\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总个数： 870\n",
      "训练集数据个数: 696\n",
      "测试集数据个数: 174\n"
     ]
    }
   ],
   "source": [
    "#划分数据集\r\n",
    "ratio = 0.8\r\n",
    "offset = int(data.shape[0]*ratio)\r\n",
    "train_data = data[0:offset]\r\n",
    "test_data = data[offset:]\r\n",
    "print('数据总个数：',len(data))\r\n",
    "print('训练集数据个数:',len(train_data))\r\n",
    "print('测试集数据个数:',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddle.io import Dataset\r\n",
    "\r\n",
    "class MyDataset(Dataset):\r\n",
    "    \"\"\"\r\n",
    "    步骤一：继承paddle.io.Dataset类\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, Data):\r\n",
    "        \"\"\"\r\n",
    "        步骤二：实现构造函数，定义数据集大小\r\n",
    "        \"\"\"\r\n",
    "        super(MyDataset, self).__init__()\r\n",
    "        self.num_samples = len(Data)\r\n",
    "        self.Data = Data.astype('float64')\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        \"\"\"\r\n",
    "        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\r\n",
    "        \"\"\"\r\n",
    "        data = self.Data[index,0]\r\n",
    "        label = self.Data[index,1]\r\n",
    "\r\n",
    "        return data, label\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        \"\"\"\r\n",
    "        步骤四：实现__len__方法，返回数据集总数目\r\n",
    "        \"\"\"\r\n",
    "        return self.num_samples\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\r\n",
    "train_loader = paddle.io.DataLoader(MyDataset(train_data), batch_size=BATCH_SIZE, shuffle=True)\r\n",
    "test_loader = paddle.io.DataLoader(MyDataset(test_data), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#建立模型\r\n",
    "class net(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(net, self).__init__()\r\n",
    "        self.fc = paddle.nn.Sequential(\r\n",
    "        paddle.nn.Linear(1, 1),\r\n",
    "        paddle.nn.ReLU(),\r\n",
    "        paddle.nn.Linear(1, 1)\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        pred = self.fc(inputs)\r\n",
    "        return pred\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step 110/696 [===>..........................] - loss: 159973.4326 - ETA: 1s - 2ms/ste"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 210/696 [========>.....................] - loss: 336170.3540 - ETA: 0s - 2ms/stepstep 696/696 [==============================] - loss: 210097.7786 - 2ms/step         \n",
      "Eval begin...\n",
      "step 174/174 [==============================] - loss: 448046.4839 - 876us/step         \n",
      "Eval samples: 174\n",
      "Epoch 2/5\n",
      "step 696/696 [==============================] - loss: 2555944.5906 - 2ms/step        \n",
      "Eval begin...\n",
      "step 174/174 [==============================] - loss: 120222.4829 - 960us/step        \n",
      "Eval samples: 174\n",
      "Epoch 3/5\n",
      "step 696/696 [==============================] - loss: 842910.1075 - 2ms/step        \n",
      "Eval begin...\n",
      "step 174/174 [==============================] - loss: 719274.0883 - 995us/step         \n",
      "Eval samples: 174\n",
      "Epoch 4/5\n",
      "step 696/696 [==============================] - loss: 187031.5694 - 2ms/step         \n",
      "Eval begin...\n",
      "step 174/174 [==============================] - loss: 120735.8642 - 915us/step        \n",
      "Eval samples: 174\n",
      "Epoch 5/5\n",
      "step 696/696 [==============================] - loss: 251842.5613 - 2ms/step        \n",
      "Eval begin...\n",
      "step 174/174 [==============================] - loss: 386682.8781 - 950us/step         \n",
      "Eval samples: 174\n"
     ]
    }
   ],
   "source": [
    "paddle.set_default_dtype(\"float64\")\r\n",
    "# step3:训练模型\r\n",
    "model = paddle.Model(net())\r\n",
    "model.prepare(paddle.optimizer.Adam(parameters=model.parameters()),\r\n",
    "              paddle.nn.MSELoss())\r\n",
    "model.fit(train_loader, test_loader, epochs=5, batch_size=20, verbose=1)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Numpy实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the raw area : 199.96\n",
      "normalization: 0.6587568635148239\n",
      "Epoch   0 / iter   0, loss = 531435.8569\n",
      "Epoch   0 / iter   1, loss = 383205.2484\n",
      "Epoch   0 / iter   2, loss = 335050.7708\n",
      "Epoch   0 / iter   3, loss = 315788.1438\n",
      "Epoch   0 / iter   4, loss = 182908.0060\n",
      "Epoch   0 / iter   5, loss = 157463.7102\n",
      "Epoch   0 / iter   6, loss = 139679.6585\n",
      "Epoch   1 / iter   0, loss = 144945.9604\n",
      "Epoch   1 / iter   1, loss = 92951.6929\n",
      "Epoch   1 / iter   2, loss = 161047.5038\n",
      "Epoch   1 / iter   3, loss = 123659.3931\n",
      "Epoch   1 / iter   4, loss = 102778.7896\n",
      "Epoch   1 / iter   5, loss = 148764.1256\n",
      "Epoch   1 / iter   6, loss = 93541.3783\n",
      "Epoch   2 / iter   0, loss = 108199.1016\n",
      "Epoch   2 / iter   1, loss = 61548.1197\n",
      "Epoch   2 / iter   2, loss = 62692.4809\n",
      "Epoch   2 / iter   3, loss = 79263.5686\n",
      "Epoch   2 / iter   4, loss = 89952.5938\n",
      "Epoch   2 / iter   5, loss = 80324.6455\n",
      "Epoch   2 / iter   6, loss = 98261.2465\n",
      "Epoch   3 / iter   0, loss = 52558.3018\n",
      "Epoch   3 / iter   1, loss = 73162.7807\n",
      "Epoch   3 / iter   2, loss = 92349.6169\n",
      "Epoch   3 / iter   3, loss = 80261.5264\n",
      "Epoch   3 / iter   4, loss = 72335.0965\n",
      "Epoch   3 / iter   5, loss = 71240.9129\n",
      "Epoch   3 / iter   6, loss = 57743.5157\n",
      "Epoch   4 / iter   0, loss = 83820.2485\n",
      "Epoch   4 / iter   1, loss = 53220.3743\n",
      "Epoch   4 / iter   2, loss = 55355.2922\n",
      "Epoch   4 / iter   3, loss = 78877.8353\n",
      "Epoch   4 / iter   4, loss = 57773.8960\n",
      "Epoch   4 / iter   5, loss = 67398.0920\n",
      "Epoch   4 / iter   6, loss = 73468.5041\n",
      "Epoch   5 / iter   0, loss = 51066.6419\n",
      "Epoch   5 / iter   1, loss = 91627.6812\n",
      "Epoch   5 / iter   2, loss = 49557.9791\n",
      "Epoch   5 / iter   3, loss = 57077.0446\n",
      "Epoch   5 / iter   4, loss = 54683.8817\n",
      "Epoch   5 / iter   5, loss = 45917.0891\n",
      "Epoch   5 / iter   6, loss = 101422.9241\n",
      "Epoch   6 / iter   0, loss = 41087.3314\n",
      "Epoch   6 / iter   1, loss = 57813.7108\n",
      "Epoch   6 / iter   2, loss = 56326.2188\n",
      "Epoch   6 / iter   3, loss = 86409.0614\n",
      "Epoch   6 / iter   4, loss = 58611.3931\n",
      "Epoch   6 / iter   5, loss = 83248.9898\n",
      "Epoch   6 / iter   6, loss = 48978.8266\n",
      "Epoch   7 / iter   0, loss = 56260.7459\n",
      "Epoch   7 / iter   1, loss = 57512.1267\n",
      "Epoch   7 / iter   2, loss = 70602.0826\n",
      "Epoch   7 / iter   3, loss = 71665.6281\n",
      "Epoch   7 / iter   4, loss = 58049.8937\n",
      "Epoch   7 / iter   5, loss = 51358.1183\n",
      "Epoch   7 / iter   6, loss = 52232.3853\n",
      "Epoch   8 / iter   0, loss = 64287.6880\n",
      "Epoch   8 / iter   1, loss = 62037.0295\n",
      "Epoch   8 / iter   2, loss = 70830.7214\n",
      "Epoch   8 / iter   3, loss = 46950.7533\n",
      "Epoch   8 / iter   4, loss = 47827.8258\n",
      "Epoch   8 / iter   5, loss = 59530.6825\n",
      "Epoch   8 / iter   6, loss = 52257.9699\n",
      "Epoch   9 / iter   0, loss = 55948.6923\n",
      "Epoch   9 / iter   1, loss = 72638.5713\n",
      "Epoch   9 / iter   2, loss = 46763.7561\n",
      "Epoch   9 / iter   3, loss = 38078.3897\n",
      "Epoch   9 / iter   4, loss = 63338.2559\n",
      "Epoch   9 / iter   5, loss = 59648.0797\n",
      "Epoch   9 / iter   6, loss = 54054.0651\n",
      "Epoch  10 / iter   0, loss = 46643.7447\n",
      "Epoch  10 / iter   1, loss = 32292.4015\n",
      "Epoch  10 / iter   2, loss = 70528.9267\n",
      "Epoch  10 / iter   3, loss = 45217.6664\n",
      "Epoch  10 / iter   4, loss = 52119.6360\n",
      "Epoch  10 / iter   5, loss = 52297.2892\n",
      "Epoch  10 / iter   6, loss = 80040.9627\n",
      "Epoch  11 / iter   0, loss = 46520.5114\n",
      "Epoch  11 / iter   1, loss = 43511.7796\n",
      "Epoch  11 / iter   2, loss = 49814.3730\n",
      "Epoch  11 / iter   3, loss = 67030.1687\n",
      "Epoch  11 / iter   4, loss = 52143.5460\n",
      "Epoch  11 / iter   5, loss = 58951.6367\n",
      "Epoch  11 / iter   6, loss = 47980.3615\n",
      "Epoch  12 / iter   0, loss = 41519.5828\n",
      "Epoch  12 / iter   1, loss = 62560.9781\n",
      "Epoch  12 / iter   2, loss = 40537.1268\n",
      "Epoch  12 / iter   3, loss = 65857.1628\n",
      "Epoch  12 / iter   4, loss = 45422.6646\n",
      "Epoch  12 / iter   5, loss = 47402.7244\n",
      "Epoch  12 / iter   6, loss = 51741.5522\n",
      "Epoch  13 / iter   0, loss = 49069.4702\n",
      "Epoch  13 / iter   1, loss = 37894.2920\n",
      "Epoch  13 / iter   2, loss = 45211.1910\n",
      "Epoch  13 / iter   3, loss = 81251.3528\n",
      "Epoch  13 / iter   4, loss = 46643.0073\n",
      "Epoch  13 / iter   5, loss = 30324.3833\n",
      "Epoch  13 / iter   6, loss = 54912.8685\n",
      "Epoch  14 / iter   0, loss = 50540.4764\n",
      "Epoch  14 / iter   1, loss = 51309.6605\n",
      "Epoch  14 / iter   2, loss = 47522.6599\n",
      "Epoch  14 / iter   3, loss = 71024.3830\n",
      "Epoch  14 / iter   4, loss = 38997.2833\n",
      "Epoch  14 / iter   5, loss = 38168.3481\n",
      "Epoch  14 / iter   6, loss = 36620.7005\n",
      "Epoch  15 / iter   0, loss = 58911.2304\n",
      "Epoch  15 / iter   1, loss = 49163.0561\n",
      "Epoch  15 / iter   2, loss = 45667.4439\n",
      "Epoch  15 / iter   3, loss = 45912.2928\n",
      "Epoch  15 / iter   4, loss = 47615.1330\n",
      "Epoch  15 / iter   5, loss = 48389.0769\n",
      "Epoch  15 / iter   6, loss = 28902.7878\n",
      "Epoch  16 / iter   0, loss = 32791.9465\n",
      "Epoch  16 / iter   1, loss = 48702.1351\n",
      "Epoch  16 / iter   2, loss = 44876.3506\n",
      "Epoch  16 / iter   3, loss = 65322.2489\n",
      "Epoch  16 / iter   4, loss = 36345.9873\n",
      "Epoch  16 / iter   5, loss = 45508.9443\n",
      "Epoch  16 / iter   6, loss = 43049.6888\n",
      "Epoch  17 / iter   0, loss = 61298.2201\n",
      "Epoch  17 / iter   1, loss = 46791.7032\n",
      "Epoch  17 / iter   2, loss = 46930.8432\n",
      "Epoch  17 / iter   3, loss = 51702.8798\n",
      "Epoch  17 / iter   4, loss = 36290.1941\n",
      "Epoch  17 / iter   5, loss = 38004.4592\n",
      "Epoch  17 / iter   6, loss = 26806.0116\n",
      "Epoch  18 / iter   0, loss = 38571.5001\n",
      "Epoch  18 / iter   1, loss = 47431.5171\n",
      "Epoch  18 / iter   2, loss = 46377.1887\n",
      "Epoch  18 / iter   3, loss = 35137.4885\n",
      "Epoch  18 / iter   4, loss = 58230.1179\n",
      "Epoch  18 / iter   5, loss = 28293.1002\n",
      "Epoch  18 / iter   6, loss = 46547.1432\n",
      "Epoch  19 / iter   0, loss = 39348.2380\n",
      "Epoch  19 / iter   1, loss = 26028.5999\n",
      "Epoch  19 / iter   2, loss = 62185.7231\n",
      "Epoch  19 / iter   3, loss = 40219.8291\n",
      "Epoch  19 / iter   4, loss = 52825.0465\n",
      "Epoch  19 / iter   5, loss = 40910.3680\n",
      "Epoch  19 / iter   6, loss = 31145.3761\n",
      "Epoch  20 / iter   0, loss = 41049.3116\n",
      "Epoch  20 / iter   1, loss = 34652.5597\n",
      "Epoch  20 / iter   2, loss = 40422.7214\n",
      "Epoch  20 / iter   3, loss = 49389.1394\n",
      "Epoch  20 / iter   4, loss = 38839.5750\n",
      "Epoch  20 / iter   5, loss = 36244.5674\n",
      "Epoch  20 / iter   6, loss = 45652.0575\n",
      "Epoch  21 / iter   0, loss = 49199.1907\n",
      "Epoch  21 / iter   1, loss = 39540.0276\n",
      "Epoch  21 / iter   2, loss = 29792.5160\n",
      "Epoch  21 / iter   3, loss = 38568.2204\n",
      "Epoch  21 / iter   4, loss = 27329.2190\n",
      "Epoch  21 / iter   5, loss = 45690.5783\n",
      "Epoch  21 / iter   6, loss = 49696.4270\n",
      "Epoch  22 / iter   0, loss = 29081.9220\n",
      "Epoch  22 / iter   1, loss = 49863.8272\n",
      "Epoch  22 / iter   2, loss = 40236.9269\n",
      "Epoch  22 / iter   3, loss = 55691.1182\n",
      "Epoch  22 / iter   4, loss = 37714.6057\n",
      "Epoch  22 / iter   5, loss = 31616.1019\n",
      "Epoch  22 / iter   6, loss = 28704.3617\n",
      "Epoch  23 / iter   0, loss = 39921.5641\n",
      "Epoch  23 / iter   1, loss = 18110.3261\n",
      "Epoch  23 / iter   2, loss = 43118.9408\n",
      "Epoch  23 / iter   3, loss = 43554.8666\n",
      "Epoch  23 / iter   4, loss = 44830.2616\n",
      "Epoch  23 / iter   5, loss = 44543.0563\n",
      "Epoch  23 / iter   6, loss = 33160.4307\n",
      "Epoch  24 / iter   0, loss = 36784.2354\n",
      "Epoch  24 / iter   1, loss = 42267.3059\n",
      "Epoch  24 / iter   2, loss = 31057.9996\n",
      "Epoch  24 / iter   3, loss = 49514.0613\n",
      "Epoch  24 / iter   4, loss = 38527.7071\n",
      "Epoch  24 / iter   5, loss = 37650.3276\n",
      "Epoch  24 / iter   6, loss = 25827.3790\n",
      "Epoch  25 / iter   0, loss = 24289.2452\n",
      "Epoch  25 / iter   1, loss = 44990.8118\n",
      "Epoch  25 / iter   2, loss = 27965.6376\n",
      "Epoch  25 / iter   3, loss = 34212.9237\n",
      "Epoch  25 / iter   4, loss = 44586.2606\n",
      "Epoch  25 / iter   5, loss = 41976.0968\n",
      "Epoch  25 / iter   6, loss = 38998.9578\n",
      "Epoch  26 / iter   0, loss = 40581.9788\n",
      "Epoch  26 / iter   1, loss = 29097.1096\n",
      "Epoch  26 / iter   2, loss = 34885.5175\n",
      "Epoch  26 / iter   3, loss = 25571.2004\n",
      "Epoch  26 / iter   4, loss = 26461.2840\n",
      "Epoch  26 / iter   5, loss = 44405.2451\n",
      "Epoch  26 / iter   6, loss = 51565.9820\n",
      "Epoch  27 / iter   0, loss = 34012.4112\n",
      "Epoch  27 / iter   1, loss = 40878.2419\n",
      "Epoch  27 / iter   2, loss = 34300.5072\n",
      "Epoch  27 / iter   3, loss = 22925.1451\n",
      "Epoch  27 / iter   4, loss = 28336.8145\n",
      "Epoch  27 / iter   5, loss = 46394.1013\n",
      "Epoch  27 / iter   6, loss = 40691.9921\n",
      "Epoch  28 / iter   0, loss = 35449.7468\n",
      "Epoch  28 / iter   1, loss = 38376.4520\n",
      "Epoch  28 / iter   2, loss = 32125.9015\n",
      "Epoch  28 / iter   3, loss = 27833.2936\n",
      "Epoch  28 / iter   4, loss = 41725.8285\n",
      "Epoch  28 / iter   5, loss = 35573.2650\n",
      "Epoch  28 / iter   6, loss = 31712.7648\n",
      "Epoch  29 / iter   0, loss = 39827.5008\n",
      "Epoch  29 / iter   1, loss = 26253.1856\n",
      "Epoch  29 / iter   2, loss = 32796.7496\n",
      "Epoch  29 / iter   3, loss = 18489.5872\n",
      "Epoch  29 / iter   4, loss = 38094.3019\n",
      "Epoch  29 / iter   5, loss = 29794.9442\n",
      "Epoch  29 / iter   6, loss = 54505.6348\n",
      "Epoch  30 / iter   0, loss = 32690.8907\n",
      "Epoch  30 / iter   1, loss = 30572.7174\n",
      "Epoch  30 / iter   2, loss = 21602.1060\n",
      "Epoch  30 / iter   3, loss = 33899.5702\n",
      "Epoch  30 / iter   4, loss = 48702.1001\n",
      "Epoch  30 / iter   5, loss = 32607.2414\n",
      "Epoch  30 / iter   6, loss = 35176.0809\n",
      "Epoch  31 / iter   0, loss = 35912.0446\n",
      "Epoch  31 / iter   1, loss = 29612.6283\n",
      "Epoch  31 / iter   2, loss = 35728.1632\n",
      "Epoch  31 / iter   3, loss = 37251.2995\n",
      "Epoch  31 / iter   4, loss = 41320.4458\n",
      "Epoch  31 / iter   5, loss = 22333.9690\n",
      "Epoch  31 / iter   6, loss = 29024.0640\n",
      "Epoch  32 / iter   0, loss = 36265.2557\n",
      "Epoch  32 / iter   1, loss = 33847.6980\n",
      "Epoch  32 / iter   2, loss = 37730.2727\n",
      "Epoch  32 / iter   3, loss = 31802.3076\n",
      "Epoch  32 / iter   4, loss = 32305.6711\n",
      "Epoch  32 / iter   5, loss = 32354.4173\n",
      "Epoch  32 / iter   6, loss = 23225.0631\n",
      "Epoch  33 / iter   0, loss = 30050.9904\n",
      "Epoch  33 / iter   1, loss = 23098.6711\n",
      "Epoch  33 / iter   2, loss = 22442.2712\n",
      "Epoch  33 / iter   3, loss = 20095.5760\n",
      "Epoch  33 / iter   4, loss = 31805.2275\n",
      "Epoch  33 / iter   5, loss = 42912.7602\n",
      "Epoch  33 / iter   6, loss = 55461.5456\n",
      "Epoch  34 / iter   0, loss = 29707.1328\n",
      "Epoch  34 / iter   1, loss = 37427.0892\n",
      "Epoch  34 / iter   2, loss = 27531.3582\n",
      "Epoch  34 / iter   3, loss = 27288.1655\n",
      "Epoch  34 / iter   4, loss = 25569.8011\n",
      "Epoch  34 / iter   5, loss = 38950.4760\n",
      "Epoch  34 / iter   6, loss = 35231.8974\n",
      "Epoch  35 / iter   0, loss = 27543.6579\n",
      "Epoch  35 / iter   1, loss = 36634.8814\n",
      "Epoch  35 / iter   2, loss = 25757.3170\n",
      "Epoch  35 / iter   3, loss = 27186.2613\n",
      "Epoch  35 / iter   4, loss = 22464.7476\n",
      "Epoch  35 / iter   5, loss = 32024.7509\n",
      "Epoch  35 / iter   6, loss = 47860.4625\n",
      "Epoch  36 / iter   0, loss = 33019.4855\n",
      "Epoch  36 / iter   1, loss = 40255.6727\n",
      "Epoch  36 / iter   2, loss = 22924.5195\n",
      "Epoch  36 / iter   3, loss = 26903.5167\n",
      "Epoch  36 / iter   4, loss = 44365.9831\n",
      "Epoch  36 / iter   5, loss = 24050.1662\n",
      "Epoch  36 / iter   6, loss = 24673.9756\n",
      "Epoch  37 / iter   0, loss = 31080.9988\n",
      "Epoch  37 / iter   1, loss = 34087.6036\n",
      "Epoch  37 / iter   2, loss = 22970.4451\n",
      "Epoch  37 / iter   3, loss = 32199.9907\n",
      "Epoch  37 / iter   4, loss = 22771.3333\n",
      "Epoch  37 / iter   5, loss = 21174.8929\n",
      "Epoch  37 / iter   6, loss = 50029.6694\n",
      "Epoch  38 / iter   0, loss = 41935.7238\n",
      "Epoch  38 / iter   1, loss = 32540.9833\n",
      "Epoch  38 / iter   2, loss = 28940.3624\n",
      "Epoch  38 / iter   3, loss = 20247.0617\n",
      "Epoch  38 / iter   4, loss = 31102.3059\n",
      "Epoch  38 / iter   5, loss = 29412.5931\n",
      "Epoch  38 / iter   6, loss = 26793.1492\n",
      "Epoch  39 / iter   0, loss = 31276.6533\n",
      "Epoch  39 / iter   1, loss = 32510.9665\n",
      "Epoch  39 / iter   2, loss = 32515.6014\n",
      "Epoch  39 / iter   3, loss = 19751.1595\n",
      "Epoch  39 / iter   4, loss = 22096.6958\n",
      "Epoch  39 / iter   5, loss = 28981.1553\n",
      "Epoch  39 / iter   6, loss = 42371.1042\n",
      "Epoch  40 / iter   0, loss = 26233.4124\n",
      "Epoch  40 / iter   1, loss = 33011.5978\n",
      "Epoch  40 / iter   2, loss = 37202.7895\n",
      "Epoch  40 / iter   3, loss = 25082.5708\n",
      "Epoch  40 / iter   4, loss = 25886.3548\n",
      "Epoch  40 / iter   5, loss = 24817.3056\n",
      "Epoch  40 / iter   6, loss = 34758.1220\n",
      "Epoch  41 / iter   0, loss = 21202.3883\n",
      "Epoch  41 / iter   1, loss = 25217.1799\n",
      "Epoch  41 / iter   2, loss = 37229.6306\n",
      "Epoch  41 / iter   3, loss = 26746.0024\n",
      "Epoch  41 / iter   4, loss = 32323.0281\n",
      "Epoch  41 / iter   5, loss = 20222.5859\n",
      "Epoch  41 / iter   6, loss = 42259.1951\n",
      "Epoch  42 / iter   0, loss = 27774.5803\n",
      "Epoch  42 / iter   1, loss = 22690.3791\n",
      "Epoch  42 / iter   2, loss = 34989.7151\n",
      "Epoch  42 / iter   3, loss = 21651.5459\n",
      "Epoch  42 / iter   4, loss = 41380.5955\n",
      "Epoch  42 / iter   5, loss = 28447.6668\n",
      "Epoch  42 / iter   6, loss = 25820.2889\n",
      "Epoch  43 / iter   0, loss = 22944.6921\n",
      "Epoch  43 / iter   1, loss = 28214.5093\n",
      "Epoch  43 / iter   2, loss = 43378.6905\n",
      "Epoch  43 / iter   3, loss = 25571.5301\n",
      "Epoch  43 / iter   4, loss = 30334.7550\n",
      "Epoch  43 / iter   5, loss = 26850.4354\n",
      "Epoch  43 / iter   6, loss = 23421.6535\n",
      "Epoch  44 / iter   0, loss = 33068.7607\n",
      "Epoch  44 / iter   1, loss = 33636.6087\n",
      "Epoch  44 / iter   2, loss = 15202.3120\n",
      "Epoch  44 / iter   3, loss = 28219.1347\n",
      "Epoch  44 / iter   4, loss = 30134.6736\n",
      "Epoch  44 / iter   5, loss = 35084.2990\n",
      "Epoch  44 / iter   6, loss = 23627.9344\n",
      "Epoch  45 / iter   0, loss = 33090.6943\n",
      "Epoch  45 / iter   1, loss = 24470.1203\n",
      "Epoch  45 / iter   2, loss = 37097.2710\n",
      "Epoch  45 / iter   3, loss = 24067.3587\n",
      "Epoch  45 / iter   4, loss = 26407.6142\n",
      "Epoch  45 / iter   5, loss = 28806.7058\n",
      "Epoch  45 / iter   6, loss = 23506.4931\n",
      "Epoch  46 / iter   0, loss = 28464.3325\n",
      "Epoch  46 / iter   1, loss = 27665.0265\n",
      "Epoch  46 / iter   2, loss = 22601.0602\n",
      "Epoch  46 / iter   3, loss = 19496.9199\n",
      "Epoch  46 / iter   4, loss = 45994.8482\n",
      "Epoch  46 / iter   5, loss = 24935.0866\n",
      "Epoch  46 / iter   6, loss = 27037.1157\n",
      "Epoch  47 / iter   0, loss = 39727.3227\n",
      "Epoch  47 / iter   1, loss = 17945.7884\n",
      "Epoch  47 / iter   2, loss = 23659.1302\n",
      "Epoch  47 / iter   3, loss = 29873.9669\n",
      "Epoch  47 / iter   4, loss = 39946.1794\n",
      "Epoch  47 / iter   5, loss = 18101.7430\n",
      "Epoch  47 / iter   6, loss = 25403.3654\n",
      "Epoch  48 / iter   0, loss = 33121.2111\n",
      "Epoch  48 / iter   1, loss = 18734.7907\n",
      "Epoch  48 / iter   2, loss = 33089.7510\n",
      "Epoch  48 / iter   3, loss = 27046.4511\n",
      "Epoch  48 / iter   4, loss = 31764.0077\n",
      "Epoch  48 / iter   5, loss = 22916.3157\n",
      "Epoch  48 / iter   6, loss = 26762.0646\n",
      "Epoch  49 / iter   0, loss = 30095.9723\n",
      "Epoch  49 / iter   1, loss = 19274.3235\n",
      "Epoch  49 / iter   2, loss = 27077.6807\n",
      "Epoch  49 / iter   3, loss = 22803.2726\n",
      "Epoch  49 / iter   4, loss = 34197.7814\n",
      "Epoch  49 / iter   5, loss = 24694.1161\n",
      "Epoch  49 / iter   6, loss = 34193.0559\n"
     ]
    }
   ],
   "source": [
    "# 导入需要用到的package\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "\r\n",
    "def load_data():\r\n",
    "    # 从文件导入数据\r\n",
    "    '''\r\n",
    "    datafile = './housing.data'\r\n",
    "    data = np.fromfile(datafile, sep=' ')\r\n",
    "\r\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\r\n",
    "    feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \\\r\n",
    "                      'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\r\n",
    "    feature_num = len(feature_names)\r\n",
    "\r\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\r\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\r\n",
    "'''\r\n",
    "    data = np.loadtxt('./房价预测/data/data.txt',delimiter=',')\r\n",
    "    x_raw = data.T[0].copy() \r\n",
    "\r\n",
    "    #axis=0,表示按列计算\r\n",
    "    #data.shape[0]表示data中一共有多少列\r\n",
    "    maximums,minimums,avgs = data.max(axis=0),data.min(axis=0),data.sum(axis=0)/data.shape[0]\r\n",
    "    print(\"the raw area :\",data[:,0].max(axis = 0))\r\n",
    "    #归一化\r\n",
    "    data[:,0] = (data[:,0]-avgs[0])/(maximums[0]-minimums[0])\r\n",
    "    print('normalization:',data[:,0].max(axis = 0))\r\n",
    "\r\n",
    "    # 将原数据集拆分成训练集和测试集\r\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\r\n",
    "    # 测试集和训练集必须是没有交集的\r\n",
    "    ratio = 0.8\r\n",
    "    offset = int(data.shape[0] * ratio)\r\n",
    "    training_data = data[:offset]\r\n",
    "\r\n",
    "    # 训练集和测试集的划分比例\r\n",
    "    training_data = data[:offset]\r\n",
    "    test_data = data[offset:]\r\n",
    "    return training_data, test_data\r\n",
    "\r\n",
    "\r\n",
    "class Network(object):\r\n",
    "    def __init__(self, num_of_weights):\r\n",
    "        # 随机产生w的初始值\r\n",
    "        # 为了保持程序每次运行结果的一致性，此处设置固定的随机数种子\r\n",
    "        # np.random.seed(0)\r\n",
    "        self.w = np.random.randn(num_of_weights, 1)\r\n",
    "        self.b = 0.\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        z = np.dot(x, self.w) + self.b\r\n",
    "        return z\r\n",
    "\r\n",
    "    def loss(self, z, y):\r\n",
    "        error = z - y\r\n",
    "        num_samples = error.shape[0]\r\n",
    "        cost = error * error\r\n",
    "        cost = np.sum(cost) / num_samples\r\n",
    "        return cost\r\n",
    "\r\n",
    "    def gradient(self, x, y):\r\n",
    "        z = self.forward(x)\r\n",
    "        N = x.shape[0]\r\n",
    "        gradient_w = 1. / N * np.sum((z - y) * x, axis=0)\r\n",
    "        gradient_w = gradient_w[:, np.newaxis]\r\n",
    "        gradient_b = 1. / N * np.sum(z - y)\r\n",
    "        return gradient_w, gradient_b\r\n",
    "\r\n",
    "    def update(self, gradient_w, gradient_b, eta=0.01):\r\n",
    "        self.w = self.w - eta * gradient_w\r\n",
    "        self.b = self.b - eta * gradient_b\r\n",
    "\r\n",
    "    def train(self, training_data, num_epoches, batch_size=10, eta=0.01):\r\n",
    "        n = len(training_data)\r\n",
    "        losses = []\r\n",
    "        for epoch_id in range(num_epoches):\r\n",
    "            # 在每轮迭代开始之前，将训练数据的顺序随机的打乱，\r\n",
    "            # 然后再按每次取batch_size条数据的方式取出\r\n",
    "            np.random.shuffle(training_data)\r\n",
    "            # 将训练数据进行拆分，每个mini_batch包含batch_size条的数据\r\n",
    "            mini_batches = [training_data[k:k + batch_size] for k in range(0, n, batch_size)]\r\n",
    "            for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "                # print(self.w.shape)\r\n",
    "                # print(self.b)\r\n",
    "                x = mini_batch[:, :-1]\r\n",
    "                y = mini_batch[:, -1:]\r\n",
    "                a = self.forward(x)\r\n",
    "                loss = self.loss(a, y)\r\n",
    "                gradient_w, gradient_b = self.gradient(x, y)\r\n",
    "                self.update(gradient_w, gradient_b, eta)\r\n",
    "                losses.append(loss)\r\n",
    "                print('Epoch {:3d} / iter {:3d}, loss = {:.4f}'.format(epoch_id, iter_id, loss))\r\n",
    "\r\n",
    "        return losses\r\n",
    "\r\n",
    "\r\n",
    "# 获取数据\r\n",
    "train_data, test_data = load_data()\r\n",
    "\r\n",
    "# 创建网络\r\n",
    "net = Network(1)\r\n",
    "# 启动训练\r\n",
    "losses = net.train(train_data, num_epoches=50, batch_size=100, eta=0.1)\r\n",
    "\r\n",
    "# 画出损失函数的变化趋势\r\n",
    "plot_x = np.arange(len(losses))\r\n",
    "plot_y = np.array(losses)\r\n",
    "plt.plot(plot_x, plot_y)\r\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
