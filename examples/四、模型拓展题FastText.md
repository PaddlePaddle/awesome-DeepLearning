FastText
简介

FastText是facebook开源的一个词向量计算和文本分类模型，其核心思想是：将整篇文档的词及n-gram向量叠加平均得到文档向量，然后使用文档向量做softmax多分类。这中间涉及到两个技巧：字符级n-gram特征的引入以及分层Softmax分类。FastText的典型应用场景是“带监督的文本分类问题”，提供简单而高效的文本分类和表征学习的方法，性能比肩深度学习而速度甚至更快。

FastText结合了自然语言处理和机器学习中最成功的理念。这些包括了使用词袋以及n-gram袋表征语句，还有使用子字(subword)信息，并通过隐藏表征在类别间共享信息。我们另外采用了一个softmax层级(利用了类别不均衡分布的优势)来加速运算过程。

一般情况下，使用FastText进行文本分类的同时也会产生词的embedding，即embedding是FastText分类的产物，除非使用预训练的embedding来训练FastText分类模型。

原理

 DastText模型架构和word2vec的CBOW模型架构非常相似。

![v2-7f38f23e98ee89d21fd16e34d5f07d69_720w](C:\Users\apple\Desktop\image\v2-7f38f23e98ee89d21fd16e34d5f07d69_720w.png)

FastText模型有三层：输入层、隐含层、输出层（Hierarchical Softmax），输入都是多个经向量表示的单词，输出都是一个特定的target，隐含层都是对多个词向量的叠加平均。FastText的输入是多个单词及其n-gram特征且被embedding过，这些特征用来表示单个文档；FastText的输出是文档对应的类标。

值得注意的是，FastText在输入时，将单词的字符级别的n-gram向量作为额外的特征；在输出时，FastText采用了分层Softmax，大大降低了模型训练时间。

对于有大量类别的数据集，FastText使用了一个分层分类器（而非扁平式架构）。不同的类别被整合进树形结构中。在某些文本分类任务中类别很多，计算线性分类器的复杂度高。为了改善运行时间，FastText 模型使用了层次 Softmax 技巧。层次 Softmax 技巧建立在哈弗曼编码的基础上，对标签进行编码，能够极大地缩小模型预测目标的数量。

![20180206115602122](C:\Users\apple\Desktop\image\20180206115602122.jpg)

fastText 也利用了类别（class）不均衡这个事实（一些类别出现次数比其他的更多），通过使用 Huffman 算法建立用于表征类别的树形结构。因此，频繁出现类别的树形结构的深度要比不频繁出现类别的树形结构的深度要小，这也使得进一步的计算效率更高。、

FastText 可以用于文本分类和句子分类。不管是文本分类还是句子分类，我们常用的特征是词袋模型。考虑到词袋模型词之间的顺序，FastText 加入了 N-gram 特征。“我 爱 她” 这句话中的词袋模型特征是 “我”，“爱”, “她”。这些特征和句子 “她 爱 我” 的特征是一样的。如果加入 2-Ngram，第一句话的特征还有 “我-爱” 和 “爱-她”，这两句话 “我 爱 她” 和 “她 爱 我” 就能区别开来了。

