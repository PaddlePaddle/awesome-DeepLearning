{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data65\tlog\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 14.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.vision.transforms import Compose, Normalize\r\n",
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "import numpy as np\r\n",
    "from paddle.metric import Accuracy\r\n",
    "import random\r\n",
    "from paddle import fluid\r\n",
    "from visualdl import LogWriter\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_writer=LogWriter(\"./data/log/train\") #log记录器\r\n",
    "\r\n",
    "\r\n",
    "transform = Compose([Normalize(mean=[127.5],\r\n",
    "                               std=[127.5],\r\n",
    "                               data_format='CHW')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#归一化\r\n",
    "\r\n",
    "#读取训练集 测试集数据\r\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\r\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InceptionA(paddle.nn.Layer):  #作为网络一层\r\n",
    "    def __init__(self,in_channels):\r\n",
    "        super(InceptionA,self).__init__()\r\n",
    "        self.branch3x3_1=paddle.nn.Conv2D(in_channels,16,kernel_size=1) #第一个分支\r\n",
    "        self.branch3x3_2=paddle.nn.Conv2D( 16,24,kernel_size=3,padding=1)\r\n",
    "        self.branch3x3_3=paddle.nn.Conv2D(24,24,kernel_size=3,padding=1)\r\n",
    "\r\n",
    "        self.branch5x5_1=paddle.nn.Conv2D(in_channels, 16,kernel_size=1) #第二个分支\r\n",
    "        self.branch5x5_2=paddle.nn.Conv2D( 16,24,kernel_size=5,padding=2)\r\n",
    "\r\n",
    "        self.branch1x1=paddle.nn.Conv2D(in_channels, 16,kernel_size=1) #第三个分支\r\n",
    "\r\n",
    "        self.branch_pool=paddle.nn.Conv2D(in_channels,24,kernel_size= 1) #第四个分支\r\n",
    "\r\n",
    "    def forward(self,x):\r\n",
    "        #分支1处理过程\r\n",
    "        branch3x3= self.branch3x3_1(x)\r\n",
    "        branch3x3= self.branch3x3_2(branch3x3)\r\n",
    "        branch3x3= self.branch3x3_3(branch3x3)\r\n",
    "        #分支2处理过程\r\n",
    "        branch5x5=self.branch5x5_1(x)\r\n",
    "        branch5x5=self.branch5x5_2(branch5x5)\r\n",
    "        #分支3处理过程\r\n",
    "        branch1x1=self.branch1x1(x)\r\n",
    "        #分支4处理过程\r\n",
    "        branch_pool=F.avg_pool2d(x,kernel_size=3,stride=1,padding= 1)\r\n",
    "        branch_pool=self.branch_pool(branch_pool)\r\n",
    "        outputs=[branch1x1,branch5x5,branch3x3,branch_pool]     #将4个分支的输出拼接起来\r\n",
    "        return fluid.layers.concat(outputs,axis=1) #横着拼接， 共有24+24+16+24=88个通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(paddle.nn.Layer):        #卷积，池化，inception，卷积，池化，inception，全连接\r\n",
    "    def __init__(self):\r\n",
    "        super(Net,self).__init__()\r\n",
    "        #定义两个卷积层\r\n",
    "        self.conv1=paddle.nn.Conv2D(1,10,kernel_size=5)\r\n",
    "        self.conv2=paddle.nn.Conv2D(88,20,kernel_size=5)\r\n",
    "        #Inception模块的输出均为88通道\r\n",
    "        self.incep1=InceptionA(in_channels=10 )\r\n",
    "        self.incep2=InceptionA(in_channels=20)\r\n",
    "        self.mp=paddle.nn.MaxPool2D(2)\r\n",
    "        self.fc=paddle.nn.Linear(1408,10) #5*5* 88 =2200，图像高*宽*通道数\r\n",
    "    def forward(self,x):\r\n",
    "        x=F.relu(self.mp(self.conv1(x)))# 卷积池化，relu  输出x为图像尺寸14*14*10\r\n",
    "        x =self.incep1(x)               #图像尺寸14*14*88\r\n",
    "\r\n",
    "        x =F.relu(self.mp(self.conv2(x)))# 卷积池化，relu  输出x为图像尺寸5*5*20\r\n",
    "        x = self.incep2(x)              #图像尺寸5*5*88\r\n",
    "\r\n",
    "        x = paddle.flatten(x, start_axis=1,stop_axis=-1)\r\n",
    "        x = self.fc(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/2\n",
      "step  10/938 [..............................] - loss: 1.6875 - acc: 0.2875 - ETA: 28s - 31ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  20/938 [..............................] - loss: 0.8002 - acc: 0.4414 - ETA: 21s - 23ms/stepstep 310/938 [========>.....................] - loss: 0.4136 - acc: 0.8654 - ETA: 10s - 16ms/st"
     ]
    }
   ],
   "source": [
    "model = paddle.Model(Net())   # 封装模型\r\n",
    "optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()) # adam优化器\r\n",
    "\r\n",
    "# 配置模型\r\n",
    "model.prepare(\r\n",
    "    optim,\r\n",
    "    paddle.nn.CrossEntropyLoss(),\r\n",
    "    Accuracy()\r\n",
    "    )\r\n",
    "# 训练模型\r\n",
    "model.fit(train_dataset,epochs=2,batch_size=64,verbose=1)\r\n",
    "#评估\r\n",
    "model.evaluate(test_dataset, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#训练\r\n",
    "def train(model,Batch_size=64):\r\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\r\n",
    "    model.train()\r\n",
    "    iterator = 0\r\n",
    "    epochs = 10\r\n",
    "    total_steps = (int(50000//Batch_size)+1)*epochs\r\n",
    "    lr = paddle.optimizer.lr.PolynomialDecay(learning_rate=0.01,decay_steps=total_steps,end_lr=0.001)\r\n",
    "    optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\r\n",
    "    # 用Adam作为优化函数\r\n",
    "    for epoch in range(epochs):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            x_data = data[0]\r\n",
    "            y_data = data[1]\r\n",
    "            predicts = model(x_data)\r\n",
    "            loss = F.cross_entropy(predicts, y_data)\r\n",
    "            # 计算损失\r\n",
    "            acc = paddle.metric.accuracy(predicts, y_data)\r\n",
    "            loss.backward()\r\n",
    "            if batch_id % 200 == 0:\r\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\r\n",
    "                log_writer.add_scalar(tag='acc',step=iterator,value=acc.numpy())\r\n",
    "                log_writer.add_scalar(tag='loss',step=iterator,value=loss.numpy())\r\n",
    "                iterator+=200\r\n",
    "            optim.step()\r\n",
    "            optim.clear_grad()\r\n",
    "        paddle.save(model.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdparams')\r\n",
    "        paddle.save(optim.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdopt')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#测试\r\n",
    "def test(model):\r\n",
    "    # 加载测试数据集\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\r\n",
    "    model.eval()\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data = data[0]\r\n",
    "        y_data = data[1]\r\n",
    "        predicts = model(x_data)\r\n",
    "        # 获取预测结果\r\n",
    "        loss = F.cross_entropy(predicts, y_data)\r\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\r\n",
    "        if batch_id % 20 == 0:\r\n",
    "            print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#随机抽取100张图片进行测试\r\n",
    "def random_test(model,num=100):\r\n",
    "    select_id = random.sample(range(1, 10000), 100) #生成一百张测试图片的下标\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data = data[0]\r\n",
    "        label = data[1]\r\n",
    "    predicts = model(x_data)\r\n",
    "    #返回正确率\r\n",
    "    acc = paddle.metric.accuracy(predicts, label)\r\n",
    "    print(\"正确率为：{}\".format(acc.numpy()))\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    model = Net()\r\n",
    "    train(model)\r\n",
    "    test(model)\r\n",
    "    random_test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
