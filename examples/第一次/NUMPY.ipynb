{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**数据处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.320e-03 1.800e+01 2.310e+00 ... 3.969e+02 7.880e+00 1.190e+01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7084,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "datafile='work/housing.data'\r\n",
    "data=np.fromfile(datafile,sep=' ')\r\n",
    "print(data)\r\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\r\n",
    "data=data.reshape(data.shape[0]//len(feature_names),len(feature_names))\r\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据划分\r\n",
    "n=0.8\r\n",
    "offset =int(data.shape[0]*n)#\r\n",
    "train_data=data[:offset]#训练集\r\n",
    "test_data=data[offset:]#测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据归一化\r\n",
    "arr1=np.array([1,2,3])\r\n",
    "arr1.max()\r\n",
    "arr1=np.array([[1,2,3],[4,5,6]])\r\n",
    "arr1.max (axis=1)#代表求最大值，0时是每一列，1时为每一行\r\n",
    "arr1.min (axis=1)\r\n",
    "arr1[:,:-1]#取除最后一个的所有元素\r\n",
    "arr1[:,-1:0]#取最后一个所有元素\r\n",
    "\r\n",
    "minnums=data.min(axis=0)#求每一列的最小值\r\n",
    "maxnums=data.max(axis=0)#最大值\r\n",
    "#avgs=data.sum(axis=0)/train_data.shape#平均值\r\n",
    "feature_nums=len(feature_names)\r\n",
    "for i in range(feature_nums):\r\n",
    "    #print(minnum[i],maxnum[i])\r\n",
    "    data[:,i]=(data[:,i]-minnums[i])/(maxnums[i]-minnums[i])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data_s(datafile,feature_num,n):\r\n",
    "    data = np.fromfile(datafile,sep=' ')\r\n",
    "    data = data.reshape(data.shape[0]//feature_num,feature_num)\r\n",
    "    minnums=data.min(axis=0)#求每一列的最小值\r\n",
    "    maxnums=data.max(axis=0)#最大值\r\n",
    "    for i in range(feature_nums):\r\n",
    "        data[:,i]=(data[:,i]-minnums[i])/(maxnums[i]-minnums[i])\r\n",
    "    offset = int(data.shape[0]*n)\r\n",
    "    train_data=data[:offset]\r\n",
    "    test_data=data[offset:]\r\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,test_data=load_data_s(datafile=\"work/housing.data\",feature_num=14,n = 0.8)\r\n",
    "x = train_data[:,:-1]\r\n",
    "y = train_data[:,-1:]\r\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**模型设计**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    }
   ],
   "source": [
    "w = [0.1,0.2,0.2,0.1,0.1,0.3,0.3,0.2,0.1,0.1,0.2,0.2,0.1]\r\n",
    "b = 0.2\r\n",
    "#z = w[0]*[0][0]+b #前向传播\r\n",
    "w = np.array(w)#将w转换为数组\r\n",
    "w=w.reshape([13,1])\r\n",
    "z = np.dot(x,w)+b#当要求N个样本时?->循环，其实numpy提供了广播机制\r\n",
    "print(len(z))\r\n",
    "#print(z)\r\n",
    "\r\n",
    "#for i in range(len(train_data)):\r\n",
    "#   z=np.dot(x[i]*w)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**封装前向传播**\n",
    "将前向传播封装成一个函数，实现调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\r\n",
    "    def __init__(self,weight_nums):\r\n",
    "        np.random.seed(0) #引入随机数种子，防止数据改变\r\n",
    "        self.w=np.random.randn(weight_nums,1) #产生weight_nums行1列的样本\r\n",
    "        self.b=0.2\r\n",
    "    def forward(self,x):\r\n",
    "        z=np.dot(x,self.w)+self.b\r\n",
    "        return z\r\n",
    "    def loss(self,z,y):\r\n",
    "        error=z-y\r\n",
    "        cost=error*error\r\n",
    "        loss=np.mean(cost)\r\n",
    "        return loss\r\n",
    "    def gradient(self,x,y): #计算梯度\r\n",
    "        z=self.forward(x)\r\n",
    "        gradient_w=(z-y)*x\r\n",
    "        gradient_w=np.mean(gradient_w,axis=0) #计算梯度的均值\r\n",
    "        gradient_w=gradient_w[:,np.newaxis] #增加梯度的维度\r\n",
    "\r\n",
    "        gradient_b=z-y\r\n",
    "        gradient_b=np.mean(gradient_b)\r\n",
    "        return gradient_w,gradient_b\r\n",
    "    #参数更新\r\n",
    "    def update(self,gradient_w,gradient_b,eta):\r\n",
    "        self.w = self.w - eta*gradient_w\r\n",
    "        self.b = self.b - eta*gradient_b\r\n",
    "    \r\n",
    "    #模型训练\r\n",
    "    def train(self,x,y,n=100,eta=0.01):\r\n",
    "        Losses=[]\r\n",
    "        for i in range(n):\r\n",
    "            z=self.forward(x)\r\n",
    "            gradient_w,gradient_b=self.gradient(x,y)\r\n",
    "            self.update(gradient_w,gradient_b,eta)\r\n",
    "            L=self.loss(z,y)\r\n",
    "            Losses.append(L)\r\n",
    "         #作业一：每隔10个打印一个loss，打印所有loss\r\n",
    "            if (i +1) % 10 == 0:\r\n",
    "               print('iter{},loss{}'.format(i,L))\r\n",
    "        return Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**模型的训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter9,loss5.6158411168609375\n",
      "iter19,loss3.3249724239788336\n",
      "iter29,loss2.1855722104515833\n",
      "iter39,loss1.6090324567404453\n",
      "iter49,loss1.3081060481988538\n",
      "iter59,loss1.1425891242459314\n",
      "iter69,loss1.0440259945520045\n",
      "iter79,loss0.9789708945185633\n",
      "iter89,loss0.9310624695354961\n",
      "iter99,loss0.8922774059915114\n",
      "iter109,loss0.8586627741520443\n",
      "iter119,loss0.8282536379989837\n",
      "iter129,loss0.8000569099931762\n",
      "iter139,loss0.7735554552391098\n",
      "iter149,loss0.7484660416684528\n",
      "iter159,loss0.7246211519683269\n",
      "iter169,loss0.7019112348490648\n",
      "iter179,loss0.6802564502449057\n",
      "iter189,loss0.659592809288425\n",
      "iter199,loss0.6398653416402492\n",
      "iter209,loss0.62102469525128\n",
      "iter219,loss0.6030254143277723\n",
      "iter229,loss0.5858250393936898\n",
      "iter239,loss0.569383611568324\n",
      "iter249,loss0.5536633770047952\n",
      "iter259,loss0.5386285917745444\n",
      "iter269,loss0.5242453784003404\n",
      "iter279,loss0.5104816100915432\n",
      "iter289,loss0.4973068108679142\n",
      "iter299,loss0.48469206568473683\n",
      "iter309,loss0.4726099375700623\n",
      "iter319,loss0.46103439020495846\n",
      "iter329,loss0.4499407150762746\n",
      "iter339,loss0.4393054626777486\n",
      "iter349,loss0.4291063774094239\n",
      "iter359,loss0.41932233591519763\n",
      "iter369,loss0.40993328864680895\n",
      "iter379,loss0.40092020447062543\n",
      "iter389,loss0.39226501815145026\n",
      "iter399,loss0.3839505805602314\n",
      "iter409,loss0.3759606114624901\n",
      "iter419,loss0.3682796547526815\n",
      "iter429,loss0.3608930360071646\n",
      "iter439,loss0.3537868222353005\n",
      "iter449,loss0.3469477837145609\n",
      "iter459,loss0.34036335780150584\n",
      "iter469,loss0.334021614616128\n",
      "iter479,loss0.3279112245023938\n",
      "iter489,loss0.32202142717286025\n",
      "iter499,loss0.31634200245003014\n",
      "iter509,loss0.3108632425216414\n",
      "iter519,loss0.30557592563138397\n",
      "iter529,loss0.3004712911306132\n",
      "iter539,loss0.29554101582048875\n",
      "iter549,loss0.2907771915176311\n",
      "iter559,loss0.2861723037798619\n",
      "iter569,loss0.28171921173188125\n",
      "iter579,loss0.27741112893385955\n",
      "iter589,loss0.2732416052388798\n",
      "iter599,loss0.2692045095879687\n",
      "iter609,loss0.26529401369411976\n",
      "iter619,loss0.26150457656922677\n",
      "iter629,loss0.2578309298502428\n",
      "iter639,loss0.254268063883142\n",
      "iter649,loss0.25081121452541233\n",
      "iter659,loss0.24745585062984654\n",
      "iter669,loss0.2441976621743252\n",
      "iter679,loss0.24103254900412469\n",
      "iter689,loss0.23795661015501116\n",
      "iter699,loss0.23496613372703506\n",
      "iter709,loss0.23205758728049625\n",
      "iter719,loss0.22922760872703332\n",
      "iter729,loss0.22647299769019152\n",
      "iter739,loss0.2237907073111546\n",
      "iter749,loss0.22117783647658812\n",
      "iter759,loss0.21863162244673504\n",
      "iter769,loss0.2161494338630417\n",
      "iter779,loss0.21372876411566266\n",
      "iter789,loss0.21136722505221717\n",
      "iter799,loss0.209062541010131\n",
      "iter809,loss0.20681254315581785\n",
      "iter819,loss0.20461516411481973\n",
      "iter829,loss0.20246843287785146\n",
      "iter839,loss0.20037046996847452\n",
      "iter849,loss0.19831948285886405\n",
      "iter859,loss0.1963137616208377\n",
      "iter869,loss0.19435167479997803\n",
      "iter879,loss0.1924316655013114\n",
      "iter889,loss0.19055224767560497\n",
      "iter899,loss0.18871200259591087\n",
      "iter909,loss0.186909575514523\n",
      "iter919,loss0.18514367249102237\n",
      "iter929,loss0.18341305738257077\n",
      "iter939,loss0.1817165489880697\n",
      "iter949,loss0.18005301833823684\n",
      "iter959,loss0.17842138612406394\n",
      "iter969,loss0.1768206202565099\n",
      "iter979,loss0.17524973355065515\n",
      "iter989,loss0.17370778152789132\n",
      "iter999,loss0.17219386033005668\n",
      "iter1009,loss0.1707071047397401\n",
      "iter1019,loss0.1692466863012777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = Network(13)\r\n",
    "n = 1026\r\n",
    "losses = net.train(x,y,n)\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "plot_x=np.arange(n)\r\n",
    "plot_y=np.array(losses)\r\n",
    "plt.plot(plot_x,plot_y)\r\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.4 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
