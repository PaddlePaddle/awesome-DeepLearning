{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像数据形状和对应数据为： (28, 28)\n",
      "图像标签形状和对应数据为： (1,) [5]\n",
      "\n",
      "打印第一个batch的第一个图像，对应标签数字为[5]\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "from paddle.nn import Linear \r\n",
    "import paddle.nn.functional as F\r\n",
    "import os\r\n",
    "import numpy as np \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "\r\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train')\r\n",
    "train_data0 = np.array(train_dataset[0][0])\r\n",
    "train_label_0= np.array(train_dataset[0][1])\r\n",
    "plt.figure(\"Image\")\r\n",
    "plt.figure(figsize=(2,2))\r\n",
    "plt.imshow(train_data0,cmap=plt.cm.binary)\r\n",
    "plt.axis('on')\r\n",
    "plt.title('image')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"图像数据形状和对应数据为：\",train_data0.shape)\r\n",
    "print(\"图像标签形状和对应数据为：\",train_label_0.shape,train_label_0)\r\n",
    "print(\"\\n打印第一个batch的第一个图像，对应标签数字为{}\".format(train_label_0))\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download training data and load training data\n"
     ]
    }
   ],
   "source": [
    "from paddle.vision.transforms import Compose, Normalize\r\n",
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "import numpy as np \r\n",
    "from paddle.metric import Accuracy\r\n",
    "import random\r\n",
    "from visualdl import LogWriter\r\n",
    "\r\n",
    "log_writer=LogWriter(\"./data/log/train\") #log记录器\r\n",
    "\r\n",
    "transform = Compose([Normalize(mean=[127.5],\r\n",
    "                               std=[127.5],\r\n",
    "                               data_format='CHW')])\r\n",
    "# 使用transform对数据集做归一化\r\n",
    "print('download training data and load training data')\r\n",
    "#读取训练集 测试集数据\r\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\r\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\r\n",
    "print('load finished')\r\n",
    "\r\n",
    "\r\n",
    "class LeNet(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(LeNet, self).__init__()\r\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\r\n",
    "        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2,  stride=2)\r\n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1)\r\n",
    "        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)\r\n",
    "        self.linear1 = paddle.nn.Linear(in_features=16*5*5, out_features=120)\r\n",
    "        self.linear2 = paddle.nn.Linear(in_features=120, out_features=84)\r\n",
    "        self.linear3 = paddle.nn.Linear(in_features=84, out_features=10)\r\n",
    "    #前馈网络\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.max_pool1(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = self.max_pool2(x)\r\n",
    "        x = paddle.flatten(x, start_axis=1,stop_axis=-1)\r\n",
    "        x = self.linear1(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.linear2(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.linear3(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "model = paddle.Model(LeNet())   # 封装模型\r\n",
    "# optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()) # adam优化器\r\n",
    "\r\n",
    "# 配置模型\r\n",
    "# model.prepare(\r\n",
    "#     optim,\r\n",
    "#     paddle.nn.CrossEntropyLoss(),\r\n",
    "#     Accuracy()\r\n",
    "#     )\r\n",
    "# # 训练模型\r\n",
    "# model.fit(train_dataset,\r\n",
    "#         epochs=2,\r\n",
    "#         batch_size=64,\r\n",
    "#         verbose=1\r\n",
    "#         )\r\n",
    "# #评估\r\n",
    "# model.evaluate(test_dataset, batch_size=64, verbose=1)\r\n",
    "\r\n",
    "#训练\r\n",
    "def train(model,Batch_size=64):\r\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\r\n",
    "    model.train()\r\n",
    "    iterator = 0\r\n",
    "    epochs = 5\r\n",
    "    total_steps = (int(50000//Batch_size)+1)*epochs\r\n",
    "    lr = paddle.optimizer.lr.PolynomialDecay(learning_rate=0.01,decay_steps=total_steps,end_lr=0.001)\r\n",
    "    optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\r\n",
    "    # 用Adam作为优化函数\r\n",
    "    for epoch in range(epochs):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            x_data = data[0]\r\n",
    "            y_data = data[1]\r\n",
    "            predicts = model(x_data)\r\n",
    "            loss = F.cross_entropy(predicts, y_data)\r\n",
    "            # 计算损失\r\n",
    "            acc = paddle.metric.accuracy(predicts, y_data)\r\n",
    "            loss.backward()\r\n",
    "            if batch_id % 200 == 0:\r\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\r\n",
    "                log_writer.add_scalar(tag='acc',step=iterator,value=acc.numpy())\r\n",
    "                log_writer.add_scalar(tag='loss',step=iterator,value=loss.numpy())\r\n",
    "                iterator+=200\r\n",
    "            optim.step()\r\n",
    "            optim.clear_grad()\r\n",
    "        paddle.save(model.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdparams')\r\n",
    "        paddle.save(optim.state_dict(),'./data/checkpoint/mnist_epoch{}'.format(epoch)+'.pdopt')\r\n",
    "\r\n",
    "\r\n",
    "#测试\r\n",
    "def test(model):\r\n",
    "    # 加载测试数据集\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\r\n",
    "    model.eval()\r\n",
    "    batch_size = 64\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data = data[0]\r\n",
    "        y_data = data[1]\r\n",
    "        predicts = model(x_data)\r\n",
    "        # 获取预测结果\r\n",
    "        loss = F.cross_entropy(predicts, y_data)\r\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\r\n",
    "        if batch_id % 20 == 0:\r\n",
    "            print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\r\n",
    "\r\n",
    "#随机抽取100张图片进行测试\r\n",
    "def random_test(model,num=100):\r\n",
    "    # select_id = random.sample(range(1, 10000), 100) #生成一百张测试图片的下标\r\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        x_data = data[0]\r\n",
    "        label = data[1]\r\n",
    "    predicts = model(x_data)\r\n",
    "    #返回正确率\r\n",
    "    acc = paddle.metric.accuracy(predicts, label)\r\n",
    "    print(\"正确率为：{}\".format(acc.numpy()))\r\n",
    "\r\n",
    "    \r\n",
    "    \r\n",
    "#调用模型\r\n",
    "model = LeNet()\r\n",
    "train(model)\r\n",
    "test(model)\r\n",
    "random_test(model)\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
