{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import random\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "import paddle.nn as nn\r\n",
    "import gzip\r\n",
    "import json\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 编写数据导入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(mode='train'):\r\n",
    "\r\n",
    "    # 数据文件\r\n",
    "    datafile = './mnist.json.gz'\r\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\r\n",
    "    data = json.load(gzip.open(datafile))\r\n",
    "    train_set, val_set, eval_set = data\r\n",
    "\r\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\r\n",
    "    IMG_ROWS = 28\r\n",
    "    IMG_COLS = 28\r\n",
    "\r\n",
    "    if mode == 'train':\r\n",
    "        imgs = train_set[0]\r\n",
    "        labels = train_set[1]\r\n",
    "    elif mode == 'valid':\r\n",
    "        imgs = val_set[0]\r\n",
    "        labels = val_set[1]\r\n",
    "    elif mode == 'eval':\r\n",
    "        imgs = eval_set[0]\r\n",
    "        labels = eval_set[1]\r\n",
    "\r\n",
    "    imgs_length = len(imgs)\r\n",
    "\r\n",
    "    assert len(imgs) == len(labels), \\\r\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\r\n",
    "                  len(imgs), len(labels))\r\n",
    "\r\n",
    "    index_list = list(range(imgs_length))\r\n",
    "\r\n",
    "    # batchsize\r\n",
    "    BATCHSIZE = 100\r\n",
    "\r\n",
    "    # 定义数据生成器\r\n",
    "    def data_generator():\r\n",
    "        if mode == 'train':\r\n",
    "            random.shuffle(index_list)\r\n",
    "        imgs_list = []\r\n",
    "        labels_list = []\r\n",
    "        for i in index_list:\r\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\r\n",
    "            label = np.reshape(labels[i], [1]).astype('float32')\r\n",
    "            imgs_list.append(img) \r\n",
    "            labels_list.append(label)\r\n",
    "            if len(imgs_list) == BATCHSIZE:\r\n",
    "                yield np.array(imgs_list), np.array(labels_list)\r\n",
    "                imgs_list = []\r\n",
    "                labels_list = []\r\n",
    "\r\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\r\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\r\n",
    "        if len(imgs_list) > 0:\r\n",
    "            yield np.array(imgs_list), np.array(labels_list)\r\n",
    "\r\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 编写ResNet网络\n",
    "## 编写残差单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Layer):\r\n",
    "    def __init__(self, num_channels, num_filters, use_1x1conv=False, stride=1):\r\n",
    "        super(Residual, self).__init__()\r\n",
    "        self.use_1x1conv = use_1x1conv\r\n",
    "        model = [\r\n",
    "            nn.Conv2D(num_channels, num_filters, 3, stride=stride, padding=1),\r\n",
    "            nn.BatchNorm2D(num_filters),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2D(num_filters, num_filters, 3, stride=1, padding=1),\r\n",
    "            nn.BatchNorm2D(num_filters),\r\n",
    "        ]\r\n",
    "        self.model = nn.Sequential(*model)\r\n",
    "        if use_1x1conv:\r\n",
    "            model_1x1 = [nn.Conv2D(num_channels, num_filters, 1, stride=stride)]\r\n",
    "            self.model_1x1 = nn.Sequential(*model_1x1)\r\n",
    "    def forward(self, X):\r\n",
    "        Y = self.model(X)\r\n",
    "        if self.use_1x1conv:\r\n",
    "            X = self.model_1x1(X)\r\n",
    "        return paddle.nn.functional.relu(X + Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 编写残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Layer):\r\n",
    "    def __init__(self, num_channels, num_filters, num_residuals, first_block=False):\r\n",
    "        super(ResnetBlock, self).__init__()\r\n",
    "        model = []\r\n",
    "        for i in range(num_residuals):\r\n",
    "            if i == 0:\r\n",
    "                if not first_block:\r\n",
    "                    model += [Residual(num_channels, num_filters, use_1x1conv=True, stride=2)]\r\n",
    "                else:\r\n",
    "                    model += [Residual(num_channels, num_filters)]\r\n",
    "            else:\r\n",
    "                model += [Residual(num_filters, num_filters)]\r\n",
    "        self.model = nn.Sequential(*model)\r\n",
    "    def forward(self, X):\r\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "class ResNet(nn.Layer):\r\n",
    "    def __init__(self, num_classes=10):\r\n",
    "        super(ResNet, self).__init__()\r\n",
    "        # ResNet 在输出通道数为64、步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。每个卷积层后增加的批量归一化层。\r\n",
    "        model = [\r\n",
    "            nn.Conv2D(1, 64, 7, stride=2, padding=3),\r\n",
    "            nn.BatchNorm2D(64),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2D(kernel_size=3, stride=2, padding=1)\r\n",
    "        ]\r\n",
    "\r\n",
    "        # 这里每个模块使用2个残差块\r\n",
    "        model += [\r\n",
    "            ResnetBlock(64, 64, 2, first_block=True),\r\n",
    "            ResnetBlock(64, 128, 2),\r\n",
    "            ResnetBlock(128, 256, 2),\r\n",
    "            ResnetBlock(256, 512, 2)\r\n",
    "        ]\r\n",
    "\r\n",
    "        # 加入全局平均池化层后接上全连接层输出。\r\n",
    "        model += [\r\n",
    "            nn.AdaptiveAvgPool2D(output_size=1),\r\n",
    "            nn.Flatten(start_axis=1, stop_axis=-1),\r\n",
    "            nn.Linear(512, num_classes),\r\n",
    "        ]\r\n",
    "        self.model = nn.Sequential(*model)\r\n",
    "    def forward(self, X):\r\n",
    "        Y = self.model(X)\r\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mnist dataset from ./mnist.json.gz ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:648: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [43.018494]\n",
      "epoch: 0, batch: 200, loss is: [1.1114743]\n",
      "epoch: 0, batch: 400, loss is: [0.6331429]\n",
      "epoch: 1, batch: 0, loss is: [0.3949953]\n",
      "epoch: 1, batch: 200, loss is: [0.45853272]\n",
      "epoch: 1, batch: 400, loss is: [0.9216258]\n",
      "epoch: 2, batch: 0, loss is: [0.29214016]\n",
      "epoch: 2, batch: 200, loss is: [0.27684498]\n",
      "epoch: 2, batch: 400, loss is: [0.17330088]\n",
      "epoch: 3, batch: 0, loss is: [0.23164555]\n",
      "epoch: 3, batch: 200, loss is: [0.351003]\n",
      "epoch: 3, batch: 400, loss is: [0.7193225]\n",
      "epoch: 4, batch: 0, loss is: [0.12296607]\n",
      "epoch: 4, batch: 200, loss is: [0.19334751]\n",
      "epoch: 4, batch: 400, loss is: [0.10125654]\n"
     ]
    }
   ],
   "source": [
    "with fluid.dygraph.guard(place=fluid.CUDAPlace(0)):\r\n",
    "    model = ResNet()\r\n",
    "    model.train()\r\n",
    "    #调用加载数据的函数\r\n",
    "    train_loader = load_data('train')\r\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\r\n",
    "    EPOCH_NUM = 5\r\n",
    "    for epoch_id in range(EPOCH_NUM):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            #准备数据\r\n",
    "            image_data, label_data = data\r\n",
    "            image = fluid.dygraph.to_variable(image_data)\r\n",
    "            label = fluid.dygraph.to_variable(label_data)\r\n",
    "             \r\n",
    "            predict = model(image)\r\n",
    "            \r\n",
    "            loss = fluid.layers.square_error_cost(predict, label)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "            \r\n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\r\n",
    "            if batch_id % 200 == 0:\r\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\r\n",
    "            \r\n",
    "            #后向传播，更新参数的过程\r\n",
    "            avg_loss.backward()\r\n",
    "            optimizer.minimize(avg_loss)\r\n",
    "            model.clear_gradients()\r\n",
    "\r\n",
    "    #保存模型参数\r\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
