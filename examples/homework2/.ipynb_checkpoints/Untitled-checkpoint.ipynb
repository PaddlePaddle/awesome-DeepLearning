{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning) # 过滤报警信息\n",
    "from PIL import Image\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 定义数据集读取器\n",
    "def load_data(mode='train'):\n",
    "\n",
    "    # 数据文件\n",
    "    datafile = './work/mnist.json.gz'\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\n",
    "    data = json.load(gzip.open(datafile))\n",
    "    train_set, val_set, eval_set = data\n",
    "\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "\n",
    "    if mode == 'train':\n",
    "        imgs = train_set[0]\n",
    "        labels = train_set[1]\n",
    "    elif mode == 'valid':\n",
    "        imgs = val_set[0]\n",
    "        labels = val_set[1]\n",
    "    elif mode == 'eval':\n",
    "        imgs = eval_set[0]\n",
    "        labels = eval_set[1]\n",
    "\n",
    "    imgs_length = len(imgs)\n",
    "\n",
    "    assert len(imgs) == len(labels), \\\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\n",
    "                  len(imgs), len(labels))\n",
    "\n",
    "    index_list = list(range(imgs_length))\n",
    "\n",
    "    # 读入数据时用到的batchsize\n",
    "    BATCHSIZE = 100\n",
    "\n",
    "    # 定义数据生成器\n",
    "    def data_generator():\n",
    "        if mode == 'train':\n",
    "            random.shuffle(index_list)\n",
    "        imgs_list = []\n",
    "        labels_list = []\n",
    "        for i in index_list:\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\n",
    "            label = np.reshape(labels[i], [1]).astype('float32')\n",
    "            imgs_list.append(img) \n",
    "            labels_list.append(label)\n",
    "            if len(imgs_list) == BATCHSIZE:\n",
    "                yield np.array(imgs_list), np.array(labels_list)\n",
    "                imgs_list = []\n",
    "                labels_list = []\n",
    "\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\n",
    "        if len(imgs_list) > 0:\n",
    "            yield np.array(imgs_list), np.array(labels_list)\n",
    "\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file C:\\Users\\LFP\\.cache\\paddle\\dataset\\mnist\\train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file C:\\Users\\LFP\\.cache\\paddle\\dataset\\mnist\\train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n",
      "Cache file C:\\Users\\LFP\\.cache\\paddle\\dataset\\mnist\\t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file C:\\Users\\LFP\\.cache\\paddle\\dataset\\mnist\\t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "..\n",
      "Download finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本量: 60000，验证集样本量: 10000\n"
     ]
    }
   ],
   "source": [
    "import paddle.vision.transforms as T\n",
    "\n",
    "# 数据的加载和预处理\n",
    "transform = T.Normalize(mean=[127.5], std=[127.5])\n",
    "\n",
    "# 训练数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "\n",
    "# 评估数据集\n",
    "eval_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "\n",
    "print('训练集样本量: {}，验证集样本量: {}'.format(len(train_dataset), len(eval_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片：\n",
      "<class 'numpy.ndarray'>\n",
      "[[[-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -0.9764706  -0.85882354 -0.85882354\n",
      "   -0.85882354 -0.01176471  0.06666667  0.37254903 -0.79607844\n",
      "    0.3019608   1.          0.9372549  -0.00392157 -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -0.7647059  -0.7176471\n",
      "   -0.2627451   0.20784314  0.33333334  0.9843137   0.9843137\n",
      "    0.9843137   0.9843137   0.9843137   0.7647059   0.34901962\n",
      "    0.9843137   0.8980392   0.5294118  -0.49803922 -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -0.6156863   0.8666667   0.9843137\n",
      "    0.9843137   0.9843137   0.9843137   0.9843137   0.9843137\n",
      "    0.9843137   0.9843137   0.96862745 -0.27058825 -0.35686275\n",
      "   -0.35686275 -0.56078434 -0.69411767 -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -0.85882354  0.7176471   0.9843137\n",
      "    0.9843137   0.9843137   0.9843137   0.9843137   0.5529412\n",
      "    0.42745098  0.9372549   0.8901961  -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -0.37254903  0.22352941\n",
      "   -0.16078432  0.9843137   0.9843137   0.60784316 -0.9137255\n",
      "   -1.         -0.6627451   0.20784314 -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -0.8901961\n",
      "   -0.99215686  0.20784314  0.9843137  -0.29411766 -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.          0.09019608  0.9843137   0.49019608 -0.9843137\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -0.9137255   0.49019608  0.9843137  -0.4509804\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -0.7254902   0.8901961   0.7647059\n",
      "    0.25490198 -0.15294118 -0.99215686 -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -0.3647059   0.88235295\n",
      "    0.9843137   0.9843137  -0.06666667 -0.8039216  -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -0.64705884\n",
      "    0.45882353  0.9843137   0.9843137   0.1764706  -0.7882353\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -0.8745098  -0.27058825  0.9764706   0.9843137   0.46666667\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.          0.9529412   0.9843137   0.9529412\n",
      "   -0.49803922 -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -0.6392157\n",
      "    0.01960784  0.43529412  0.9843137   0.9843137   0.62352943\n",
      "   -0.9843137  -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -0.69411767  0.16078432  0.79607844\n",
      "    0.9843137   0.9843137   0.9843137   0.9607843   0.42745098\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -0.8117647  -0.10588235  0.73333335  0.9843137   0.9843137\n",
      "    0.9843137   0.9843137   0.5764706  -0.3882353  -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -0.81960785 -0.48235294\n",
      "    0.67058825  0.9843137   0.9843137   0.9843137   0.9843137\n",
      "    0.5529412  -0.3647059  -0.9843137  -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -0.85882354  0.34117648  0.7176471   0.9843137\n",
      "    0.9843137   0.9843137   0.9843137   0.5294118  -0.37254903\n",
      "   -0.92941177 -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -0.5686275\n",
      "    0.34901962  0.77254903  0.9843137   0.9843137   0.9843137\n",
      "    0.9843137   0.9137255   0.04313726 -0.9137255  -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.          0.06666667\n",
      "    0.9843137   0.9843137   0.9843137   0.6627451   0.05882353\n",
      "    0.03529412 -0.8745098  -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]]]\n",
      "标签：\n",
      "<class 'numpy.ndarray'>\n",
      "[5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('图片：')\n",
    "print(type(train_dataset[0][0]))\n",
    "print(train_dataset[0][0])\n",
    "print('标签：')\n",
    "print(type(train_dataset[0][1]))\n",
    "print(train_dataset[0][1])\n",
    "\n",
    "# 可视化展示\n",
    "plt.figure()\n",
    "plt.imshow(train_dataset[0][0].reshape([28,28]), cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Layer):\n",
    "    def __init__(self, num_channels, num_filters, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.use_1x1conv = use_1x1conv\n",
    "        model = [\n",
    "            nn.Conv2D(num_channels, num_filters, 3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2D(num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(num_filters, num_filters, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2D(num_filters),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*model)\n",
    "        if use_1x1conv:\n",
    "            model_1x1 = [nn.Conv2D(num_channels, num_filters, 1, stride=stride)]\n",
    "            self.model_1x1 = nn.Sequential(*model_1x1)\n",
    "    def forward(self, X):\n",
    "        Y = self.model(X)\n",
    "        if self.use_1x1conv:\n",
    "            X = self.model_1x1(X)\n",
    "        return paddle.nn.functional.relu(X + Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Layer):\n",
    "    def __init__(self, num_channels, num_filters, num_residuals, first_block=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        model = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0:\n",
    "                if not first_block:\n",
    "                    model += [Residual(num_channels, num_filters, use_1x1conv=True, stride=2)]\n",
    "                else:\n",
    "                    model += [Residual(num_channels, num_filters)]\n",
    "            else:\n",
    "                model += [Residual(num_filters, num_filters)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet(nn.Layer):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        # ResNet的前两层跟之前介绍的GoogLeNet中的一样：\n",
    "        # 在输出通道数为64、步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。\n",
    "        # 不同之处在于ResNet每个卷积层后增加的批量归一化层。\n",
    "        model = [\n",
    "            nn.Conv2D(1, 64, 7, stride=2, padding=3),\n",
    "            nn.BatchNorm2D(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
    "        ]\n",
    "\n",
    "        # 接着我们为ResNet加入所有残差块。这里每个模块使用2个残差块。\n",
    "        model += [\n",
    "            ResnetBlock(64, 64, 2, first_block=True),\n",
    "            ResnetBlock(64, 128, 2),\n",
    "            ResnetBlock(128, 256, 2),\n",
    "            ResnetBlock(256, 512, 2)\n",
    "        ]\n",
    "\n",
    "        # 最后，与GoogLeNet一样，加入全局平均池化层后接上全连接层输出。\n",
    "        model += [\n",
    "            nn.AdaptiveAvgPool2D(output_size=1),\n",
    "            nn.Flatten(start_axis=1, stop_axis=-1),\n",
    "            nn.Linear(512, num_classes),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*model)\n",
    "    def forward(self, X):\n",
    "        Y = self.model(X)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "     Conv2D-41        [[1, 1, 28, 28]]     [1, 64, 14, 14]         3,200     \n",
      "  BatchNorm2D-35     [[1, 64, 14, 14]]     [1, 64, 14, 14]          256      \n",
      "      ReLU-19        [[1, 64, 14, 14]]     [1, 64, 14, 14]           0       \n",
      "    MaxPool2D-3      [[1, 64, 14, 14]]      [1, 64, 7, 7]            0       \n",
      "     Conv2D-42        [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      "  BatchNorm2D-36      [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "      ReLU-20         [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "     Conv2D-43        [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      "  BatchNorm2D-37      [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "    Residual-17       [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "     Conv2D-44        [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      "  BatchNorm2D-38      [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "      ReLU-21         [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "     Conv2D-45        [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      "  BatchNorm2D-39      [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "    Residual-18       [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "   ResnetBlock-9      [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "     Conv2D-46        [[1, 64, 7, 7]]       [1, 128, 4, 4]        73,856     \n",
      "  BatchNorm2D-40      [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "      ReLU-22         [[1, 128, 4, 4]]      [1, 128, 4, 4]           0       \n",
      "     Conv2D-47        [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "  BatchNorm2D-41      [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "     Conv2D-48        [[1, 64, 7, 7]]       [1, 128, 4, 4]         8,320     \n",
      "    Residual-19       [[1, 64, 7, 7]]       [1, 128, 4, 4]           0       \n",
      "     Conv2D-49        [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "  BatchNorm2D-42      [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "      ReLU-23         [[1, 128, 4, 4]]      [1, 128, 4, 4]           0       \n",
      "     Conv2D-50        [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "  BatchNorm2D-43      [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "    Residual-20       [[1, 128, 4, 4]]      [1, 128, 4, 4]           0       \n",
      "  ResnetBlock-10      [[1, 64, 7, 7]]       [1, 128, 4, 4]           0       \n",
      "     Conv2D-51        [[1, 128, 4, 4]]      [1, 256, 2, 2]        295,168    \n",
      "  BatchNorm2D-44      [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "      ReLU-24         [[1, 256, 2, 2]]      [1, 256, 2, 2]           0       \n",
      "     Conv2D-52        [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "  BatchNorm2D-45      [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "     Conv2D-53        [[1, 128, 4, 4]]      [1, 256, 2, 2]        33,024     \n",
      "    Residual-21       [[1, 128, 4, 4]]      [1, 256, 2, 2]           0       \n",
      "     Conv2D-54        [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "  BatchNorm2D-46      [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "      ReLU-25         [[1, 256, 2, 2]]      [1, 256, 2, 2]           0       \n",
      "     Conv2D-55        [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "  BatchNorm2D-47      [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "    Residual-22       [[1, 256, 2, 2]]      [1, 256, 2, 2]           0       \n",
      "  ResnetBlock-11      [[1, 128, 4, 4]]      [1, 256, 2, 2]           0       \n",
      "     Conv2D-56        [[1, 256, 2, 2]]      [1, 512, 1, 1]       1,180,160   \n",
      "  BatchNorm2D-48      [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "      ReLU-26         [[1, 512, 1, 1]]      [1, 512, 1, 1]           0       \n",
      "     Conv2D-57        [[1, 512, 1, 1]]      [1, 512, 1, 1]       2,359,808   \n",
      "  BatchNorm2D-49      [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "     Conv2D-58        [[1, 256, 2, 2]]      [1, 512, 1, 1]        131,584    \n",
      "    Residual-23       [[1, 256, 2, 2]]      [1, 512, 1, 1]           0       \n",
      "     Conv2D-59        [[1, 512, 1, 1]]      [1, 512, 1, 1]       2,359,808   \n",
      "  BatchNorm2D-50      [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "      ReLU-27         [[1, 512, 1, 1]]      [1, 512, 1, 1]           0       \n",
      "     Conv2D-60        [[1, 512, 1, 1]]      [1, 512, 1, 1]       2,359,808   \n",
      "  BatchNorm2D-51      [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "    Residual-24       [[1, 512, 1, 1]]      [1, 512, 1, 1]           0       \n",
      "  ResnetBlock-12      [[1, 256, 2, 2]]      [1, 512, 1, 1]           0       \n",
      "AdaptiveAvgPool2D-3   [[1, 512, 1, 1]]      [1, 512, 1, 1]           0       \n",
      "     Flatten-4        [[1, 512, 1, 1]]         [1, 512]              0       \n",
      "     Linear-3            [[1, 512]]            [1, 10]             5,130     \n",
      "===============================================================================\n",
      "Total params: 11,186,186\n",
      "Trainable params: 11,170,570\n",
      "Non-trainable params: 15,616\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.01\n",
      "Params size (MB): 42.67\n",
      "Estimated Total Size (MB): 43.69\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "{'total_params': 11186186, 'trainable_params': 11170570}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mnist dataset from ./work/mnist.json.gz ......\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './work/mnist.json.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bbd4d3880f3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#调用加载数据的函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGDOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameter_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mEPOCH_NUM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-60971027449c>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdatafile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./work/mnist.json.gz'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loading mnist dataset from {} ......'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './work/mnist.json.gz'"
     ]
    }
   ],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    model = ResNet()\n",
    "    model.train()\n",
    "    #调用加载数据的函数\n",
    "    train_loader = load_data('train')\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据\n",
    "            image_data, label_data = data\n",
    "            image = fluid.dygraph.to_variable(image_data)\n",
    "            label = fluid.dygraph.to_variable(label_data)\n",
    "             \n",
    "            #前向计算的过程\n",
    "            predict = model(image)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = fluid.layers.square_error_cost(predict, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            optimizer.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "\n",
    "    #保存模型参数\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
