{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data16317\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing.data\r\n"
     ]
    }
   ],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 20.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#导入相关的库\r\n",
    "import paddle\r\n",
    "from paddle.nn import Linear\r\n",
    "import paddle.nn.functional as F\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import random\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 编写加载数据的函数\r\n",
    "def load_data():\r\n",
    "    # 从文件导入数据\r\n",
    "    datafile='./work/housing.data'\r\n",
    "    data=np.fromfile(datafile,sep=' ',dtype=np.float32)\r\n",
    "    \r\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\r\n",
    "    feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \\\r\n",
    "                      'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\r\n",
    "    feature_num = len(feature_names)\r\n",
    "\r\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\r\n",
    "    #将一维的数据转成二维\r\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\r\n",
    "    \r\n",
    "    # 将原数据集拆分成训练集和测试集\r\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\r\n",
    "    # 测试集和训练集必须是没有交集的\r\n",
    "    ratio=0.8\r\n",
    "    offset=int(data.shape[0]*ratio)\r\n",
    "    training_data=data[:offset]\r\n",
    "\r\n",
    "    # 计算train数据集的最大值，最小值，平均值\r\n",
    "    maximums,minimums,avgs=training_data.max(axis=0),training_data.min(axis=0),training_data.sum(axis=0)/training_data.shape[0]\r\n",
    "\r\n",
    "    # 记录数据的归一化参数，在预测时对数据做归一化\r\n",
    "    global max_values\r\n",
    "    global min_values\r\n",
    "    global avg_values\r\n",
    "    max_values=maximums\r\n",
    "    min_values=minimums\r\n",
    "    avg_values=avgs\r\n",
    "\r\n",
    "    # 对数据进行归一化处理\r\n",
    "    for i in range(feature_num):\r\n",
    "        data[:,i]=(data[:,i]-avgs[i])/(maximums[i]-minimums[i])\r\n",
    "\r\n",
    "    # 训练集和测试集的划分比例\r\n",
    "    training_data=data[:offset]\r\n",
    "    test_data=data[offset:]\r\n",
    "    \r\n",
    "    return training_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义网络结构为两层，全连接层+激活函数+全连接层\r\n",
    "class Net(paddle.nn.Layer):\r\n",
    "    # self代表类的实例自身\r\n",
    "    def __init__(self):\r\n",
    "        # 初始化父类中的一些参数\r\n",
    "        super(Net,self).__init__()\r\n",
    "\r\n",
    "        self.fc1=Linear(in_features=13,out_features=128)\r\n",
    "        self.fc2=Linear(in_features=128,out_features=1)\r\n",
    "        \r\n",
    "    def forward(self,inputs):\r\n",
    "        x=self.fc1(inputs)\r\n",
    "        x=F.relu(x)\r\n",
    "        x=self.fc2(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#创建网络的一个对象\r\n",
    "model=Net()\r\n",
    "model.train()\r\n",
    "#进入模型的训练模式\r\n",
    "training_data, test_data = load_data()\r\n",
    "opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())\r\n",
    "#设置优化器为Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 0, loss is: [0.02875786]\n",
      "epoch: 1, iter: 20, loss is: [0.01014329]\n",
      "epoch: 1, iter: 40, loss is: [0.00580197]\n",
      "epoch: 2, iter: 0, loss is: [0.00517416]\n",
      "epoch: 2, iter: 20, loss is: [0.00755648]\n",
      "epoch: 2, iter: 40, loss is: [0.00383944]\n",
      "epoch: 3, iter: 0, loss is: [0.0033968]\n",
      "epoch: 3, iter: 20, loss is: [0.00634085]\n",
      "epoch: 3, iter: 40, loss is: [0.00484461]\n",
      "epoch: 4, iter: 0, loss is: [0.00301662]\n",
      "epoch: 4, iter: 20, loss is: [0.00820194]\n",
      "epoch: 4, iter: 40, loss is: [0.00469439]\n",
      "epoch: 5, iter: 0, loss is: [0.00098433]\n",
      "epoch: 5, iter: 20, loss is: [0.00840407]\n",
      "epoch: 5, iter: 40, loss is: [0.00357361]\n",
      "epoch: 6, iter: 0, loss is: [0.00463749]\n",
      "epoch: 6, iter: 20, loss is: [0.00470148]\n",
      "epoch: 6, iter: 40, loss is: [0.00227926]\n",
      "epoch: 7, iter: 0, loss is: [0.00078318]\n",
      "epoch: 7, iter: 20, loss is: [0.0062756]\n",
      "epoch: 7, iter: 40, loss is: [0.00940356]\n",
      "epoch: 8, iter: 0, loss is: [0.00267786]\n",
      "epoch: 8, iter: 20, loss is: [0.00360906]\n",
      "epoch: 8, iter: 40, loss is: [0.00121929]\n",
      "epoch: 9, iter: 0, loss is: [0.00123987]\n",
      "epoch: 9, iter: 20, loss is: [0.00247582]\n",
      "epoch: 9, iter: 40, loss is: [0.00483735]\n",
      "epoch: 10, iter: 0, loss is: [0.00212717]\n",
      "epoch: 10, iter: 20, loss is: [0.00240224]\n",
      "epoch: 10, iter: 40, loss is: [0.00024015]\n",
      "epoch: 11, iter: 0, loss is: [0.00327615]\n",
      "epoch: 11, iter: 20, loss is: [0.00142267]\n",
      "epoch: 11, iter: 40, loss is: [0.00291984]\n",
      "epoch: 12, iter: 0, loss is: [0.00141478]\n",
      "epoch: 12, iter: 20, loss is: [0.00668099]\n",
      "epoch: 12, iter: 40, loss is: [0.00568745]\n",
      "epoch: 13, iter: 0, loss is: [0.00238869]\n",
      "epoch: 13, iter: 20, loss is: [0.00184444]\n",
      "epoch: 13, iter: 40, loss is: [0.00276492]\n",
      "epoch: 14, iter: 0, loss is: [0.00148403]\n",
      "epoch: 14, iter: 20, loss is: [0.00137826]\n",
      "epoch: 14, iter: 40, loss is: [0.00025064]\n",
      "epoch: 15, iter: 0, loss is: [0.00563653]\n",
      "epoch: 15, iter: 20, loss is: [0.0009081]\n",
      "epoch: 15, iter: 40, loss is: [0.00566186]\n",
      "epoch: 16, iter: 0, loss is: [0.00917763]\n",
      "epoch: 16, iter: 20, loss is: [0.00114248]\n",
      "epoch: 16, iter: 40, loss is: [0.00094825]\n",
      "epoch: 17, iter: 0, loss is: [0.00234339]\n",
      "epoch: 17, iter: 20, loss is: [0.00086521]\n",
      "epoch: 17, iter: 40, loss is: [0.00199057]\n",
      "epoch: 18, iter: 0, loss is: [0.0031646]\n",
      "epoch: 18, iter: 20, loss is: [0.00311996]\n",
      "epoch: 18, iter: 40, loss is: [0.00343166]\n",
      "epoch: 19, iter: 0, loss is: [0.00370589]\n",
      "epoch: 19, iter: 20, loss is: [0.00113868]\n",
      "epoch: 19, iter: 40, loss is: [0.00101918]\n",
      "epoch: 20, iter: 0, loss is: [0.00499664]\n",
      "epoch: 20, iter: 20, loss is: [0.00575106]\n",
      "epoch: 20, iter: 40, loss is: [0.00339944]\n",
      "epoch: 21, iter: 0, loss is: [0.00504293]\n",
      "epoch: 21, iter: 20, loss is: [0.00516602]\n",
      "epoch: 21, iter: 40, loss is: [0.00243568]\n",
      "epoch: 22, iter: 0, loss is: [0.00280842]\n",
      "epoch: 22, iter: 20, loss is: [0.00928806]\n",
      "epoch: 22, iter: 40, loss is: [0.00284278]\n",
      "epoch: 23, iter: 0, loss is: [0.00055773]\n",
      "epoch: 23, iter: 20, loss is: [0.00175183]\n",
      "epoch: 23, iter: 40, loss is: [0.0040466]\n",
      "epoch: 24, iter: 0, loss is: [0.00229102]\n",
      "epoch: 24, iter: 20, loss is: [0.00194634]\n",
      "epoch: 24, iter: 40, loss is: [0.00138109]\n",
      "epoch: 25, iter: 0, loss is: [0.00105629]\n",
      "epoch: 25, iter: 20, loss is: [0.00450127]\n",
      "epoch: 25, iter: 40, loss is: [0.00202979]\n",
      "epoch: 26, iter: 0, loss is: [0.00153941]\n",
      "epoch: 26, iter: 20, loss is: [0.00146637]\n",
      "epoch: 26, iter: 40, loss is: [0.00078709]\n",
      "epoch: 27, iter: 0, loss is: [0.00156418]\n",
      "epoch: 27, iter: 20, loss is: [0.00307898]\n",
      "epoch: 27, iter: 40, loss is: [0.00159091]\n",
      "epoch: 28, iter: 0, loss is: [0.00221024]\n",
      "epoch: 28, iter: 20, loss is: [0.00030636]\n",
      "epoch: 28, iter: 40, loss is: [0.00593501]\n",
      "epoch: 29, iter: 0, loss is: [0.00156992]\n",
      "epoch: 29, iter: 20, loss is: [0.00518662]\n",
      "epoch: 29, iter: 40, loss is: [0.00029163]\n",
      "epoch: 30, iter: 0, loss is: [0.00230511]\n",
      "epoch: 30, iter: 20, loss is: [0.01831392]\n",
      "epoch: 30, iter: 40, loss is: [0.00188278]\n",
      "epoch: 31, iter: 0, loss is: [0.00433233]\n",
      "epoch: 31, iter: 20, loss is: [0.0012584]\n",
      "epoch: 31, iter: 40, loss is: [0.00132161]\n",
      "epoch: 32, iter: 0, loss is: [0.00199349]\n",
      "epoch: 32, iter: 20, loss is: [0.00240079]\n",
      "epoch: 32, iter: 40, loss is: [0.00052856]\n",
      "epoch: 33, iter: 0, loss is: [0.00088804]\n",
      "epoch: 33, iter: 20, loss is: [0.00134803]\n",
      "epoch: 33, iter: 40, loss is: [0.00475573]\n",
      "epoch: 34, iter: 0, loss is: [0.00149057]\n",
      "epoch: 34, iter: 20, loss is: [0.00175693]\n",
      "epoch: 34, iter: 40, loss is: [0.00035865]\n",
      "epoch: 35, iter: 0, loss is: [0.00085386]\n",
      "epoch: 35, iter: 20, loss is: [0.00194511]\n",
      "epoch: 35, iter: 40, loss is: [0.00288477]\n",
      "epoch: 36, iter: 0, loss is: [0.00162462]\n",
      "epoch: 36, iter: 20, loss is: [0.00928449]\n",
      "epoch: 36, iter: 40, loss is: [0.01139897]\n",
      "epoch: 37, iter: 0, loss is: [0.00156048]\n",
      "epoch: 37, iter: 20, loss is: [0.00349555]\n",
      "epoch: 37, iter: 40, loss is: [0.01269172]\n",
      "epoch: 38, iter: 0, loss is: [0.00288169]\n",
      "epoch: 38, iter: 20, loss is: [0.00128855]\n",
      "epoch: 38, iter: 40, loss is: [0.00074797]\n",
      "epoch: 39, iter: 0, loss is: [0.00089703]\n",
      "epoch: 39, iter: 20, loss is: [0.00382079]\n",
      "epoch: 39, iter: 40, loss is: [0.00412294]\n",
      "epoch: 40, iter: 0, loss is: [0.00227687]\n",
      "epoch: 40, iter: 20, loss is: [0.00537139]\n",
      "epoch: 40, iter: 40, loss is: [0.00429609]\n",
      "epoch: 41, iter: 0, loss is: [0.00288302]\n",
      "epoch: 41, iter: 20, loss is: [0.0038525]\n",
      "epoch: 41, iter: 40, loss is: [0.0005166]\n",
      "epoch: 42, iter: 0, loss is: [0.00228357]\n",
      "epoch: 42, iter: 20, loss is: [0.00083685]\n",
      "epoch: 42, iter: 40, loss is: [0.0014928]\n",
      "epoch: 43, iter: 0, loss is: [0.00192754]\n",
      "epoch: 43, iter: 20, loss is: [0.0008681]\n",
      "epoch: 43, iter: 40, loss is: [0.01015293]\n",
      "epoch: 44, iter: 0, loss is: [0.00184615]\n",
      "epoch: 44, iter: 20, loss is: [0.00246284]\n",
      "epoch: 44, iter: 40, loss is: [0.00046719]\n",
      "epoch: 45, iter: 0, loss is: [0.00405301]\n",
      "epoch: 45, iter: 20, loss is: [0.00321802]\n",
      "epoch: 45, iter: 40, loss is: [0.00145279]\n",
      "epoch: 46, iter: 0, loss is: [0.00148617]\n",
      "epoch: 46, iter: 20, loss is: [0.00146899]\n",
      "epoch: 46, iter: 40, loss is: [0.00420052]\n",
      "epoch: 47, iter: 0, loss is: [0.00182993]\n",
      "epoch: 47, iter: 20, loss is: [0.0067679]\n",
      "epoch: 47, iter: 40, loss is: [0.00858084]\n",
      "epoch: 48, iter: 0, loss is: [0.00209639]\n",
      "epoch: 48, iter: 20, loss is: [0.00126133]\n",
      "epoch: 48, iter: 40, loss is: [0.00010561]\n",
      "epoch: 49, iter: 0, loss is: [0.00060388]\n",
      "epoch: 49, iter: 20, loss is: [0.00394217]\n",
      "epoch: 49, iter: 40, loss is: [0.00297848]\n",
      "epoch: 50, iter: 0, loss is: [0.00376099]\n",
      "epoch: 50, iter: 20, loss is: [0.00168184]\n",
      "epoch: 50, iter: 40, loss is: [0.00281202]\n",
      "epoch: 51, iter: 0, loss is: [0.00353447]\n",
      "epoch: 51, iter: 20, loss is: [0.0012068]\n",
      "epoch: 51, iter: 40, loss is: [0.00310346]\n",
      "epoch: 52, iter: 0, loss is: [0.00080819]\n",
      "epoch: 52, iter: 20, loss is: [0.00035375]\n",
      "epoch: 52, iter: 40, loss is: [0.00150859]\n",
      "epoch: 53, iter: 0, loss is: [0.00195881]\n",
      "epoch: 53, iter: 20, loss is: [0.00099058]\n",
      "epoch: 53, iter: 40, loss is: [0.01058385]\n",
      "epoch: 54, iter: 0, loss is: [0.00359258]\n",
      "epoch: 54, iter: 20, loss is: [0.00314672]\n",
      "epoch: 54, iter: 40, loss is: [0.00125784]\n",
      "epoch: 55, iter: 0, loss is: [0.00145655]\n",
      "epoch: 55, iter: 20, loss is: [0.00134341]\n",
      "epoch: 55, iter: 40, loss is: [0.00101067]\n",
      "epoch: 56, iter: 0, loss is: [0.00148967]\n",
      "epoch: 56, iter: 20, loss is: [0.00103631]\n",
      "epoch: 56, iter: 40, loss is: [0.00023277]\n",
      "epoch: 57, iter: 0, loss is: [0.00358311]\n",
      "epoch: 57, iter: 20, loss is: [0.00097266]\n",
      "epoch: 57, iter: 40, loss is: [0.0052584]\n",
      "epoch: 58, iter: 0, loss is: [0.00265441]\n",
      "epoch: 58, iter: 20, loss is: [0.00222927]\n",
      "epoch: 58, iter: 40, loss is: [0.00315406]\n",
      "epoch: 59, iter: 0, loss is: [0.00292198]\n",
      "epoch: 59, iter: 20, loss is: [0.0013723]\n",
      "epoch: 59, iter: 40, loss is: [0.00096784]\n",
      "epoch: 60, iter: 0, loss is: [0.00221458]\n",
      "epoch: 60, iter: 20, loss is: [0.00097334]\n",
      "epoch: 60, iter: 40, loss is: [0.00242306]\n",
      "epoch: 61, iter: 0, loss is: [0.00532796]\n",
      "epoch: 61, iter: 20, loss is: [0.00106668]\n",
      "epoch: 61, iter: 40, loss is: [0.00209771]\n",
      "epoch: 62, iter: 0, loss is: [0.00202765]\n",
      "epoch: 62, iter: 20, loss is: [0.00940344]\n",
      "epoch: 62, iter: 40, loss is: [0.00030849]\n",
      "epoch: 63, iter: 0, loss is: [0.0013235]\n",
      "epoch: 63, iter: 20, loss is: [0.00703744]\n",
      "epoch: 63, iter: 40, loss is: [0.00101989]\n",
      "epoch: 64, iter: 0, loss is: [0.00161416]\n",
      "epoch: 64, iter: 20, loss is: [0.00176575]\n",
      "epoch: 64, iter: 40, loss is: [0.00401699]\n",
      "epoch: 65, iter: 0, loss is: [0.00194829]\n",
      "epoch: 65, iter: 20, loss is: [0.00348632]\n",
      "epoch: 65, iter: 40, loss is: [0.00140784]\n",
      "epoch: 66, iter: 0, loss is: [0.00102757]\n",
      "epoch: 66, iter: 20, loss is: [0.00173963]\n",
      "epoch: 66, iter: 40, loss is: [0.00246787]\n",
      "epoch: 67, iter: 0, loss is: [0.00312775]\n",
      "epoch: 67, iter: 20, loss is: [0.00099895]\n",
      "epoch: 67, iter: 40, loss is: [0.00251181]\n",
      "epoch: 68, iter: 0, loss is: [0.00134294]\n",
      "epoch: 68, iter: 20, loss is: [0.00095609]\n",
      "epoch: 68, iter: 40, loss is: [0.00989814]\n",
      "epoch: 69, iter: 0, loss is: [0.00136242]\n",
      "epoch: 69, iter: 20, loss is: [0.00039332]\n",
      "epoch: 69, iter: 40, loss is: [0.00089508]\n",
      "epoch: 70, iter: 0, loss is: [0.00701522]\n",
      "epoch: 70, iter: 20, loss is: [0.00166017]\n",
      "epoch: 70, iter: 40, loss is: [0.00193081]\n",
      "epoch: 71, iter: 0, loss is: [0.00182427]\n",
      "epoch: 71, iter: 20, loss is: [0.00113767]\n",
      "epoch: 71, iter: 40, loss is: [0.00551878]\n",
      "epoch: 72, iter: 0, loss is: [0.00144884]\n",
      "epoch: 72, iter: 20, loss is: [0.00082769]\n",
      "epoch: 72, iter: 40, loss is: [0.00033181]\n",
      "epoch: 73, iter: 0, loss is: [0.00265743]\n",
      "epoch: 73, iter: 20, loss is: [0.00200795]\n",
      "epoch: 73, iter: 40, loss is: [0.00190243]\n",
      "epoch: 74, iter: 0, loss is: [0.0007589]\n",
      "epoch: 74, iter: 20, loss is: [0.00298402]\n",
      "epoch: 74, iter: 40, loss is: [0.00482131]\n",
      "epoch: 75, iter: 0, loss is: [0.00055222]\n",
      "epoch: 75, iter: 20, loss is: [0.00316835]\n",
      "epoch: 75, iter: 40, loss is: [0.00048058]\n",
      "epoch: 76, iter: 0, loss is: [0.00176407]\n",
      "epoch: 76, iter: 20, loss is: [0.00239981]\n",
      "epoch: 76, iter: 40, loss is: [0.00024439]\n",
      "epoch: 77, iter: 0, loss is: [0.00078359]\n",
      "epoch: 77, iter: 20, loss is: [0.00346533]\n",
      "epoch: 77, iter: 40, loss is: [0.00140136]\n",
      "epoch: 78, iter: 0, loss is: [0.00122374]\n",
      "epoch: 78, iter: 20, loss is: [0.00063193]\n",
      "epoch: 78, iter: 40, loss is: [0.00041882]\n",
      "epoch: 79, iter: 0, loss is: [0.00218466]\n",
      "epoch: 79, iter: 20, loss is: [0.00118188]\n",
      "epoch: 79, iter: 40, loss is: [0.00049251]\n",
      "epoch: 80, iter: 0, loss is: [0.00079595]\n",
      "epoch: 80, iter: 20, loss is: [0.00150322]\n",
      "epoch: 80, iter: 40, loss is: [0.0015422]\n",
      "epoch: 81, iter: 0, loss is: [0.00127569]\n",
      "epoch: 81, iter: 20, loss is: [0.00160835]\n",
      "epoch: 81, iter: 40, loss is: [0.00520353]\n",
      "epoch: 82, iter: 0, loss is: [0.00132467]\n",
      "epoch: 82, iter: 20, loss is: [0.00212951]\n",
      "epoch: 82, iter: 40, loss is: [0.00575307]\n",
      "epoch: 83, iter: 0, loss is: [0.00341268]\n",
      "epoch: 83, iter: 20, loss is: [0.00163028]\n",
      "epoch: 83, iter: 40, loss is: [0.00356409]\n",
      "epoch: 84, iter: 0, loss is: [0.00094034]\n",
      "epoch: 84, iter: 20, loss is: [0.00150003]\n",
      "epoch: 84, iter: 40, loss is: [0.00025169]\n",
      "epoch: 85, iter: 0, loss is: [0.00163074]\n",
      "epoch: 85, iter: 20, loss is: [0.00184239]\n",
      "epoch: 85, iter: 40, loss is: [0.00420461]\n",
      "epoch: 86, iter: 0, loss is: [0.00172155]\n",
      "epoch: 86, iter: 20, loss is: [0.00098929]\n",
      "epoch: 86, iter: 40, loss is: [0.00075994]\n",
      "epoch: 87, iter: 0, loss is: [0.00122421]\n",
      "epoch: 87, iter: 20, loss is: [0.00165098]\n",
      "epoch: 87, iter: 40, loss is: [0.00824334]\n",
      "epoch: 88, iter: 0, loss is: [0.0003448]\n",
      "epoch: 88, iter: 20, loss is: [0.00666341]\n",
      "epoch: 88, iter: 40, loss is: [0.00264483]\n",
      "epoch: 89, iter: 0, loss is: [0.00943951]\n",
      "epoch: 89, iter: 20, loss is: [0.00160093]\n",
      "epoch: 89, iter: 40, loss is: [0.00211143]\n",
      "epoch: 90, iter: 0, loss is: [0.00035986]\n",
      "epoch: 90, iter: 20, loss is: [0.0027773]\n",
      "epoch: 90, iter: 40, loss is: [0.00074996]\n",
      "epoch: 91, iter: 0, loss is: [0.00188069]\n",
      "epoch: 91, iter: 20, loss is: [0.00042422]\n",
      "epoch: 91, iter: 40, loss is: [0.00274049]\n",
      "epoch: 92, iter: 0, loss is: [0.00052669]\n",
      "epoch: 92, iter: 20, loss is: [0.00086471]\n",
      "epoch: 92, iter: 40, loss is: [0.00079585]\n",
      "epoch: 93, iter: 0, loss is: [0.00050847]\n",
      "epoch: 93, iter: 20, loss is: [0.00164568]\n",
      "epoch: 93, iter: 40, loss is: [0.0025435]\n",
      "epoch: 94, iter: 0, loss is: [0.00245285]\n",
      "epoch: 94, iter: 20, loss is: [0.00386984]\n",
      "epoch: 94, iter: 40, loss is: [0.00540782]\n",
      "epoch: 95, iter: 0, loss is: [0.00242601]\n",
      "epoch: 95, iter: 20, loss is: [0.00548464]\n",
      "epoch: 95, iter: 40, loss is: [6.0451086e-05]\n",
      "epoch: 96, iter: 0, loss is: [0.00322242]\n",
      "epoch: 96, iter: 20, loss is: [0.00588672]\n",
      "epoch: 96, iter: 40, loss is: [0.00061623]\n",
      "epoch: 97, iter: 0, loss is: [0.00070497]\n",
      "epoch: 97, iter: 20, loss is: [0.00212467]\n",
      "epoch: 97, iter: 40, loss is: [7.4080235e-05]\n",
      "epoch: 98, iter: 0, loss is: [0.00081023]\n",
      "epoch: 98, iter: 20, loss is: [0.00251241]\n",
      "epoch: 98, iter: 40, loss is: [0.00256539]\n",
      "epoch: 99, iter: 0, loss is: [0.00055783]\n",
      "epoch: 99, iter: 20, loss is: [0.00193705]\n",
      "epoch: 99, iter: 40, loss is: [0.00084013]\n",
      "epoch: 100, iter: 0, loss is: [0.00248172]\n",
      "epoch: 100, iter: 20, loss is: [0.00091145]\n",
      "epoch: 100, iter: 40, loss is: [0.00043632]\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 100   #设置迭代次数\r\n",
    "BATCH_SIZE = 10  #设置批次大小\r\n",
    "\r\n",
    "# 定义外层循环\r\n",
    "losses=[]\r\n",
    "for epoch_id in range(1,EPOCH_NUM+1):\r\n",
    "    # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\r\n",
    "    np.random.shuffle(training_data)\r\n",
    "    # 将训练数据进行拆分，每个batch包含10条数据\r\n",
    "    mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\r\n",
    "    # 定义内层循环\r\n",
    "    for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "        x = np.array(mini_batch[:, :-1]) # 获得当前批次训练数据\r\n",
    "        y = np.array(mini_batch[:, -1:]) # 获得当前批次训练标签（真实房价）\r\n",
    "        # 将numpy数据转为飞桨动态图tensor形式\r\n",
    "        house_features = paddle.to_tensor(x)\r\n",
    "        prices = paddle.to_tensor(y)\r\n",
    "        \r\n",
    "        # 前向计算\r\n",
    "        predicts = model(house_features)\r\n",
    "        \r\n",
    "        # 计算损失\r\n",
    "        loss = F.square_error_cost(predicts, label=prices)\r\n",
    "        avg_loss = paddle.mean(loss)\r\n",
    "        losses.append(avg_loss.numpy())\r\n",
    "        if iter_id % 20==0:\r\n",
    "            print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, iter_id, avg_loss.numpy()))\r\n",
    "        \r\n",
    "        # 反向传播\r\n",
    "        avg_loss.backward()\r\n",
    "        # 最小化loss,更新参数\r\n",
    "        opt.step()\r\n",
    "        # 清除梯度\r\n",
    "        opt.clear_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_x = np.arange(len(losses))\r\n",
    "plot_y = np.array(losses)\r\n",
    "plt.plot(plot_x, plot_y)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型保存成功，模型参数保存在LR_model.pdparams中\n"
     ]
    }
   ],
   "source": [
    "# 保存模型参数，文件名为LR_model.pdparams\r\n",
    "paddle.save(model.state_dict(), 'LR_model.pdparams')\r\n",
    "print(\"模型保存成功，模型参数保存在LR_model.pdparams中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result is [[25.91603]], the corresponding label is 23.899999618530273\n"
     ]
    }
   ],
   "source": [
    "# 参数为保存模型参数的文件地址\r\n",
    "model_dict = paddle.load('LR_model.pdparams')\r\n",
    "model.load_dict(model_dict)\r\n",
    "model.eval()\r\n",
    "\r\n",
    "# 从上边已加载的测试集中，随机选择一条作为测试数据\r\n",
    "idx = np.random.randint(0, test_data.shape[0])\r\n",
    "one_data, label = test_data[idx, :-1], test_data[idx, -1]\r\n",
    "# 修改该条数据shape为[1,13]\r\n",
    "one_data =  one_data.reshape([1,-1])\r\n",
    "\r\n",
    "# 将数据转为动态图的variable格式 \r\n",
    "one_data = paddle.to_tensor(one_data)\r\n",
    "predict = model(one_data)\r\n",
    "\r\n",
    "# 对结果做反归一化处理\r\n",
    "predict = predict * (max_values[-1] - min_values[-1]) + avg_values[-1]\r\n",
    "# 对label数据做反归一化处理\r\n",
    "label = label * (max_values[-1] - min_values[-1]) + avg_values[-1]\r\n",
    "\r\n",
    "print(\"Inference result is {}, the corresponding label is {}\".format(predict.numpy(), label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
