{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data5646\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 13.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/home/aistudio/data/data5646/housing.csv'\r\n",
    "data = pd.read_csv(path, header=0)\r\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvar = np.var(train_data, axis=0)\\navgs = np.sum(train_data, axis=0) / train_data.shape[0]\\nfor i in range(len(feature_names)):\\n    data[:, i] = ((data[:, i]) - avgs[i])  / var[i] \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 0.8\r\n",
    "train_num  =int(ratio*data.shape[0])\r\n",
    "train_data = data[:train_num]\r\n",
    "test_data = data[train_num:, ]\r\n",
    "maxn, minn, avgs = np.max(train_data, axis=0) , np.min(train_data, axis=0), np.sum(train_data, axis=0) / train_data.shape[0]\r\n",
    "feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX','PTRATIO','B', 'LSTAT', 'MEDV']\r\n",
    "for i in range(len(feature_names)):\r\n",
    "    data[:, i] = (data[:, i] - avgs[i])/( maxn[i] - minn[i])\r\n",
    "'''\r\n",
    "var = np.var(train_data, axis=0)\r\n",
    "avgs = np.sum(train_data, axis=0) / train_data.shape[0]\r\n",
    "for i in range(len(feature_names)):\r\n",
    "    data[:, i] = ((data[:, i]) - avgs[i])  / var[i] \r\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上就是对数据的导入以及预处理（归一化和标准化），可将其组合起来封装成一个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network():\r\n",
    "\r\n",
    "    def __init__(self, num):\r\n",
    "        np.random.seed(0)\r\n",
    "        self.w1 = np.random.random([num, 5])   #没有先验知识或者数学指导，不知道中间层的节点该定义为多少，随便定义了一个20\r\n",
    "        self.b1 = np.zeros([1, 5])\r\n",
    "        self.w2 = np.random.random([5, 1])\r\n",
    "        self.b2 = 0\r\n",
    "        self.gradient1 = 0\r\n",
    "        self.gradient2 = 0\r\n",
    "        self.g1 = 0\r\n",
    "        self.g2 = 0\r\n",
    "    \r\n",
    "    def forward(self, x):                     #relu\r\n",
    "        z1 = np.dot(x, self.w1) + self.b1\r\n",
    "        bck = z1\r\n",
    "        for i in range (5):\r\n",
    "            if z1[0, i] <= 0 :\r\n",
    "                bck[0, i] =0\r\n",
    "        z2 = np.dot(bck, self.w2) + self.b2 \r\n",
    "        return z2\r\n",
    "\r\n",
    "    def loss(self, x, y):\r\n",
    "        err  = x-y\r\n",
    "        cost = err*err\r\n",
    "        cost = np.mean(cost) / 2\r\n",
    "        return cost\r\n",
    "    \r\n",
    "    def bp(self, x ,y): #对所有样本的BP算法,这里要求样本要一个一个输入，两层之间的激活函数是Relu。\r\n",
    "        lr = 0.1\r\n",
    "        z1 = np.dot(x, self.w1)+ self.b1 #第一层的输出\r\n",
    "        z2 = self.forward(x) #第二层的输出\r\n",
    "        g = (y-z2) #中间变量g\r\n",
    "        self.g1 -= g \r\n",
    "        self.gradient1 += lr*g*z1   #第二层的梯度\r\n",
    "        e = self.w2*g\r\n",
    "        for i in range (5):\r\n",
    "            if z1[0, i] <= 0:\r\n",
    "                e[i, 0] = 0\r\n",
    "        self.g2 -= e \r\n",
    "        x = np.reshape(x, (13, 1))\r\n",
    "        self.gradient2 += lr*np.dot(x, np.transpose(e))  #第一层的梯度,对每一个数据产生的梯度累加求和\r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "    def mn(self, num):\r\n",
    "        self.gradient1 = self.gradient1 / num\r\n",
    "        self.gradient2 = self.gradient2 / num  #对梯度需要取平均值否则会梯度爆炸\r\n",
    "        self.g1 = self.g1 / num\r\n",
    "        self.g2 = self.g2 /num\r\n",
    "\r\n",
    "\r\n",
    "    def update(self):\r\n",
    "        self.w1 += self.gradient2\r\n",
    "        self.w2 += np.transpose(self.gradient1)\r\n",
    "        self.b1 -= np.transpose(self.g2)\r\n",
    "        self.b2 -= self.g1\r\n",
    "\r\n",
    "    def grad_zero(self):\r\n",
    "        self.gradient1, self.gradient2, self.g1, self.g2 = 0, 0, 0, 0\r\n",
    "        \r\n",
    "    #梯度更新及清零\r\n",
    "# 两层神经网络的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.54713539  0.67676566  0.63659096  0.51417386  0.40026492]\n",
      " [ 0.65520184  0.45695356  0.77805755  1.0543483   0.42812732]\n",
      " [ 0.76630257  0.4812026   0.35733948  0.82777878  0.08688273]\n",
      " [ 0.09727114  0.00799831  0.86771726  0.7676996   0.80807082]\n",
      " [ 0.97930341  0.75111038  0.59155805  0.43208312  0.17096193]\n",
      " [ 0.64564209  0.14966058  0.76238332  0.59786826  0.96111377]\n",
      " [ 0.24178891  0.73126793  0.43974716  0.51470465  0.24282337]\n",
      " [ 0.63380786  0.64277001  0.81118363  0.96056669  0.25922387]\n",
      " [ 0.31366698  0.34867452  0.60543094 -0.01656983  0.74480979]\n",
      " [ 0.62699131  0.13019795  0.09099704  0.22176611  0.25243302]\n",
      " [ 0.53560284  0.41068848  0.84482962  0.07314422  0.08153898]\n",
      " [ 0.15762897  0.65023949  0.18137806  0.50087022  0.26915195]\n",
      " [ 0.16878724  0.07716897  0.90049696 -0.09833664 -0.18491055]]\n"
     ]
    }
   ],
   "source": [
    "net = Network(13)\r\n",
    "x = train_data[:, :13]\r\n",
    "y = train_data[:, -1]\r\n",
    "y = np.reshape(y, (404, 1))\r\n",
    "\r\n",
    "\r\n",
    "for i in range(2000):\r\n",
    "    for j in range(train_data.shape[0]):\r\n",
    "        net.bp(x[j], y[j])    \r\n",
    "        net.mn(train_data.shape[0])\r\n",
    "        net.update()\r\n",
    "        net.grad_zero()\r\n",
    "print(net.w1)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result is [[12.129126]], the corresponding label is 12.0\n"
     ]
    }
   ],
   "source": [
    "def load_one_example():\r\n",
    "    # 从上边已加载的测试集中，随机选择一条作为测试数据\r\n",
    "    idx = np.random.randint(0, test_data.shape[0])\r\n",
    "\r\n",
    "    one_data, label = test_data[idx, :-1], test_data[idx, -1]\r\n",
    "    # 修改该条数据shape为[1,13]\r\n",
    "    one_data =  one_data.reshape([1,-1])\r\n",
    "\r\n",
    "    return one_data, label\r\n",
    "\r\n",
    "one_data, label = load_one_example()\r\n",
    "\r\n",
    "predict = net.forward(one_data)\r\n",
    "\r\n",
    "# 对结果做反归一化处理\r\n",
    "predict = predict * (maxn[-1] - minn[-1]) + avgs[-1]\r\n",
    "# 对label数据做反归一化处理\r\n",
    "label = label * (maxn[-1] - minn[-1]) + avgs[-1]\r\n",
    "\r\n",
    "print(\"Inference result is {}, the corresponding label is {}\".format(predict, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "对于两个网络的比价的说明相关部分在神经网络的代码文件里"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
