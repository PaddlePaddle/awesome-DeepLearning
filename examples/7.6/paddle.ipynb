{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data5646\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 15.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "from paddle.nn import Linear\r\n",
    "import paddle.nn.functional as F\r\n",
    "#导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvar = np.var(train_data, axis=0)\\navgs = np.sum(train_data, axis=0) / train_data.shape[0]\\nfor i in range(len(feature_names)):\\n    data[:, i] = ((data[:, i]) - avgs[i])  / var[i] #标准化\\n '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/aistudio/data/data5646/housing.csv'\r\n",
    "data = pd.read_csv(path, header=0)\r\n",
    "data = np.array(data)\r\n",
    "\r\n",
    "ratio = 0.8\r\n",
    "train_num  =int(ratio*data.shape[0])\r\n",
    "train_data = data[:train_num]\r\n",
    "test_data = data[train_num:, ]\r\n",
    "maxn, minn, avgs = np.max(train_data, axis=0) , np.min(train_data, axis=0), np.sum(train_data, axis=0) / train_data.shape[0]\r\n",
    "feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX','PTRATIO', 'B','LSTAT', 'MEDV']\r\n",
    "for i in range(len(feature_names)):\r\n",
    "    data[:, i] = (data[:, i] - avgs[i])/( maxn[i] - minn[i]) #归一化\r\n",
    "'''\r\n",
    "var = np.var(train_data, axis=0)\r\n",
    "avgs = np.sum(train_data, axis=0) / train_data.shape[0]\r\n",
    "for i in range(len(feature_names)):\r\n",
    "    data[:, i] = ((data[:, i]) - avgs[i])  / var[i] #标准化\r\n",
    " '''\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(paddle.nn.Layer):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(Network, self).__init__()\r\n",
    "        self.fc1 = Linear(in_features=13, out_features=20)\r\n",
    "        self.fc2 = Linear(in_features=20, out_features=1)\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        z1 = self.fc1(x)\r\n",
    "        z2 = F.relu(z1)\r\n",
    "        z3 = self.fc2(z2)\r\n",
    "        return z3\r\n",
    "#两层网络的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Network()\r\n",
    "model.train()\r\n",
    "opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\r\n",
    "#常规设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.17197114])\n",
      "模型保存成功，模型参数保存在LR_model.pdparams中\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.08989324])\n",
      "模型保存成功，模型参数保存在LR_model.pdparams中\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.19300707])\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.09118554])\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.00654959])\n",
      "模型保存成功，模型参数保存在LR_model.pdparams中\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.01464849])\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.01363039])\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.00266808])\n",
      "模型保存成功，模型参数保存在LR_model.pdparams中\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.01784513])\n",
      "Tensor(shape=[1], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
      "       [0.02264032])\n"
     ]
    }
   ],
   "source": [
    "epoch = 2000\r\n",
    "batch_size = 10\r\n",
    "l = 10000\r\n",
    "for i in range (epoch):\r\n",
    "    np.random.shuffle(train_data)\r\n",
    "    mini_batches = [train_data[k:k+batch_size] for k in range(0, len(train_data), batch_size)] #打乱 拆分数据集\r\n",
    "    for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "        x = np.array(mini_batch[:, :-1])\r\n",
    "        x = np.float32(x)\r\n",
    "        y = np.array(mini_batch[:, -1])\r\n",
    "        y = np.float32(y)\r\n",
    "        features = paddle.to_tensor(x)\r\n",
    "        price = paddle.to_tensor(y)\r\n",
    "\r\n",
    "        pred = model(features)\r\n",
    "        loss = F.square_error_cost(pred, price)\r\n",
    "        avg_loss = paddle.mean(loss)\r\n",
    "        avg_loss.backward()\r\n",
    "        opt.step()\r\n",
    "        opt.clear_grad()\r\n",
    "    if i % 200 ==0 :\r\n",
    "        print(avg_loss)\r\n",
    "\r\n",
    "    #保存loss最小,即最优的模型参数\r\n",
    "       \r\n",
    "        if avg_loss < l :\r\n",
    "            l = avg_loss\r\n",
    "            paddle.save(model.state_dict(), 'LR_model.pdparams')\r\n",
    "            print(\"模型保存成功，模型参数保存在LR_model.pdparams中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result is [[23.196688]], the corresponding label is 20.1\n"
     ]
    }
   ],
   "source": [
    "def load_one_example():\r\n",
    "    # 从上边已加载的测试集中，随机选择一条作为测试数据\r\n",
    "    idx = np.random.randint(0, test_data.shape[0])\r\n",
    "    one_data, label = test_data[idx, :-1], test_data[idx, -1]\r\n",
    "    # 修改该条数据shape为[1,13]\r\n",
    "    one_data =  one_data.reshape([1,-1])\r\n",
    "\r\n",
    "    return one_data, label\r\n",
    "\r\n",
    "\r\n",
    "# 参数为保存模型参数的文件地址\r\n",
    "model_dict = paddle.load('LR_model.pdparams')\r\n",
    "model.load_dict(model_dict)\r\n",
    "model.eval()\r\n",
    "\r\n",
    "# 参数为数据集的文件地址\r\n",
    "one_data, label = load_one_example()\r\n",
    "# 将数据转为动态图的variable格式 \r\n",
    "one_data = np.float32(one_data)\r\n",
    "one_data = paddle.to_tensor(one_data)\r\n",
    "predict = model(one_data)\r\n",
    "\r\n",
    "# 对结果做反归一化处理\r\n",
    "predict = predict * (maxn[-1] - minn[-1]) + avgs[-1]\r\n",
    "# 对label数据做反归一化处理\r\n",
    "label = label * (maxn[-1] - minn[-1]) + avgs[-1]\r\n",
    "\r\n",
    "print(\"Inference result is {}, the corresponding label is {}\".format(predict.numpy(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "网络结构为全连接+Relu+全连接的两层神经网络分别用Numpy和paddlepaddle成功编写。实现了线性回归的功能，能够比较准确的预测房价。\n",
    "在损失函数这一点，问题的本质都是线性回归，对应的误差的概率分布是一样的，优化函数也就是损失函数也就是一样的，都是均方差损失MSELoss，可能写的形式不同。\n",
    "在经过训练2000次之后，经过多次取值实验，大部分时候预测值和真实值的误差都在2以内，误差大的时候也一般不超过10，并且两个模型在此时性能接近，用paddlepaddle编写的网络要略优一点。\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
