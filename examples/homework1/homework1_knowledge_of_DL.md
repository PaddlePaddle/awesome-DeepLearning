## 深度学习基础知识

### 深度学习发展历史

![image](https://z3.ax1x.com/2021/07/09/Rj8wlV.png)

由图可以明显看出DL在从06年崛起之前经历了两个低谷，这两个低谷也将神经网络的发展分为了三个不同的阶段，下面就分别讲述这三个阶段

**第一代神经网络（1958~1969）**

最早的神经网络的思想起源于**1943年的MCP人工神经元模型**，当时是希望能够用计算机来模拟人的神经元反应的过程，该模型将神经元简化为了三个过程：输入信号线性加权，求和，非线性激活（阈值法）。如下图所示

![image](https://z3.ax1x.com/2021/07/09/Rj8WSx.png)第一次将MCP用于机器学习（分类）的当属

1958年Rosenblatt发明的感知器（perceptron)算法。该算法使用MCP模型对输入的多维数据进行二分类，且能够使用梯度下降法从训练样本中自动学习更新权值。1962年，该方法被证明为能够收敛，理论与实践效果引起第一次神经网络的浪潮。然而学科发展的历史不总是一帆风顺的。1969年，美国数学家及人工智能先驱Minsky在其著作中证明了感知器本质上是一种线性模型，只能处理线性分类问题，就连最简单的XOR（亦或）问题都无法正确分类。这等于直接宣判了感知器的死刑，神经网络的研究也陷入了近20年的停滞。

**第二代神经网络（1986~1998）**

第一次打破非线性诅咒的当属现代DL大牛Hinton，其在1986年发明了适用于多层感知器（MLP）的BP算法，并采用Sigmoid进行非线性映射**，**有效解决了非线性分类和学习的问题。该方法引起了神经网络的第二次热潮。

**1989年**，Robert Hecht-Nielsen证明了MLP的**万能逼近定理**，即**对于任何闭区间内的一个连续函数f，都可以用含有一个隐含层的BP网络来逼近**该定理的发现极大的鼓舞了神经网络的研究人员。

也是在1989年，**LeCun发明了卷积神经网络-LeNet**，并将其用于数字识别，且取得了较好的成绩，不过当时并没有引起足够的注意。

值得强调的是在1989年以后由于没有特别突出的方法被提出，且NN一直缺少相应的严格的数学理论支持，神经网络的热潮渐渐冷淡下去。冰点来自于**1991年**，BP算法被指出存在**梯度消失问题**，即**在误差梯度后向传递的过程中，后层梯度以乘性方式叠加到前层，由于Sigmoid函数的饱和特性，后层梯度本来就小，误差梯度传到前层时几乎为0，因此无法对前层进行有效的学习**，该发现对此时的NN发展雪上加霜。

**1997年，LSTM模型**被发明，尽管该模型在序列建模上的特性非常突出，但由于正处于NN的下坡期，也没有引起足够的重视。

**统计学习方法的春天（1986~2006）**

**1986年，决策树方法**被提出，很快ID3，ID4，CART等改进的决策树方法相继出现，到目前仍然是非常常用的一种机器学习方法。该方法也是符号学习方法的代表。 

**1995年，线性SVM**被统计学家**Vapnik**提出。该方法的特点有两个：由非常完美的数学理论推导而来（统计学与凸优化等），符合人的直观感受（最大间隔）。不过，最重要的还是该方法在线性分类的问题上取得了当时最好的成绩。 

**1997年，AdaBoost**被提出，该方法是PAC（Probably Approximately Correct）理论在机器学习实践上的代表，也催生了集成方法这一类。该方法通过一系列的弱分类器集成，达到强分类器的效果。 

**2000年，KernelSVM**被提出，核化的SVM通过一种巧妙的方式将原空间线性不可分的问题，通过Kernel映射成高维空间的线性可分问题，成功解决了非线性分类的问题，且分类效果非常好。至此也更加终结了NN时代。 

**2001年，随机森林**被提出，这是集成方法的另一代表，该方法的理论扎实，比AdaBoost更好的抑制过拟合问题，实际效果也非常不错。 

**2001年，一种新的统一框架-图模型**被提出，该方法试图统一机器学习混乱的方法，如朴素贝叶斯，SVM，隐马尔可夫模型等，为各种学习方法提供一个统一的描述框架。

**第三代神经网络-DL（2006-至今）**

该阶段又分为两个时期：快速发展期（2006~2012）与爆发期（2012~至今）

**快速发展期（2006~2012）**

**2006年，DL元年**。是年，Hinton提出了深层网络训练中梯度消失问题的解决方案：**无监督预训练对权值进行初始化+有监督训练微调**。其主要思想是先通过自学习的方法学习到训练数据的结构（自动编码器），然后在该结构上进行有监督训练微调。但是由于没有特别有效的实验验证，该论文并没有引起重视。

**2011年，ReLU激活函数**被提出，该激活函数能够有效的抑制梯度消失问题。

**2011年，微软首次将DL应用在语音识别上**，取得了重大突破。

**爆发期（2012~至今）**

**2012年，Hinton**课题组为了证明深度学习的潜力，首次参加ImageNet图像识别比赛，其通过构建的CNN网络**AlexNet**一举夺得冠军，且碾压第二名（SVM方法）的分类性能。也正是由于该比赛，CNN吸引到了众多研究者的注意。 

AlexNet的创新点： 

（1）首次采用ReLU激活函数，极大增大收敛速度且从根本上解决了梯度消失问题；（2）由于ReLU方法可以很好抑制梯度消失问题，AlexNet抛弃了“预训练+微调”的方法，完全采用有监督训练。也正因为如此，**DL的主流学习方法也因此变为了纯粹的有监督学习**；（3）扩展了LeNet5结构，添加Dropout层减小过拟合，LRN层增强泛化能力/减小过拟合；（4）首次采用GPU对计算进行加速；

**2013,2014,2015年**，通过ImageNet图像识别比赛，DL的网络结构，训练方法，GPU硬件的不断进步，促使其在其他领域也在不断的征服战场

**2015年，Hinton，LeCun，Bengio论证了**局部极值问题对于DL的影响，结果是**Loss的局部极值问题对于深层网络来说影响可以忽略**。该论断也消除了笼罩在神经网络上的局部极值问题的阴霾。具体原因是**深层网络虽然局部极值非常多，但是通过DL的BatchGradientDescent优化方法很难陷进去，而且就算陷进去，其局部极小值点与全局极小值点也是非常接近，但是浅层网络却不然，其拥有较少的局部极小值点，但是却很容易陷进去，且这些局部极小值点与全局极小值点相差较大**。论述原文其实没有证明，只是简单叙述，严密论证是猜的。。。

**2015，DeepResidualNet发明**。分层预训练，ReLU和BatchNormalization都是为了解决深度神经网络优化时的梯度消失或者爆炸问题。但是在对更深层的神经网络进行优化时，又出现了新的**Degradation**问题，即”**通常来说，如果在VGG16后面加上若干个单位映射，网络的输出特性将和VGG16一样，这说明更深次的网络其潜在的分类性能只可能>=VGG16的性能，不可能变坏，然而实际效果却是只是简单的加深VGG16的话，分类性能会下降（不考虑模型过拟合问题）**“Residual网络认为这说明**DL网络在学习单位映射方面有困难**，因此设计了一个对于单位映射（或接近单位映射）有较强学习能力的DL网络，极大的增强了DL网络的表达能力。此方法能够轻松的训练高达150层的网络。

### 人工智能、机器学习、深度学习有什么区别和联系？

**联系：**

​	人工智能、机器学习和深度学习覆盖的技术范畴是逐层递减的。人工智能是最宽泛的概念。机器学习是当前比较有效的一种实现人工智能的方式。深度学习是机器学习算法中最热门的一个分支，近些年取得了显著的进展，并替代了大多数传统机器学习算法。三者的关系如下图：人工智能 > 机器学习 > 深度学习。

![image](https://z3.ax1x.com/2021/07/08/ROJeCq.png)

**区别：**

人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。我们现在看到的许多技术，如图像识别、NLP，依然没有脱离人工智能的范围，就是“模拟人在看图方面的智能”和“模拟人在听话方面的智能”，本质上和“模拟人在计算方面的智能”并无区别，虽然难度有高低，但目的是一样的——模拟、延伸和扩展人的智能。另外，人工智能提出于50年代。

机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。研究人员会用大量数据和算法“训练”机器，让机器学会如何执行任务。这里有三个重要的信息：1、“机器学习”是“模拟、延伸和扩展人的智能”的一条路径，所以是人工智能的一个子集；2、“机器学习”是要基于大量数据的，也就是说它的“智能”是用大量数据喂出来的；3、正是因为要处理海量数据，所以大数据技术尤为重要；“机器学习”只是大数据技术上的一个应用。常用的10大机器学习算法有：决策树、随机森林、逻辑回归、SVM、朴素贝叶斯、K最近邻算法、K均值算法、Adaboost算法、神经网络、马尔科夫。

相较而言，深度学习是一个比较新的概念，严格地说提出于2006年。深度学习是用于建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据的一种机器学习技术。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。最显著的应用是计算机视觉和自然语言处理领域。显然，“深度学习”是与机器学习中的“神经网络”是强相关，“神经网络”也是其主要的算法和手段；或者我们可以将“深度学习”称之为“改良版的神经网络”算法。深度学习又分为卷积神经网络（Convolutional neural networks，简称CNN）和深度置信网（Deep Belief Nets，简称DBN）。

###  神经元、单层感知机、多层感知机

**神经元**

人工神经元（Artificial Neuron），简称神经元（Neuron），是构成神经网络的基本单元，其主要是模拟生物神经元的结构和特性，接收一组输入信号并产出输出。

1943 年，心理学家 McCulloch 和数学家 Pitts 根据生物神经元的结构，提出 了一种非常简单的神经元模型，MP神经元[McCulloch et al., 1943]。现代神经网 络中的神经元和MP神经元的结构并无太多变化。不同的是，MP神经元中的激活 函数 𝑓 为 0 或 1 的阶跃函数，而现代神经元中的激活函数通常要求是连续可导的函数。假设一个神经元接收$D$个输入$x_1, x_2, ⋯ , x_D$，令向量$\mathrm{x}=[x_1, x_2, ⋯ , x_D]$来表示这组输入， 净输入也叫净活性值（Net Activation）。并用净输入（Net Input）$mathrm{z} \in ℝ$表示一个神经元所获得的输入信 号$\mathrm{x}$的加权和，
$$
\begin{align*}
\mathrm{z}&=\sum^D_{d=1}w_dx_d+b\\
&=\mathrm{w^Tx}+b
\end{align*}
$$
其中$\mathrm{w} = [w_1 ; w_2 ; ⋯ ; w_𝐷]\inℝ^D$ 是$D$ 维的权重向量，$b\in \mathbb{R}$是偏置。净输入$\mathrm{z}$ 在经过一个非线性函数 $f(⋅) $后，得到神经元的活性值（Activation）$a$，
$$
a=f(\mathrm{z})
$$
其中非线性函数𝑓(⋅)称为激活函数（Activation Function）。

**单层感知机**

感知器（Perceptron）由Frank Roseblatt 于1957年提出，是一种广泛使用的线性分类器。感知器可谓是最简单的人工神经网络，只有一个神经元。感知器是对生物神经元的简单数学模拟，有与生物神经元相对应的部件，如 权重（突触）、偏置（阈值）及激活函数（细胞体），输出为+1或-1。感知器是一种简单的两类线性分类模型，其分类准则如下：
$$
\hat{y}=sgn(\mathbf{w^Tx})
$$
感知器学习算法也是一个经典的线性分类器的参数学习算法。给定𝑁 个样本的训练集：$\{(𝒙(𝑛), 𝑦(𝑛))\}^𝑁_{𝑛=1}$，其中$𝑦 (𝑛) ∈ \{+1, −1\}$，感知器学习算法试图找到一组参数𝒘∗，使得对于每个样本(𝒙(𝑛), 𝑦(𝑛))有
$$
𝑦 (𝑛)𝒘∗^T 𝒙^{ (𝑛)} > 0, ∀𝑛 ∈ {1, ⋯ , 𝑁}.
$$
感知器的学习算法是一种错误驱动的在线学习算法 。先初始化一个权重向量 𝒘 ← 0（通常是全零向量），然后每次分错一个样本 (𝒙, 𝑦) 时，即$𝑦𝒘^T𝒙 < 0$，就用这个样本来更新权重. 𝒘 ← 𝒘 + 𝑦𝒙。

**多层感知机**

<img src="https://z3.ax1x.com/2021/07/08/ROaRHO.png" alt="image" style="zoom:50%;" />

多层感知机由感知机推广而来，最主要的特点是有多个神经元层。可用如下公式表示一个两层的感知机：
$$
\begin{align*}
z_2&=XW_1\\
a_2&=f(z_2)\\
z_3&=a_2W_2\\
\hat{y}&=softmax(z_3)
\end{align*}
$$
其中 :
$$
\begin{align*}
X&=输入|\in \mathbb{R}^{N\times D}\\
W_1&=第一层的权重|\in\mathbb{R}^{D\times H}\\
z_2&=第一层网络的输出\in \mathbb{R}^{N\times H}\\
f&=非线性激活函数\\
a_2&=通过激活函数后的第一层输出|\in \mathbb{R}^{N\times H}\\
W_2&=第二层权重 |\in \mathbb{R}^{H\times C}(C为分类类别数)\\
\hat{y}&=预测值|\in
\end{align*}
$$

这是一个简单的二层多层感知机

- **目标:** 给定输入$X$, 预测它属于类别$y$的概率。非线性激活函数的使用后可以帮助训练复杂，非线性的数据。

- **优点:**

- - 在非线性数据上表现非常好

- **缺点:**

- - 容易过拟合
  - 计算复杂度和网络复杂度成正比
  - 可解释性不强

- **其它:** 未来我们会接触的神经网络会使用MLP作为向前传播得模块 (非线性操作后的仿射变换affine transformation(XW))

### 什么是前向传播

前向传播过程，即网络如何根据输入X得到输出Y的。这个很容易理解，粗略看一下即可，这里主要是为了统一后面的符号表达。

![image](https://z3.ax1x.com/2021/07/09/RjJBa4.png)

记$w^l_{jk}$为第$l−1$层第$k$个神经元到第$l$层第$j$个神经元的权重，$b^l_j$为第$l$层第$j$个神经元的偏置，$a^l_j$为第$l$层第$j$个神经元的激活值（激活函数的输出）。不难看出，$a^l_j$的值取决于上一层神经元的激活:
$$
a^l_j=\sigma(\sum_kw^l_{jk}a^{l-1}_k+b^l_j)
$$
将上式重写为矩阵形式：
$$
a^l=\sigma(w^;a^{l-1}+b^l)
$$
为了方便表示，记$z^l=w^la^{l−1}+b^l$为每一层的权重输入， 2式则变为 $a^l=σ(z^l)$。
　　利用 2式一层层计算网络的激活值，最终能够根据输入X得到相应的输出Y。

### 什么是反向传播过程

　　第𝑙 层的误差项可以通过第𝑙 + 1层的误差项计算得 到，这就是误差的反向传播（BackPropagation，BP）.。反向传播算法的含义是：第 𝑙 层的一个神经元的误差项（或敏感性）是所有与该神经元相连的第𝑙 + 1层的神 经元的误差项的权重和。然后，再乘上该神经元激活函数的梯度。反向传播过程中要计算$\frac{∂C}{∂w}$和$\frac{∂C}{∂b}$，我们先对代价函数做两个假设，以二次损失函数为例：
$$
C=\frac{1}{2n}\sum_x||y(x)-a^L(x)||^2
$$
其中 n为训练样本xx的总数， $y=y(x)$为期望的输出，即ground truth， L为网络的层数，$a^L(x)$为网络的输出向量。
假设1：总的代价函数可以表示为单个样本的代价函数之和的平均：
$$
C=\frac{1}{n}\sum_xC_x\\
C_x=\frac{1}{2}||y-a^L||^2
$$


　　这个假设的意义在于，因为反向传播过程中我们只能计算单个训练样本的$\frac{∂C}{∂w}$和$\frac{∂C}{∂b}$，在这个假设下，我们可以通过计算所有样本的平均来得到总体的$\frac{∂C}{∂w}$和 $\frac{∂C}{∂b}$。
假设2：代价函数可以表达为网络输出的函数 $costC=C(a^L)$，比如单个样本x的二次代价函数可以写为：
$$
C_x=\frac{1}{2}||y-a^L||^2=\frac{1}{2}\sum_j(y_j-a^L_j)^2
$$



