{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # 从文件导入数据\n",
    "    datafile = 'housing.data'\n",
    "    data = np.fromfile(datafile, sep=' ')\n",
    "\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\n",
    "    feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \\\n",
    "                      'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\n",
    "    feature_num = len(feature_names)\n",
    "\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\n",
    "\n",
    "    # 将原数据集拆分成训练集和测试集\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\n",
    "    # 测试集和训练集必须是没有交集的\n",
    "    ratio = 0.8\n",
    "    offset = int(data.shape[0] * ratio)\n",
    "    training_data = data[:offset]\n",
    "\n",
    "    # 计算训练集的最大值，最小值，平均值\n",
    "    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), \\\n",
    "                                 training_data.sum(axis=0) / training_data.shape[0]\n",
    "\n",
    "    # 对数据进行归一化处理\n",
    "    for i in range(feature_num):\n",
    "        #print(maximums[i], minimums[i], avgs[i])\n",
    "        data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])\n",
    "\n",
    "    # 训练集和测试集的划分比例\n",
    "    training_data = data[:offset]\n",
    "    test_data = data[offset:]\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, num_of_weights):\n",
    "        # 随机产生w的初始值\n",
    "        # 为了保持程序每次运行结果的一致性，此处设置固定的随机数种子\n",
    "        #np.random.seed(0)\n",
    "        self.w = np.random.randn(num_of_weights, 1)\n",
    "        self.b = 0.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = np.dot(x, self.w) + self.b\n",
    "        return z\n",
    "    \n",
    "    def loss(self, z, y):\n",
    "        error = z - y\n",
    "        num_samples = error.shape[0]\n",
    "        cost = error * error\n",
    "        cost = np.sum(cost) / num_samples\n",
    "        return cost\n",
    "    \n",
    "    def gradient(self, x, y):\n",
    "        z = self.forward(x)\n",
    "        N = x.shape[0]\n",
    "        gradient_w = 1. / N * np.sum((z-y) * x, axis=0)\n",
    "        gradient_w = gradient_w[:, np.newaxis]\n",
    "        gradient_b = 1. / N * np.sum(z-y)\n",
    "        return gradient_w, gradient_b\n",
    "    \n",
    "    def update(self, gradient_w, gradient_b, eta = 0.01):\n",
    "        self.w = self.w - eta * gradient_w\n",
    "        self.b = self.b - eta * gradient_b\n",
    "            \n",
    "                \n",
    "    def train(self, training_data, num_epochs, batch_size=10, eta=0.01):\n",
    "        n = len(training_data)\n",
    "        losses = []\n",
    "        for epoch_id in range(num_epochs):\n",
    "            # 在每轮迭代开始之前，将训练数据的顺序随机打乱\n",
    "            # 然后再按每次取batch_size条数据的方式取出\n",
    "            np.random.shuffle(training_data)\n",
    "            # 将训练数据进行拆分，每个mini_batch包含batch_size条的数据\n",
    "            mini_batches = [training_data[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "            for iter_id, mini_batch in enumerate(mini_batches):\n",
    "                #print(self.w.shape)\n",
    "                #print(self.b)\n",
    "                x = mini_batch[:, :-1]\n",
    "                y = mini_batch[:, -1:]\n",
    "                a = self.forward(x)\n",
    "                loss = self.loss(a, y)\n",
    "                gradient_w, gradient_b = self.gradient(x, y)\n",
    "                self.update(gradient_w, gradient_b, eta)\n",
    "                losses.append(loss)\n",
    "                print('Epoch {:3d} / iter {:3d}, loss = {:.4f}'.\n",
    "                                 format(epoch_id, iter_id, loss))\n",
    "        \n",
    "        return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 / iter   0, loss = 9.2902\n",
      "Epoch   0 / iter   1, loss = 4.6070\n",
      "Epoch   0 / iter   2, loss = 1.9129\n",
      "Epoch   0 / iter   3, loss = 0.8296\n",
      "Epoch   0 / iter   4, loss = 0.8291\n",
      "Epoch   1 / iter   0, loss = 0.2509\n",
      "Epoch   1 / iter   1, loss = 0.2588\n",
      "Epoch   1 / iter   2, loss = 0.2809\n",
      "Epoch   1 / iter   3, loss = 0.2724\n",
      "Epoch   1 / iter   4, loss = 0.3719\n",
      "Epoch   2 / iter   0, loss = 0.3004\n",
      "Epoch   2 / iter   1, loss = 0.2199\n",
      "Epoch   2 / iter   2, loss = 0.2306\n",
      "Epoch   2 / iter   3, loss = 0.2134\n",
      "Epoch   2 / iter   4, loss = 0.3363\n",
      "Epoch   3 / iter   0, loss = 0.3362\n",
      "Epoch   3 / iter   1, loss = 0.1657\n",
      "Epoch   3 / iter   2, loss = 0.2548\n",
      "Epoch   3 / iter   3, loss = 0.1776\n",
      "Epoch   3 / iter   4, loss = 0.2557\n",
      "Epoch   4 / iter   0, loss = 0.1981\n",
      "Epoch   4 / iter   1, loss = 0.2269\n",
      "Epoch   4 / iter   2, loss = 0.1947\n",
      "Epoch   4 / iter   3, loss = 0.2337\n",
      "Epoch   4 / iter   4, loss = 0.1374\n",
      "Epoch   5 / iter   0, loss = 0.1884\n",
      "Epoch   5 / iter   1, loss = 0.2109\n",
      "Epoch   5 / iter   2, loss = 0.1602\n",
      "Epoch   5 / iter   3, loss = 0.2481\n",
      "Epoch   5 / iter   4, loss = 0.3700\n",
      "Epoch   6 / iter   0, loss = 0.2362\n",
      "Epoch   6 / iter   1, loss = 0.1230\n",
      "Epoch   6 / iter   2, loss = 0.2251\n",
      "Epoch   6 / iter   3, loss = 0.2232\n",
      "Epoch   6 / iter   4, loss = 0.0097\n",
      "Epoch   7 / iter   0, loss = 0.1889\n",
      "Epoch   7 / iter   1, loss = 0.1160\n",
      "Epoch   7 / iter   2, loss = 0.1678\n",
      "Epoch   7 / iter   3, loss = 0.2664\n",
      "Epoch   7 / iter   4, loss = 0.1613\n",
      "Epoch   8 / iter   0, loss = 0.1659\n",
      "Epoch   8 / iter   1, loss = 0.2397\n",
      "Epoch   8 / iter   2, loss = 0.1855\n",
      "Epoch   8 / iter   3, loss = 0.1245\n",
      "Epoch   8 / iter   4, loss = 0.0283\n",
      "Epoch   9 / iter   0, loss = 0.1364\n",
      "Epoch   9 / iter   1, loss = 0.1573\n",
      "Epoch   9 / iter   2, loss = 0.1688\n",
      "Epoch   9 / iter   3, loss = 0.1777\n",
      "Epoch   9 / iter   4, loss = 1.0999\n",
      "Epoch  10 / iter   0, loss = 0.2016\n",
      "Epoch  10 / iter   1, loss = 0.1653\n",
      "Epoch  10 / iter   2, loss = 0.1829\n",
      "Epoch  10 / iter   3, loss = 0.1890\n",
      "Epoch  10 / iter   4, loss = 0.0971\n",
      "Epoch  11 / iter   0, loss = 0.1353\n",
      "Epoch  11 / iter   1, loss = 0.1618\n",
      "Epoch  11 / iter   2, loss = 0.1527\n",
      "Epoch  11 / iter   3, loss = 0.1625\n",
      "Epoch  11 / iter   4, loss = 0.0443\n",
      "Epoch  12 / iter   0, loss = 0.1387\n",
      "Epoch  12 / iter   1, loss = 0.1322\n",
      "Epoch  12 / iter   2, loss = 0.1489\n",
      "Epoch  12 / iter   3, loss = 0.1711\n",
      "Epoch  12 / iter   4, loss = 0.0412\n",
      "Epoch  13 / iter   0, loss = 0.1389\n",
      "Epoch  13 / iter   1, loss = 0.0931\n",
      "Epoch  13 / iter   2, loss = 0.1476\n",
      "Epoch  13 / iter   3, loss = 0.1820\n",
      "Epoch  13 / iter   4, loss = 0.2238\n",
      "Epoch  14 / iter   0, loss = 0.1461\n",
      "Epoch  14 / iter   1, loss = 0.1073\n",
      "Epoch  14 / iter   2, loss = 0.1602\n",
      "Epoch  14 / iter   3, loss = 0.1414\n",
      "Epoch  14 / iter   4, loss = 0.1856\n",
      "Epoch  15 / iter   0, loss = 0.1109\n",
      "Epoch  15 / iter   1, loss = 0.1197\n",
      "Epoch  15 / iter   2, loss = 0.1875\n",
      "Epoch  15 / iter   3, loss = 0.1027\n",
      "Epoch  15 / iter   4, loss = 0.2040\n",
      "Epoch  16 / iter   0, loss = 0.1725\n",
      "Epoch  16 / iter   1, loss = 0.1193\n",
      "Epoch  16 / iter   2, loss = 0.0825\n",
      "Epoch  16 / iter   3, loss = 0.1165\n",
      "Epoch  16 / iter   4, loss = 0.0115\n",
      "Epoch  17 / iter   0, loss = 0.1015\n",
      "Epoch  17 / iter   1, loss = 0.1525\n",
      "Epoch  17 / iter   2, loss = 0.0852\n",
      "Epoch  17 / iter   3, loss = 0.1319\n",
      "Epoch  17 / iter   4, loss = 0.1367\n",
      "Epoch  18 / iter   0, loss = 0.1083\n",
      "Epoch  18 / iter   1, loss = 0.1235\n",
      "Epoch  18 / iter   2, loss = 0.1258\n",
      "Epoch  18 / iter   3, loss = 0.0981\n",
      "Epoch  18 / iter   4, loss = 0.0326\n",
      "Epoch  19 / iter   0, loss = 0.0978\n",
      "Epoch  19 / iter   1, loss = 0.1009\n",
      "Epoch  19 / iter   2, loss = 0.1442\n",
      "Epoch  19 / iter   3, loss = 0.0938\n",
      "Epoch  19 / iter   4, loss = 0.2716\n",
      "Epoch  20 / iter   0, loss = 0.0866\n",
      "Epoch  20 / iter   1, loss = 0.0975\n",
      "Epoch  20 / iter   2, loss = 0.1194\n",
      "Epoch  20 / iter   3, loss = 0.1193\n",
      "Epoch  20 / iter   4, loss = 0.0395\n",
      "Epoch  21 / iter   0, loss = 0.1089\n",
      "Epoch  21 / iter   1, loss = 0.0818\n",
      "Epoch  21 / iter   2, loss = 0.1160\n",
      "Epoch  21 / iter   3, loss = 0.1033\n",
      "Epoch  21 / iter   4, loss = 0.0199\n",
      "Epoch  22 / iter   0, loss = 0.1116\n",
      "Epoch  22 / iter   1, loss = 0.0777\n",
      "Epoch  22 / iter   2, loss = 0.0923\n",
      "Epoch  22 / iter   3, loss = 0.1040\n",
      "Epoch  22 / iter   4, loss = 0.3751\n",
      "Epoch  23 / iter   0, loss = 0.1114\n",
      "Epoch  23 / iter   1, loss = 0.1279\n",
      "Epoch  23 / iter   2, loss = 0.1149\n",
      "Epoch  23 / iter   3, loss = 0.0802\n",
      "Epoch  23 / iter   4, loss = 0.0074\n",
      "Epoch  24 / iter   0, loss = 0.1062\n",
      "Epoch  24 / iter   1, loss = 0.0908\n",
      "Epoch  24 / iter   2, loss = 0.0740\n",
      "Epoch  24 / iter   3, loss = 0.0909\n",
      "Epoch  24 / iter   4, loss = 0.2829\n",
      "Epoch  25 / iter   0, loss = 0.0677\n",
      "Epoch  25 / iter   1, loss = 0.1069\n",
      "Epoch  25 / iter   2, loss = 0.1161\n",
      "Epoch  25 / iter   3, loss = 0.0794\n",
      "Epoch  25 / iter   4, loss = 0.0505\n",
      "Epoch  26 / iter   0, loss = 0.0639\n",
      "Epoch  26 / iter   1, loss = 0.1008\n",
      "Epoch  26 / iter   2, loss = 0.0986\n",
      "Epoch  26 / iter   3, loss = 0.0835\n",
      "Epoch  26 / iter   4, loss = 0.0390\n",
      "Epoch  27 / iter   0, loss = 0.0958\n",
      "Epoch  27 / iter   1, loss = 0.1003\n",
      "Epoch  27 / iter   2, loss = 0.0768\n",
      "Epoch  27 / iter   3, loss = 0.0598\n",
      "Epoch  27 / iter   4, loss = 0.1770\n",
      "Epoch  28 / iter   0, loss = 0.0756\n",
      "Epoch  28 / iter   1, loss = 0.0793\n",
      "Epoch  28 / iter   2, loss = 0.0974\n",
      "Epoch  28 / iter   3, loss = 0.0744\n",
      "Epoch  28 / iter   4, loss = 0.0635\n",
      "Epoch  29 / iter   0, loss = 0.0982\n",
      "Epoch  29 / iter   1, loss = 0.0658\n",
      "Epoch  29 / iter   2, loss = 0.0758\n",
      "Epoch  29 / iter   3, loss = 0.0674\n",
      "Epoch  29 / iter   4, loss = 0.1902\n",
      "Epoch  30 / iter   0, loss = 0.0902\n",
      "Epoch  30 / iter   1, loss = 0.0711\n",
      "Epoch  30 / iter   2, loss = 0.1007\n",
      "Epoch  30 / iter   3, loss = 0.0594\n",
      "Epoch  30 / iter   4, loss = 0.0472\n",
      "Epoch  31 / iter   0, loss = 0.0709\n",
      "Epoch  31 / iter   1, loss = 0.0974\n",
      "Epoch  31 / iter   2, loss = 0.0576\n",
      "Epoch  31 / iter   3, loss = 0.0595\n",
      "Epoch  31 / iter   4, loss = 0.2713\n",
      "Epoch  32 / iter   0, loss = 0.1022\n",
      "Epoch  32 / iter   1, loss = 0.0806\n",
      "Epoch  32 / iter   2, loss = 0.0552\n",
      "Epoch  32 / iter   3, loss = 0.0545\n",
      "Epoch  32 / iter   4, loss = 0.0716\n",
      "Epoch  33 / iter   0, loss = 0.0688\n",
      "Epoch  33 / iter   1, loss = 0.0560\n",
      "Epoch  33 / iter   2, loss = 0.0830\n",
      "Epoch  33 / iter   3, loss = 0.0760\n",
      "Epoch  33 / iter   4, loss = 0.0115\n",
      "Epoch  34 / iter   0, loss = 0.0555\n",
      "Epoch  34 / iter   1, loss = 0.0851\n",
      "Epoch  34 / iter   2, loss = 0.0730\n",
      "Epoch  34 / iter   3, loss = 0.0594\n",
      "Epoch  34 / iter   4, loss = 0.0140\n",
      "Epoch  35 / iter   0, loss = 0.0590\n",
      "Epoch  35 / iter   1, loss = 0.0647\n",
      "Epoch  35 / iter   2, loss = 0.0734\n",
      "Epoch  35 / iter   3, loss = 0.0650\n",
      "Epoch  35 / iter   4, loss = 0.2065\n",
      "Epoch  36 / iter   0, loss = 0.0573\n",
      "Epoch  36 / iter   1, loss = 0.0692\n",
      "Epoch  36 / iter   2, loss = 0.0636\n",
      "Epoch  36 / iter   3, loss = 0.0702\n",
      "Epoch  36 / iter   4, loss = 0.0436\n",
      "Epoch  37 / iter   0, loss = 0.0628\n",
      "Epoch  37 / iter   1, loss = 0.0837\n",
      "Epoch  37 / iter   2, loss = 0.0748\n",
      "Epoch  37 / iter   3, loss = 0.0344\n",
      "Epoch  37 / iter   4, loss = 0.0301\n",
      "Epoch  38 / iter   0, loss = 0.0685\n",
      "Epoch  38 / iter   1, loss = 0.0772\n",
      "Epoch  38 / iter   2, loss = 0.0481\n",
      "Epoch  38 / iter   3, loss = 0.0611\n",
      "Epoch  38 / iter   4, loss = 0.0033\n",
      "Epoch  39 / iter   0, loss = 0.0786\n",
      "Epoch  39 / iter   1, loss = 0.0558\n",
      "Epoch  39 / iter   2, loss = 0.0490\n",
      "Epoch  39 / iter   3, loss = 0.0620\n",
      "Epoch  39 / iter   4, loss = 0.0151\n",
      "Epoch  40 / iter   0, loss = 0.0356\n",
      "Epoch  40 / iter   1, loss = 0.0727\n",
      "Epoch  40 / iter   2, loss = 0.0637\n",
      "Epoch  40 / iter   3, loss = 0.0679\n",
      "Epoch  40 / iter   4, loss = 0.0170\n",
      "Epoch  41 / iter   0, loss = 0.0692\n",
      "Epoch  41 / iter   1, loss = 0.0362\n",
      "Epoch  41 / iter   2, loss = 0.0655\n",
      "Epoch  41 / iter   3, loss = 0.0657\n",
      "Epoch  41 / iter   4, loss = 0.0353\n",
      "Epoch  42 / iter   0, loss = 0.0547\n",
      "Epoch  42 / iter   1, loss = 0.0728\n",
      "Epoch  42 / iter   2, loss = 0.0542\n",
      "Epoch  42 / iter   3, loss = 0.0516\n",
      "Epoch  42 / iter   4, loss = 0.1005\n",
      "Epoch  43 / iter   0, loss = 0.0677\n",
      "Epoch  43 / iter   1, loss = 0.0646\n",
      "Epoch  43 / iter   2, loss = 0.0566\n",
      "Epoch  43 / iter   3, loss = 0.0400\n",
      "Epoch  43 / iter   4, loss = 0.0320\n",
      "Epoch  44 / iter   0, loss = 0.0564\n",
      "Epoch  44 / iter   1, loss = 0.0541\n",
      "Epoch  44 / iter   2, loss = 0.0565\n",
      "Epoch  44 / iter   3, loss = 0.0516\n",
      "Epoch  44 / iter   4, loss = 0.0716\n",
      "Epoch  45 / iter   0, loss = 0.0405\n",
      "Epoch  45 / iter   1, loss = 0.0639\n",
      "Epoch  45 / iter   2, loss = 0.0572\n",
      "Epoch  45 / iter   3, loss = 0.0553\n",
      "Epoch  45 / iter   4, loss = 0.0973\n",
      "Epoch  46 / iter   0, loss = 0.0442\n",
      "Epoch  46 / iter   1, loss = 0.0382\n",
      "Epoch  46 / iter   2, loss = 0.0775\n",
      "Epoch  46 / iter   3, loss = 0.0528\n",
      "Epoch  46 / iter   4, loss = 0.0708\n",
      "Epoch  47 / iter   0, loss = 0.0324\n",
      "Epoch  47 / iter   1, loss = 0.0514\n",
      "Epoch  47 / iter   2, loss = 0.0559\n",
      "Epoch  47 / iter   3, loss = 0.0599\n",
      "Epoch  47 / iter   4, loss = 0.2206\n",
      "Epoch  48 / iter   0, loss = 0.0623\n",
      "Epoch  48 / iter   1, loss = 0.0635\n",
      "Epoch  48 / iter   2, loss = 0.0334\n",
      "Epoch  48 / iter   3, loss = 0.0665\n",
      "Epoch  48 / iter   4, loss = 0.0431\n",
      "Epoch  49 / iter   0, loss = 0.0309\n",
      "Epoch  49 / iter   1, loss = 0.0471\n",
      "Epoch  49 / iter   2, loss = 0.0797\n",
      "Epoch  49 / iter   3, loss = 0.0349\n",
      "Epoch  49 / iter   4, loss = 0.0620\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 获取数据\n",
    "train_data, test_data = load_data()\n",
    "\n",
    "# 创建网络\n",
    "net = Network(13)\n",
    "# 启动训练\n",
    "losses = net.train(train_data, num_epochs=50, batch_size=100, eta=0.1)\n",
    "\n",
    "# 画出损失函数的变化趋势\n",
    "plot_x = np.arange(len(losses))\n",
    "plot_y = np.array(losses)\n",
    "plt.plot(plot_x, plot_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddlepaddle_2.1",
   "language": "python",
   "name": "paddlepaddle_2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
