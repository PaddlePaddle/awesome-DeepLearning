{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data19469  data93479\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "# !ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "# !mkdir /home/aistudio/external-libraries\n",
    "# !pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "# import sys \n",
    "# sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **眼疾识别案例的ResNet实现**\n",
    "本文参考paddle课程文档，通过paddle框架实现了ResNet模型基础B版本和变体D版本，通过模型API：version进行切换版本。训练部分和验证部分都采用分批训练的方式，用来解决模型迭代过程中显存不足的问题。 \n",
    "\n",
    "**参考文献：**\n",
    "\n",
    "> https://blog.csdn.net/sinat_17456165/article/details/106045728\n",
    "> \n",
    "> https://aistudio.baidu.com/aistudio/education/preview/1533758\n",
    "> \n",
    "> https://zhuanlan.zhihu.com/p/31852747/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **数据集介绍**\n",
    "\n",
    "如今近视已经成为困扰人们健康的一项全球性负担，在近视人群中，有超过35%的人患有重度近视。近视会拉长眼睛的光轴，也可能引起视网膜或者络网膜的病变。随着近视度数的不断加深，高度近视有可能引发病理性病变，这将会导致以下几种症状：视网膜或者络网膜发生退化、视盘区域萎缩、漆裂样纹损害、Fuchs斑等。因此，及早发现近视患者眼睛的病变并采取治疗，显得非常重要。\n",
    "\n",
    "`iChallenge-PM`是百度大脑和中山大学中山眼科中心联合举办的`iChallenge`比赛中，提供的关于病理性近视（Pathologic Myopia，PM）的医疗类数据集，包含1200个受试者的眼底视网膜图片，训练、验证和测试数据集各400张，其中训练集名称第一个字符表示类别，验证集的类别信息储存在PALM-Validation-GT的PM_Label_and_Fovea_Location.xlsx文件中。（以下图片仅供参考）\n",
    "\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://raw.githubusercontent.com/buriedms/Eye-disease-recognition-ResNet-vd/main/eye_disease_recognition/images/data1.png\" width=\"315\"/>\n",
    "    <img src=\"https://github.com/buriedms/Eye-disease-recognition-ResNet-vd/blob/main/eye_disease_recognition/images/data2.png?raw=true\" width=\"315\"/>\n",
    "    <img src=\"https://github.com/buriedms/Eye-disease-recognition-ResNet-vd/blob/main/eye_disease_recognition/images/data3.png?raw=true\" width=\"315\"/>\n",
    "</center>\n",
    "\n",
    "图1  数据集的的大致情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **数据集的导入和预处理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 导入相关库\n",
    "导入相关的库，以备后续使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/openpyxl/compat/numbers.py:41: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  numpy.float,\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import os\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "数据集在`aistudio`平台上可直接载入数据集，并且通过以下代码指令，我们进行解压到指定位置。\n",
    "\n",
    "数据集data19469存放在data文件夹中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data exist\n",
      "The data has been decompressed\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"train_data\"):\r\n",
    "    os.mkdir(\"train_data\")\r\n",
    "else:\r\n",
    "    print('Train_data exist')\r\n",
    "if not os.path.isdir('PALM-Training400'):\r\n",
    "    !unzip -oq /home/aistudio/data/data19469/training.zip\r\n",
    "    !unzip -oq /home/aistudio/data/data19469/validation.zip\r\n",
    "    !unzip -oq /home/aistudio/data/data19469/valid_gt.zip\r\n",
    "    !unzip -oq /home/aistudio/PALM-Training400/PALM-Training400.zip -d /home/aistudio/train_data/\r\n",
    "else:\r\n",
    "    print('The data has been decompressed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "基于cv2，对数据集进行导入,由于导入图像数据的格式为[H,W,C]，因此需要基于cv2.resize对结构进行重组为[C,H,W]。并且对数据进行相应的标准化操作。\n",
    "\n",
    "**标准化作用 ：**\n",
    "\n",
    "1. 统一数据量纲\n",
    "2. 平衡各特征的贡献\n",
    "3. 加快了梯度下降求最优解的速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_img(img):\r\n",
    "    # 将图片尺寸缩放到 224x224\r\n",
    "    img=cv2.resize(img,(224,224))\r\n",
    "    # 读入的图像数据格式是[H,W,C]\r\n",
    "    # 使用转置操作将其变成[C,H,W]\r\n",
    "    img=np.transpose(img,(2,0,1))\r\n",
    "    img.astype('float32')\r\n",
    "    img=img/255.0\r\n",
    "    img=img*2.0-1.0\r\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过自定义的`data_loader`和`valid_loader`导入训练集和验证集，并且在`data_loader`中打乱训练集。两者都预设`batch_size`选项设定每一个预设batch的大小。验证准确率和损失值由所有的batch的平均所得到。\n",
    "\n",
    "参数解释：\n",
    "\n",
    "`datadir`：图片数据存在的文件夹路径\n",
    "\n",
    "`annotiondir`：验证集标签文件路径\n",
    "\n",
    "`batch_size`：每个批次的图片数据的数量\n",
    "\n",
    "output：\n",
    "\n",
    "每个batch的图片数据，数据类型：`float32`，`numpy`保存，维度：[N,C,H,W]\n",
    "\n",
    "**注意：其中训练集再导入时每个epoch都会进行随机打乱，而验证集不会**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_loader(datadir,batch_size=10,mode='train'):\r\n",
    "    filenames=os.listdir(datadir)\r\n",
    "    def reader():\r\n",
    "        if mode =='train':\r\n",
    "            np.random.shuffle(filenames)\r\n",
    "        batch_imgs=[]\r\n",
    "        batch_labels=[]\r\n",
    "        for name in filenames:\r\n",
    "            filepath=os.path.join(datadir,name)\r\n",
    "            img=cv2.imread(filepath)\r\n",
    "            img=transform_img(img)\r\n",
    "            if name[0]=='H' or name[0]=='N':\r\n",
    "                label=0\r\n",
    "            elif name[0]=='P':\r\n",
    "                label=1\r\n",
    "            elif name[0]=='V':\r\n",
    "                continue\r\n",
    "            else:\r\n",
    "                raise('Not excepted file name')\r\n",
    "            batch_imgs.append(img)\r\n",
    "            batch_labels.append(label)\r\n",
    "            if len(batch_imgs)==batch_size:\r\n",
    "                imgs_array=np.array(batch_imgs).astype('float32')\r\n",
    "                labels_array=np.array(batch_labels).astype('float32').reshape(-1,1)\r\n",
    "                yield imgs_array,labels_array\r\n",
    "                batch_imgs=[]\r\n",
    "                batch_labels=[]\r\n",
    "        if len(batch_imgs)>0:\r\n",
    "            imgs_array=np.array(batch_imgs).astype('float32')\r\n",
    "            labels_array=np.array(batch_labels).astype('float32').reshape(-1,1)\r\n",
    "            yield imgs_array,labels_array\r\n",
    "    return reader\r\n",
    "    \r\n",
    "def valid_data_loader(datadir,annotiondir):\r\n",
    "    labeldir=annotiondir\r\n",
    "    def reader(batch_size=50):\r\n",
    "        images=[]\r\n",
    "        labels=[]\r\n",
    "        workbook=openpyxl.load_workbook(labeldir,data_only=True)\r\n",
    "        worksheet=workbook.active\r\n",
    "        for row in worksheet.iter_rows(min_row=2,max_row=worksheet.max_row):\r\n",
    "            image=cv2.imread(datadir+'/'+row[1].value)\r\n",
    "            image=transform_img(image)\r\n",
    "            images.append(image)\r\n",
    "            label=float(row[2].value)\r\n",
    "            labels.append(label)\r\n",
    "            if len(images)==batch_size:\r\n",
    "                images_array=np.array(images).astype('float32')\r\n",
    "                labels_array=np.array(labels).astype('float32').reshape(-1,1)\r\n",
    "                yield images_array,labels_array\r\n",
    "                images=[]\r\n",
    "                labels=[]\r\n",
    "        if len(images)>0:\r\n",
    "            images_array=np.array(images).astype('float32')\r\n",
    "            labels_array=np.array(labels).astype('float32').reshape(-1,1)\r\n",
    "            yield images_array,labels_array\r\n",
    "    return reader\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **`ResNet`模型及其变体D的理论解析**\n",
    "\n",
    "##### **`ResNet`模型背景**\n",
    "\n",
    "2015 年，`ResNet` 横空出世，一举斩获 CVPR 2016 最佳论文奖，而且在 `Imagenet` 比赛的三个任务以及 COCO 比赛的检测和分割任务上都获得了第一名。\n",
    "\n",
    "从经验来说，网络深度增加后，网络可以进行更加复杂的特征提取，因此可以取得更好的结果。但事实上并非如此，人们实验发现随着网络深度的增加，模型精度并不总是提升，并且这个问题显然不是由过拟合（overfitting）造成的，因为网络加深后不仅测试误差变高了，它的训练误差竟然也变高了。作者[何凯明](http://kaiminghe.com/)提出，这可能是因为更深的网络会伴随梯度消失/爆炸问题，从而阻碍网络的收敛。作者将这种加深网络深度但网络性能却下降的现象称为**退化问题**（degradation problem）。\n",
    "\n",
    "##### **`ResNet`的网络模型**\n",
    "\n",
    "`ResNet`网络是参考了VGG19网络，在其基础上进行了修改，并通过短路机制加入了残差单元。\n",
    "\n",
    "变化主要体现在`ResNet`直接使用stride=2的卷积做下采样，并且用global average pool层替换了全连接层。`ResNet`的一个重要设计原则是：当feature map大小降低一半时，feature map的数量增加一倍，这保持了网络层的复杂度。以下为几种基本层数的`ResNet`版本的网络模型架构。\n",
    "\n",
    "![图2  `ResNet`的模型结构](https://github.com/buriedms/Eye-disease-recognition-ResNet-vd/blob/main/eye_disease_recognition/images/model_structure.png?raw=true)\n",
    "\n",
    "图2  `ResNet`的模型结构\n",
    "\n",
    "整个`ResNet`不使用`dropout`，全部使用BN。此外，回到最初的这张细节图，我们不难发现一些规律和特点：\n",
    "\n",
    "- 全图大致分为5个模块，其中2-5模块是残差单元构成的模块\n",
    "- 受VGG的启发，卷积层主要是3×3卷积；\n",
    "\n",
    "- **同一模块内图片的尺寸大小不变，不同模块之间相差大小减半，深度变为4倍**\n",
    "\n",
    "- **第2个模块网络输出和输出图像尺寸相同，因此不需要下采样**\n",
    "- **第3-5模块的下采样仅操作一次，因此仅需要在每个模块的第一个`block`进行`stride=2`的下采样**\n",
    "\n",
    "- 网络以平均池化层和`softmax`的全连接层结束，实际上工程上一般用自适应全局平均池化 (Adaptive Global Average Pooling)；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **重点知识解读**\n",
    "\n",
    "##### **`Bottleneck`结构和1*1卷积**\n",
    "\n",
    "**1x1卷积作用：**\n",
    "\n",
    "- 对通道数进行升维和降维（跨通道信息整合），实现了多个特征图的线性组合，同时保持了原有的特征图大小；\n",
    "\n",
    "- 相比于其他尺寸的卷积核，可以极大地降低运算复杂度；\n",
    "\n",
    "- 如果使用两个3x3卷积堆叠，只有一个`relu`，但使用1x1卷积就会有两个`relu`，引入了更多的非线性映射；\n",
    "\n",
    "![图3  残差单元结构和1x1卷积](https://github.com/buriedms/Eye-disease-recognition-ResNet-vd/blob/main/eye_disease_recognition/images/bottleneck.png?raw=true)\n",
    "\n",
    "图3  残差单元结构和1x1卷积\n",
    "\n",
    "（以上左图为`Basicblock`结构，右图为`Bottleneck`结构)\n",
    "我们来计算一下1*1卷积的计算量优势：首先看上图右边的`bottleneck`结构，对于256维的输入特征，参数数目：\n",
    "$$\n",
    "1*1*56*64+3*3*64*64+1*1*64*256=69632\n",
    "$$\n",
    "如果同样的输入输出维度但不使用1x1卷积，而使用两个3x3卷积的话，参数数目:\n",
    "$$\n",
    "(3*3*256*256)*2=1179648\n",
    "$$\n",
    "简单计算可知，使用了1x1卷积的`bottleneck`将计算量简化为原有的5.9%。\n",
    "\n",
    "##### **`ResNet-vb`及`ResNet-vd`模型设计**\n",
    "\n",
    "基于以上的规律和特点，我们做出如下设计：\n",
    "\n",
    "1. 为保证每个模块内部卷积前后的图像尺寸不变 ，将卷积**BN块的`padding`设计为`(kernel_size-1)//2`**，这就保证了`stride=1`图像尺寸不变，`stride=2`图像尺寸减半。\n",
    "\n",
    "2. 在2-5模块的残差单元block卷积采用如下类似的结构，**注意stride的设置**。\n",
    "\n",
    "![图4  `ResNet`的残差单元结构](https://github.com/buriedms/Eye-disease-recognition-ResNet-vd/blob/main/eye_disease_recognition/images/residual_unit.png?raw=true)\n",
    "\n",
    "图4  `ResNet`的残差单元结构\n",
    "\n",
    "（以上左图为`ResNet-vb`，右图为`ResNet-vd`）\n",
    "\n",
    "**注意：第2模块的stride=1，第3-5模块的stride=2实现下采样**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **`ResNet`模型及变体的paddle实现**\n",
    "参考paddle官方课程的ResNet网络模型教程搭建网络，并且修改为变体vd版本。\n",
    "\n",
    "详情参考[paddle课程文档](https://aistudio.baidu.com/aistudio/education/preview/1533758)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ResNet中使用BatchNorm层，在卷积层的后面加上BatchNorm以提升数值稳定性\r\n",
    "# 定义卷积BN块\r\n",
    "class ConvBNLayer(nn.Layer):\r\n",
    "    def __init__(self,\r\n",
    "                 num_channels,\r\n",
    "                 num_filters,\r\n",
    "                 filter_size,\r\n",
    "                 stride=1,\r\n",
    "                 groups=1,\r\n",
    "                 act='relu'):\r\n",
    "        \"\"\"\r\n",
    "        num_channels,卷积层的输入通道数\r\n",
    "        num_filters,卷积层的输出通道数\r\n",
    "        stride,卷积层的步幅\r\n",
    "        groups,分组卷积的组数，默认groups=1不使用分组卷积\r\n",
    "        \"\"\"\r\n",
    "        super(ConvBNLayer,self).__init__()\r\n",
    "        self._conv=nn.Conv2D(\r\n",
    "            in_channels=num_channels,\r\n",
    "            out_channels=num_filters,\r\n",
    "            kernel_size=filter_size,\r\n",
    "            stride=stride,\r\n",
    "            padding=(filter_size-1)//2,\r\n",
    "            groups=groups,\r\n",
    "            bias_attr=False,\r\n",
    "        )\r\n",
    "        self._batch_norm=nn.BatchNorm2D(num_filters)\r\n",
    "        self.act=act\r\n",
    "    def forward(self,inputs):\r\n",
    "        x=self._conv(inputs)\r\n",
    "        x=self._batch_norm(x)\r\n",
    "        if self.act=='leaky':\r\n",
    "            x=nn.functional.leaky_relu(x=x,negative_slope=0.1)\r\n",
    "        elif self.act=='relu':\r\n",
    "            x=nn.functional.relu(x=x)\r\n",
    "        return x\r\n",
    "\r\n",
    "# 定义残差块\r\n",
    "# 每个残差块会对输入图片做三次卷积，然后跟输入图片进行短接\r\n",
    "# 如果残差块中第三次卷积输出特征图的形状和输入不一致，则对输入图片做1x1卷积，将其输出形状调整为一致\r\n",
    "class BottleneckBlock(nn.Layer):\r\n",
    "    def __init__(self,\r\n",
    "                 num_channels,\r\n",
    "                 num_filters,\r\n",
    "                 stride=1,\r\n",
    "                 shortcut=True,\r\n",
    "                 version='B'\r\n",
    "                 ):\r\n",
    "        super(BottleneckBlock,self).__init__()\r\n",
    "        # 创建第一个1x1卷积层\r\n",
    "        self.conv1=ConvBNLayer(\r\n",
    "            num_channels=num_channels,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=1,\r\n",
    "            act='relu',\r\n",
    "        )\r\n",
    "        # 创建第二个3x3卷积层\r\n",
    "        self.conv2=ConvBNLayer(\r\n",
    "            num_channels=num_filters,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=3,\r\n",
    "            stride=stride,\r\n",
    "            act='relu'\r\n",
    "        )\r\n",
    "        # 创建第三个1x1层，但是输出通道数乘4\r\n",
    "        self.conv3=ConvBNLayer(\r\n",
    "            num_channels=num_filters,\r\n",
    "            num_filters=num_filters*4,\r\n",
    "            filter_size=1,\r\n",
    "            act='relu'\r\n",
    "        )\r\n",
    "        # 如果conv3的输出跟此残差块的输入数据形状一致，则shortcut=True\r\n",
    "        # 否则shortcut=False，添加1个1x1的卷积作用在输入数据上，使其形状变为和conv3一样 \r\n",
    "        if not shortcut:\r\n",
    "            if version=='B':\r\n",
    "                self.short=ConvBNLayer(\r\n",
    "                    num_channels=num_channels,\r\n",
    "                    num_filters=num_filters*4,\r\n",
    "                    filter_size=1,\r\n",
    "                    stride=stride\r\n",
    "                )\r\n",
    "            elif version=='D':\r\n",
    "                self.short=nn.Sequential(\r\n",
    "                    nn.AvgPool2D(kernel_size=stride,stride=stride),\r\n",
    "                    ConvBNLayer(num_channels=num_channels,\r\n",
    "                                num_filters=num_filters*4,\r\n",
    "                                filter_size=1))      \r\n",
    "            else:\r\n",
    "                raise(f'bottleneck block version:{version} error, you can choice B or D')          \r\n",
    "        self.shortcut=shortcut\r\n",
    "        self._num_channels_out=num_filters*4\r\n",
    "    def forward(self,inputs):\r\n",
    "        x=self.conv1(inputs)\r\n",
    "        x=self.conv2(x)\r\n",
    "        x=self.conv3(x)\r\n",
    "        # 如果shortcut=Ture，直接将inputs跟conv2的输出相加\r\n",
    "        # 否则需要对inputs进行一次 卷积，将形状调整成跟conv2输出一致\r\n",
    "        if self.shortcut:\r\n",
    "            short=inputs\r\n",
    "        else:\r\n",
    "            short=self.short(inputs)\r\n",
    "        y=paddle.add(x=short,y=x)\r\n",
    "        return y\r\n",
    "\r\n",
    "# 定义ResNet模型\r\n",
    "class ResNet(nn.Layer):\r\n",
    "    def __init__(self,layers=50,class_dim=10,version='B'):\r\n",
    "        \"\"\"\r\n",
    "        layers,网络层数，可以可选项：50,101,152\r\n",
    "        class_dim,分类标签的类别数\r\n",
    "        \"\"\"\r\n",
    "        super(ResNet,self).__init__()\r\n",
    "        self.version=version\r\n",
    "        self.layers=layers\r\n",
    "        supported_layers=[50,101,152]\r\n",
    "        assert layers in supported_layers,\\\r\n",
    "        \"supported layers are {} but input layer is {}\".format(supported_layers,layers)\r\n",
    "        # ResNet50包含的第2-5模块分别包括3,4,6,3个残差块\r\n",
    "        if layers==50:\r\n",
    "            depth=[3,4,6,3]\r\n",
    "        # ResNet101包含的第2-5模块分别包括3,4,23,3个残差块\r\n",
    "        if layers==101:\r\n",
    "            depth=[3,4,23,3]\r\n",
    "        # ResNet152包含的第2-5模块分别包括3,8,36,3个残差块\r\n",
    "        if layers==152:\r\n",
    "            depth=[3,8,36,3]\r\n",
    "        # 第2-5模块所使用残差块的输出通道数\r\n",
    "        num_filters=[64,128,256,512]\r\n",
    "\r\n",
    "        # 第1个模块,64个7x7的卷积加上一个3x3最大化池化层，步长均为2\r\n",
    "        self.conv=ConvBNLayer(\r\n",
    "            num_channels=3,\r\n",
    "            num_filters=64,\r\n",
    "            filter_size=7,\r\n",
    "            stride=2,\r\n",
    "            act='relu')\r\n",
    "        self.pool2d_max=nn.MaxPool2D(\r\n",
    "            kernel_size=3,\r\n",
    "            stride=2,\r\n",
    "            padding=1)\r\n",
    "        # 第2-5模块，使用各个残差块进行卷积操作\r\n",
    "        self.bottleneck_block_list=[]\r\n",
    "        num_channels=64\r\n",
    "        for block in range(len(depth)):\r\n",
    "            shortcut=False\r\n",
    "            for i in range(depth[block]):\r\n",
    "                bottleneck_block=self.add_sublayer(\r\n",
    "                    'bb_%d_%d'%(block,i),\r\n",
    "                    BottleneckBlock(\r\n",
    "                        num_channels=num_channels,\r\n",
    "                        num_filters=num_filters[block],\r\n",
    "                        stride=2 if i==0 and block!=0 else 1,\r\n",
    "                        shortcut=shortcut,\r\n",
    "                        version=version))\r\n",
    "                num_channels=bottleneck_block._num_channels_out\r\n",
    "                self.bottleneck_block_list.append(bottleneck_block)\r\n",
    "                shortcut=True\r\n",
    "\r\n",
    "        # 在c5的输出特征图上使用全局池化\r\n",
    "        self.pool2d_avg=nn.AdaptiveAvgPool2D(output_size=1)\r\n",
    "        \r\n",
    "        # stdv用来作为全连接层随机初始化参数的方差\r\n",
    "        import math\r\n",
    "        stdv=1.0/math.sqrt(2048*1.0)\r\n",
    "        # 创建全连接层，输出大小为类别数目，经过残差网络的卷积核全局池化后，\r\n",
    "        # 卷积特征的维度是[B,2048,1,1]，故最后一层全连接层的输入维度是2048\r\n",
    "        self.out=nn.Linear(in_features=2048,out_features=class_dim,\r\n",
    "        weight_attr=paddle.ParamAttr(\r\n",
    "            initializer=paddle.nn.initializer.Uniform(-stdv,stdv)))\r\n",
    "    \r\n",
    "    def forward(self,inputs):\r\n",
    "        x=self.conv(inputs)\r\n",
    "        x=self.pool2d_max(x)\r\n",
    "        for bottleneck_block in self.bottleneck_block_list:\r\n",
    "            x=bottleneck_block(x)\r\n",
    "        x=self.pool2d_avg(x)\r\n",
    "        x=paddle.reshape(x,[x.shape[0],-1])\r\n",
    "        x=self.out(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练函数  \n",
    "\n",
    "input:    \n",
    "`model`:待训练的模型  \n",
    "`datadir`:存放文件的主路径  \n",
    "`annotiondir`:存放标签数据的xlsx文件的路径    \n",
    "`optimizer`:优化模型参数所使用的优化器  \n",
    "`batch_size`：每个批次选取图片数量大小  \n",
    "`EPOCH_NUM`：训练的代数  \n",
    "`use_gpu`：是否使用GPU进行训练  \n",
    "`save`：模型保存的策略  \n",
    "\n",
    "相关代码参考如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save success !\n"
     ]
    }
   ],
   "source": [
    "# 构建模型保存策略函数，返回为模型保存函数\r\n",
    "def model_save(model_version):\r\n",
    "    def save(save_model,model):\r\n",
    "        if save_model:\r\n",
    "            print('model save success !')\r\n",
    "            if model==None:\r\n",
    "                return \r\n",
    "            paddle.save(model.state_dict(),f'./model/resnet50_v{model_version}_PALM.pdparams')\r\n",
    "            \r\n",
    "    return save\r\n",
    "save=model_save('C')\r\n",
    "save(1>0,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_pm(model,\r\n",
    "             datadir,\r\n",
    "             annotiondir,\r\n",
    "             optimizer,\r\n",
    "             batch_size=10,\r\n",
    "             EPOCH_NUM=20,\r\n",
    "             use_gpu=False,\r\n",
    "             save=None):\r\n",
    "    # 使用0号GPU训练\r\n",
    "    paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\r\n",
    "    max_accuracy=0.\r\n",
    "\r\n",
    "    print('********start training********')\r\n",
    "    model.train()\r\n",
    "    # 定义数据读取器\r\n",
    "    train_loader=data_loader(datadir=datadir+'/train_data/PALM-Training400',batch_size=batch_size,mode='train')\r\n",
    "    valid_loader=valid_data_loader(datadir+'/PALM-Validation400',annotiondir)\r\n",
    "    for epoch in range(EPOCH_NUM):\r\n",
    "        for batch_id,data in enumerate(train_loader()):\r\n",
    "            x_data,y_data=data\r\n",
    "            img=paddle.to_tensor(x_data)\r\n",
    "            label=paddle.to_tensor(y_data).astype('int64')\r\n",
    "            # 使用模型进行前向计算，得到预测值\r\n",
    "            out=model(img)\r\n",
    "            loss=nn.functional.cross_entropy(out,label,reduction='none')\r\n",
    "            avg_loss=paddle.mean(loss)\r\n",
    "            if batch_id%10==0:\r\n",
    "                print(\"epoch:{}===batch_id:{}===loss:{:.4f}\".format(\r\n",
    "                    epoch,batch_id,float(avg_loss.numpy())))\r\n",
    "            # 反向传播，更新权重，消除梯度\r\n",
    "            avg_loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.clear_grad()\r\n",
    "        valid_accuracy,valid_loss=valid_pm(model,valid_loader,batch_size=50)\r\n",
    "        print('[validation]:======accuracy:{:.5f}/loss:{:.5f}'.format(valid_accuracy,valid_loss))\r\n",
    "        if save!=None and valid_accuracy>max_accuracy:\r\n",
    "            save(valid_accuracy>max_accuracy,model)\r\n",
    "            max_accuracy=valid_accuracy\r\n",
    "            print('max accuracy :',max_accuracy)\r\n",
    "        print()\r\n",
    "\r\n",
    "        \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  验证函数\n",
    "\n",
    "input:  \n",
    "\n",
    "`model`:待训练的模型  \n",
    "`valid_loader`:验证数据的迭代生成器  \n",
    "`batch_size`:每一个批次验证数据的大小  \n",
    "\n",
    "\n",
    "相关代码参考如下。\n",
    "\n",
    "**注意：为保证避免显存问题，采用分批次验证，求平均值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def valid_pm(model,valid_loader,batch_size=100):\r\n",
    "    model.eval()\r\n",
    "    print(\"*****valid data import success*****\")\r\n",
    "    batch_accuracy=[]\r\n",
    "    batch_loss=[]\r\n",
    "    for batch_id,data in enumerate(valid_loader(batch_size=batch_size)):\r\n",
    "        x_data,y_data=data\r\n",
    "        img=paddle.to_tensor(x_data)\r\n",
    "        label=paddle.to_tensor(y_data).astype('int64')\r\n",
    "        out=model(img)\r\n",
    "        predict=paddle.argmax(out,1)\r\n",
    "        loss=nn.functional.cross_entropy(out,label,reduction='none')\r\n",
    "        avg_loss=paddle.mean(loss)\r\n",
    "        accuracy=sum(predict.numpy().reshape(-1,1)==label.numpy())/float(label.shape[0])\r\n",
    "        batch_loss.append(float(avg_loss.numpy()))\r\n",
    "        batch_accuracy.append(accuracy)\r\n",
    "        # print('batch_id:{}===accuracy:{}/loss:{}'.format(batch_id,accuracy,avg_loss.numpy()))\r\n",
    "        # if batch_id==1:\r\n",
    "        #     print('predict:{}'.format(predict.numpy()))\r\n",
    "        #     print('label  :{}'.format(label.numpy()[:,0]))\r\n",
    "    avg_loss=np.mean(batch_loss)\r\n",
    "    avg_accuracy=np.mean(batch_accuracy)\r\n",
    "    return avg_accuracy,avg_loss\r\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 超参数及训练部分\n",
    "超参数含义：\n",
    "\n",
    "`model_version`：选择使用的ResNet版本，可选B或D，默认B；  \n",
    "`use_gpu`：是否使用gpu进行训练，默认True；  \n",
    "`lr`：学习率；  \n",
    "`momentum`：动量系数  \n",
    "`load_model`：是否载入预训练模型，默认True   \n",
    "`save_model`：是否保存训练模型，默认False\n",
    "\n",
    "**注释：因为在2.1.2的更新中线下了paddle.save对paddle.nn.Layer的支持，所以更换模型保存方式**\n",
    "\n",
    "**后期优化想法：根据验证集中正确率是否上升来确定本次的模型参数是否保存，达到选取最优参数的目的。**(over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件主路径： /home/aistudio\n",
      "训练模型版本： D\n",
      "是否采用预训练模型： True\n",
      "是否采用GPU： True\n",
      "********start training********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0===batch_id:0===loss:0.6875\n",
      "epoch:0===batch_id:10===loss:0.3790\n",
      "epoch:0===batch_id:20===loss:0.4460\n",
      "epoch:0===batch_id:30===loss:0.2065\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94000/loss:0.17656\n",
      "model save success !\n",
      "max accuracy : 0.94\n",
      "\n",
      "epoch:1===batch_id:0===loss:0.1594\n",
      "epoch:1===batch_id:10===loss:1.1010\n",
      "epoch:1===batch_id:20===loss:0.5696\n",
      "epoch:1===batch_id:30===loss:0.2365\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.75250/loss:0.49017\n",
      "\n",
      "epoch:2===batch_id:0===loss:0.8436\n",
      "epoch:2===batch_id:10===loss:0.6267\n",
      "epoch:2===batch_id:20===loss:0.3740\n",
      "epoch:2===batch_id:30===loss:0.5817\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.93000/loss:0.19103\n",
      "\n",
      "epoch:3===batch_id:0===loss:0.2321\n",
      "epoch:3===batch_id:10===loss:0.4272\n",
      "epoch:3===batch_id:20===loss:0.0627\n",
      "epoch:3===batch_id:30===loss:0.5146\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.93500/loss:0.19195\n",
      "\n",
      "epoch:4===batch_id:0===loss:0.4224\n",
      "epoch:4===batch_id:10===loss:0.0539\n",
      "epoch:4===batch_id:20===loss:0.4069\n",
      "epoch:4===batch_id:30===loss:0.2020\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.87500/loss:0.32050\n",
      "\n",
      "epoch:5===batch_id:0===loss:0.5316\n",
      "epoch:5===batch_id:10===loss:0.3561\n",
      "epoch:5===batch_id:20===loss:0.0460\n",
      "epoch:5===batch_id:30===loss:1.2740\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95000/loss:0.16042\n",
      "model save success !\n",
      "max accuracy : 0.95\n",
      "\n",
      "epoch:6===batch_id:0===loss:0.0231\n",
      "epoch:6===batch_id:10===loss:0.8852\n",
      "epoch:6===batch_id:20===loss:0.4515\n",
      "epoch:6===batch_id:30===loss:0.8795\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95000/loss:0.15842\n",
      "\n",
      "epoch:7===batch_id:0===loss:0.2164\n",
      "epoch:7===batch_id:10===loss:0.0807\n",
      "epoch:7===batch_id:20===loss:0.0351\n",
      "epoch:7===batch_id:30===loss:0.5469\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94250/loss:0.15026\n",
      "\n",
      "epoch:8===batch_id:0===loss:0.1626\n",
      "epoch:8===batch_id:10===loss:0.0074\n",
      "epoch:8===batch_id:20===loss:0.0584\n",
      "epoch:8===batch_id:30===loss:0.2788\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94250/loss:0.16527\n",
      "\n",
      "epoch:9===batch_id:0===loss:0.2395\n",
      "epoch:9===batch_id:10===loss:0.1562\n",
      "epoch:9===batch_id:20===loss:0.0132\n",
      "epoch:9===batch_id:30===loss:0.3651\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95000/loss:0.15449\n",
      "\n",
      "epoch:10===batch_id:0===loss:0.3940\n",
      "epoch:10===batch_id:10===loss:0.2583\n",
      "epoch:10===batch_id:20===loss:0.0423\n",
      "epoch:10===batch_id:30===loss:0.4661\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95000/loss:0.15846\n",
      "\n",
      "epoch:11===batch_id:0===loss:0.1888\n",
      "epoch:11===batch_id:10===loss:0.0854\n",
      "epoch:11===batch_id:20===loss:0.0684\n",
      "epoch:11===batch_id:30===loss:0.6246\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95250/loss:0.15426\n",
      "model save success !\n",
      "max accuracy : 0.9524999999999999\n",
      "\n",
      "epoch:12===batch_id:0===loss:0.0360\n",
      "epoch:12===batch_id:10===loss:0.0664\n",
      "epoch:12===batch_id:20===loss:0.2892\n",
      "epoch:12===batch_id:30===loss:0.0742\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95250/loss:0.15050\n",
      "\n",
      "epoch:13===batch_id:0===loss:0.1397\n",
      "epoch:13===batch_id:10===loss:0.0489\n",
      "epoch:13===batch_id:20===loss:0.5626\n",
      "epoch:13===batch_id:30===loss:0.1723\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.88750/loss:0.29846\n",
      "\n",
      "epoch:14===batch_id:0===loss:0.3331\n",
      "epoch:14===batch_id:10===loss:0.0380\n",
      "epoch:14===batch_id:20===loss:0.0635\n",
      "epoch:14===batch_id:30===loss:0.3922\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95750/loss:0.14014\n",
      "model save success !\n",
      "max accuracy : 0.9575\n",
      "\n",
      "epoch:15===batch_id:0===loss:0.0646\n",
      "epoch:15===batch_id:10===loss:0.1431\n",
      "epoch:15===batch_id:20===loss:0.0754\n",
      "epoch:15===batch_id:30===loss:0.3814\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94000/loss:0.16570\n",
      "\n",
      "epoch:16===batch_id:0===loss:0.2551\n",
      "epoch:16===batch_id:10===loss:0.0619\n",
      "epoch:16===batch_id:20===loss:0.2396\n",
      "epoch:16===batch_id:30===loss:0.1278\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94000/loss:0.18599\n",
      "\n",
      "epoch:17===batch_id:0===loss:0.2959\n",
      "epoch:17===batch_id:10===loss:0.0372\n",
      "epoch:17===batch_id:20===loss:0.0639\n",
      "epoch:17===batch_id:30===loss:0.0279\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.91500/loss:0.25830\n",
      "\n",
      "epoch:18===batch_id:0===loss:0.6300\n",
      "epoch:18===batch_id:10===loss:0.0225\n",
      "epoch:18===batch_id:20===loss:0.1312\n",
      "epoch:18===batch_id:30===loss:0.5042\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.94250/loss:0.15748\n",
      "\n",
      "epoch:19===batch_id:0===loss:0.0433\n",
      "epoch:19===batch_id:10===loss:0.0531\n",
      "epoch:19===batch_id:20===loss:0.2526\n",
      "epoch:19===batch_id:30===loss:0.0098\n",
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95250/loss:0.15064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filedir=os.getcwd()\r\n",
    "model_version='D'\r\n",
    "use_gpu=True\r\n",
    "lr=0.001\r\n",
    "momentum=0.3\r\n",
    "load_model=True\r\n",
    "save_model=False\r\n",
    "\r\n",
    "model=ResNet(layers=50,version=model_version)\r\n",
    "if os.path.exists(f'./model/resnet50_v{model_version}_PALM.pdmodel') and load_model:\r\n",
    "    model_params=paddle.load(f'./model/resnet50_v{model_version}_PALM.pdparams')\r\n",
    "    model.set_state_dict(model_params)\r\n",
    "annotion_path=filedir+'/PALM-Validation-GT/PM_Label_and_Fovea_Location.xlsx'\r\n",
    "optimizer=paddle.optimizer.Momentum(learning_rate=lr,momentum=momentum,parameters=model.parameters())\r\n",
    "\r\n",
    "print('文件主路径：',filedir)\r\n",
    "print('训练模型版本：',model_version)\r\n",
    "print('是否采用预训练模型：',load_model)\r\n",
    "print('是否采用GPU：',use_gpu)\r\n",
    "\r\n",
    "if save_model:\r\n",
    "    save=model_save(model_version)\r\n",
    "else:\r\n",
    "    save=None\r\n",
    "train_pm(model,filedir,annotion_path,optimizer,use_gpu=use_gpu,save=save)\r\n",
    "\r\n",
    "# paddle.save(model,f'./model/resnet50_v{model_version}_PALM.pdmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **ResNet-vb导入和验证**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95000/loss:0.16074\n"
     ]
    }
   ],
   "source": [
    "annotion_path='./PALM-Validation-GT/PM_Label_and_Fovea_Location.xlsx'\r\n",
    "valid_loader=valid_data_loader('./PALM-Validation400',annotion_path)\r\n",
    "model_version='B'\r\n",
    "model=ResNet(layers=50,version=model_version)\r\n",
    "\r\n",
    "model_params=paddle.load(f'./model/resnet50_v{model_version}_PALM.pdparams')\r\n",
    "model.set_state_dict(model_params)\r\n",
    "valid_accuracy,valid_loss=valid_pm(model,valid_loader,batch_size=50)\r\n",
    "print('[validation]:======accuracy:{:.5f}/loss:{:.5f}'.format(valid_accuracy,valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **ResNet-vd的导入和验证**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****valid data import success*****\n",
      "[validation]:======accuracy:0.95750/loss:0.14014\n"
     ]
    }
   ],
   "source": [
    "annotion_path='./PALM-Validation-GT/PM_Label_and_Fovea_Location.xlsx'\r\n",
    "valid_loader=valid_data_loader('./PALM-Validation400',annotion_path)\r\n",
    "model_version='D'\r\n",
    "model=ResNet(layers=50,version=model_version)\r\n",
    "\r\n",
    "model_params=paddle.load(f'./model/resnet50_v{model_version}_PALM.pdparams')\r\n",
    "model.set_state_dict(model_params)\r\n",
    "valid_accuracy,valid_loss=valid_pm(model,valid_loader,batch_size=50)\r\n",
    "print('[validation]:======accuracy:{:.5f}/loss:{:.5f}'.format(valid_accuracy,valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **总结**\n",
    "\n",
    "本次实验通过眼疾识别案例，来进一步的理解在aistudio平台下导入训练集和进行训练集的预处理操作，这其中包含了很多图像预处理方面的基础知识和基本操作，更有体现了平台所特有的在线操作文件特性，让代码编辑工作不再局限于个人电脑的配置，有利于广大代码爱好者的学习和进一步提升。后续使用paddle框架进一步全面阐述`ResNet`网络的基本原理和及其变体D版本的特性，在并且在基础上基于框架将其实现，这其中包含大量的网络模型图的阅读和理解、1x1卷积的巧妙作用和模型的巧妙设计等等知识，值得深层次的体会和学习。\n",
    "\n",
    "在此次实验中，生成器的使用和分批次的训练和验证这是一个非常必要且有效的节省显存的办法，这也体现了在运行大型项目工程的实际当中，代码的参数量、运行效率和占用空间是必须要考虑的因素。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
