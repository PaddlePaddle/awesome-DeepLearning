# 1. CNN-DSSM知识点补充

CNN-DSSM在DSSM的基础上改进了数据的预处理和深度



## 1.1 CNN-DSSM概念

针对 DSSM 词袋模型丢失上下文信息的缺点。通过卷积层实现的“窗口”，模型可以捕获文本中类似n-gram的上下文结构信息，并用最显著的上下文特征转化为表示文本的语义向量。最终提升模型的效果。CNN-DSSM 与 DSSM 的区别主要在于输入层和表示层。

## 1.2 模型

### 1.2.1 输入层

#### （1）英文

英文的处理方式，除了上文提到的 letter-trigram，CNN-DSSM 还在输入层增加了word-trigram

![img](https://ask.qcloudimg.com/http-save/yehe-1881084/ty96sfl81g.png?imageView2/2/w/1620)

**如上图所示，word-trigram其实就是一个包含了上下文信息的滑动窗口。** 举个例子：把<`s`> online auto body ... <`s`>这句话提取出前三个词<`s`> online auto，之后再 **==分别对==这三个词进行 letter-trigram 映射到一个 3 万维的向量空间里，然后把三个向量 concat 起来，最终映射到一个 9 万维的向量空间里。**

#### （2）中文

英文的处理方式（word-trigram letter-trigram）在中文中并不可取，因为英文中虽然用了 word-ngram 把样本空间拉成了百万级，但是经过 letter-trigram 又把向量空间降到可控级别，只有 3`*`30K（9 万）。而中文如果用 word-trigram，那向量空间就是百万级的了，显然还是字向量（1.5 万维）比较可控。

### 1.2.2 表示层

CNN-DSSM 的表示层由一个卷积神经网络组成，如下图所示：

![img](https://ask.qcloudimg.com/http-save/yehe-1881084/cj8jiqy22w.png?imageView2/2/w/1620)

#### （1）卷积层——Convolutional layer

**卷积层的作用是提取滑动窗口下的上下文特征。** 以下图为例，假设输入层是一个 302`*`90000（302 行，9 万列）的矩阵，代表 302 个字向量（Query 的和 Doc 的长度一般小于 300，这里少了就补全，多了就截断），每个字向量有 9 万维。而卷积核是一个 3`*`90000 的权值矩阵，卷积核以步长为 1 向下移动，得到的 feature map 是一个 300`*`1 的矩阵，feature map 的计算公式是(输入层维数 302-卷积核大小 3 步长 1)/步长 1=300。而这样的卷积核有 300 个，所以形成了 300 个 300`*`1 的 feature map 矩阵。 

![img](https://blog-10039692.file.myqcloud.com/1501555869244_9824_1501555870293.png)

每个英文单词经过 word hash 之后都可以由一个30K大小的向量表示，我们的卷积可以理解为一维卷积，窗口大小为3，即将待卷积部分三个单词拼接成一个90K的向量，而卷积核为一个 90K`*`300 的矩阵，每次卷积输出一个 1`*`300 的向量。

#### （2）池化层——Max pooling layer

池化层的作用是为句子找到**全局的上下文特征**。池化层以 Max-over-time pooling 的方式，每个 feature map 都取最大值，得到一个 300 维的向量。Max-over-pooling 可以解决可变长度的句子输入问题（因为不管 Feature Map 中有多少个值，只需要提取其中的最大值）。不过我们在上一步已经做了句子的定长处理（固定句子长度为 302），所以就没有可变长度句子的问题。最终池化层的输出为各个 Feature Map 的最大值，即一个 300`*`1 的向量。这里多提一句，之所以 Max pooling 层要保持固定的输出维度，是因为下一层全链接层要求有固定的输入层数，才能进行训练。

#### （3）全连接层——Semantic layer

最后通过全连接层把一个 300 维的向量转化为一个 128 维的低维语义向量。全连接层采用 tanh 函数：

![img](https://ask.qcloudimg.com/http-save/yehe-1881084/urw4zppzjc.png?imageView2/2/w/1620)

### 1.2.3 匹配层

Query 和 Doc 的语义相似性可以用这**两个语义向量(128 维) 的 cosine 距离(即余弦相似度)** 来表示：

![img](https://ask.qcloudimg.com/http-save/yehe-1881084/kln8bra03o.png?imageView2/2/w/1620)

通过 **softmax** 函数可以把 Query 与正样本 Doc 的语义相似性转化为一个后验概率：

![img](https://ask.qcloudimg.com/http-save/yehe-1881084/13wfjyykvz.png?imageView2/2/w/1620)

其中 r 为 softmax 的平滑因子，D 为 Query 下的正样本，D-为 Query 下的负样本（采取随机负采样），D 为 Query 下的整个样本空间。

在训练阶段，通过**极大似然估计**，我们最小化损失函数：

![img](https://ask.qcloudimg.com/http-save/yehe-1881084/4gb01dkyra.png?imageView2/2/w/1620)

残差会在表示层的 DNN 中反向传播，最终通过随机梯度下降（SGD）使模型收敛，得到各网络层的参数{Wi,bi}。

## 1.3 作用

相较于DSSM，CNN-DSSM可以很好的结合上下文计算语义相似度

## 1.4 场景

广告推荐业务场景

搜索场景

其他推荐业务场景

## 1.5 优缺点

- 优点：1.CNN-DSSM 通过卷积层提取了滑动窗口下的上下文信息，又通过池化层提取了全局的上下文信息，上下文信息得到较为有效的保留。

  2.解决了LSA、LDA、Autoencoder等方法存在的字典爆炸问题，从而降低了计算复杂度。因为英文中词的数量要远远高于字母n-gram的数量；

  3.中文方面使用字作为最细切分粒度，可以复用每个字表达的语义，减少分词的依赖，从而提高模型的泛化能力；

  4.字母的n-gram可以更好的处理新词，具有较强的鲁棒性；

  5.使用有监督的方法，优化语义embedding的映射问题；

  6.省去了人工特征工程；

  7.采用有监督训练，精度较高。传统的输入层使用embedding的方式(比如Word2vec的词向量)或者主题模型的方式(比如LDA的主题向量)做词映射，再把各个词的向量拼接或者累加起来。由于Word2vec和LDA都是无监督训练，会给模型引入误差。

  

- 缺点：1.CNN-DSSM 滑动窗口（卷积核）大小的限制，导致无法捕获该上下文信息，对于间隔较远的上下文信息，难以有效保留。

  2.Word Hashing可能造成词语冲突；

  3.采用词袋模型，损失了上下文语序信息。这也是后面会有CNN-DSSM、LSTM-DSSM等DSSM模型变种的原因；

  4.搜索引擎的排序由多种因素决定，用户点击时doc排名越靠前越容易被点击，仅用点击来判断正负样本，产生的噪声较大，模型难以收敛；

  5.效果不可控。因为是端到端模型，好处是省去了人工特征工程，但是也带来了端到端模型效果不可控的问题。

  

## 1.6. 总结

CNN-DSSM的结构可分为数据预处理（把文本向量化），在经过深度神经网络，压缩矩阵，最后拿压缩后的矩阵进行相似度计算。和DNN-DSSM相比主要的变化在深度神经网络这一层的处理方式。


# 2 LSTM-DSSM知识点补充

## 2.1LSTM-DSSM概念

LSTM-DSSM通过采用LSTM进行编码的方式，同样将文本编码为一段向量，LSTM需要对文本长度进行预先的处理，对于query的长尾词处理非常的友好。

## 2.2LSTM-DSSM模型

LSTM-DSSM模型图如下：

 

#### ![img](https://img-blog.csdnimg.cn/20210621204250625.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hxbV8xOTk0,size_16,color_FFFFFF,t_70) RNN

RNN（Recurrent Neural Networks）可以被看做是同一神经网络的多次复制，每个神经网络模块会把消息传递给下一个。如果我们将这个循环展开：

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626142910077-895842182.png)

假设输入 xi 为一个 Query 中几个连续的词，hi 为输出。那么上一个神经元的输出 h(t-1) 与当前细胞的输入 Xt 拼接后经过 tanh 函数会输出 ht，同时把 ht 传递给下一个细胞。

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626143131248-798300031.png)

不幸的是，在这个间隔不断增大时，RNN 会逐渐丧失学习到远距离信息的能力。因为 RNN 随着距离的加长，会导致**梯度消失**。简单来说，**由于求导的链式法则，直接导致梯度被表示为连乘的形式，以至梯度消失（几个小于 1 的数相乘会逐渐趋向于 0）。**

#### LSTM

LSTM[4](（Long-Short-Term Memory）是一种 RNN 特殊的类型，可以学习长期依赖信息。我们分别来介绍它最重要的几个模块：

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626143253896-687816956.png)

#### （0）细胞状态

细胞状态这条线可以理解成是一条信息的传送带，只有一些少量的线性交互。在上面流动可以保持信息的不变性。

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626143339469-1032589589.png)

#### （1）遗忘门

遗忘门[5]由 Gers 提出，它用来控制细胞状态 cell 有哪些信息可以通过，继续往下传递。如下图所示，上一层的输出 h(t-1) concat 上本层的输入 xt，经过一个 sigmoid 网络（遗忘门）产生一个从 0 到 1 的数值 ft，然后与细胞状态 C(t-1) 相乘，最终决定有多少细胞状态可以继续往后传递。

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626145124011-729475638.png)

#### （2）输入门

输入门决定要新增什么信息到细胞状态，这里包含两部分：一个 sigmoid 输入门和一个 tanh 函数。sigmoid 决定输入的信号控制，tanh 决定输入什么内容。如下图所示，上一层的输出 h(t-1) concat 上本层的输入 xt，经过一个 sigmoid 网络（输入门）产生一个从 0 到 1 的数值 it，同样的信息经过 tanh 网络做非线性变换得到结果 Ct，sigmoid 的结果和 tanh 的结果相乘，最终决定有哪些信息可以输入到细胞状态里。

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626145222297-1196511539.png)

#### （3）输出门

输出门决定从细胞状态要输出什么信息，这里也包含两部分：一个 sigmoid 输出门和一个 tanh 函数。sigmoid 决定输出的信号控制，tanh 决定输出什么内容。如下图所示，上一层的输出 h(t-1) concat 上本层的输入 xt，经过一个 sigmoid 网络（输出门）产生一个从 0 到 1 的数值 Ot，细胞状态 Ct 经过 tanh 网络做非线性变换，得到结果再与 sigmoid 的结果 Ot 相乘，最终决定有哪些信息可以输出，输出的结果 ht 会作为这个细胞的输出，也会作为传递个下一个细胞。

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626145256491-2142349187.png)

####  LSTM-DSSM

LSTM-DSSM 其实用的是 LSTM 的一个变种——加入了**peep hole**[6]的 LSTM。如下图所示：

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626145411188-1989417089.png)

看起来有点复杂，我们换一个图，读者可以看的更清晰：

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626145456387-2019106774.png)

**这里三条黑线就是所谓的 peephole，传统的 LSTM 中遗忘门、输入门和输出门只用了 h(t-1) 和 xt 来控制门缝的大小，peephole 的意思是说不但要考虑 h(t-1) 和 xt，也要考虑 Ct-1 和 Ct，其中遗忘门和输入门考虑了 Ct-1，而输出门考虑了 Ct。** 总体来说需要考虑的信息更丰富了。

好了，来看一个 LSTM-DSSM 整体的网络结构：

![img](https://images2018.cnblogs.com/blog/1192699/201806/1192699-20180626145633105-438365884.png)

【Bert训练Embedding】

这里基于迁移学习的思想，不是简单的随机初始化词token的Embedding向量，而是以亿级别的搜索query和docment的title为语料，先使用HanLP分词器进行分词处理，将分词所得的词token按顺序编码，生成后续模型需要的词典，基于Bert预训练模型进行训练，这样就能得到每个词token的语义向量，并当作为模型的输入。

【LSTM语义向量】

先进行分词得到句子的词token-X(i)，基于训练好的Bert模型映射到一个word representation，就是embedding，也就是上图中的l(i)。然后把整个句子送入LSTM，训练LSTM，拿出最后输出的状态y(m),即可得到LSTM潜层语义向量。

【模型输出】

LSTM-DSSM里其实就是将DSSM的全连接改成LSTM，此处案例基于海量的搜索点击数据，分别计算搜索的query的LSTM语义向量和点击以及未点击的document的LSTM语义向量，基于LSTM训练的语义向量进行相似度度量，后续的操作与DSSM模型一致。


## 2.3 LSTM-DSSM作用

相较于 CNN-DSSM 能捕获较远距离上下文特征，且能很好的计算语义近似度，运用方便。

## 2.4 LSTM-DSSM场景

可以运用到电商场景，当然不同的场景可能使用到不同模型的变种，在电商领域，document除开标题以外，可能还会有其他很重要的信息，例如品牌和类目。此时可以将品牌、类目通过Embedding表示学习层、两层MLP直接映射成和LSTM提取的语义向量同一维度的向量，再将两者相加得到最终的语义向量表示，使用最终的语义向量表示输入到DSSM模型中进行召回。结构如下图：

![img](https://img-blog.csdnimg.cn/20210621204312611.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hxbV8xOTk0,size_16,color_FFFFFF,t_70)

## 2.5 LSTM-DSSM优缺点

优点：能捕获较远距离的上下文特征

缺点：LSTM方式的缺点在于需要对文本长度进行预先的处理，同时对于长文本的处理效果也不是很理想。



# 3 MMoE多任务学习知识点补充

## 3.1MMoE概念

mmoe的思想就是，在底部的embedding层上设立多个expert网络，不同的task可以根据需求选择expert，通过expert输出的概率加权平均获得每个task的输入。每个task是单独的mlp tower。同时设置了gate网络，使得不同的任务可以多样化的使用共享层，每个任务的gating networks通过最终输出权重不同实现对experts的选择性利用。不同任务的gating networks可以学习到不同的组合experts的模式，因此模型考虑到了捕捉到任务的相关性和区别。

## 3.2MMoE模型

MMoE模型的结构(下图c)**基于广泛使用的Shared-Bottom结构(下图a)和MoE结构**，其中图(b)是图(c)的一种特殊情况，下面依次介绍。

![img](https://ask.qcloudimg.com/developer-images/article/2365398/0ujiqst4yc.png?imageView2/2/w/1620)image.png

### Shared-Bottom Multi-task Model

如上图a所示，shared-bottom网络（表示为函数f）位于底部，多个任务共用这一层。往上，K个子任务分别对应一个tower network（表示为hk），每个子任务的输出yk=hk(f(x)) 

### Mixture-of-Experts(MoE)

MoE模型可以形式化表示为y=∑ni=1gi(x)fi(x) , 其中∑ni=1gi(x)=1, 且fi,i=1,...,n是n个expert network（expert network可认为是一个神经网络）。

g是组合experts结果的gating network，具体来说g产生n个experts上的概率分布，最终的输出是**所有experts的带权加和**。显然，MoE可看做基于多个独立模型的集成方法。这里注意MoE并不对应上图中的b部分。

后面有些文章将MoE作为一个基本的组成单元，将多个MoE结构堆叠在一个大网络中。比如一个MoE层可以接受上一层MoE层的输出作为输入，其输出作为下一层的输入使用。

### Multi-gate Mixture-of-Experts(MMoE)

MMoE目的就是**相对于shared-bottom结构不明显增加模型参数的要求下捕捉任务的不同**。其核心思想是将**shared-bottom网络中的函数f替换成MoE层**，如上图c所示，形式化表达为：

yk=hk(fk(x)),fk(x)=n∑i=1gk(x)ifi(x)

其中gk(x)=softmax(Wgkx) ，输入就是input feature，输出是所有experts上的权重。

一方面，因为gating networks通常是轻量级的，而且expert networks是所有任务共用，所以相对于论文中提到的一些baseline方法在计算量和参数量上具有优势。

另一方面，相对于所有任务公共一个门控网络(One-gate MoE model，如上图b)，这里MMoE(上图c)中每个任务使用单独的gating networks。每个任务的gating networks通过最终输出权重不同实现对experts的选择性利用。不同任务的gating networks可以学习到不同的组合experts的模式，因此模型考虑到了捕捉到任务的相关性和区别。

## 3.3 MMoE作用

在MMoE提出之前，多任务模型已经有许多经典架构被提出，其中绝大多数的优化都基于share-bottom架构，即不同的任务共享相同的feature或feature_map。然而，这种架构极大地限制了模型表达的能力，为什么这么说？因为我们在共享特征的上层直接接入了多个目标的输出，而由于多个任务各自有不同的数据分布，也就是说我们对不同任务的输出具有一定的差异性，而相同的特征输入会极大地削弱模型的多任务输出表达而在某种程度上降低了多目标模型的泛化能力。MMoE通过“gate network”就可以极大地提高多任务模型的表达能力了。

在线上推荐预测任务时往往需要预测用户的多个行为，如关注、点赞、停留时间等，从而调整策略进行权衡。多任务模型通过学习不同任务的联系和差异，可提高每个任务的学习效率和质量。多任务学习的的框架广泛采用shared-bottom的结构，不同任务间共用底部的隐层。这种结构本质上可以减少过拟合的风险。MMoE中的multi-gate的结构对于任务差异带来的冲突有一定的缓解作用。广泛运用于推荐等场景业务。

## 3.4 MMoE场景

推荐系统中对用户推荐物品

## 3.5 MMoE优缺点

优点：MMoE模型刻画了任务相关性，基于共享表示来学习特定任务的函数，避免了明显增加参数的缺点。

MMoE针对不同任务均设置了一个对应的Gate，这样的好处是在不添加大量的新参数的情况下学习任务特定的函数去平衡共享的表达来对任务之间的关系进行更明确地建模。

MMoE中的multi-gate的结构对于任务差异带来的冲突有一定的缓解作用。

模型的可训练性较好。

缺点：超参数仍需调节

## 3.6 MMoE总结

MoE与MMoE两者的共同点都是把原先Hard-parameter sharing中底层全连接层网络划分成了多个子网络Expert，这样的做法更多是模仿了集成学习中的思想，即同等规模下单个网络无法有效学习到所有任务之间通用的表达但通过划分得到多个子网络后每个子网络总能学到某个任务中一些相关独特的表达，再通过Gate的输出(Softmax)加权各个Expert输出，送入各自多层全连接就能将特定任务学习地较好。

MoE只有一个Gate输出，而MMoE是有多个输出。所以不同点在于MMoE针对不同任务均设置了一个对应的Gate，这样的**好处**是在不添加大量的新参数的情况下**学习任务特定的函数去平衡共享的表达来对任务之间的关系进行更明确地建模**。

在将MMoE应用在Youtube的论文可以得到不同的Expert在不同任务中的重要性不同(可通过看各个Gate的输出来判断每个任务对应哪些Expert比较重要)，因此如果想要某个Expert与某个任务之间的相关性越高，可以在输入Gate之前加入一些预设好的任务和Expert权值关系，或者直接自定义Softmax函数，让占比大的Expert输出更大。该论文中提出了wide&deep的框架并有效结合了MMoE的优势，wide部分引入一个浅层网络来缓和选择偏见问题，这被证明是一个很有效的解决方案。

应用实践方面，知乎在2019年利用MMoE替换了Hard-parameter sharing并取得了用户互动率提升100%的巨大成绩，而互动率直接影响的就是用户体验。

知乎后期的努力方向也主要是使用各种策略优化方法来最大化模型的价值，也就是更好地改善用户的体验。一个好的多任务学习方法应该存在一种最合理的方式去对目标进行权衡和融合，才能得到用户和平台收益的最大化。这就是知乎正在尝试的方法：即对用户进行分群，利用用户对不同内容的不同层次的满意度来动态地调整每个目标的权重，最终融合输出，给出一个最终的排序。



# 4 ShareBottom多任务学习知识点

## 4.1 ShareBottom概念

多目标建模目前业内有两种模式，一种叫Shared-Bottom模式，另一种叫MOE。Shared-Bottom的思路就是多个目标底层共用一套共享layer，在这之上基于不同的目标构建不同的Tower。这样的好处就是底层的layer复用，减少计算量，同时也可以防止过拟合的情况出现。

## 4.2 ShareBottom 模型

### Shared-Bottom多目标模型

![img](https://pic4.zhimg.com/80/v2-1b080c010842ae0948ff2419a838088b_720w.jpg)

最简单直观的多目标模型，底层共享输入，上层各个任务各接一个sub-network，输出对应目标的预测值。

## 4.3 ShareBottom作用

能在推荐系统中使用多目标建模算法以获得更好的业务收入和用户体验

## 4.4 ShareBottom场景

视频推荐业务及各种推荐业务

## 4.5 ShareBottom优缺点

Shared-Bottom 优点：降低overfit风险，利用任务之间的关联性使模型学习效果更强

Shared-Bottom 缺点：任务之间的相关性将严重影响模型效果。假如任务之间相关性较低，模型的效果相对会较差。



# 5 YouTube深度学习视频推荐系统知识点

## 5.1 YouTube深度学习视频推荐系统概念与挑战

youtube是世界上最大的视频内容平台，在如此体量的平台中，推荐系统是至关重要的。但是，youtube的视频推荐面临三方面的挑战：

1）Scale：视频和用户数量巨大，很多现有的推荐算法能够在小的数据集上表现得很好，但是在这里效果不佳。需要构建高度专业化的分布式学习算法和高效的服务系统来处理youtube庞大的用户和视频数量。

2）Freshness：这体现在两方面，一方面视频更新频繁，另一方面用户行为更新频繁。 

3）Noise：相较于庞大的视频库，用户的行为是十分稀疏的，同时，我们基本上能获得的都是用户的隐式反馈信号。构造一个强健的系统是十分困难的。

## 5.2 YouTube深度学习视频推荐系统流程与原理

为了对海量的视频进行快速、准确的排序，YouTube 也采用了经典的召回层 + 排序层的推荐系统架构。

其推荐过程可以分成二级。第一级是用候选集生成模型（Candidate Generation Model）完成候选视频的快速筛选，在这一步，候选视频集合由百万降低到几百量级，这就相当于经典推荐系统架构中的召回层。第二级是用排序模型（Ranking Model）完成几百个候选视频的精排，这相当于经典推荐系统架构中的排序层。

无论是候选集生成模型还是排序模型，YouTube 都采用了深度学习的解决方案。

#### 1.候选集生成模型

用于视频召回的候选集生成模型，架构如下图所示。


最底层是它的输入层，输入的特征包括用户历史观看视频的 Embedding 向量，以及搜索词的 Embedding 向量。对于这些 Embedding 特征，YouTube 是利用用户的观看序列和搜索序列，采用了类似 Item2vec 的预训练方式生成的。

除了视频和搜索词 Embedding 向量，特征向量中还包括用户的地理位置 Embedding、年龄、性别等特征。这里我们需要注意的是，对于样本年龄这个特征，YouTube 不仅使用了原始特征值，还把经过平方处理的特征值也作为一个新的特征输入模型。
这个操作其实是为了挖掘特征非线性的特性。

确定好了特征，这些特征会在 concat 层中连接起来，输入到上层的 ReLU 神经网络进行训练。

三层 ReLU 神经网络过后，YouTube 又使用了 softmax 函数作为输出层。值得一提的是，这里的输出层不是要预测用户会不会点击这个视频，而是要预测用户会点击哪个视频，这就跟一般深度推荐模型不一样。

总的来讲，YouTube 推荐系统的候选集生成模型，是一个标准的利用了 Embedding 预训练特征的深度推荐模型，它遵循Embedding MLP 模型的架构，只是在最后的输出层有所区别。

#### 2.候选集生成模型独特的线上服务方法

#### 3.排序模型

输入层，相比于候选集生成模型需要对几百万候选集进行粗筛，排序模型只需对几百个候选视频进行排序，因此可以引入更多特征进行精排。具体来说，YouTube 的输入层从左至右引入的特征依次是：

impression video ID embedding：当前候选视频的 Embedding；
watched video IDs average embedding：用户观看过的最后 N 个视频 Embedding 的平均值；
language embedding：用户语言的 Embedding 和当前候选视频语言的 Embedding；
time since last watch：表示用户上次观看同频道视频距今的时间；
#previous impressions：该视频已经被曝光给该用户的次数；
这 5 类特征连接起来之后，需要再经过三层 ReLU 网络进行充分的特征交叉，然后就到了输出层。这里重点注意，排序模型的输出层与候选集生成模型又有所不同。不同主要有两点：一是候选集生成模型选择了 softmax 作为其输出层，而排序模型选择了 weighted logistic regression（加权逻辑回归）作为模型输出层；二是候选集生成模型预测的是用户会点击“哪个视频”，排序模型预测的是用户“要不要点击当前视频”。

其实，排序模型采用不同输出层的根本原因就在于，YouTube 想要更精确地预测 用户的观看时长，因为观看时长才是 YouTube 最看中的商业指标，而使用 Weighted LR 作为输出层，就可以实现这样的目标。

在 Weighted LR 的训练中，我们需要为每个样本设置一个权重，权重的大小，代表了这个样本的重要程度。为了能够预估观看时长，YouTube 将正样本的权重设置为用户观看这个视频的时长，然后再用 Weighted LR 进行训练，就可以让模型学到用户观看时长的信息。

对于排序模型，必须使用 TensorFlow Serving 等模型服务平台，来进行模型的线上推断。

#### 4.训练和测试样本的处理

为了能够提高模型的训练效率和预测准确率，Youtube采取了诸多处理训练样本的工程措施，主要有3点：

候选集生成模型把推荐模型转换成 多分类问题，在预测下一次观看的场景中，每一个备选视频都会是一个分类，而如果采用softmax对其训练是很低效的。
Youtube采用word2vec中常用的 负采样训练方法减少每次预测的分类数量，从而加快整个模型的收敛速度。
在对训练集的预处理过程中，Youtube没有采用原始的用户日志，而是 对每个用户提取等数量的训练样本。
YouTube这样做的目的是减少高度活跃用户对模型损失的过度影响，使模型过于偏向活跃用户的行为模式，忽略数量更广大的长尾用户体验。
在处理测试集时，Youtube没有采用经典的随机留一法，而是一定要以用户最近一次观看的行为作为测试集。
只留最后一次观看行为做测试集主要是为了避免引入未来信息(future information)，产生于事实不符的数据穿越问题。

#### 5.处理用户对新视频的爱好

## 5.3YouTube深度学习视频推荐系统作用

在面临用户数量如此巨大的平台，推荐效果优秀且能不断的进行更新。

## 5.4YouTube深度学习视频推荐系统优缺点

优点：能够在大体量的数据中准确给出用户推荐。

缺点：模型相较复杂。

## 5.5YouTube深度学习视频推荐系统总结

YouTube 推荐系统的架构是一个典型的召回层加排序层的架构，其中候选集生成模型负责从百万候选集中召回几百个候选视频，排序模型负责几百个候选视频的精排，最终选出几十个推荐给用户。

候选集生成模型是一个典型的 Embedding MLP 的架构，要注意的是它的输出层一个多分类的输出层，预测的是用户点击了“哪个”视频。在候选集生成模型的 serving 过程中，需要从输出层提取出视频 Embedding，从最后一层 ReLU 层得到用户 Embedding，然后利用 最近邻搜索快速 得到候选集。

排序模型同样是一个 Embedding MLP 的架构，不同的是，它的输入层包含了更多的用户和视频的特征，输出层采用了 Weighted LR 作为输出层，并且使用观看时长作为正样本权重，让模型能够预测出观看时长，这更接近 YouTube 要达成的商业目标。




