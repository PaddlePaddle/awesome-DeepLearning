1.深度学习发展历史
可分为五个时期：
1.启蒙萌芽时期：
1943年McCullonch和Pritts提出了神经元的数学描述和网络的结构方法，这标志着神经网络计算时代的开始。1957年Rosenblatt定义一个称为感知器的神经网络结构，第一次把神经网络从纯理论的探讨推向了工程实现，掀起了神经网络研究的高潮。
2.低潮反思时期：
Minsky和Papert在1969年发表论著《Perceptrons》指出感知器仅能解决一阶谓词逻辑，只能完成线性划分，对于非线性或者其他分类会遇到很多困难，就连简单的XOR（异或）问题都解决不了。由此，神经网络的研究进入了反思期。
3.复兴发展时期：
1982年Hopfield提出的全连接网络模型才使得人们对神经网络有了重新的认识,开辟了一条新的研究道路。1986年Rumelhart等人提出的反向传播算法，使Hopfield模型和多层前馈神经网络成为应用最广泛的神经网络模型之一。
4.新的发展时期：
20世纪90年代中后期，神经网络研究进入了一个新的发展阶段，一方面已有理论在不断地深化和得到进一步推广，另一方面，新的理论和方法也在不断出现。光学神经网络、混沌神经网络模糊神经网络、进化神经网络等新模型陆续出现。
5.深度神经网络：
2006年辛顿等人首次提出了“深度置信网络”的概念。他给多层神经网络相关的学习方法赋予了一个新名词——“深度学习”。2012年第一个深度神经网络Alexnet在ImageNet 竞赛中获得冠军。2016年谷歌旗下的DeepMind公司公布其创造的“阿尔法狗”(AlphaGo)围棋程序击败了世界围棋冠军，掀起再一次的人工智能研究热潮。

2.人工智能、机器学习、深度学习有什么区别和联系？
人工智能是三个概念之中范围最大的，它包含另外两个概念。AI的内容有人工智能的三大学派等。其中的代表性技术有专家系统，模糊逻辑，计算智能等。机器学习是AI的一个分支，强调的是数据科学，过程可以被概括为输入——手工设计的特征——学习映射——输出，典型应用有逻辑回归，决策树等。深度学习被机器学习包含，是最小的概念。由于数据量与日俱增，计算机硬件性能的提升，机器学习中的神经网络被广泛开发和应用，网络的层数朝着越来越深发展，也就成为了一个专门的分支——深度学习。代表技术有现在各种各样的神经网络，包括ResNet， GoogLeNet， 常规的CNN,RNN，变体Faster R-CNN等种类非常多的网络。
![](https://ai-studio-static-online.cdn.bcebos.com/3434ee4c87d84453b17552aaece9c29ee1b0450a161a4059b00fd33d3529a786)
![](https://ai-studio-static-online.cdn.bcebos.com/b6c71f463aeb4e44a429b561f89c6f271f3c36a779224f8f966d7161c3d571f3)


3.神经元，单层感知机，多层感知机
神经元是生物结构，是神经系统的基本单位。
![](https://ai-studio-static-online.cdn.bcebos.com/fcf9719c68004333834e32753298b3c8955a9979f7864ab69a94d787cf82515c)
![](https://ai-studio-static-online.cdn.bcebos.com/647ab4d718cc419faba79c8facb3747f37a029aab8ff4169bb3a4678475ed954)

在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会像相连的神经元发送化学物质，从而改变这些神经元内的电位。如果某神经元的电位超过了一个阈值，那么它就会被激活，即“兴奋”起来，向其他神经元发送化学物质。1943年，该模型被抽象为M-P神经元模型。在这个模型中，神经元接收到来自n个其他神经元传递过来的输入信号，它们通过带权重的连接进行传递，神经元接受到的总输入值将与神经元的阈值进行比较，，然后通过激活函数处理以产生神经元的输出。
![](https://ai-studio-static-online.cdn.bcebos.com/c874bd0ccb94435f995549269e77182660a63fc6ce584d36a5e9eda5c7f84894)

单层感知机由两层神经元足证，输入层接受外界信号之后传递给输出层，输出层是一个神经元。它只有输出层神经元会进行激活函数处理，即只有一层功能性神经元，学习能力很有限，只能解决线性可分问题。而且通过数学证明是可以知道两类数据线性可分时感知机一定能收敛。单层感知机也只能解决二分类问题。
为了找到能够解决多分类问题的模型，最简单的一个想法就是增加感知机的层数。
![](https://ai-studio-static-online.cdn.bcebos.com/c0edc56dc55a447c9d07c7fb645525285205b68c528d44fc8c3a5e1512c25b50)
一些常见的神经网络可以简化表示为上面的结构，每层神经元与下一层神经元完全互联，同层之间不连接，也没有跨层链接，这样的多层感知机也就是多层前馈神经网络了。其中输入层接受外界输入，隐层和输出层对信号进行加工，最终结果由输出层输出。

4.前向传播
前向传播，顾名思义就是数据从网络的输入层输入，沿着隐藏层或者其他结构一路往输出层传播，最后达到输出层输出结果的过程。
![](https://ai-studio-static-online.cdn.bcebos.com/889f20678c0e4db88884435cef2849fd8ad8b95819dc430cab870945dfe6c3c7)
![](https://ai-studio-static-online.cdn.bcebos.com/8ed84f532a324e98a332bfb4958ac1d3a44cb9b5f7e0429284a517d21aa8f91a)


5.反向传播
根据输出和真实值的差异反向修改网络参数的过程。
![](https://ai-studio-static-online.cdn.bcebos.com/5b29e1545f814c23af484bf2f5595bf4cd54b9189d6641bf98afb3800f017b65)
![](https://ai-studio-static-online.cdn.bcebos.com/3ba2a6bfb03d447c9c90cf4c4bf6cf561ad1971d509d411488eef18c9b8acb41)

