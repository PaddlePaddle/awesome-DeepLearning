{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, ..., 3.969e+02, 7.880e+00,\n",
       "       1.190e+01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入需要用到的package\r\n",
    "import numpy as np\r\n",
    "import json\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# 读入训练数据\r\n",
    "datafile = './work/housing.data'\r\n",
    "data = np.fromfile(datafile, sep=' ')\r\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读入之后的数据被转化成1维array，其中array的第0-13项是第一条数据，第14-27项是第二条数据，以此类推.... \r\n",
    "# 这里对原始数据做reshape，变成N x 14的形式\r\n",
    "feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE','DIS', \r\n",
    "                 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\r\n",
    "feature_num = len(feature_names)\r\n",
    "data = data.reshape([data.shape[0] // feature_num, feature_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01\n",
      " 4.090e+00 1.000e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00 2.400e+01]\n"
     ]
    }
   ],
   "source": [
    "# 查看数据\r\n",
    "x = data[0]\r\n",
    "print(x.shape)\r\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 0.8\r\n",
    "offset = int(data.shape[0] * ratio)\r\n",
    "training_data = data[:offset]\r\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 计算train数据集的最大值，最小值，平均值\r\n",
    "maximums, minimums, avgs = \\\r\n",
    "                     training_data.max(axis=0), \\\r\n",
    "                     training_data.min(axis=0), \\\r\n",
    "     training_data.sum(axis=0) / training_data.shape[0]\r\n",
    "# 对数据进行归一化处理\r\n",
    "for i in range(feature_num):\r\n",
    "    #print(maximums[i], minimums[i], avgs[i])\r\n",
    "    data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\r\n",
    "    # 从文件导入数据\r\n",
    "    datafile = './work/housing.data'\r\n",
    "    data = np.fromfile(datafile, sep=' ')\r\n",
    "\r\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\r\n",
    "    feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \\\r\n",
    "                      'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\r\n",
    "    feature_num = len(feature_names)\r\n",
    "\r\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\r\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\r\n",
    "\r\n",
    "    # 将原数据集拆分成训练集和测试集\r\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\r\n",
    "    # 测试集和训练集必须是没有交集的\r\n",
    "    ratio = 0.8\r\n",
    "    offset = int(data.shape[0] * ratio)\r\n",
    "    training_data = data[:offset]\r\n",
    "\r\n",
    "    # 计算训练集的最大值，最小值，平均值\r\n",
    "    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), \\\r\n",
    "                                 training_data.sum(axis=0) / training_data.shape[0]\r\n",
    "\r\n",
    "    # 对数据进行归一化处理\r\n",
    "    for i in range(feature_num):\r\n",
    "        #print(maximums[i], minimums[i], avgs[i])\r\n",
    "        data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])\r\n",
    "\r\n",
    "    # 训练集和测试集的划分比例\r\n",
    "    training_data = data[:offset]\r\n",
    "    test_data = data[offset:]\r\n",
    "    return training_data,test_data,minimums[13],maximums[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 / iter   0, loss = 12.4815\n",
      "Epoch   0 / iter   1, loss = 4.1831\n",
      "Epoch   0 / iter   2, loss = 0.2040\n",
      "Epoch   0 / iter   3, loss = 0.1761\n",
      "Epoch   0 / iter   4, loss = 0.3379\n",
      "Epoch   1 / iter   0, loss = 0.2353\n",
      "Epoch   1 / iter   1, loss = 0.1551\n",
      "Epoch   1 / iter   2, loss = 0.1460\n",
      "Epoch   1 / iter   3, loss = 0.1684\n",
      "Epoch   1 / iter   4, loss = 0.3293\n",
      "Epoch   2 / iter   0, loss = 0.1362\n",
      "Epoch   2 / iter   1, loss = 0.1478\n",
      "Epoch   2 / iter   2, loss = 0.1250\n",
      "Epoch   2 / iter   3, loss = 0.1123\n",
      "Epoch   2 / iter   4, loss = 0.1559\n",
      "Epoch   3 / iter   0, loss = 0.1985\n",
      "Epoch   3 / iter   1, loss = 0.0869\n",
      "Epoch   3 / iter   2, loss = 0.0799\n",
      "Epoch   3 / iter   3, loss = 0.1127\n",
      "Epoch   3 / iter   4, loss = 0.1423\n",
      "Epoch   4 / iter   0, loss = 0.1235\n",
      "Epoch   4 / iter   1, loss = 0.0870\n",
      "Epoch   4 / iter   2, loss = 0.1083\n",
      "Epoch   4 / iter   3, loss = 0.1272\n",
      "Epoch   4 / iter   4, loss = 0.0648\n",
      "Epoch   5 / iter   0, loss = 0.1442\n",
      "Epoch   5 / iter   1, loss = 0.1648\n",
      "Epoch   5 / iter   2, loss = 0.0938\n",
      "Epoch   5 / iter   3, loss = 0.1533\n",
      "Epoch   5 / iter   4, loss = 0.2198\n",
      "Epoch   6 / iter   0, loss = 0.2289\n",
      "Epoch   6 / iter   1, loss = 0.1409\n",
      "Epoch   6 / iter   2, loss = 0.2386\n",
      "Epoch   6 / iter   3, loss = 0.1364\n",
      "Epoch   6 / iter   4, loss = 0.0491\n",
      "Epoch   7 / iter   0, loss = 0.3894\n",
      "Epoch   7 / iter   1, loss = 0.0920\n",
      "Epoch   7 / iter   2, loss = 0.1520\n",
      "Epoch   7 / iter   3, loss = 0.1495\n",
      "Epoch   7 / iter   4, loss = 0.0808\n",
      "Epoch   8 / iter   0, loss = 0.1110\n",
      "Epoch   8 / iter   1, loss = 0.1973\n",
      "Epoch   8 / iter   2, loss = 0.1580\n",
      "Epoch   8 / iter   3, loss = 0.2494\n",
      "Epoch   8 / iter   4, loss = 0.0063\n",
      "Epoch   9 / iter   0, loss = 0.1259\n",
      "Epoch   9 / iter   1, loss = 0.2331\n",
      "Epoch   9 / iter   2, loss = 0.3064\n",
      "Epoch   9 / iter   3, loss = 0.1322\n",
      "Epoch   9 / iter   4, loss = 0.1963\n",
      "Epoch  10 / iter   0, loss = 0.6299\n",
      "Epoch  10 / iter   1, loss = 0.8225\n",
      "Epoch  10 / iter   2, loss = 1.5914\n",
      "Epoch  10 / iter   3, loss = 1.9198\n",
      "Epoch  10 / iter   4, loss = 3.2016\n",
      "Epoch  11 / iter   0, loss = 3.4144\n",
      "Epoch  11 / iter   1, loss = 4.0595\n",
      "Epoch  11 / iter   2, loss = 1.6970\n",
      "Epoch  11 / iter   3, loss = 1.0009\n",
      "Epoch  11 / iter   4, loss = 0.4895\n",
      "Epoch  12 / iter   0, loss = 0.6385\n",
      "Epoch  12 / iter   1, loss = 0.2764\n",
      "Epoch  12 / iter   2, loss = 0.3371\n",
      "Epoch  12 / iter   3, loss = 0.1911\n",
      "Epoch  12 / iter   4, loss = 0.2067\n",
      "Epoch  13 / iter   0, loss = 0.6703\n",
      "Epoch  13 / iter   1, loss = 0.4122\n",
      "Epoch  13 / iter   2, loss = 0.2656\n",
      "Epoch  13 / iter   3, loss = 0.2233\n",
      "Epoch  13 / iter   4, loss = 0.1833\n",
      "Epoch  14 / iter   0, loss = 0.2602\n",
      "Epoch  14 / iter   1, loss = 0.1546\n",
      "Epoch  14 / iter   2, loss = 0.1087\n",
      "Epoch  14 / iter   3, loss = 0.1989\n",
      "Epoch  14 / iter   4, loss = 0.1375\n",
      "Epoch  15 / iter   0, loss = 0.2371\n",
      "Epoch  15 / iter   1, loss = 0.2334\n",
      "Epoch  15 / iter   2, loss = 0.1966\n",
      "Epoch  15 / iter   3, loss = 0.1182\n",
      "Epoch  15 / iter   4, loss = 0.0069\n",
      "Epoch  16 / iter   0, loss = 0.0776\n",
      "Epoch  16 / iter   1, loss = 0.2516\n",
      "Epoch  16 / iter   2, loss = 0.2417\n",
      "Epoch  16 / iter   3, loss = 0.0703\n",
      "Epoch  16 / iter   4, loss = 0.8685\n",
      "Epoch  17 / iter   0, loss = 0.1841\n",
      "Epoch  17 / iter   1, loss = 0.1517\n",
      "Epoch  17 / iter   2, loss = 0.1469\n",
      "Epoch  17 / iter   3, loss = 0.0841\n",
      "Epoch  17 / iter   4, loss = 0.0070\n",
      "Epoch  18 / iter   0, loss = 0.1580\n",
      "Epoch  18 / iter   1, loss = 0.1880\n",
      "Epoch  18 / iter   2, loss = 0.1100\n",
      "Epoch  18 / iter   3, loss = 0.0769\n",
      "Epoch  18 / iter   4, loss = 0.1471\n",
      "Epoch  19 / iter   0, loss = 1.2013\n",
      "Epoch  19 / iter   1, loss = 2.2692\n",
      "Epoch  19 / iter   2, loss = 2.9661\n",
      "Epoch  19 / iter   3, loss = 2.0850\n",
      "Epoch  19 / iter   4, loss = 2.5201\n",
      "Epoch  20 / iter   0, loss = 2.3904\n",
      "Epoch  20 / iter   1, loss = 2.2885\n",
      "Epoch  20 / iter   2, loss = 1.4657\n",
      "Epoch  20 / iter   3, loss = 1.0527\n",
      "Epoch  20 / iter   4, loss = 0.7737\n",
      "Epoch  21 / iter   0, loss = 0.8357\n",
      "Epoch  21 / iter   1, loss = 0.5031\n",
      "Epoch  21 / iter   2, loss = 0.2562\n",
      "Epoch  21 / iter   3, loss = 0.1938\n",
      "Epoch  21 / iter   4, loss = 0.1019\n",
      "Epoch  22 / iter   0, loss = 0.1245\n",
      "Epoch  22 / iter   1, loss = 0.0719\n",
      "Epoch  22 / iter   2, loss = 0.1485\n",
      "Epoch  22 / iter   3, loss = 0.0995\n",
      "Epoch  22 / iter   4, loss = 0.0334\n",
      "Epoch  23 / iter   0, loss = 0.2103\n",
      "Epoch  23 / iter   1, loss = 0.0854\n",
      "Epoch  23 / iter   2, loss = 0.1458\n",
      "Epoch  23 / iter   3, loss = 0.1159\n",
      "Epoch  23 / iter   4, loss = 0.0315\n",
      "Epoch  24 / iter   0, loss = 0.1171\n",
      "Epoch  24 / iter   1, loss = 0.1639\n",
      "Epoch  24 / iter   2, loss = 0.1157\n",
      "Epoch  24 / iter   3, loss = 0.1511\n",
      "Epoch  24 / iter   4, loss = 0.1494\n",
      "Epoch  25 / iter   0, loss = 0.3823\n",
      "Epoch  25 / iter   1, loss = 0.3668\n",
      "Epoch  25 / iter   2, loss = 0.3967\n",
      "Epoch  25 / iter   3, loss = 0.3910\n",
      "Epoch  25 / iter   4, loss = 0.2490\n",
      "Epoch  26 / iter   0, loss = 0.6781\n",
      "Epoch  26 / iter   1, loss = 0.2556\n",
      "Epoch  26 / iter   2, loss = 0.2270\n",
      "Epoch  26 / iter   3, loss = 0.1847\n",
      "Epoch  26 / iter   4, loss = 0.0275\n",
      "Epoch  27 / iter   0, loss = 0.1627\n",
      "Epoch  27 / iter   1, loss = 0.0577\n",
      "Epoch  27 / iter   2, loss = 0.1702\n",
      "Epoch  27 / iter   3, loss = 0.1661\n",
      "Epoch  27 / iter   4, loss = 0.1040\n",
      "Epoch  28 / iter   0, loss = 0.1825\n",
      "Epoch  28 / iter   1, loss = 0.1240\n",
      "Epoch  28 / iter   2, loss = 0.2225\n",
      "Epoch  28 / iter   3, loss = 0.0984\n",
      "Epoch  28 / iter   4, loss = 0.0185\n",
      "Epoch  29 / iter   0, loss = 0.0720\n",
      "Epoch  29 / iter   1, loss = 0.1661\n",
      "Epoch  29 / iter   2, loss = 0.2996\n",
      "Epoch  29 / iter   3, loss = 0.0844\n",
      "Epoch  29 / iter   4, loss = 0.0147\n",
      "Epoch  30 / iter   0, loss = 0.1472\n",
      "Epoch  30 / iter   1, loss = 0.0820\n",
      "Epoch  30 / iter   2, loss = 0.1732\n",
      "Epoch  30 / iter   3, loss = 0.1487\n",
      "Epoch  30 / iter   4, loss = 0.0269\n",
      "Epoch  31 / iter   0, loss = 0.1144\n",
      "Epoch  31 / iter   1, loss = 0.2218\n",
      "Epoch  31 / iter   2, loss = 0.0725\n",
      "Epoch  31 / iter   3, loss = 0.2121\n",
      "Epoch  31 / iter   4, loss = 0.1182\n",
      "Epoch  32 / iter   0, loss = 0.2985\n",
      "Epoch  32 / iter   1, loss = 0.4876\n",
      "Epoch  32 / iter   2, loss = 0.4186\n",
      "Epoch  32 / iter   3, loss = 0.2461\n",
      "Epoch  32 / iter   4, loss = 0.2383\n",
      "Epoch  33 / iter   0, loss = 0.4828\n",
      "Epoch  33 / iter   1, loss = 0.5900\n",
      "Epoch  33 / iter   2, loss = 0.6483\n",
      "Epoch  33 / iter   3, loss = 0.7227\n",
      "Epoch  33 / iter   4, loss = 0.6890\n",
      "Epoch  34 / iter   0, loss = 0.5561\n",
      "Epoch  34 / iter   1, loss = 1.0142\n",
      "Epoch  34 / iter   2, loss = 1.6571\n",
      "Epoch  34 / iter   3, loss = 1.8784\n",
      "Epoch  34 / iter   4, loss = 3.9919\n",
      "Epoch  35 / iter   0, loss = 14.6388\n",
      "Epoch  35 / iter   1, loss = 5.8051\n",
      "Epoch  35 / iter   2, loss = 0.4671\n",
      "Epoch  35 / iter   3, loss = 0.2357\n",
      "Epoch  35 / iter   4, loss = 0.1756\n",
      "Epoch  36 / iter   0, loss = 0.2658\n",
      "Epoch  36 / iter   1, loss = 0.1848\n",
      "Epoch  36 / iter   2, loss = 0.1599\n",
      "Epoch  36 / iter   3, loss = 0.1302\n",
      "Epoch  36 / iter   4, loss = 0.1371\n",
      "Epoch  37 / iter   0, loss = 0.1486\n",
      "Epoch  37 / iter   1, loss = 0.0847\n",
      "Epoch  37 / iter   2, loss = 0.1599\n",
      "Epoch  37 / iter   3, loss = 0.1151\n",
      "Epoch  37 / iter   4, loss = 0.1054\n",
      "Epoch  38 / iter   0, loss = 0.0952\n",
      "Epoch  38 / iter   1, loss = 0.1063\n",
      "Epoch  38 / iter   2, loss = 0.1076\n",
      "Epoch  38 / iter   3, loss = 0.0783\n",
      "Epoch  38 / iter   4, loss = 0.2014\n",
      "Epoch  39 / iter   0, loss = 0.1720\n",
      "Epoch  39 / iter   1, loss = 0.0577\n",
      "Epoch  39 / iter   2, loss = 0.0768\n",
      "Epoch  39 / iter   3, loss = 0.0924\n",
      "Epoch  39 / iter   4, loss = 0.0832\n",
      "Epoch  40 / iter   0, loss = 0.0670\n",
      "Epoch  40 / iter   1, loss = 0.0887\n",
      "Epoch  40 / iter   2, loss = 0.0552\n",
      "Epoch  40 / iter   3, loss = 0.0955\n",
      "Epoch  40 / iter   4, loss = 0.1584\n",
      "Epoch  41 / iter   0, loss = 0.2365\n",
      "Epoch  41 / iter   1, loss = 0.0750\n",
      "Epoch  41 / iter   2, loss = 0.1777\n",
      "Epoch  41 / iter   3, loss = 0.1026\n",
      "Epoch  41 / iter   4, loss = 0.1080\n",
      "Epoch  42 / iter   0, loss = 0.0768\n",
      "Epoch  42 / iter   1, loss = 0.1757\n",
      "Epoch  42 / iter   2, loss = 0.0686\n",
      "Epoch  42 / iter   3, loss = 0.0652\n",
      "Epoch  42 / iter   4, loss = 0.7503\n",
      "Epoch  43 / iter   0, loss = 0.4660\n",
      "Epoch  43 / iter   1, loss = 0.2102\n",
      "Epoch  43 / iter   2, loss = 0.1284\n",
      "Epoch  43 / iter   3, loss = 0.0738\n",
      "Epoch  43 / iter   4, loss = 0.0038\n",
      "Epoch  44 / iter   0, loss = 0.1187\n",
      "Epoch  44 / iter   1, loss = 0.0673\n",
      "Epoch  44 / iter   2, loss = 0.0758\n",
      "Epoch  44 / iter   3, loss = 0.1097\n",
      "Epoch  44 / iter   4, loss = 0.0435\n",
      "Epoch  45 / iter   0, loss = 0.0917\n",
      "Epoch  45 / iter   1, loss = 0.0649\n",
      "Epoch  45 / iter   2, loss = 0.0548\n",
      "Epoch  45 / iter   3, loss = 0.1570\n",
      "Epoch  45 / iter   4, loss = 0.0248\n",
      "Epoch  46 / iter   0, loss = 0.1063\n",
      "Epoch  46 / iter   1, loss = 0.0964\n",
      "Epoch  46 / iter   2, loss = 0.0781\n",
      "Epoch  46 / iter   3, loss = 0.0716\n",
      "Epoch  46 / iter   4, loss = 0.3887\n",
      "Epoch  47 / iter   0, loss = 0.2720\n",
      "Epoch  47 / iter   1, loss = 0.1716\n",
      "Epoch  47 / iter   2, loss = 0.1322\n",
      "Epoch  47 / iter   3, loss = 0.1706\n",
      "Epoch  47 / iter   4, loss = 0.0698\n",
      "Epoch  48 / iter   0, loss = 0.1828\n",
      "Epoch  48 / iter   1, loss = 0.0797\n",
      "Epoch  48 / iter   2, loss = 0.0612\n",
      "Epoch  48 / iter   3, loss = 0.0778\n",
      "Epoch  48 / iter   4, loss = 0.0068\n",
      "Epoch  49 / iter   0, loss = 0.0936\n",
      "Epoch  49 / iter   1, loss = 0.0969\n",
      "Epoch  49 / iter   2, loss = 0.1431\n",
      "Epoch  49 / iter   3, loss = 0.0615\n",
      "Epoch  49 / iter   4, loss = 0.0429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if isinstance(obj, collections.Iterator):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2366: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return list(data) if isinstance(data, collections.MappingView) else data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "class Network(object):\r\n",
    "    def __init__(self, num_of_weights):\r\n",
    "        # 随机产生w的初始值\r\n",
    "        # 为了保持程序每次运行结果的一致性，此处设置固定的随机数种子\r\n",
    "        # np.random.seed(0)\r\n",
    "        self.w1 = np.random.randn(num_of_weights, num_of_weights)\r\n",
    "        self.b1= 0.\r\n",
    "        self.w2 = np.random.randn(num_of_weights, 1)\r\n",
    "        self.b2 = 0.\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        z1 = np.dot(x, self.w1) + self.b1\r\n",
    "        z1relu=np.maximum(z1,0)\r\n",
    "        z =np.dot(z1relu,self.w2) + self.b2\r\n",
    "        return z,z1relu,z1\r\n",
    "\r\n",
    "    def loss(self, z, y):\r\n",
    "\r\n",
    "        error = z - y\r\n",
    "\r\n",
    "        num_samples = error.shape[0]\r\n",
    "        cost = error * error\r\n",
    "        cost = np.sum(cost) / num_samples\r\n",
    "        return cost\r\n",
    "\r\n",
    "    def gradient(self, x, y):\r\n",
    "        z,z1relu,z1= self.forward(x)\r\n",
    "        N = x.shape[0]\r\n",
    "        gradient_w2 = 1. / N * np.sum((z - y) * z1relu, axis=0)\r\n",
    "        gradient_w2 = gradient_w2[:, np.newaxis]\r\n",
    "        gradient_b2 = 1. / N * np.sum(z - y)\r\n",
    "        gradient_w1 = 1. / N * np.sum((z - y) * z1relu * x, axis=0)\r\n",
    "        gradient_w1 = gradient_w1[:, np.newaxis]\r\n",
    "        gradient_b1 = 1. / N * np.sum((z - y)*(y-z1relu))\r\n",
    "        \r\n",
    "        return gradient_w1, gradient_b1,gradient_w2,gradient_b2\r\n",
    "\r\n",
    "    def update(self, gradient_w1, gradient_b1,gradient_w2 ,gradient_b2,eta=0.01):\r\n",
    "        self.w1 = self.w1 - eta * gradient_w1\r\n",
    "        self.b1 = self.b1 - eta * gradient_b1\r\n",
    "        self.w2 = self.w2 - eta * gradient_w2\r\n",
    "        self.b2 = self.b2 - eta * gradient_b2\r\n",
    "    def train(self, training_data, num_epochs, batch_size=10, eta=0.01):\r\n",
    "        n = len(training_data)\r\n",
    "        losses = []\r\n",
    "        for epoch_id in range(num_epochs):\r\n",
    "            # 在每轮迭代开始之前，将训练数据的顺序随机打乱\r\n",
    "            # 然后再按每次取batch_size条数据的方式取出\r\n",
    "            np.random.shuffle(training_data)\r\n",
    "            # 将训练数据进行拆分，每个mini_batch包含batch_size条的数据\r\n",
    "            mini_batches = [training_data[k:k + batch_size] for k in range(0, n, batch_size)]\r\n",
    "            for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "                # print(self.w.shape)\r\n",
    "                # print(self.b)\r\n",
    "                x = mini_batch[:, :-1]\r\n",
    "                y = mini_batch[:, -1:]\r\n",
    "                a ,a1,a2= self.forward(x)\r\n",
    "                loss = self.loss(a, y)\r\n",
    "                gradient_w1, gradient_b1,gradient_w2,gradient_b2 = self.gradient(x, y)\r\n",
    "                self.update(gradient_w1, gradient_b1,gradient_w2,gradient_b2, eta)\r\n",
    "                losses.append(loss)\r\n",
    "                print('Epoch {:3d} / iter {:3d}, loss = {:.4f}'.\r\n",
    "                      format(epoch_id, iter_id, loss))\r\n",
    "\r\n",
    "        return losses\r\n",
    "\r\n",
    "\r\n",
    "# 获取数据\r\n",
    "train_data, test_data,min,max= load_data()\r\n",
    "\r\n",
    "# 创建网络\r\n",
    "net = Network(13)\r\n",
    "# 启动训练\r\n",
    "losses = net.train(train_data, num_epochs=50, batch_size=100, eta=0.1)\r\n",
    "\r\n",
    "# 画出损失函数的变化趋势\r\n",
    "plot_x = np.arange(len(losses))\r\n",
    "plot_y = np.array(losses)\r\n",
    "plt.plot(plot_x, plot_y)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "取倒数第十行数据测试实际值为 19.7 预测值为 [29.26028117]\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "x=test_data[-10,-1]\r\n",
    "pred,pred1,pred2=net.forward(test_data[-10,:-1])\r\n",
    "repred=(pred*max)-(min*(pred-1))\r\n",
    "retest=(x*max)-(min*(x-1))\r\n",
    "print(\"取倒数第十行数据测试实际值为\",retest,\"预测值为\",repred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
