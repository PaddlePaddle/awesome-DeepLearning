{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要用到的package\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # 从文件导入数据\n",
    "    datafile = './work/housing.data'\n",
    "    data = np.fromfile(datafile, sep=' ')\n",
    "\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\n",
    "    feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE',                       'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\n",
    "    feature_num = len(feature_names)\n",
    "\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\n",
    "\n",
    "    # 将原数据集拆分成训练集和测试集\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\n",
    "    # 测试集和训练集必须是没有交集的\n",
    "    ratio = 0.8\n",
    "    offset = int(data.shape[0] * ratio)\n",
    "    training_data = data[:offset]\n",
    "\n",
    "    # 计算训练集的最大值，最小值，平均值\n",
    "    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0),                                  training_data.sum(axis=0) / training_data.shape[0]\n",
    "\n",
    "    # 对数据进行归一化处理\n",
    "    for i in range(feature_num):\n",
    "        #print(maximums[i], minimums[i], avgs[i])\n",
    "        data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])\n",
    "\n",
    "    # 训练集和测试集的划分比例\n",
    "    training_data = data[:offset]\n",
    "    test_data = data[offset:]\n",
    "    return training_data,test_data,minimums[13],maximums[13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Network(object):\n",
    "    def __init__(self, num_of_weights):\n",
    "        # 随机产生w的初始值\n",
    "        # 为了保持程序每次运行结果的一致性，此处设置固定的随机数种子\n",
    "        # np.random.seed(0)\n",
    "        self.w1 = np.random.randn(num_of_weights, num_of_weights)\n",
    "        self.b1= 0.\n",
    "        self.w2 = np.random.randn(num_of_weights, 1)\n",
    "        self.b2 = 0.\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = np.dot(x, self.w1) + self.b1\n",
    "        z1relu=np.maximum(z1,0)\n",
    "        z =np.dot(z1relu,self.w2) + self.b2\n",
    "        return z,z1relu,z1\n",
    "\n",
    "    def loss(self, z, y):\n",
    "\n",
    "        error = z - y\n",
    "\n",
    "        num_samples = error.shape[0]\n",
    "        cost = error * error\n",
    "        cost = np.sum(cost) / num_samples\n",
    "        return cost\n",
    "\n",
    "    def gradient(self, x, y):\n",
    "        z,z1relu,z1= self.forward(x)\n",
    "        N = x.shape[0]\n",
    "        gradient_w2 = 1. / N * np.sum((z - y) * z1relu, axis=0)\n",
    "        gradient_w2 = gradient_w2[:, np.newaxis]\n",
    "        gradient_b2 = 1. / N * np.sum(z - y)\n",
    "        gradient_w1 = 1. / N * np.sum((z - y) * z1relu * x, axis=0)\n",
    "        gradient_w1 = gradient_w1[:, np.newaxis]\n",
    "        gradient_b1 = 1. / N * np.sum((z - y)*(y-z1relu))\n",
    "        \n",
    "        return gradient_w1, gradient_b1,gradient_w2,gradient_b2\n",
    "\n",
    "    def update(self, gradient_w1, gradient_b1,gradient_w2 ,gradient_b2,eta=0.01):\n",
    "        self.w1 = self.w1 - eta * gradient_w1\n",
    "        self.b1 = self.b1 - eta * gradient_b1\n",
    "        self.w2 = self.w2 - eta * gradient_w2\n",
    "        self.b2 = self.b2 - eta * gradient_b2\n",
    "    def train(self, training_data, num_epochs, batch_size=10, eta=0.01):\n",
    "        n = len(training_data)\n",
    "        losses = []\n",
    "        for epoch_id in range(num_epochs):\n",
    "            # 在每轮迭代开始之前，将训练数据的顺序随机打乱\n",
    "            # 然后再按每次取batch_size条数据的方式取出\n",
    "            np.random.shuffle(training_data)\n",
    "            # 将训练数据进行拆分，每个mini_batch包含batch_size条的数据\n",
    "            mini_batches = [training_data[k:k + batch_size] for k in range(0, n, batch_size)]\n",
    "            for iter_id, mini_batch in enumerate(mini_batches):\n",
    "                # print(self.w.shape)\n",
    "                # print(self.b)\n",
    "                x = mini_batch[:, :-1]\n",
    "                y = mini_batch[:, -1:]\n",
    "                a ,a1,a2= self.forward(x)\n",
    "                loss = self.loss(a, y)\n",
    "                gradient_w1, gradient_b1,gradient_w2,gradient_b2 = self.gradient(x, y)\n",
    "                self.update(gradient_w1, gradient_b1,gradient_w2,gradient_b2, eta)\n",
    "                losses.append(loss)\n",
    "                print('Epoch {:3d} / iter {:3d}, loss = {:.4f}'.\n",
    "                      format(epoch_id, iter_id, loss))\n",
    "\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 / iter   0, loss = 75.3968\n",
      "Epoch   0 / iter   1, loss = 4183.8838\n",
      "Epoch   0 / iter   2, loss = 27.2488\n",
      "Epoch   0 / iter   3, loss = 22.0293\n",
      "Epoch   0 / iter   4, loss = 18.8132\n",
      "Epoch   1 / iter   0, loss = 14.2320\n",
      "Epoch   1 / iter   1, loss = 11.6494\n",
      "Epoch   1 / iter   2, loss = 9.4008\n",
      "Epoch   1 / iter   3, loss = 7.7021\n",
      "Epoch   1 / iter   4, loss = 5.9976\n",
      "Epoch   2 / iter   0, loss = 5.1901\n",
      "Epoch   2 / iter   1, loss = 4.0066\n",
      "Epoch   2 / iter   2, loss = 3.2979\n",
      "Epoch   2 / iter   3, loss = 2.6414\n",
      "Epoch   2 / iter   4, loss = 2.4212\n",
      "Epoch   3 / iter   0, loss = 1.7553\n",
      "Epoch   3 / iter   1, loss = 1.4098\n",
      "Epoch   3 / iter   2, loss = 1.1607\n",
      "Epoch   3 / iter   3, loss = 1.0089\n",
      "Epoch   3 / iter   4, loss = 0.5721\n",
      "Epoch   4 / iter   0, loss = 0.6805\n",
      "Epoch   4 / iter   1, loss = 0.5288\n",
      "Epoch   4 / iter   2, loss = 0.4691\n",
      "Epoch   4 / iter   3, loss = 0.3586\n",
      "Epoch   4 / iter   4, loss = 0.2011\n",
      "Epoch   5 / iter   0, loss = 0.2823\n",
      "Epoch   5 / iter   1, loss = 0.2184\n",
      "Epoch   5 / iter   2, loss = 0.1963\n",
      "Epoch   5 / iter   3, loss = 0.1517\n",
      "Epoch   5 / iter   4, loss = 0.2054\n",
      "Epoch   6 / iter   0, loss = 0.1085\n",
      "Epoch   6 / iter   1, loss = 0.1191\n",
      "Epoch   6 / iter   2, loss = 0.0859\n",
      "Epoch   6 / iter   3, loss = 0.0742\n",
      "Epoch   6 / iter   4, loss = 0.0982\n",
      "Epoch   7 / iter   0, loss = 0.0648\n",
      "Epoch   7 / iter   1, loss = 0.0635\n",
      "Epoch   7 / iter   2, loss = 0.0566\n",
      "Epoch   7 / iter   3, loss = 0.0509\n",
      "Epoch   7 / iter   4, loss = 0.0205\n",
      "Epoch   8 / iter   0, loss = 0.0491\n",
      "Epoch   8 / iter   1, loss = 0.0539\n",
      "Epoch   8 / iter   2, loss = 0.0421\n",
      "Epoch   8 / iter   3, loss = 0.0476\n",
      "Epoch   8 / iter   4, loss = 0.0671\n",
      "Epoch   9 / iter   0, loss = 0.0414\n",
      "Epoch   9 / iter   1, loss = 0.0530\n",
      "Epoch   9 / iter   2, loss = 0.0366\n",
      "Epoch   9 / iter   3, loss = 0.0486\n",
      "Epoch   9 / iter   4, loss = 0.0163\n",
      "Epoch  10 / iter   0, loss = 0.0487\n",
      "Epoch  10 / iter   1, loss = 0.0425\n",
      "Epoch  10 / iter   2, loss = 0.0359\n",
      "Epoch  10 / iter   3, loss = 0.0449\n",
      "Epoch  10 / iter   4, loss = 0.0191\n",
      "Epoch  11 / iter   0, loss = 0.0483\n",
      "Epoch  11 / iter   1, loss = 0.0360\n",
      "Epoch  11 / iter   2, loss = 0.0457\n",
      "Epoch  11 / iter   3, loss = 0.0406\n",
      "Epoch  11 / iter   4, loss = 0.0259\n",
      "Epoch  12 / iter   0, loss = 0.0424\n",
      "Epoch  12 / iter   1, loss = 0.0327\n",
      "Epoch  12 / iter   2, loss = 0.0590\n",
      "Epoch  12 / iter   3, loss = 0.0362\n",
      "Epoch  12 / iter   4, loss = 0.0180\n",
      "Epoch  13 / iter   0, loss = 0.0370\n",
      "Epoch  13 / iter   1, loss = 0.0424\n",
      "Epoch  13 / iter   2, loss = 0.0466\n",
      "Epoch  13 / iter   3, loss = 0.0444\n",
      "Epoch  13 / iter   4, loss = 0.0086\n",
      "Epoch  14 / iter   0, loss = 0.0473\n",
      "Epoch  14 / iter   1, loss = 0.0446\n",
      "Epoch  14 / iter   2, loss = 0.0363\n",
      "Epoch  14 / iter   3, loss = 0.0419\n",
      "Epoch  14 / iter   4, loss = 0.0195\n",
      "Epoch  15 / iter   0, loss = 0.0444\n",
      "Epoch  15 / iter   1, loss = 0.0355\n",
      "Epoch  15 / iter   2, loss = 0.0505\n",
      "Epoch  15 / iter   3, loss = 0.0397\n",
      "Epoch  15 / iter   4, loss = 0.0236\n",
      "Epoch  16 / iter   0, loss = 0.0473\n",
      "Epoch  16 / iter   1, loss = 0.0445\n",
      "Epoch  16 / iter   2, loss = 0.0356\n",
      "Epoch  16 / iter   3, loss = 0.0407\n",
      "Epoch  16 / iter   4, loss = 0.0679\n",
      "Epoch  17 / iter   0, loss = 0.0385\n",
      "Epoch  17 / iter   1, loss = 0.0589\n",
      "Epoch  17 / iter   2, loss = 0.0407\n",
      "Epoch  17 / iter   3, loss = 0.0318\n",
      "Epoch  17 / iter   4, loss = 0.0650\n",
      "Epoch  18 / iter   0, loss = 0.0390\n",
      "Epoch  18 / iter   1, loss = 0.0471\n",
      "Epoch  18 / iter   2, loss = 0.0458\n",
      "Epoch  18 / iter   3, loss = 0.0390\n",
      "Epoch  18 / iter   4, loss = 0.0066\n",
      "Epoch  19 / iter   0, loss = 0.0425\n",
      "Epoch  19 / iter   1, loss = 0.0474\n",
      "Epoch  19 / iter   2, loss = 0.0399\n",
      "Epoch  19 / iter   3, loss = 0.0378\n",
      "Epoch  19 / iter   4, loss = 0.0959\n",
      "Epoch  20 / iter   0, loss = 0.0527\n",
      "Epoch  20 / iter   1, loss = 0.0292\n",
      "Epoch  20 / iter   2, loss = 0.0442\n",
      "Epoch  20 / iter   3, loss = 0.0403\n",
      "Epoch  20 / iter   4, loss = 0.1135\n",
      "Epoch  21 / iter   0, loss = 0.0423\n",
      "Epoch  21 / iter   1, loss = 0.0389\n",
      "Epoch  21 / iter   2, loss = 0.0425\n",
      "Epoch  21 / iter   3, loss = 0.0427\n",
      "Epoch  21 / iter   4, loss = 0.1217\n",
      "Epoch  22 / iter   0, loss = 0.0347\n",
      "Epoch  22 / iter   1, loss = 0.0398\n",
      "Epoch  22 / iter   2, loss = 0.0489\n",
      "Epoch  22 / iter   3, loss = 0.0439\n",
      "Epoch  22 / iter   4, loss = 0.0950\n",
      "Epoch  23 / iter   0, loss = 0.0560\n",
      "Epoch  23 / iter   1, loss = 0.0278\n",
      "Epoch  23 / iter   2, loss = 0.0515\n",
      "Epoch  23 / iter   3, loss = 0.0323\n",
      "Epoch  23 / iter   4, loss = 0.0929\n",
      "Epoch  24 / iter   0, loss = 0.0432\n",
      "Epoch  24 / iter   1, loss = 0.0361\n",
      "Epoch  24 / iter   2, loss = 0.0477\n",
      "Epoch  24 / iter   3, loss = 0.0449\n",
      "Epoch  24 / iter   4, loss = 0.0029\n",
      "Epoch  25 / iter   0, loss = 0.0524\n",
      "Epoch  25 / iter   1, loss = 0.0339\n",
      "Epoch  25 / iter   2, loss = 0.0399\n",
      "Epoch  25 / iter   3, loss = 0.0423\n",
      "Epoch  25 / iter   4, loss = 0.0610\n",
      "Epoch  26 / iter   0, loss = 0.0425\n",
      "Epoch  26 / iter   1, loss = 0.0418\n",
      "Epoch  26 / iter   2, loss = 0.0417\n",
      "Epoch  26 / iter   3, loss = 0.0450\n",
      "Epoch  26 / iter   4, loss = 0.0027\n",
      "Epoch  27 / iter   0, loss = 0.0510\n",
      "Epoch  27 / iter   1, loss = 0.0382\n",
      "Epoch  27 / iter   2, loss = 0.0400\n",
      "Epoch  27 / iter   3, loss = 0.0410\n",
      "Epoch  27 / iter   4, loss = 0.0145\n",
      "Epoch  28 / iter   0, loss = 0.0348\n",
      "Epoch  28 / iter   1, loss = 0.0469\n",
      "Epoch  28 / iter   2, loss = 0.0433\n",
      "Epoch  28 / iter   3, loss = 0.0448\n",
      "Epoch  28 / iter   4, loss = 0.0278\n",
      "Epoch  29 / iter   0, loss = 0.0326\n",
      "Epoch  29 / iter   1, loss = 0.0479\n",
      "Epoch  29 / iter   2, loss = 0.0402\n",
      "Epoch  29 / iter   3, loss = 0.0480\n",
      "Epoch  29 / iter   4, loss = 0.0589\n",
      "Epoch  30 / iter   0, loss = 0.0399\n",
      "Epoch  30 / iter   1, loss = 0.0381\n",
      "Epoch  30 / iter   2, loss = 0.0487\n",
      "Epoch  30 / iter   3, loss = 0.0433\n",
      "Epoch  30 / iter   4, loss = 0.0247\n",
      "Epoch  31 / iter   0, loss = 0.0489\n",
      "Epoch  31 / iter   1, loss = 0.0373\n",
      "Epoch  31 / iter   2, loss = 0.0510\n",
      "Epoch  31 / iter   3, loss = 0.0325\n",
      "Epoch  31 / iter   4, loss = 0.0283\n",
      "Epoch  32 / iter   0, loss = 0.0353\n",
      "Epoch  32 / iter   1, loss = 0.0420\n",
      "Epoch  32 / iter   2, loss = 0.0370\n",
      "Epoch  32 / iter   3, loss = 0.0525\n",
      "Epoch  32 / iter   4, loss = 0.0973\n",
      "Epoch  33 / iter   0, loss = 0.0370\n",
      "Epoch  33 / iter   1, loss = 0.0503\n",
      "Epoch  33 / iter   2, loss = 0.0398\n",
      "Epoch  33 / iter   3, loss = 0.0395\n",
      "Epoch  33 / iter   4, loss = 0.1041\n",
      "Epoch  34 / iter   0, loss = 0.0359\n",
      "Epoch  34 / iter   1, loss = 0.0397\n",
      "Epoch  34 / iter   2, loss = 0.0397\n",
      "Epoch  34 / iter   3, loss = 0.0555\n",
      "Epoch  34 / iter   4, loss = 0.0066\n",
      "Epoch  35 / iter   0, loss = 0.0473\n",
      "Epoch  35 / iter   1, loss = 0.0387\n",
      "Epoch  35 / iter   2, loss = 0.0469\n",
      "Epoch  35 / iter   3, loss = 0.0367\n",
      "Epoch  35 / iter   4, loss = 0.0300\n",
      "Epoch  36 / iter   0, loss = 0.0415\n",
      "Epoch  36 / iter   1, loss = 0.0464\n",
      "Epoch  36 / iter   2, loss = 0.0382\n",
      "Epoch  36 / iter   3, loss = 0.0429\n",
      "Epoch  36 / iter   4, loss = 0.0483\n",
      "Epoch  37 / iter   0, loss = 0.0281\n",
      "Epoch  37 / iter   1, loss = 0.0548\n",
      "Epoch  37 / iter   2, loss = 0.0534\n",
      "Epoch  37 / iter   3, loss = 0.0346\n",
      "Epoch  37 / iter   4, loss = 0.0050\n",
      "Epoch  38 / iter   0, loss = 0.0504\n",
      "Epoch  38 / iter   1, loss = 0.0351\n",
      "Epoch  38 / iter   2, loss = 0.0441\n",
      "Epoch  38 / iter   3, loss = 0.0396\n",
      "Epoch  38 / iter   4, loss = 0.0519\n",
      "Epoch  39 / iter   0, loss = 0.0377\n",
      "Epoch  39 / iter   1, loss = 0.0434\n",
      "Epoch  39 / iter   2, loss = 0.0377\n",
      "Epoch  39 / iter   3, loss = 0.0478\n",
      "Epoch  39 / iter   4, loss = 0.1435\n",
      "Epoch  40 / iter   0, loss = 0.0411\n",
      "Epoch  40 / iter   1, loss = 0.0445\n",
      "Epoch  40 / iter   2, loss = 0.0389\n",
      "Epoch  40 / iter   3, loss = 0.0456\n",
      "Epoch  40 / iter   4, loss = 0.0279\n",
      "Epoch  41 / iter   0, loss = 0.0437\n",
      "Epoch  41 / iter   1, loss = 0.0373\n",
      "Epoch  41 / iter   2, loss = 0.0401\n",
      "Epoch  41 / iter   3, loss = 0.0483\n",
      "Epoch  41 / iter   4, loss = 0.0324\n",
      "Epoch  42 / iter   0, loss = 0.0437\n",
      "Epoch  42 / iter   1, loss = 0.0416\n",
      "Epoch  42 / iter   2, loss = 0.0388\n",
      "Epoch  42 / iter   3, loss = 0.0456\n",
      "Epoch  42 / iter   4, loss = 0.0496\n",
      "Epoch  43 / iter   0, loss = 0.0301\n",
      "Epoch  43 / iter   1, loss = 0.0483\n",
      "Epoch  43 / iter   2, loss = 0.0484\n",
      "Epoch  43 / iter   3, loss = 0.0438\n",
      "Epoch  43 / iter   4, loss = 0.0099\n",
      "Epoch  44 / iter   0, loss = 0.0562\n",
      "Epoch  44 / iter   1, loss = 0.0404\n",
      "Epoch  44 / iter   2, loss = 0.0370\n",
      "Epoch  44 / iter   3, loss = 0.0374\n",
      "Epoch  44 / iter   4, loss = 0.0105\n",
      "Epoch  45 / iter   0, loss = 0.0467\n",
      "Epoch  45 / iter   1, loss = 0.0479\n",
      "Epoch  45 / iter   2, loss = 0.0381\n",
      "Epoch  45 / iter   3, loss = 0.0350\n",
      "Epoch  45 / iter   4, loss = 0.1020\n",
      "Epoch  46 / iter   0, loss = 0.0409\n",
      "Epoch  46 / iter   1, loss = 0.0447\n",
      "Epoch  46 / iter   2, loss = 0.0434\n",
      "Epoch  46 / iter   3, loss = 0.0367\n",
      "Epoch  46 / iter   4, loss = 0.1263\n",
      "Epoch  47 / iter   0, loss = 0.0451\n",
      "Epoch  47 / iter   1, loss = 0.0365\n",
      "Epoch  47 / iter   2, loss = 0.0437\n",
      "Epoch  47 / iter   3, loss = 0.0451\n",
      "Epoch  47 / iter   4, loss = 0.0182\n",
      "Epoch  48 / iter   0, loss = 0.0432\n",
      "Epoch  48 / iter   1, loss = 0.0385\n",
      "Epoch  48 / iter   2, loss = 0.0380\n",
      "Epoch  48 / iter   3, loss = 0.0490\n",
      "Epoch  48 / iter   4, loss = 0.0522\n",
      "Epoch  49 / iter   0, loss = 0.0476\n",
      "Epoch  49 / iter   1, loss = 0.0312\n",
      "Epoch  49 / iter   2, loss = 0.0448\n",
      "Epoch  49 / iter   3, loss = 0.0468\n",
      "Epoch  49 / iter   4, loss = 0.0131\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获取数据\n",
    "train_data, test_data,min,max= load_data()\n",
    "\n",
    "# 创建网络\n",
    "net = Network(13)\n",
    "# 启动训练\n",
    "losses = net.train(train_data, num_epochs=50, batch_size=100, eta=0.1)\n",
    "\n",
    "# 画出损失函数的变化趋势\n",
    "plot_x = np.arange(len(losses))\n",
    "plot_y = np.array(losses)\n",
    "plt.plot(plot_x, plot_y)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
