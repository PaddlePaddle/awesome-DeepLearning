{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data68632\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. \n",
    "# All changes under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 12.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/beautifulsoup4-4.9.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/bs4 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/aistudio/external-libraries/soupsieve already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\r\n",
    "    # 从文件导入数据\r\n",
    "    datafile = './data/data68632/housing.csv'\r\n",
    "    data = np.fromfile(datafile, sep=' ')\r\n",
    "\r\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\r\n",
    "\r\n",
    "    feature_num = 14\r\n",
    "\r\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\r\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\r\n",
    "\r\n",
    "    # 将原数据集拆分成训练集和测试集\r\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\r\n",
    "    # 测试集和训练集必须是没有交集的\r\n",
    "    ratio = 0.8\r\n",
    "    feature=data\r\n",
    "    offset = int(data.shape[0] * ratio)\r\n",
    "    training_data = data[:offset]\r\n",
    "\r\n",
    "    # 计算训练集的最大值，最小值，平均值\r\n",
    "    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), \\\r\n",
    "                                 training_data.sum(axis=0) / training_data.shape[0]\r\n",
    "\r\n",
    "    # 对数据进行归一化处理\r\n",
    "    for i in range(feature_num):\r\n",
    "        #print(maximums[i], minimums[i], avgs[i])\r\n",
    "        data[:, i] = (data[:, i] - minimums[i]) / (maximums[i] - minimums[i])\r\n",
    "\r\n",
    "    # 训练集和测试集的划分比例\r\n",
    "    training_data = data[:offset]\r\n",
    "    test_data = data[offset:]\r\n",
    "    return training_data,test_data,minimums[13],maximums[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\r\n",
    "    def __init__(self, num_of_weights):\r\n",
    "        # 随机产生w的初始值\r\n",
    "        # 为了保持程序每次运行结果的一致性，此处设置固定的随机数种子\r\n",
    "        # np.random.seed(0)\r\n",
    "        self.w1 = np.random.randn(num_of_weights, num_of_weights)\r\n",
    "        self.b1= 0.\r\n",
    "        self.w2 = np.random.randn(num_of_weights, 1)\r\n",
    "        self.b2 = 0.\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        z1 = np.dot(x, self.w1) + self.b1\r\n",
    "        z1relu=np.maximum(z1,0)\r\n",
    "        z =np.dot(z1relu,self.w2) + self.b2\r\n",
    "        return z,z1relu,z1\r\n",
    "\r\n",
    "    def loss(self, z, y):\r\n",
    "\r\n",
    "        error = z - y\r\n",
    "\r\n",
    "        num_samples = error.shape[0]\r\n",
    "        cost = error * error\r\n",
    "        cost = np.sum(cost) / num_samples\r\n",
    "        return cost\r\n",
    "\r\n",
    "    def gradient(self, x, y):\r\n",
    "        z,z1relu,z1= self.forward(x)\r\n",
    "        N = x.shape[0]\r\n",
    "        gradient_w1 = 1. / N * np.sum((z - y) * z1relu * x, axis=0)\r\n",
    "        gradient_w1 = gradient_w1[:, np.newaxis]\r\n",
    "        gradient_b1 = 1. / N * np.sum((z - y)*(y-z1relu))\r\n",
    "        gradient_w2 = 1. / N * np.sum((z - y) * z1relu, axis=0)\r\n",
    "        gradient_w2 = gradient_w2[:, np.newaxis]\r\n",
    "        gradient_b2 = 1. / N * np.sum(z - y)\r\n",
    "        return gradient_w1, gradient_b1,gradient_w2,gradient_b2\r\n",
    "\r\n",
    "    def update(self, gradient_w1, gradient_b1,gradient_w2 ,gradient_b2,eta=0.01):\r\n",
    "        self.w1 = self.w1 - eta * gradient_w1\r\n",
    "        self.b1 = self.b1 - eta * gradient_b1\r\n",
    "        self.w2 = self.w2 - eta * gradient_w2\r\n",
    "        self.b2 = self.b2 - eta * gradient_b2\r\n",
    "    def train(self, training_data, num_epochs, batch_size=10, eta=0.01):\r\n",
    "        n = len(training_data)\r\n",
    "        losses = []\r\n",
    "        for epoch_id in range(num_epochs):\r\n",
    "            # 在每轮迭代开始之前，将训练数据的顺序随机打乱\r\n",
    "            # 然后再按每次取batch_size条数据的方式取出\r\n",
    "            np.random.shuffle(training_data)\r\n",
    "            # 将训练数据进行拆分，每个mini_batch包含batch_size条的数据\r\n",
    "            mini_batches = [training_data[k:k + batch_size] for k in range(0, n, batch_size)]\r\n",
    "            for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "                # print(self.w.shape)\r\n",
    "                # print(self.b)\r\n",
    "                x = mini_batch[:, :-1]\r\n",
    "                y = mini_batch[:, -1:]\r\n",
    "                a ,a1,a2= self.forward(x)\r\n",
    "                loss = self.loss(a, y)\r\n",
    "                gradient_w1, gradient_b1,gradient_w2,gradient_b2 = self.gradient(x, y)\r\n",
    "                self.update(gradient_w1, gradient_b1,gradient_w2,gradient_b2, eta)\r\n",
    "                losses.append(loss)\r\n",
    "                print('Epoch {:3d} / iter {:3d}, loss = {:.4f}'.\r\n",
    "                      format(epoch_id, iter_id, loss))\r\n",
    "\r\n",
    "        return losses\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 / iter   0, loss = 11.8691\n",
      "Epoch   0 / iter   1, loss = 2.6153\n",
      "Epoch   0 / iter   2, loss = 2.7220\n",
      "Epoch   0 / iter   3, loss = 1.3440\n",
      "Epoch   0 / iter   4, loss = 0.3506\n",
      "Epoch   1 / iter   0, loss = 1.3944\n",
      "Epoch   1 / iter   1, loss = 0.7274\n",
      "Epoch   1 / iter   2, loss = 0.4148\n",
      "Epoch   1 / iter   3, loss = 0.8300\n",
      "Epoch   1 / iter   4, loss = 0.1580\n",
      "Epoch   2 / iter   0, loss = 0.5554\n",
      "Epoch   2 / iter   1, loss = 0.6380\n",
      "Epoch   2 / iter   2, loss = 0.2867\n",
      "Epoch   2 / iter   3, loss = 0.3996\n",
      "Epoch   2 / iter   4, loss = 0.0993\n",
      "Epoch   3 / iter   0, loss = 0.4571\n",
      "Epoch   3 / iter   1, loss = 0.5723\n",
      "Epoch   3 / iter   2, loss = 0.4078\n",
      "Epoch   3 / iter   3, loss = 0.3883\n",
      "Epoch   3 / iter   4, loss = 0.3289\n",
      "Epoch   4 / iter   0, loss = 0.7743\n",
      "Epoch   4 / iter   1, loss = 0.3767\n",
      "Epoch   4 / iter   2, loss = 0.4063\n",
      "Epoch   4 / iter   3, loss = 0.2566\n",
      "Epoch   4 / iter   4, loss = 0.5815\n",
      "Epoch   5 / iter   0, loss = 0.4219\n",
      "Epoch   5 / iter   1, loss = 0.5180\n",
      "Epoch   5 / iter   2, loss = 0.2564\n",
      "Epoch   5 / iter   3, loss = 0.1969\n",
      "Epoch   5 / iter   4, loss = 0.0188\n",
      "Epoch   6 / iter   0, loss = 0.2397\n",
      "Epoch   6 / iter   1, loss = 0.3834\n",
      "Epoch   6 / iter   2, loss = 0.3261\n",
      "Epoch   6 / iter   3, loss = 0.3597\n",
      "Epoch   6 / iter   4, loss = 0.0606\n",
      "Epoch   7 / iter   0, loss = 0.1998\n",
      "Epoch   7 / iter   1, loss = 0.2982\n",
      "Epoch   7 / iter   2, loss = 0.3144\n",
      "Epoch   7 / iter   3, loss = 0.3967\n",
      "Epoch   7 / iter   4, loss = 0.3444\n",
      "Epoch   8 / iter   0, loss = 0.2923\n",
      "Epoch   8 / iter   1, loss = 0.3789\n",
      "Epoch   8 / iter   2, loss = 0.3039\n",
      "Epoch   8 / iter   3, loss = 0.2037\n",
      "Epoch   8 / iter   4, loss = 0.0484\n",
      "Epoch   9 / iter   0, loss = 0.2009\n",
      "Epoch   9 / iter   1, loss = 0.1945\n",
      "Epoch   9 / iter   2, loss = 0.1747\n",
      "Epoch   9 / iter   3, loss = 0.5068\n",
      "Epoch   9 / iter   4, loss = 0.0259\n",
      "Epoch  10 / iter   0, loss = 0.1946\n",
      "Epoch  10 / iter   1, loss = 0.3152\n",
      "Epoch  10 / iter   2, loss = 0.2234\n",
      "Epoch  10 / iter   3, loss = 0.2880\n",
      "Epoch  10 / iter   4, loss = 0.2080\n",
      "Epoch  11 / iter   0, loss = 0.1748\n",
      "Epoch  11 / iter   1, loss = 0.1809\n",
      "Epoch  11 / iter   2, loss = 0.4165\n",
      "Epoch  11 / iter   3, loss = 0.2325\n",
      "Epoch  11 / iter   4, loss = 0.0929\n",
      "Epoch  12 / iter   0, loss = 0.1818\n",
      "Epoch  12 / iter   1, loss = 0.1873\n",
      "Epoch  12 / iter   2, loss = 0.3119\n",
      "Epoch  12 / iter   3, loss = 0.2869\n",
      "Epoch  12 / iter   4, loss = 0.0466\n",
      "Epoch  13 / iter   0, loss = 0.2014\n",
      "Epoch  13 / iter   1, loss = 0.1566\n",
      "Epoch  13 / iter   2, loss = 0.2082\n",
      "Epoch  13 / iter   3, loss = 0.2939\n",
      "Epoch  13 / iter   4, loss = 0.0296\n",
      "Epoch  14 / iter   0, loss = 0.1553\n",
      "Epoch  14 / iter   1, loss = 0.1929\n",
      "Epoch  14 / iter   2, loss = 0.1720\n",
      "Epoch  14 / iter   3, loss = 0.2552\n",
      "Epoch  14 / iter   4, loss = 0.8138\n",
      "Epoch  15 / iter   0, loss = 0.5924\n",
      "Epoch  15 / iter   1, loss = 0.2617\n",
      "Epoch  15 / iter   2, loss = 0.1856\n",
      "Epoch  15 / iter   3, loss = 0.1881\n",
      "Epoch  15 / iter   4, loss = 0.0285\n",
      "Epoch  16 / iter   0, loss = 0.1772\n",
      "Epoch  16 / iter   1, loss = 0.1314\n",
      "Epoch  16 / iter   2, loss = 0.1241\n",
      "Epoch  16 / iter   3, loss = 0.2027\n",
      "Epoch  16 / iter   4, loss = 0.1343\n",
      "Epoch  17 / iter   0, loss = 0.2306\n",
      "Epoch  17 / iter   1, loss = 0.1549\n",
      "Epoch  17 / iter   2, loss = 0.1173\n",
      "Epoch  17 / iter   3, loss = 0.0929\n",
      "Epoch  17 / iter   4, loss = 1.8137\n",
      "Epoch  18 / iter   0, loss = 0.2290\n",
      "Epoch  18 / iter   1, loss = 0.1599\n",
      "Epoch  18 / iter   2, loss = 0.1057\n",
      "Epoch  18 / iter   3, loss = 0.1691\n",
      "Epoch  18 / iter   4, loss = 0.0215\n",
      "Epoch  19 / iter   0, loss = 0.1059\n",
      "Epoch  19 / iter   1, loss = 0.1369\n",
      "Epoch  19 / iter   2, loss = 0.1003\n",
      "Epoch  19 / iter   3, loss = 0.1471\n",
      "Epoch  19 / iter   4, loss = 0.0219\n",
      "Epoch  20 / iter   0, loss = 0.0979\n",
      "Epoch  20 / iter   1, loss = 0.1197\n",
      "Epoch  20 / iter   2, loss = 0.0915\n",
      "Epoch  20 / iter   3, loss = 0.1389\n",
      "Epoch  20 / iter   4, loss = 0.2153\n",
      "Epoch  21 / iter   0, loss = 0.0977\n",
      "Epoch  21 / iter   1, loss = 0.1700\n",
      "Epoch  21 / iter   2, loss = 0.1684\n",
      "Epoch  21 / iter   3, loss = 0.1149\n",
      "Epoch  21 / iter   4, loss = 0.1307\n",
      "Epoch  22 / iter   0, loss = 0.0796\n",
      "Epoch  22 / iter   1, loss = 0.1371\n",
      "Epoch  22 / iter   2, loss = 0.1221\n",
      "Epoch  22 / iter   3, loss = 0.1014\n",
      "Epoch  22 / iter   4, loss = 0.0332\n",
      "Epoch  23 / iter   0, loss = 0.1030\n",
      "Epoch  23 / iter   1, loss = 0.0990\n",
      "Epoch  23 / iter   2, loss = 0.1136\n",
      "Epoch  23 / iter   3, loss = 0.1495\n",
      "Epoch  23 / iter   4, loss = 0.0264\n",
      "Epoch  24 / iter   0, loss = 0.1435\n",
      "Epoch  24 / iter   1, loss = 0.0980\n",
      "Epoch  24 / iter   2, loss = 0.0921\n",
      "Epoch  24 / iter   3, loss = 0.1314\n",
      "Epoch  24 / iter   4, loss = 0.0426\n",
      "Epoch  25 / iter   0, loss = 0.1191\n",
      "Epoch  25 / iter   1, loss = 0.0866\n",
      "Epoch  25 / iter   2, loss = 0.1500\n",
      "Epoch  25 / iter   3, loss = 0.0881\n",
      "Epoch  25 / iter   4, loss = 0.6838\n",
      "Epoch  26 / iter   0, loss = 0.1718\n",
      "Epoch  26 / iter   1, loss = 0.2172\n",
      "Epoch  26 / iter   2, loss = 0.1517\n",
      "Epoch  26 / iter   3, loss = 0.1327\n",
      "Epoch  26 / iter   4, loss = 0.0903\n",
      "Epoch  27 / iter   0, loss = 0.2778\n",
      "Epoch  27 / iter   1, loss = 0.1910\n",
      "Epoch  27 / iter   2, loss = 0.1716\n",
      "Epoch  27 / iter   3, loss = 0.1527\n",
      "Epoch  27 / iter   4, loss = 0.0591\n",
      "Epoch  28 / iter   0, loss = 0.3201\n",
      "Epoch  28 / iter   1, loss = 0.1515\n",
      "Epoch  28 / iter   2, loss = 0.3112\n",
      "Epoch  28 / iter   3, loss = 0.1993\n",
      "Epoch  28 / iter   4, loss = 0.6709\n",
      "Epoch  29 / iter   0, loss = 0.2935\n",
      "Epoch  29 / iter   1, loss = 0.2867\n",
      "Epoch  29 / iter   2, loss = 0.3662\n",
      "Epoch  29 / iter   3, loss = 0.2050\n",
      "Epoch  29 / iter   4, loss = 0.1663\n",
      "Epoch  30 / iter   0, loss = 0.3247\n",
      "Epoch  30 / iter   1, loss = 0.3595\n",
      "Epoch  30 / iter   2, loss = 0.2230\n",
      "Epoch  30 / iter   3, loss = 0.3867\n",
      "Epoch  30 / iter   4, loss = 0.0794\n",
      "Epoch  31 / iter   0, loss = 0.3458\n",
      "Epoch  31 / iter   1, loss = 0.5260\n",
      "Epoch  31 / iter   2, loss = 0.4347\n",
      "Epoch  31 / iter   3, loss = 0.4440\n",
      "Epoch  31 / iter   4, loss = 0.7211\n",
      "Epoch  32 / iter   0, loss = 0.4317\n",
      "Epoch  32 / iter   1, loss = 0.3830\n",
      "Epoch  32 / iter   2, loss = 0.3424\n",
      "Epoch  32 / iter   3, loss = 0.2917\n",
      "Epoch  32 / iter   4, loss = 0.1937\n",
      "Epoch  33 / iter   0, loss = 0.2418\n",
      "Epoch  33 / iter   1, loss = 0.2335\n",
      "Epoch  33 / iter   2, loss = 0.2071\n",
      "Epoch  33 / iter   3, loss = 0.2823\n",
      "Epoch  33 / iter   4, loss = 0.4387\n",
      "Epoch  34 / iter   0, loss = 2.0128\n",
      "Epoch  34 / iter   1, loss = 1.9089\n",
      "Epoch  34 / iter   2, loss = 0.2224\n",
      "Epoch  34 / iter   3, loss = 0.2851\n",
      "Epoch  34 / iter   4, loss = 0.0316\n",
      "Epoch  35 / iter   0, loss = 0.5233\n",
      "Epoch  35 / iter   1, loss = 0.5525\n",
      "Epoch  35 / iter   2, loss = 0.7210\n",
      "Epoch  35 / iter   3, loss = 0.6251\n",
      "Epoch  35 / iter   4, loss = 0.2714\n",
      "Epoch  36 / iter   0, loss = 0.2217\n",
      "Epoch  36 / iter   1, loss = 0.2530\n",
      "Epoch  36 / iter   2, loss = 0.2853\n",
      "Epoch  36 / iter   3, loss = 0.1981\n",
      "Epoch  36 / iter   4, loss = 0.5296\n",
      "Epoch  37 / iter   0, loss = 0.5005\n",
      "Epoch  37 / iter   1, loss = 0.5620\n",
      "Epoch  37 / iter   2, loss = 0.2982\n",
      "Epoch  37 / iter   3, loss = 0.4116\n",
      "Epoch  37 / iter   4, loss = 0.4702\n",
      "Epoch  38 / iter   0, loss = 1.3423\n",
      "Epoch  38 / iter   1, loss = 1.4727\n",
      "Epoch  38 / iter   2, loss = 0.6438\n",
      "Epoch  38 / iter   3, loss = 0.6979\n",
      "Epoch  38 / iter   4, loss = 0.1468\n",
      "Epoch  39 / iter   0, loss = 0.2259\n",
      "Epoch  39 / iter   1, loss = 0.1997\n",
      "Epoch  39 / iter   2, loss = 0.1973\n",
      "Epoch  39 / iter   3, loss = 0.2264\n",
      "Epoch  39 / iter   4, loss = 0.1977\n",
      "Epoch  40 / iter   0, loss = 1.3738\n",
      "Epoch  40 / iter   1, loss = 2.4439\n",
      "Epoch  40 / iter   2, loss = 2.2723\n",
      "Epoch  40 / iter   3, loss = 0.1665\n",
      "Epoch  40 / iter   4, loss = 0.1642\n",
      "Epoch  41 / iter   0, loss = 0.1953\n",
      "Epoch  41 / iter   1, loss = 0.1277\n",
      "Epoch  41 / iter   2, loss = 0.1081\n",
      "Epoch  41 / iter   3, loss = 0.1449\n",
      "Epoch  41 / iter   4, loss = 0.3406\n",
      "Epoch  42 / iter   0, loss = 0.1514\n",
      "Epoch  42 / iter   1, loss = 0.1625\n",
      "Epoch  42 / iter   2, loss = 0.1971\n",
      "Epoch  42 / iter   3, loss = 0.1567\n",
      "Epoch  42 / iter   4, loss = 0.0964\n",
      "Epoch  43 / iter   0, loss = 0.1595\n",
      "Epoch  43 / iter   1, loss = 0.2165\n",
      "Epoch  43 / iter   2, loss = 0.2121\n",
      "Epoch  43 / iter   3, loss = 0.2546\n",
      "Epoch  43 / iter   4, loss = 0.1515\n",
      "Epoch  44 / iter   0, loss = 0.2807\n",
      "Epoch  44 / iter   1, loss = 0.2439\n",
      "Epoch  44 / iter   2, loss = 0.2413\n",
      "Epoch  44 / iter   3, loss = 0.5729\n",
      "Epoch  44 / iter   4, loss = 1.5338\n",
      "Epoch  45 / iter   0, loss = 8.5547\n",
      "Epoch  45 / iter   1, loss = 1.3322\n",
      "Epoch  45 / iter   2, loss = 3.9527\n",
      "Epoch  45 / iter   3, loss = 2.1427\n",
      "Epoch  45 / iter   4, loss = 0.0485\n",
      "Epoch  46 / iter   0, loss = 1.2858\n",
      "Epoch  46 / iter   1, loss = 0.8408\n",
      "Epoch  46 / iter   2, loss = 0.5767\n",
      "Epoch  46 / iter   3, loss = 0.3611\n",
      "Epoch  46 / iter   4, loss = 0.2392\n",
      "Epoch  47 / iter   0, loss = 0.5730\n",
      "Epoch  47 / iter   1, loss = 0.4093\n",
      "Epoch  47 / iter   2, loss = 0.3127\n",
      "Epoch  47 / iter   3, loss = 0.3123\n",
      "Epoch  47 / iter   4, loss = 0.0601\n",
      "Epoch  48 / iter   0, loss = 0.2633\n",
      "Epoch  48 / iter   1, loss = 0.3047\n",
      "Epoch  48 / iter   2, loss = 0.2556\n",
      "Epoch  48 / iter   3, loss = 0.2760\n",
      "Epoch  48 / iter   4, loss = 0.0667\n",
      "Epoch  49 / iter   0, loss = 0.1834\n",
      "Epoch  49 / iter   1, loss = 0.2148\n",
      "Epoch  49 / iter   2, loss = 0.2299\n",
      "Epoch  49 / iter   3, loss = 0.1789\n",
      "Epoch  49 / iter   4, loss = 0.2415\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获取数据\r\n",
    "train_data, test_data,min,max= load_data()\r\n",
    "\r\n",
    "# 创建网络\r\n",
    "net = Network(13)\r\n",
    "# 启动训练\r\n",
    "losses = net.train(train_data, num_epochs=50, batch_size=100, eta=0.1)\r\n",
    "\r\n",
    "# 画出损失函数的变化趋势\r\n",
    "plot_x = np.arange(len(losses))\r\n",
    "plot_y = np.array(losses)\r\n",
    "plt.plot(plot_x, plot_y)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "取倒数第十行数据测试实际值为 19.7 预测值为 [-2.82325999]\n"
     ]
    }
   ],
   "source": [
    "x=test_data[-10,-1]\r\n",
    "pred,pred1,pred2=net.forward(test_data[-10,:-1])\r\n",
    "repred=(pred*max)-(min*(pred-1))\r\n",
    "retest=(x*max)-(min*(x-1))\r\n",
    "print(\"取倒数第十行数据测试实际值为\",retest,\"预测值为\",repred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
