# -*- coding: utf-8 -*-
"""minist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16mDJAeGRe8Murwr7rBYYnk4Veeq3x0o3
"""

# Commented out IPython magic to ensure Python compatibility.
from torchvision import  transforms
from torchvision import  datasets
from torch.utils.data import Dataset,DataLoader
import torch.nn.functional as F
import torch.optim as optim
import torch
import torch.nn as nn
import time
import matplotlib.pyplot as plt
from matplotlib.pyplot import MultipleLocator
import numpy as np
import itertools
import pandas as pd
import seaborn as sns
# %matplotlib inline

# 残差神经网络 ResNet
class ResidualBlock(nn.Module):  # 保证卷积层输入输出通道数一样
    def __init__(self,channels):
        super(ResidualBlock,self).__init__()
        self.channels=channels
        self.conv1=nn.Conv2d(channels,channels,kernel_size=3,padding=1)
        self.conv2=nn.Conv2d(channels,channels,kernel_size=3,padding=1)
        
    def forward(self,x):
        y=F.relu(self.conv1(x))
        y=self.conv2(y)
        return F.relu(x+y)  # 先求和在激活
    

class Net(torch.nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        self.conv1=torch.nn.Conv2d(1,16,kernel_size=5)
        self.conv2=torch.nn.Conv2d(16,32,kernel_size=5)  
        self.mp=torch.nn.MaxPool2d(2)
        
        self.block1=ResidualBlock(16)
        self.block2=ResidualBlock(32)

        self.fc=nn.Linear(512,10)
        
    def forward(self,x):
        in_size=x.size(0)
        x=self.mp(F.relu(self.conv1(x)))
        x=self.block1(x)
        x=self.mp(F.relu(self.conv2(x)))
        x=self.block2(x)
        x=x.view(in_size,-1)
        x=self.fc(x)
        return x
    
def train(epoch,model,optimizer):
    running_loss=0.0
    for batch_idx,data in enumerate(train_loader,0):
        inputs,target = data
    # ----------------------------------------------------
    #  把运算转移到GPU上
        inputs,target = inputs.to(device),target.to(device)
    #----------------------------------------------------
        optimizer.zero_grad()
        
        outputs=model(inputs)
        loss=criterion(outputs,target)
        loss.backward()
        optimizer.step()
        
        running_loss+=loss.item()
        if batch_idx % 300 == 299:
#             print('{},{} loss:{}'.format(epoch+1,batch_idx+1,running_loss/300))
            if batch_idx==899: record_loss=running_loss/300
            running_loss=0.0
    return record_loss
            
def test(model,optimizer):
    correct=0
    total=0
    with torch.no_grad():
        for data in test_loader:
            images,labels = data
        # ----------------------------------------------------
        #  把运算转移到GPU上
            images,labels = images.to(device),labels.to(device)
        #----------------------------------------------------
            outputs=model(images)
            _,predicted=torch.max(outputs.data,dim=1)  # 返回的是 （每一行的最大值，该最大值的下标）
            total+=labels.size(0)  # 预测样本个数
            correct+=(predicted==labels).sum().item()  # 相等就是真，真就是1
    print('acc:',correct/total)
    return correct/total


def run(model,optimizer):  # 返回 测试集上准确率列表l1，每次epoch结束后在训练集上的loss组成的列表，作图用
    acc=[]
    loss=[]
    for epoch in range(100):
        loss.append(train(epoch,model,optimizer))
        acc.append(test(model,optimizer))
    print('测试集上准确率',acc)
    print('loss',loss)
    return acc,loss



    
if __name__=='__main__':

    batch_size=64
    trans1=transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,),(0.3081,))
    ])  
    # 神经网络希望input在(0,1)之间，transform的作用是将 PIL Image0~255 转化为tensor ∈ （0,1）
    # 同时通道作为第一维的特征
    #在做归一化，0.1307为均值，0.3081为标准差
    train_dataset=datasets.MNIST(root='../data',train=True,download=True,transform=trans1)
    test_dataset=datasets.MNIST(root='../data',train=False,download=True,transform=trans1)

    train_loader=DataLoader(train_dataset,shuffle=False,batch_size=batch_size)
    test_loader=DataLoader(test_dataset,shuffle=False,batch_size=batch_size)

    criterion=torch.nn.CrossEntropyLoss()
    
#----------------------------------------------------
# #  把运算转移到GPU上
#     device=torch.device('cuda:0'if torch.cuda.is_available() else "cpu")
#     model.to(device)
#----------------------------------------------------
    print("------------------SGDM--------------------")
    t0=time.process_time()
    model1=Net()
    device=torch.device('cuda:0'if torch.cuda.is_available() else "cpu")
    model1.to(device)
    optimizer1=optim.SGD(model1.parameters(),lr=0.01,momentum=0.5)
    sgd_acc,sgd_loss=run(model1,optimizer1)
    print('耗时为：'+str(time.process_time()-t0))
    print("------------------SGD--------------------")
    t1=time.process_time()
    model2=Net()
    device=torch.device('cuda:0'if torch.cuda.is_available() else "cpu")
    model2.to(device)
    optimizer2=optim.SGD(model2.parameters(),lr=0.01,momentum=0)
    sgdm_acc,sgdm_loss=run(model2,optimizer2)
    print('耗时为：'+str(time.process_time()-t1))
    print("------------------Adagrad--------------------")
    t2=time.process_time()
    model3=Net()
    device=torch.device('cuda:0'if torch.cuda.is_available() else "cpu")
    model3.to(device)
    optimizer3=optim.Adagrad(model3.parameters(),lr=0.01, lr_decay=0, weight_decay=0)
    adagrad_acc,adagrad_loss=run(model3,optimizer3)
    print('耗时为：'+str(time.process_time()-t2))
#     print("------------------Rprop--------------------")
#     t3=time.process_time()
#     model4=Net()
#     device=torch.device('cuda:0'if torch.cuda.is_available() else "cpu")
#     model4.to(device)
#     optimizer4=optim.Rprop(model4.parameters(), lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))
#     rms_acc,rms_loss=run(model4,optimizer4)
#     print('耗时为：'+str(time.process_time()-t3))
    print("------------------Adam--------------------")
    t4=time.process_time()
    model5=Net()
    device=torch.device('cuda:0'if torch.cuda.is_available() else "cpu")
    model5.to(device)
    optimizer5=optim.Adam(model5.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)
    adam_acc,adam_loss=run(model5,optimizer5)
    print('耗时为：'+str(time.process_time()-t4))



# 保存adam作为optimizer的Resnet模型
# 为了避免使用新版pytorch经常会遇到与旧版不同用法而导致的问题，采用以下方式储存与读取模型
torch.save({'state_dict': model5.state_dict()}, 'checkpoint.pth.tar')

# 读取
model_load = Net()
checkpoint = torch.load('checkpoint.pth.tar')
model_load.load_state_dict(checkpoint['state_dict'])

# 作不同优化器下loss图
x = list(int(i) for i in range(1,len(sgd_loss)+1))
print(x)
fig,ax = plt.subplots(figsize=(14,6))

ax.plot(x,sgd_loss,label='sgd')
ax.plot(x,sgdm_loss,label='sgdm')
ax.plot(x,adagrad_loss,label='adagrad')
ax.plot(x,adam_loss,label='adm')
# ax.plot(x,rms_loss,label='RMSProp')

ax.set_xlabel('epoch')
ax.set_ylabel('loss')
ax.set_title('loss')

x_major_locator=MultipleLocator(10)
ax.xaxis.set_major_locator(x_major_locator)

ax.legend()
plt.show()

# 作不同优化器下ACC 图形
x = list(int(i) for i in range(1,len(sgd_acc)+1))
print(x)
fig,ax = plt.subplots(figsize=(14,6))

ax.plot(x,sgd_acc,label='sgd')
ax.plot(x,sgdm_acc,label='sgdm')
ax.plot(x,adagrad_acc,label='adagrad')
ax.plot(x,adam_acc,label='adm')
# ax.plot(x,rms_acc,label='RMSProp')

ax.set_xlabel('epoch')
ax.set_ylabel('acc')
ax.set_title('acc')

x_major_locator=MultipleLocator(10)
ax.xaxis.set_major_locator(x_major_locator)

ax.legend()
plt.show()

# 下面几个函数是对结果进行评估的，只针对adam作为optimizer的Resnet模型
def get2list(model):
    # 返回预测结果的列表pre_l和真实标签列表lab_l
    l1=[]
    pre_l=[]
    
    l2=[] 
    lab_l=[]
    
    correct=0
    total=0
    with torch.no_grad():
        for data in test_loader:
            images,labels = data
        # ----------------------------------------------------
        #  把运算转移到GPU上
            images,labels = images.to(device),labels.to(device)
        #----------------------------------------------------
            outputs=model(images)
            
            _,predicted=torch.max(outputs.data,dim=1)  # 返回的是 （每一行的最大值，该最大值的下标）
            total+=labels.size(0)  # 预测样本个数
            correct+=(predicted==labels).sum().item()  # 相等就是真，真就是1
            
            l1.append(predicted.cpu().numpy().tolist()) 
            l2.append(labels.cpu().numpy().tolist())  
    for item in l1:
        for data in item:
            pre_l.append(data)
    for item in l2:
        for data in item:
            lab_l.append(data)
    return pre_l,lab_l

pre_l,lab_l=get2list(model5)  
print(pre_l[:10])  # 打印一下前十个预测值看一下

# 得到混淆矩阵
def return_confusion(pre_l,lab_l):
    confusion=np.array([0]*100).reshape(10,10)
    for i,j in zip(pre_l,lab_l):
        confusion[i][j]+=1
    
    print(confusion)
    return confusion
    
confusion=return_confusion(pre_l,lab_l)

# 混淆矩阵可视化
def plot_confusion_matrix(cm, classes, normalize=False, title='confusion matrix', cmap=plt.cm.Blues):
    
    plt.figure()
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)

    plt.axis("equal")

    ax = plt.gca()
    left, right = plt.xlim()
    ax.spines['left'].set_position(('data', left))
    ax.spines['right'].set_position(('data', right))
    for edge_i in ['top', 'bottom', 'right', 'left']:
        ax.spines[edge_i].set_edgecolor("white")
        

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        num = '{:.2f}'.format(cm[i, j]) if normalize else int(cm[i, j])
        plt.text(j, i, num,
                 verticalalignment='center',
                 horizontalalignment="center",
                 color="white" if num > thresh else "black")
    
    plt.ylabel('prediction')
    plt.xlabel('label')
    
    plt.tight_layout()
    plt.savefig('混淆矩阵热力图.png', transparent=True, dpi=800) 
    
    plt.show()


label = ["{}".format(i) for i in range(1, confusion.shape[0]+1)]
plot_confusion_matrix(confusion, label)

from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

def cal_indicators(pre_l,lab_l):

#     w_average=metrics.precision_score(lab_l, pre_l, average='micro')  # 微平均，精确率 两者都是precsion
#     h_average=metrics.precision_score(lab_l, pre_l, average='macro')  # 宏平均，精确率
#     acc=accuracy_score(lab_l, pre_l) #acc
#     recall=metrics.recall_score(lab_l, pre_l, average='micro')
#     f1=metrics.f1_score(lab_l, pre_l, average='weighted')
    
    target_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
    print(classification_report(lab_l, pre_l, target_names=target_names))
    # 分类报告：precision/recall/fi-score/均值/分类个数
    
cal_indicators(pre_l,lab_l)