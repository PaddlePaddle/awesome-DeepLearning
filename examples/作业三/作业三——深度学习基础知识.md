# <center>**作业三——深度学习基础知识**</center>

**<p align="right">王峰、闫雨泽、张森源</p>** 


---

层归一化
--------

深度神经网络的训练是具有高度的计算复杂性的。减少训练的时间成本的一种方法是对神经元的输入进行规范化处理进而加快网络的收敛速度。层规范化是在训练时和测试时对数据同时进行处理，通过对输入同一层的数据进行汇总，计算平均值和方差，来对每一层的输入数据做规范化处理。层规范化是基于批规范化进行优化得到的。相比较而言，批规范化是对一个神经元输入的数据以mini-batch为单位来进行汇总，计算平均值和方法，再用这个数据对每个训练样例的输入进行规整。层规范化在面对RNN等问题的时候效果更加优越，也不会受到mini-batch选值的影响。
###简介

深度神经网络的训练是具有高度的计算复杂性的。减少训练的时间成本的一种方法是对神经元的输入进行规范化处理进而加快网络的收敛速度。层规范化是在训练时和测试时对数据同时进行处理，通过对输入同一层的数据进行汇总，计算平均值和方差，来对每一层的输入数据做规范化处理。因此，计算出同一层中所有隐藏单元的层规范化的统计信息的公式如下所示：
![图1 层归一化公式](/images/p1.jpeg)
其中$h_t$表示隐层第t层的输出，$a_t^i$表示隐层第t层的第i个输入，b是偏置，g是在非线性激活函数之前对归一化激活进行缩放的增益参数。

层规范化是基于批规范化进行优化得到的。相比较而言，批规范化是对一个神经元输入的数据以mini-batch为单位来进行汇总，计算平均值和方法，再用这个数据对每个训练样例的输入进行规整。层规范化在面对RNN等问题的时候效果更加优越，也不会受到mini-batch选值的影响。对比图如下所示：
![图2 层归一化与批归一化](/images/p2.jpeg)

###训练过程
![图3 层归一化训练过程](/images/p3.png)

###发展历史

为了加快神经网模型的收敛速度，2015年，Ioffe S和Szegedy C提出了批规范化方法对神经网每一层的输入进行处理，获得了较为优越的效果，但这这种方法的性能受到mini-batch选值的影响，而且无法应用到RNN等神经网中。2016年，JimmyLeiBa,Hinton等人提出了层规范化的方法，不仅可以应用于RNN中，而且由于不再受到mini-batch选值的影响，算法性能得到了提升。2017年，提出了基于语言识别的动态批层范化算法。

|  年份   | 事件  | 相关论文/Reference |
|  ----  | ----  |  |
| 2015  | 提出了批规范化算法，来对网络每一层的输入进行规范化处理 |Ioffe S, Szegedy C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift[J]. 2015:448-456.|
| 2016  | Hinton针对批规范化存在的问题，提出了层规范化处理的方法 |  Ba J L, Kiros J R, Hinton G E. Layer Normalization[J]. 2016.  |
| 2017  | 提出了基于语言识别的动态批层范化算法 | Kim T, Song I, Bengio Y. Dynamic Layer Normalization for Adaptive Neural Acoustic Modeling in Speech Recognition[C]// INTERSPEECH. 2017:2411-2415.   |

###发展分析

瓶颈：相比较于批规范化，层规范化在速度上不占有优势。特别是在对CNN进行处理时，有实验证明，层规范化在面对ConvNet时，层规范化在效果和速度上都比批规范化效果差。

未来发展方向：为了提高深度学习算法在训练模型时的效率，基于对输入数据规范化的思路，构建效果更优良的规范化方法，是层规范化算法的未来发展。


可变形卷积
-----

###背景
在计算机视觉领域，同一物体在不同场景，角度中未知的几何变换是检测/识别的一大挑战，通常来说我们有两种做法:

(1)通过充足的数据增强，扩充足够多的样本去增强模型适应尺度变换的能力。

(2)设置一些针对几何变换不变的特征或者算法，比如SIFT和sliding windows。

两种方法都有缺陷，第一种方法因为样本的局限性显然模型的泛化能力比较低，无法泛化到一般场景中，第二种方法则因为手工设计的不变特征和算法对于过于复杂的变换是很难的而无法设计。所以作者提出了Deformable Conv（可变形卷积）和 Deformable Pooling（可变形池化）来解决这个问题。

###可变形卷积
可变形卷积顾名思义就是卷积的位置是可变形的，并非在传统的N × N的网格上做卷积，这样的好处就是更准确地提取到我们想要的特征（传统的卷积仅仅只能提取到矩形框的特征），通过一张图我们可以更直观地了解：
![图4](/images/p4.png)


在上面这张图里面，左边传统的卷积显然没有提取到完整绵羊的特征，而右边的可变形卷积则提取到了完整的不规则绵羊的特征。

那可变卷积实际上是怎么做的呢？其实就是在每一个卷积采样点加上了一个偏移量，如下图所示：
![图5](/images/p5.png)



(a) 所示的正常卷积规律的采样 9 个点（绿点），(b)(c)(d) 为可变形卷积，在正常的采样坐标上加上一个位移量（蓝色箭头），其中 (c)(d) 作为 (b) 的特殊情况，展示了可变形卷积可以作为尺度变换，比例变换和旋转变换等特殊情况。
我们先看普通的卷积，以3x3卷积为例对于每个输出y(p0)，都要从x上采样9个位置，这9个位置都在中心位置x(p0)向四周扩散，(-1,-1)代表x(p0)的左上角，(1,1)代表x(p0)的右下角。

$$R={(-1,-1),(-1,0),...,(0,1),(1,1)}$$
所以传统的卷积输出就是（其中就是网格中的n个点）：
$$y(p_0)=\sum_{p_n\in{R}}{w(p_n)}*x(p_0+p_n)$$
正如我们上面阐述的可变形卷积，他就是在传统的卷积操作上加入了一个偏移量，正是这个偏移量才让卷积变形为不规则的卷积，这里要注意这个偏移量可以是小数，所以下面的式子的特征值需要通过双线性插值的方法来计算：


$$y(p_0)=\sum_{p_n\in{R}}{w(p_n)}*x(p_0+p_n+\Delta{p_n})$$
偏移量的计算方法如下：
![图6](/images/p6.png)

对于输入的一张feature map，假设原来的卷积操作是3×3的，那么为了学习偏移量offset，我们定义另外一个3×3的卷积层（图中上面的那层），输出的维度其实就是原来feature map大小，channel数等于2N（分别表示x,y方向的偏移）。下面的可变形卷积可以看作先基于上面那部分生成的offset做了一个插值操作，然后再执行普通的卷积。

DCN v2
------

###背景
DCN v1听起来不错，但其实也有问题：我们的可变形卷积有可能引入了无用的上下文（区域）来干扰我们的特征提取，这显然会降低算法的表现。作者也做了一个实验进行对比说明：

![图7](/images/p7.png)
我们可以看到虽然DCN v1更能覆盖整个物体，但是同时也会引入一些无关的背景，这造成了干扰，所以作者提出了三个解决方法：
（1）More Deformable Conv Layers（使用更多的可变形卷积）。

（2）Modulated Deformable Modules（在DCNv1基础（添加offset）上添加每个采样点的权重）

（3）R-CNN Feature Mimicking（模拟R-CNN的feature）。

####1、使用更多的可变形卷积
在DCN v1中只在conv 5中使用了三个可变形卷积，在DCN v2中把conv3到conv5都换成了可变形卷积，提高算法对几何形变的建模能力。
![图8](/images/p8.png)
在DCNv1基础（添加offset）上添加每个采样点的权重
我们知道在DCN v1中的卷积是添加了一个offset$\Delta{P_n}$:
$$y(p_0)=\sum_{p_n\in{R}}{w(p_n)}*x(p_0+p_n+\Delta{p_n})$$
为了解决引入了一些无关区域的问题，在DCN v2中我们不只添加每一个采样点的偏移，还添加了一个权重系数，来区分我们引入的区域是否为我们感兴趣的区域，假如这个采样点的区域我们不感兴趣，则把权重学习为0即可：
$$y(p_0)=\sum_{k=1}^{K}{w_k}*x(p+p_k+\Delta{p_k})*\Delta{m_k}$$
总的来说，DCN v1中引入的offset是要寻找有效信息的区域位置，DCN v2中引入权重系数是要给找到的这个位置赋予权重，这两方面保证了有效信息的准确提取。
R-CNN Feature Mimicking
作者发现把R-CNN和Faster RCNN的classification score结合起来可以提升performance，说明R-CNN学到的focus在物体上的feature可以解决无关上下文的问题。但是增加额外的R-CNN会使inference速度变慢很多。DCNV2里的解决方法是把R-CNN当做teacher network，让DCN V2的ROIPooling之后的feature去模拟R-CNN的feature，类似知识蒸馏的做法，下面会具体展开：
![图9](/images/p9.png)
左边的网络为主网络（Faster RCNN），右边的网络为子网络（RCNN）。实现上大致是用主网络训练过程中得到的RoI去裁剪原图，然后将裁剪到的图resize到224×224大小作为子网络的输入，这部分最后提取的特征和主网络输出的1024维特征作为feature mimicking loss的输入，用来约束这2个特征的差异（通过一个余弦相似度计算，如下图所示），同时子网络通过一个分类损失进行监督学习，因为并不需要回归坐标，所以没有回归损失。在inference阶段仅有主网络部分，因此这个操作不会在inference阶段增加计算成本。
$$L_{mimic}=\sum_{b\in{\Omega}}[1-cos(f_{RCNN}(b),f_{FRCNN}(b))]$$
再用直白一点的话说，因为RCNN这个子网络的输入就是RoI在原输入图像上裁剪出来的图像，因此不存在RoI以外区域信息的干扰，这就使得RCNN这个网络训练得到的分类结果更加可靠，以此通过一个损失函数监督主网络Faster RCNN的分类支路训练就能够使网络提取到更多RoI内部特征，而不是自己引入的外部特征。

总的loss由三部分组成：mimic loss + R-CNN classification loss + Faster-RCNN loss.



