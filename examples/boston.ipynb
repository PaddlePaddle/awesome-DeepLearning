####python+numpy

import numpy as np
import matplotlib.pyplot as plt
'''
项目介绍：
    此项目是使用numpy搭建神经网络模型，预测波士顿房价。
数据介绍：
    每一条房屋数据有14个值，前13个值是房屋属性，比如面积，长度等，最后一个是房屋价格,共506条数据。
模型介绍：
    在combat1.py文件二层神经网络模型的基础上，此文件将搭建三层神经网络，其中包含输入层(13)、隐藏层(13)、输出层(1)
'''
#数据导入以及处理
def deal_data():
    #读取文件数据，此时数据形状是(7084,)，即所有数据在一行中
    housingdata = np.fromfile('data/housing.data',sep=' ')

    #修改数据格式，将每一条房屋数据放在一行中。
    housingdata = np.array(housingdata).reshape((-1,14))#此时数据形状为(506,14)

    #对数据的前13个属性进行归一化操作，有助于提高模型精准度，这里使用max-min归一化方式。公式为(x-min)/(max-min)
    for i in range(13):
        Max =  np.max(housingdata[:,i])
        Min = np.min(housingdata[:,i])
        housingdata[:,i]=(housingdata[:,i]-Min)/(Max-Min)

    #依据2-8原则，80%的数据作为训练数据，20%数据作为测试数据；此时训练数据是405条，测试数据是101条
    Splitdata = round(len(housingdata)*0.8)
    Train = housingdata[:Splitdata]#训练数据集
    Test = housingdata[Splitdata:]#测试数据集
    return Train,Test

#模型设计以及配置
#首先确定有13个权值参数w，并随机初始化
class Model_Config(object):
    def __init__(self,firstnetnum,secondnetnum):
        np.random.seed(1)
        self.w0 = np.random.randn(firstnetnum*secondnetnum,1).reshape(firstnetnum,secondnetnum)
        self.w1 = np.random.randn(secondnetnum,1)
        self.b0 = np.random.randn(firstnetnum,1).reshape(1,firstnetnum)
        self.b1 = np.random.randn(1,1)
     #计算预测值
    def forward(self,x):
        hidden1 = np.dot(x,self.w0)+self.b0
        y = np.dot(hidden1,self.w1)+self.b1
        return hidden1,y
    #设置损失函数,这里使用差平方损失函数计算方式
    def loss(self,z,y):
        error = z-y
        cost = error*error
        avg_cost = np.mean(cost)
        return avg_cost
    #计算梯度
    def back(self,x,y):
        hidden1,z = self.forward(x)
        #hidden层的梯度
        gradient_w1 = (z-y)*hidden1
        gradient_w1 = np.mean(gradient_w1,axis=0)#这里注意，axis=0必须写上，否则默认将这个数组变成一维的求平均
        gradient_w1 = gradient_w1[:,np.newaxis]#
        gradient_b1 = (z-y)
        gradient_b1 = np.mean(gradient_b1)
        gradient_w0 = np.zeros(shape=(13,13))
        for i in range(len(x)):
            data = x[i,:]
            data = data[:,np.newaxis]
            # print("data.shape",data.shape)
            w1 = self.w1.reshape(1,13)
            # print("self.w1.shape",w1.shape)
            gradient_w01 = (z-y)[i]*np.dot(data,w1)
            # print("gradient_w01.shape:",gradient_w01.shape)
            gradient_w0+=gradient_w01
        gradient_w0 = gradient_w0/len(x)
        w2 = self.w1.reshape(1,13)
        gradient_b0 =np.mean((z-y)*w2,axis=0)

        return gradient_w1,gradient_b1,gradient_w0,gradient_b0
        #输入层的梯度
        #(z-y)x*self.w1
        # gradient_w0 = np.zeros(shape=(13,13))
        # gradient_w01 = gradient_w1.reshape(1,13)
        # for i in range(13):
        #     data = x[:,i]
        #     data = data[:,np.newaxis]
        #     gradient = data*gradient_w01
        #     gradient = np.mean(gradient,axis=0)
        #     gradient_w0[i,:] = gradient
        # gradient_b0 = gradient_b1*self.b0
        # return gradient_w1,gradient_b1,gradient_w0,gradient_b0

    #使用梯度更新权值参数w
    def update(self,gradient_w1,gradient_b1,gradient_w0,gradient_b0,learning_rate):
        self.w1 = self.w1-learning_rate*gradient_w1
        self.b1 = self.b1-learning_rate*gradient_b1
        self.w0 = self.w0-learning_rate*gradient_w0
        self.b0 = self.b0-learning_rate*gradient_b0

    #开始训练
    def train(self,epoch_num,x,y,learning_rate):
        #循环迭代
        losses=[]
        for i in range(epoch_num):
            _,z = self.forward(x)
            avg_loss = self.loss(z,y)
            gradient_w1,gradient_b1,gradient_w0,gradient_b0 = self.back(x,y)
            self.update(gradient_w1,gradient_b1,gradient_w0,gradient_b0,learning_rate)
            losses.append(avg_loss)
            #每进行20此迭代，显示一下当前的损失值
            if(i%20==0):
                print("iter:{},loss:{}".format(i,avg_loss))

        return losses
def showpeocess(loss,epoch_num):
    plt.title("The Process Of Train")
    plt.plot([i for i in range(epoch_num)],loss)
    plt.xlabel("epoch_num")
    plt.ylabel("loss")
    plt.show()
if __name__ == '__main__':
    Train,Test = deal_data()
    np.random.shuffle(Train)
    #只获取前13个属性的数据
    x = Train[:,:-1]
    y = Train[:,-1:]
    epoch_num = 1000#设置迭代次数
    Model = Model_Config(13,13)
    losses = Model.train(epoch_num=epoch_num,x=x,y=y,learning_rate=0.001)
    showpeocess(loss=losses,epoch_num=epoch_num)

############



###paddlepaddle
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 第一阶段：训练阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 - 引用库\r\n",
    "\r\n",
    "首先载入需要用到的库，它们分别是：\r\n",
    "\r\n",
    "- > paddle.fluid：引入PaddlePaddle深度学习框架的fluid版本库；  \r\n",
    "- > numpy：NumPy是Python语言的一个扩展程序库。支持高端大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。NumPy的核心功能是\"ndarray\"(即n-dimensional array，多维数组)数据结构。\r\n",
    "- > os: python的模块，可使用该模块对操作系统、目录、文件等进行操作\r\n",
    "- > matplotlib.pyplot：用于生成图，在验证模型准确率和展示成本变化趋势时会使用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-09 19:44:06,198-INFO: font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2021-07-09 19:44:06,607-INFO: generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 - 数据集介绍\r\n",
    "\r\n",
    "\r\n",
    "- > 本次所用数据集已经集成在paddle.dataset中了，并且已经为我们拆分成了训练集和测试集；我们可以通过调用paddle.dataset.uci_housing.train()和paddle.dataset.uci_housing.test()两个接口来获取训练集和测试集，非常的方便。\r\n",
    "\r\n",
    "- > 数据集共506行,每行14列。前13列用来描述房屋的各种信息，最后一列为该类房屋价格中位数。\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3 - 数据提供器\r\n",
    "\r\n",
    "- > 接下来我们通过paddle.batch这个接口，来定义数据提供器：train_reader和test_reader。分别向我们的网络提供训练数据和测试数据。\r\n",
    "- > 提供器每次读入一个大小为BATCH_SIZE的数据批次。如果用户希望加一些随机性，它可以同时定义一个批次大小和一个缓存大小。这样的话，每次数据提供器会从缓存中随机读取批次大小那么多的数据。我们都可以通过batch_size进行设置，这个大小一般是2的N次方。\r\n",
    "\r\n",
    "**关于参数的解释如下：**\r\n",
    "\r\n",
    "- paddle.reader.shuffle(train(), buf_size=500)表示trainer从train()这个reader中读取了buf_size=500大小的数据并打乱顺序\r\n",
    "- paddle.batch(reader(), batch_size=BATCH_SIZE)表示从打乱的数据中再取出BATCH_SIZE=20大小的数据进行一次迭代训练\r\n",
    "\r\n",
    "如果buf_size设置的数值大于数据集本身，就直接把整个数据集打乱顺序；如果buf_size设置的数值小于数据集本身，就按照buf_size的大小打乱顺序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/uci_housing/housing.data not found, downloading http://paddlemodels.bj.bcebos.com/uci_housing/housing.data \n",
      "Begin to download\n",
      "............\n",
      "Download finished\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/dataset/uci_housing.py:49: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2859, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 314, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "BUF_SIZE=500\r\n",
    "BATCH_SIZE=20\r\n",
    "\r\n",
    "#用于训练的数据提供器，每次从缓存中随机读取批次大小的数据\r\n",
    "train_reader = paddle.batch(\r\n",
    "    paddle.reader.shuffle(paddle.dataset.uci_housing.train(), buf_size=BUF_SIZE), batch_size=BATCH_SIZE)   \r\n",
    "\r\n",
    "\r\n",
    "#用于测试的数据提供器，每次从缓存中随机读取批次大小的数据\r\n",
    "test_reader = paddle.batch(\r\n",
    "    paddle.reader.shuffle(paddle.dataset.uci_housing.test(),buf_size=BUF_SIZE),batch_size=BATCH_SIZE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4 - 配置网络结构和设置参数\n",
    "\n",
    "\n",
    "**配置网络结构:**\n",
    "\n",
    "\n",
    "线性回归的模型其实就是一个采用线性激活函数（linear activation）的全连接层（fully-connected layer，fc_layer），因此在Peddlepeddle中利用全连接层模型构造线性回归，这样一个全连接层就可以看做是一个简单的神经网络，只包含输入层和输出层即可。本次的模型由于只有一个影响参数，因此输入只含一个$X_0$。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e62e0567d83f47ac895db06cff5eefb8a995cf50e3b942a19d0d722f53aae77d)\n",
    "\n",
    "接下来就让我们利用PaddlePaddle提供的接口，搭建我们自己的网络吧！\n",
    "\n",
    "**输入层:**  \n",
    "我们可以用 x = fluid.layers.data(name='x', shape=[13], dtype='float32')来表示数据的一个输入层，其中name属性的名称为\"x\"，数据的shape为13维向量，这是因为本次所用的房价数据集的每条数据有13个属性，所以shape=13。\n",
    "\n",
    "\n",
    "\n",
    "**输出层:**  \n",
    "用y_predict = fluid.layers.fc(input=x, size=1, act=None)来表示输出层：其中paddle.layer.fc表示全连接层，input=x表示该层输入数据为x，size=1表示该层有一个神经元，在Fluid版本中使用的激活函数不再是调用一个函数了，而是传入一个字符串就可以，比如：act='relu'就表示使用relu激活函数。act=None表示激活函数为线性激活函数。\n",
    "\n",
    "\n",
    "**标签层:**\n",
    "\n",
    "用y = fluid.layers.data(name='y', shape=[1], dtype='float32')来表示标签数据，名称为y，有时我们名称不用y而用label。数据类型为一维向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义张量变量x，表示13维的特征值\r\n",
    "x = fluid.layers.data(name='x', shape=[13], dtype='float32')\r\n",
    "#定义张量y,表示目标值\r\n",
    "y = fluid.layers.data(name='y', shape=[1], dtype='float32')\r\n",
    "#定义一个简单的线性网络,连接输入和输出的全连接层\r\n",
    "#input:输入tensor;\r\n",
    "#size:该层输出单元的数目\r\n",
    "#act:激活函数\r\n",
    "y_predict=fluid.layers.fc(input=x,size=1,act=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5 - 定义损失函数 \r\n",
    "\r\n",
    "PaddlePaddle提供了很多的损失函数的接口，比如交叉熵损失函数(cross_entropy)。因为本项目是一个线性回归任务，所以我们使用的是均方差损失函数。可以调用fluid.layers.square_error_cost(input= ,laybel= )实现方差计算。因为fluid.layers.square_error_cost(input= ,laybel= )求的是一个Batch的损失值，所以我们还要通过调用fluid.layers.mean(loss)对方差求平均。\r\n",
    "\r\n",
    "将输入定义为 **房价预测值**，label定义为 **标签数据**。进而计算损失值。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = fluid.layers.square_error_cost(input=y_predict, label=y) #求一个batch的损失值\r\n",
    "avg_cost = fluid.layers.mean(cost)                              #对损失值求平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6 - 优化方法 \r\n",
    "\r\n",
    "损失函数定义确定后，需要定义参数优化方法。为了改善模型的训练速度以及效果，学术界先后提出了很多优化算法，包括： Momentum、RMSProp、Adam 等，已经被封装在fluid内部，读者可直接调用。本次可以用 fluid.optimizer.SGD(learning_rate= ) 使用随机梯度下降的方法优化，其中learning_rate表示学习率，大家可以自己尝试修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.001)\r\n",
    "opts = optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- > fluid有两个program，一个是default_main_program，一个是default_startup_program;\r\n",
    "- > fluid.default_main_program()用于获取默认或全局main program(主程序)。该主程序用于训练和测试模型。fluid.layers 中的所有layer函数可以向 default_main_program 中添加算子和变量。\r\n",
    "- > 参数初始化操作会被写入fluid.default_startup_program();\r\n",
    "- > 使用fluid.default_main_program().clone(for_test=True)语句，我们可以克隆一个default_main_program，以备将来测试时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_program = fluid.default_main_program().clone(for_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 7 - 设置训练场所+创建执行器+参数初始化\r\n",
    "\r\n",
    "**设置训练场所：**  \r\n",
    "首先进行设置训练使用的设备。也就是选择是在CPU上进行训练，还是在GPU上进行训练。在复杂量较低的时候使用 CPU 就可以完成任务，但是对于大规模计算就需要使用 GPU 训练。目前 GPU 训练都是基于 CUDA 工具之上的。\r\n",
    "\r\n",
    "代码实现也很简单，我们使用两行代码就可以实现，如下面所示：  \r\n",
    "\r\n",
    "- use_cuda=False 表示不使用 GPU 进行训练\r\n",
    "\r\n",
    "**创建执行器：**  \r\n",
    "为了能够运行开发者定义的网络拓扑结构和优化器，需要定义执行器。由执行器来真正的执行参数的初始化和网络的训练过程。fulid使用了一个C++类Executor用于运行一个程序，Executor类似一个解释器，Fluid将会使用这样一个解析器来训练和测试模型。\r\n",
    "\r\n",
    "之后我们run一下，初始化执行器；\r\n",
    "用户配置完模型后，参数初始化操作会被写入到 fluid.default_startup_program() 中。\r\n",
    "使用 fluid.Executor() 运行 这一程序，即可在全局中随机初始化参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "#使用CPU训练\r\n",
    "use_cuda = True\r\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace() \r\n",
    "\r\n",
    "exe = fluid.Executor(place)              #创建一个Executor实例exe\r\n",
    "exe.run(fluid.default_startup_program()) #Executor的run()方法执行startup_program(),进行参数初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "接下来定义映射  \r\n",
    "\r\n",
    "输入网络的数据要与网络本身应该接受的数据相匹配。在paddle的 fluid 中使用 feed_list 的概念来保证输入的数据与网络接受的数据的顺序是一致的。本示例中使用 feed_list = [x,y] 来告知网络，输入的数据是分为两部分，第一部分是 x 值，第二部分是 label 值。\r\n",
    "\r\n",
    "映射完之后，创建 DataFeeder 对象，在训练的时候，用户可调用其 feeder.feed(iterable) 方法将用户传入的iterable 数据转换为 LoDTensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义feeder \r\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[x, y])#feed_list:向模型输入的变量名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "为了便于观察训练过程，我们可以定义一个绘制函数，用来把“训练过程的损失值变化趋势”实时的展示出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iter=0;\r\n",
    "iters=[]\r\n",
    "train_costs=[]\r\n",
    "\r\n",
    "def plot_train_cost(iters,train_costs):\r\n",
    "    title=\"training cost\"\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    plt.xlabel(\"iter\", fontsize=14)\r\n",
    "    plt.ylabel(\"cost\", fontsize=14)\r\n",
    "    plt.plot(iters, train_costs,color='blue',label='training cost') \r\n",
    "    plt.grid()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 8 - 开始训练\r\n",
    "- > 接下来我们就是用双层循环，来进行训练；\r\n",
    "- > 在训练之前还要定义一个模型保存路径，用来保存我们训练好的模型；\r\n",
    "- > 我们还要定义一个变量，来规定训练的总epoch；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPOCH_NUM=100\r\n",
    "model_save_dir = \"/home/aistudio/data/model_save_dir/inference.model\"\r\n",
    "\r\n",
    "for pass_id in range(EPOCH_NUM):                                  #训练EPOCH_NUM轮\r\n",
    "    # 开始训练并输出最后一个batch的损失值\r\n",
    "    train_cost = 0\r\n",
    "    for batch_id, data in enumerate(train_reader()):              #遍历train_reader迭代器\r\n",
    "        train_cost = exe.run(program=fluid.default_main_program(),#运行主程序\r\n",
    "                             feed=feeder.feed(data),              #喂入一个batch的训练数据，根据feed_list和data提供的信息，将输入数据转成一种特殊的数据结构\r\n",
    "                             fetch_list=[avg_cost])     \r\n",
    "        #print(\"Pass:%d, Cost:%0.5f\" % (pass_id, train_cost[0][0]))    #打印最后一个batch的损失值\r\n",
    "        iter=iter+BATCH_SIZE\r\n",
    "        iters.append(iter)\r\n",
    "        train_costs.append(train_cost[0][0])\r\n",
    "\r\n",
    "   \r\n",
    "    # 开始测试并输出最后一个batch的损失值\r\n",
    "    test_cost = 0\r\n",
    "    for batch_id, data in enumerate(test_reader()):               #遍历test_reader迭代器\r\n",
    "        test_cost= exe.run(program=test_program, #运行测试cheng\r\n",
    "                            feed=feeder.feed(data),               #喂入一个batch的测试数据\r\n",
    "                            fetch_list=[avg_cost])                #fetch均方误差\r\n",
    "    print('Test:%d, Cost:%0.5f' % (pass_id, test_cost[0][0]))     #打印最后一个batch的损失值\r\n",
    "    \r\n",
    "    #保存模型\r\n",
    "    # 如果保存路径不存在就创建\r\n",
    "    if not os.path.exists(model_save_dir):\r\n",
    "        os.makedirs(model_save_dir)\r\n",
    "    print ('save models to %s' % (model_save_dir))\r\n",
    "    #保存训练参数到指定路径中，构建一个专门用预测的program\r\n",
    "    fluid.io.save_inference_model(model_save_dir,   #保存推理model的路径\r\n",
    "                                  ['x'],            #推理（inference）需要 feed 的数据\r\n",
    "                                  [y_predict],      #保存推理（inference）结果的 Variables\r\n",
    "                                  exe)              #exe 保存 inference model\r\n",
    "plot_train_cost(iters,train_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 第二阶段： 预测阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "我们同样可以定义一个画图的函数，把我们的预测结果展示出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#先定两个list，用来存放预测结果、真实值；\r\n",
    "infer_results=[]\r\n",
    "groud_truths=[]\r\n",
    "\r\n",
    "#绘制真实值和预测值对比图\r\n",
    "def plot_infer_result(groud_truths,infer_results):\r\n",
    "    title='Boston'\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    x = np.arange(1,20) \r\n",
    "    y = x\r\n",
    "    plt.plot(x, y)\r\n",
    "    plt.xlabel('ground truth', fontsize=14)\r\n",
    "    plt.ylabel('infer result', fontsize=14)\r\n",
    "    plt.scatter(groud_truths, infer_results,color='red',label='training cost') \r\n",
    "    plt.grid()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "\r\n",
    "#预测之前，我们需要创建预测用的Executor\r\n",
    "infer_exe = fluid.Executor(place)    #创建推测用的executor\r\n",
    "inference_scope = fluid.core.Scope() #Scope指定作用域\r\n",
    "\r\n",
    "with fluid.scope_guard(inference_scope):#修改全局/默认作用域（scope）, 运行时的所有变量都将分配给新的scope。\r\n",
    "    #从指定目录中加载 预测用的model(inference model)\r\n",
    "    [inference_program,                             #推理的program\r\n",
    "     feed_target_names,                             #需要在推理program中提供数据的变量名称\r\n",
    "     fetch_targets] = fluid.io.load_inference_model(#fetch_targets: 推断结果\r\n",
    "                                    model_save_dir, #model_save_dir:模型训练路径 \r\n",
    "                                    infer_exe)      #infer_exe: 预测用executor\r\n",
    "    #获取预测数据\r\n",
    "    infer_reader = paddle.batch(paddle.dataset.uci_housing.test(),  #获取uci_housing的测试数据\r\n",
    "                          batch_size=200)                           #从测试数据中读取一个大小为10的batch数据\r\n",
    "    #从test_reader中分割x和label\r\n",
    "    test_data = next(infer_reader())\r\n",
    "    test_x = np.array([data[0] for data in test_data]).astype(\"float32\") # 提取测试集中的x\r\n",
    "    test_y= np.array([data[1] for data in test_data]).astype(\"float32\")  # 提取测试集中的label\r\n",
    "    results = infer_exe.run(inference_program,                              #预测模型\r\n",
    "                            feed={feed_target_names[0]: np.array(test_x)},  #喂入要预测的x值\r\n",
    "                            fetch_list=fetch_targets)                       #得到推测结果 \r\n",
    "                            \r\n",
    "    print(\"infer results: (House Price)\")\r\n",
    "    for idx, val in enumerate(results[0]):\r\n",
    "        print(\"%d: %.2f\" % (idx, val))\r\n",
    "        infer_results.append(val)\r\n",
    "    print(\"ground truth:\")\r\n",
    "    for idx, val in enumerate(test_y):\r\n",
    "        print(\"%d: %.2f\" % (idx, val))\r\n",
    "        groud_truths.append(val)\r\n",
    "    plot_infer_result(groud_truths,infer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\r\n",
    "\r\n",
    "至此线性回归模型的训练和预测工作完成，希望通过本次课程的学习，让您初步了解PaddlePaddle这一易学易用的分布式深度学习框架平台，以及熟悉aistudio的使用；\r\n",
    "本节课作为PaddlePaddle的快速入门章节，希望可以开启您的下一步深度学习之门。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
