{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# SENet模型分类眼疾识别数据集\n",
    "### 数据集准备\n",
    "\n",
    "/home/aistudio/data/data19065 目录包括如下三个文件，解压缩后存放在/home/aistudio/data/palm目录下。\n",
    "- training.zip：包含训练中的图片和标签\n",
    "- validation.zip：包含验证集的图片\n",
    "- valid_gt.zip：包含验证集的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data/palm/PALM-Training400\n"
     ]
    }
   ],
   "source": [
    "!unzip -o -q -d /home/aistudio/data/palm /home/aistudio/data/data19469/training.zip\r\n",
    "%cd /home/aistudio/data/palm/PALM-Training400/\r\n",
    "!unzip -o -q PALM-Training400.zip\r\n",
    "!unzip -o -q -d /home/aistudio/data/palm /home/aistudio/data/data19469/validation.zip\r\n",
    "!unzip -o -q -d /home/aistudio/data/palm /home/aistudio/data/data19469/valid_gt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义数据读取器\n",
    "\n",
    "使用OpenCV从磁盘读入图片，将每张图缩放到$224\\times224$大小，并且将像素值调整到$[-1, 1]$之间，代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\r\n",
    "import os\r\n",
    "import random\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import numpy as np\r\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\r\n",
    "from paddle.fluid.dygraph.base import to_variable\r\n",
    "\r\n",
    "DATADIR = '/home/aistudio/data/palm/PALM-Training400/PALM-Training400'\r\n",
    "DATADIR2 = '/home/aistudio/data/palm/PALM-Validation400'\r\n",
    "CSVFILE = '/home/aistudio/labels.csv'\r\n",
    "\r\n",
    "def transform_img(img):\r\n",
    "    img = cv2.resize(img, (224, 224))\r\n",
    "    img = np.transpose(img, (2,0,1))\r\n",
    "    img = img.astype('float32')\r\n",
    "    img = img / 255.\r\n",
    "    img = img * 2.0 - 1.0\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def data_loader(datadir, batch_size=10, mode = 'train'):\r\n",
    "    filenames = os.listdir(datadir)\r\n",
    "    def reader():\r\n",
    "        if mode == 'train':\r\n",
    "            random.shuffle(filenames)\r\n",
    "        batch_imgs = []\r\n",
    "        batch_labels = []\r\n",
    "        for name in filenames:\r\n",
    "            filepath = os.path.join(datadir, name)\r\n",
    "            img = cv2.imread(filepath)\r\n",
    "            img = transform_img(img)\r\n",
    "            if name[0] == 'H' or name[0] == 'N':\r\n",
    "                label = 0\r\n",
    "            elif name[0] == 'P':\r\n",
    "                label = 1\r\n",
    "            else:\r\n",
    "                raise('Not excepted file name')\r\n",
    "            batch_imgs.append(img)\r\n",
    "            batch_labels.append(label)\r\n",
    "            if len(batch_imgs) == batch_size:\r\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "                yield imgs_array, labels_array\r\n",
    "                batch_imgs = []\r\n",
    "                batch_labels = []\r\n",
    "\r\n",
    "        if len(batch_imgs) > 0:\r\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "            yield imgs_array, labels_array\r\n",
    "\r\n",
    "    return reader\r\n",
    "\r\n",
    "def valid_data_loader(datadir, csvfile, batch_size=10, mode='valid'):\r\n",
    "    filelists = open(csvfile).readlines()\r\n",
    "    def reader():\r\n",
    "        batch_imgs = []\r\n",
    "        batch_labels = []\r\n",
    "        for line in filelists[1:]:\r\n",
    "            line = line.strip().split(',')\r\n",
    "            name = line[1]\r\n",
    "            label = int(line[2])\r\n",
    "            filepath = os.path.join(datadir, name)\r\n",
    "            img = cv2.imread(filepath)\r\n",
    "            img = transform_img(img)\r\n",
    "            batch_imgs.append(img)\r\n",
    "            batch_labels.append(label)\r\n",
    "            if len(batch_imgs) == batch_size:\r\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "                yield imgs_array, labels_array\r\n",
    "                batch_imgs = []\r\n",
    "                batch_labels = []\r\n",
    "\r\n",
    "        if len(batch_imgs) > 0:\r\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\r\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\r\n",
    "            yield imgs_array, labels_array\r\n",
    "\r\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SENet网络模型\n",
    "\n",
    "在深度学习领域，CNN分类网络的发展对其它计算机视觉任务如目标检测和语义分割都起到至关重要的作用，因为检测和分割模型通常是构建在CNN分类网络（称为backbone）之上。提到CNN分类网络，我们所熟知的是VGG，ResNet，Inception，DenseNet等模型，它们的效果已经被充分验证，而且被广泛应用在各类计算机视觉任务上。这里我们使用的是SENet模型，它赢得了最后一届ImageNet 2017竞赛分类任务的冠军。重要的一点是SENet思路很简单，很容易扩展在已有网络结构中。\n",
    "\n",
    "SENet的基本结构如图\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/86433f577c784c15b98560a7d5dad101b300b923331b497a9458fdedfa7e48f3)\n",
    "\n",
    "原来的任意变换，将输入X变为输出U，现在，假设输出的U不是最优的，每个通道的重要程度不同，有的通道更有用，有的通道则不太有用。\n",
    "\n",
    "对于每一输出通道，先global average pool，每个通道得到1个标量，C个通道得到C个数，然后经过FC-ReLU-FC-Sigmoid得到C个0到1之间的标量，作为通道的权重，然后原来的输出通道每个通道用对应的权重进行加权（对应通道的每个元素与权重分别相乘），得到新的加权后的特征，作者称之为feature recalibration。\n",
    "\n",
    "第一步每个通道HxW个数全局平均池化得到一个标量，称之为Squeeze，然后两个FC得到01之间的一个权重值，对原始的每个HxW的每个元素乘以对应通道的权重，得到新的feature map，称之为Excitation。任意的原始网络结构，都可以通过这个Squeeze-Excitation的方式进行feature recalibration，采用了改方式的网络，即SENet版本。\n",
    "\n",
    "在Inception和ResNet模块上使用了se模块\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4b6a886cb54e4a75b19c674088401e94409eaa278d0b4feca7b25496d3842ef7)\n",
    "\n",
    "上述的se模块的顺序是global average pooling-FC-ReLU-FC-Sigmoid过程。r是中间隐藏状态特征的维度，在后面也就是了调参实验。最后用了Sigmoid函数确保了权重大小在(0,1)之间。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear, AvgPool2D\r\n",
    "import paddle.nn.functional as F\r\n",
    "import paddle.nn as nn\r\n",
    "import math\r\n",
    "\r\n",
    "class BasicBlock(nn.Layer):\r\n",
    "    def __init__(self, in_planes, planes, stride=1):\r\n",
    "        super(BasicBlock, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2D(in_planes, planes, kernel_size=3, stride=stride, padding=1)\r\n",
    "        self.bn1 = nn.BatchNorm2D(planes)\r\n",
    "        self.conv2 = nn.Conv2D(planes, planes, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn2 = nn.BatchNorm2D(planes)\r\n",
    "\r\n",
    "        self.shortcut = nn.Sequential()\r\n",
    "        if stride != 1 or in_planes != planes:\r\n",
    "            self.shortcut = nn.Sequential(\r\n",
    "                nn.Conv2D(in_planes, planes, kernel_size=1, stride=stride),\r\n",
    "                nn.BatchNorm2D(planes)\r\n",
    "            )\r\n",
    "\r\n",
    "        # SE layers\r\n",
    "        self.fc1 = nn.Conv2D(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\r\n",
    "        self.fc2 = nn.Conv2D(planes//16, planes, kernel_size=1)\r\n",
    "        \r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
    "        out = self.bn2(self.conv2(out))\r\n",
    "\r\n",
    "        # Squeeze\r\n",
    "        aa = out.shape[2]\r\n",
    "        w = F.avg_pool2d(out, aa)\r\n",
    "        w = F.relu(self.fc1(w))\r\n",
    "        w = F.sigmoid(self.fc2(w))\r\n",
    "        # Excitation\r\n",
    "        out = out * w  # New broadcasting feature from v0.2!\r\n",
    "\r\n",
    "        out += self.shortcut(x)\r\n",
    "        out = F.relu(out)\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class PreActBlock(nn.Layer):\r\n",
    "    def __init__(self, in_planes, planes, stride=1):\r\n",
    "        super(PreActBlock, self).__init__()\r\n",
    "        self.bn1 = nn.BatchNorm2D(in_planes)\r\n",
    "        self.conv1 = nn.Conv2D(in_planes, planes, kernel_size=3, stride=stride, padding=1)\r\n",
    "        self.bn2 = nn.BatchNorm2D(planes)\r\n",
    "        self.conv2 = nn.Conv2D(planes, planes, kernel_size=3, stride=1, padding=1)\r\n",
    "\r\n",
    "        if stride != 1 or in_planes != planes:\r\n",
    "            self.shortcut = nn.Sequential(\r\n",
    "                nn.Conv2D(in_planes, planes, kernel_size=1, stride=stride)\r\n",
    "            )\r\n",
    "\r\n",
    "        # SE layers\r\n",
    "        self.fc1 = nn.Conv2D(planes, planes//16, kernel_size=1)\r\n",
    "        self.fc2 = nn.Conv2D(planes//16, planes, kernel_size=1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = F.relu(self.bn1(x))\r\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\r\n",
    "        out = self.conv1(out)\r\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\r\n",
    "\r\n",
    "        # Squeeze\r\n",
    "        \r\n",
    "        aa = out.shape[2]\r\n",
    "        w = F.avg_pool2d(out, aa)\r\n",
    "        w = self.fc1(w)\r\n",
    "        w = F.relu(w)\r\n",
    "        w = F.sigmoid(self.fc2(w))\r\n",
    "        # Excitation\r\n",
    "        out = out * w\r\n",
    "\r\n",
    "        out += shortcut\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class SENet(nn.Layer):\r\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\r\n",
    "        super(SENet, self).__init__()\r\n",
    "        self.in_planes = 64\r\n",
    "\r\n",
    "        self.conv1 = nn.Conv2D(3, 64, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn1 = nn.BatchNorm2D(64)\r\n",
    "        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\r\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\r\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\r\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\r\n",
    "        self.linear = nn.Linear(25088, num_classes)\r\n",
    "        stdv = 1.0/math.sqrt(25088 * 1.0)\r\n",
    "        self.out = paddle.fluid.dygraph.nn.Linear(input_dim=10, output_dim=1,param_attr=fluid.param_attr.ParamAttr(initializer=fluid.initializer.Uniform(-stdv, stdv)))\r\n",
    "\r\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\r\n",
    "        strides = [stride] + [1]*(num_blocks-1)\r\n",
    "        layers = []\r\n",
    "        for stride in strides:\r\n",
    "            layers.append(block(self.in_planes, planes, stride))\r\n",
    "            self.in_planes = planes\r\n",
    "        return nn.Sequential(*layers)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
    "        out = self.layer1(out)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = self.layer3(out)\r\n",
    "        out = self.layer4(out)\r\n",
    "        out = F.avg_pool2d(out, 4)\r\n",
    "        out = paddle.reshape(out, [out.shape[0], -1])\r\n",
    "        out = self.linear(out)\r\n",
    "        out = self.out(out)\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "def SENet18():\r\n",
    "    return SENet(PreActBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练模型并在验证集上进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n",
      "epoch: 0, batch_id: 0, loss is: [0.6937493]\n",
      "epoch: 0, batch_id: 10, loss is: [0.6856425]\n",
      "epoch: 0, batch_id: 20, loss is: [0.63147783]\n",
      "epoch: 0, batch_id: 30, loss is: [0.5303859]\n",
      "[validation] accuracy/loss: 0.9200000762939453/0.31031665205955505\n",
      "epoch: 1, batch_id: 0, loss is: [0.27883127]\n",
      "epoch: 1, batch_id: 10, loss is: [0.3297333]\n",
      "epoch: 1, batch_id: 20, loss is: [0.05639496]\n",
      "epoch: 1, batch_id: 30, loss is: [0.3844355]\n",
      "[validation] accuracy/loss: 0.9475000500679016/0.17045293748378754\n",
      "epoch: 2, batch_id: 0, loss is: [0.09746314]\n",
      "epoch: 2, batch_id: 10, loss is: [0.23634449]\n",
      "epoch: 2, batch_id: 20, loss is: [0.61998594]\n",
      "epoch: 2, batch_id: 30, loss is: [0.04771285]\n",
      "[validation] accuracy/loss: 0.9524999856948853/0.11882917582988739\n"
     ]
    }
   ],
   "source": [
    "with fluid.dygraph.guard():\r\n",
    "    model = SENet18()\r\n",
    "    print('start training ... ')\r\n",
    "    model.train()\r\n",
    "    epoch_num = 3\r\n",
    "    # 定义优化器\r\n",
    "    opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\r\n",
    "    # 定义数据读取器，训练数据读取器和验证数据读取器\r\n",
    "    train_loader = data_loader(DATADIR, batch_size=10, mode='train')\r\n",
    "    valid_loader = valid_data_loader(DATADIR2, CSVFILE)\r\n",
    "    for epoch in range(epoch_num):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            x_data, y_data = data\r\n",
    "            img = fluid.dygraph.to_variable(x_data)\r\n",
    "            label = fluid.dygraph.to_variable(y_data)\r\n",
    "            logits = model(img)\r\n",
    "            # 进行loss计算\r\n",
    "            loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)  #loss的目的是让sigmoid(logits)去逼近label 所以在预测的时候预测值是sigmoid(logits) \r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "            if batch_id % 10 == 0:\r\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\r\n",
    "            # 反向传播，更新权重，清除梯度\r\n",
    "            avg_loss.backward()\r\n",
    "            opt.minimize(avg_loss)\r\n",
    "            model.clear_gradients()\r\n",
    "            \r\n",
    "        model.eval()\r\n",
    "        accuracies = []\r\n",
    "        losses = []\r\n",
    "        for batch_id, data in enumerate(valid_loader()):\r\n",
    "            x_data, y_data = data\r\n",
    "            img = fluid.dygraph.to_variable(x_data)\r\n",
    "            label = fluid.dygraph.to_variable(y_data)\r\n",
    "            # 运行模型前向计算，得到预测值\r\n",
    "            logits = model(img)\r\n",
    "            # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\r\n",
    "            # 计算sigmoid后的预测概率，进行loss计算\r\n",
    "            pred = fluid.layers.sigmoid(logits)## 这个值大余）0.5就代表预测值为1\r\n",
    "            loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\r\n",
    "            pred2 = pred * (-1.0) + 1.0\r\n",
    "            # 得到两个类别的预测概率，并沿第一个维度级联\r\n",
    "            pred = fluid.layers.concat([pred2, pred], axis=1) # [10，2]\r\n",
    "            acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\r\n",
    "            accuracies.append(acc.numpy())\r\n",
    "            losses.append(loss.numpy())\r\n",
    "        print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\r\n",
    "        model.train()\r\n",
    "    # save params of model\r\n",
    "    fluid.save_dygraph(model.state_dict(), 'palm')\r\n",
    "    # save optimizer state\r\n",
    "    fluid.save_dygraph(opt.state_dict(), 'palm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
