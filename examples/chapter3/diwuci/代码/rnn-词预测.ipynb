{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'to_Tensor' from 'paddle' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b6d736ca92db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_Tensor' from 'paddle' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/__init__.py)"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import paddle.nn as nn\r\n",
    "import paddle as optimizer\r\n",
    "import paddle.io as Data\r\n",
    "from paddle import to_Tensor\r\n",
    "dtype = paddle.to_tensor\r\n",
    "\r\n",
    "sentences = [ \"i like dog\", \"i love coffee\", \"i hate milk\"]\r\n",
    "\r\n",
    "word_list = \" \".join(sentences).split()\r\n",
    "vocab = list(set(word_list))\r\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\r\n",
    "idx2word = {i: w for i, w in enumerate(vocab)}\r\n",
    "n_class = len(vocab)\r\n",
    "\r\n",
    "# TextRNN Parameter\r\n",
    "batch_size = 2\r\n",
    "n_step = 2 # number of cells(= number of Step)\r\n",
    "n_hidden = 5 # number of hidden units in one cell\r\n",
    "\r\n",
    "def make_data(sentences):\r\n",
    "    input_batch = []\r\n",
    "    target_batch = []\r\n",
    "\r\n",
    "    for sen in sentences:\r\n",
    "        word = sen.split()\r\n",
    "        input = [word2idx[n] for n in word[:-1]]\r\n",
    "        target = word2idx[word[-1]]\r\n",
    "\r\n",
    "        input_batch.append(np.eye(n_class)[input])\r\n",
    "        target_batch.append(target)\r\n",
    "\r\n",
    "    return input_batch, target_batch\r\n",
    "\r\n",
    "input_batch, target_batch = make_data(sentences)\r\n",
    "input_batch, target_batch = to_Tensor(input_batch), torch.LongTensor(target_batch)\r\n",
    "dataset = Data.TensorDataset(input_batch, target_batch)\r\n",
    "loader = Data.DataLoader(dataset, batch_size, True)\r\n",
    "\r\n",
    "class TextRNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(TextRNN, self).__init__()\r\n",
    "        self.rnn = nn.RNN(input_size=n_class, hidden_size=n_hidden)\r\n",
    "        # fc\r\n",
    "        self.fc = nn.Linear(n_hidden, n_class)\r\n",
    "\r\n",
    "    def forward(self, hidden, X):\r\n",
    "        # X: [batch_size, n_step, n_class]\r\n",
    "        X = X.transpose(0, 1) # X : [n_step, batch_size, n_class]\r\n",
    "        out, hidden = self.rnn(X, hidden)\r\n",
    "        # out : [n_step, batch_size, num_directions(=1) * n_hidden]\r\n",
    "        # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\r\n",
    "        out = out[-1] # [batch_size, num_directions(=1) * n_hidden] â­\r\n",
    "        model = self.fc(out)\r\n",
    "        return model\r\n",
    "\r\n",
    "model = TextRNN()\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\r\n",
    "\r\n",
    "# Training\r\n",
    "for epoch in range(500):\r\n",
    "    for x, y in loader:\r\n",
    "      # hidden : [num_layers * num_directions, batch, hidden_size]\r\n",
    "      hidden = torch.zeros(1, x.shape[0], n_hidden)\r\n",
    "      # x : [batch_size, n_step, n_class]\r\n",
    "      pred = model(hidden, x)\r\n",
    "\r\n",
    "      # pred : [batch_size, n_class], y : [batch_size] (LongTensor, not one-hot)\r\n",
    "      loss = criterion(pred, y)\r\n",
    "      if (epoch + 1) % 100 == 0:\r\n",
    "          print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\r\n",
    "\r\n",
    "      optimizer.zero_grad()\r\n",
    "      loss.backward()\r\n",
    "      optimizer.step()\r\n",
    "  \r\n",
    "input = [sen.split()[:2] for sen in sentences]\r\n",
    "# Predict\r\n",
    "hidden = torch.zeros(1, len(input), n_hidden)\r\n",
    "predict = model(hidden, input_batch).data.max(1, keepdim=True)[1]\r\n",
    "print([sen.split()[:2] for sen in sentences], '->', [idx2word[n.item()] for n in predict.squeeze()])\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
