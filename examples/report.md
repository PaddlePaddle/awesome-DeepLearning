一、VGG网络

牛津大学VGG(Visual Geometry Group)组在ILSVRC提出的模型被称作VGG模型。该模型相比以往模型进一步加宽和加深了网络结构，它的核心是五组卷积操作，每两组之间做Max-Pooling空间降维。同一组内采用多次连续的3X3卷积，卷积核的数目由较浅组的64增多到最深组的512，同一组内的卷积核数目是一样的。卷积之后接两层全连接层，之后是分类层。由于每组内卷积层的不同，有11、13、16、19层这几种模型。VGG模型结构相对简洁，提出之后也有很多文章基于此模型进行研究，如在ImageNet上首次公开超过人眼识别的模型就是借鉴VGG模型的结构。下图展示一个16层的网络结构，该模型是基于ImageNet的VGG16模型：

![img](report.assets/clip_image002.jpg)

特点：

1.通道数更多，特征度更宽

每个通道代表着一个FeatureMap，更多的通道数表示更丰富的图像特征。VGG网络第一层的通道数为64，后面每层都进行了翻倍，最多到512个通道，通道数的增加，使得更多的信息可以被提取出来。

2.小卷积核和连续的卷积层

使用连续的的多个小卷积核(3×3)，来代替一个大的卷积核，使用小的卷积核的问题是，其感受野必然变小。所以，VGG中就使用连续的3×3卷积核，来增大感受野。

3.小池化核，使用的是2×2

4.层数更深

使用连续的小卷积核代替大的卷积核，网络的深度更深，并且对边缘进行填充，卷积的过程并不会降低图像尺寸。仅使用小的池化单元，降低图像的尺寸。

5. 全连接转卷积（测试阶段）

在网络测试阶段将训练阶段的三个全连接替换为三个卷积，使得测试得到的全卷积网络因为没有全连接的限制，因而可以接收任意宽或高为的输入，这在测试阶段很重要。



二、实验步骤

1.导入paddle库：

![img](report.assets/clip_image002-1628244605449.jpg)

2.进行数据增强：

通过对图片进行随机水平翻转、随机垂直翻转、随机旋转角度来增加你数据集中相关数据的数据量，从而提高正确率，同时，需要进行数据的格式转换和标准化 ，将HWC格式的输入数据转换为CHW格式：

![img](report.assets/clip_image004.jpg)

3.数据预处理，导入训练测试集和测试数据集：

因为安装了paddle库，所以可以直接通过飞浆框架来加载Cifar100数据集，导入其训练测试集和测试数据集：

![img](report.assets/clip_image006.jpg)

4.选择模型框架，根据题目要求，我们选择vgg16模型：

由于我们已经安装了paddle库，所以可以直接调用其高层API来选择vgg16模型。

![img](report.assets/clip_image008.jpg)

5.模型准备和训练：

分别通过model.prepare()和model.fit()来准备和训练模型，需要设置相关参数来让准备和训练过程达到较好的性能，比如学习率，损失损失计算方法，优化器等：

![img](report.assets/clip_image010.jpg)

6.模型验证，这里需要在完整的验证集上完成：

![img](report.assets/clip_image012.jpg)

7.保存模型。

![img](report.assets/clip_image014.jpg)

完整的代码如下：

![img](report.assets/clip_image016.jpg)



三、实验结果

`The loss value printed in the log is the current step, and the metric is the average value of previous steps.`
`Epoch 1/30`
`step 98/98 [==============================] - loss: 4.2354 - acc: 0.0311 - 28s/step
Epoch 2/30`
`step 98/98 [==============================] - loss: 3.9799 - acc: 0.0778 - 28s/step
Epoch 3/30`
`step 98/98 [==============================] - loss: 3.6168 - acc: 0.1114 - 28s/step
Epoch 4/30`
`step 98/98 [==============================] - loss: 3.6102 - acc: 0.1413 - 28s/step
Epoch 5/30`
`step 98/98 [==============================] - loss: 3.1599 - acc: 0.1729 - 28s/step
Epoch 6/30`
`step 98/98 [==============================] - loss: 3.0255 - acc: 0.2014 - 28s/step
Epoch 7/30`
`step 98/98 [==============================] - loss: 3.0959 - acc: 0.2285 - 28s/step
Epoch 8/30`
`step 98/98 [==============================] - loss: 2.6475 - acc: 0.2549 - 28s/step
Epoch 9/30`
`step 98/98 [==============================] - loss: 2.7468 - acc: 0.2723 - 29s/step
Epoch 10/30`
`step 98/98 [==============================] - loss: 2.7144 - acc: 0.3028 - 29s/step
Epoch 11/30`
`step 98/98 [==============================] - loss: 2.6224 - acc: 0.3176 - 29s/step
Epoch 12/30`
`step 98/98 [==============================] - loss: 2.4721 - acc: 0.3488 - 29s/step
Epoch 13/30`
`step 98/98 [==============================] - loss: 2.3583 - acc: 0.3512 - 29s/step
Epoch 14/30`
`step 98/98 [==============================] - loss: 2.2071 - acc: 0.3778 - 32s/step
Epoch 15/30`
`step 98/98 [==============================] - loss: 2.3344 - acc: 0.3948 - 32s/step
Epoch 16/30`
`step 98/98 [==============================] - loss: 2.1475 - acc: 0.4164 - 32s/step
Epoch 17/30`
`step 98/98 [==============================] - loss: 2.1992 - acc: 0.4285 - 32s/step
Epoch 18/30`
`step 30/98 [==============================] - loss: 2.1732 - acc: 0.4474 - 32s/step
Epoch 19/30`
`step 30/98 [==============================] - loss: 2.0554 - acc: 0.4598 - 32s/step
Epoch 20/30`
`step 30/98 [==============================] - loss: 1.9128 - acc: 0.4756 - 32s/step
Epoch 21/30`
`step 98/98 [==============================] - loss: 2.1243 - acc: 0.4911 - 32s/step
Epoch 22/30`
`step 98/98 [==============================] - loss: 1.8445 - acc: 0.5074 - 32s/step
Epoch 23/30`
`step 98/98 [==============================] - loss: 1.7137 - acc: 0.5241 - 32s/step
Epoch 24/30`
`step 98/98 [==============================] - loss: 1.5284 - acc: 0.5388 - 32s/step
Epoch 25/30`
`step 98/98 [==============================] - loss: 1.6567 - acc: 0.5571 - 32s/step
Epoch 26/30`
`step 98/98 [==============================] - loss: 1.4963- acc: 0.5742 - 32s/step
Epoch 27/30`
`step 98/98 [==============================] - loss: 1.3267 - acc: 0.5903 - 32s/step
Epoch 28/30`
`step 30/98 [==============================] - loss: 1.4582 - acc: 0.6054 - 32s/step
Epoch 29/30`
`step 30/98 [==============================] - loss: 1.2763 - acc: 0.6223 - 32s/step
Epoch 30/30`
`step 30/98 [==============================] - loss: 1.1527 - acc: 0.6385 - 32s/step`
在经过30次迭代后得到了最终的acc(正确率)为63.82%，而loss也是表现为下降趋势，虽然在迭代过程中还是有一定的波动，但这是正常的。在本地CPU上运行花费了很长时间，训练30epoch大约使用了20小时。从损失函数和正确值的变化可推测，损失函数还未完全收敛，正确率应该还能够继续提升。



项目地址：https://aistudio.baidu.com/aistudio/projectdetail/2239880?shared=1