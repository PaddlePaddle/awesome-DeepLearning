{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import gzip\n",
    "import  json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(mode='train'):\r\n",
    "    datafile='work/mnist.json.gz'\r\n",
    "    data=json.load(gzip.open(datafile))\r\n",
    "    train_set,val_set,eval_set=data\r\n",
    "    #shape of the images\r\n",
    "    IMG_ROWS=28\r\n",
    "    IMG_CLOS=28\r\n",
    "    #load data based on the mode\r\n",
    "    if mode=='train':\r\n",
    "        imgs=train_set[0]\r\n",
    "        labels=train_set[1]\r\n",
    "    elif mode=='valid':\r\n",
    "        imgs=val_set[0]\r\n",
    "        labels=val_set[1]\r\n",
    "    elif mode=='eval':\r\n",
    "        imgs=eval_set[0]\r\n",
    "        labels=eval_set[1]\r\n",
    "\r\n",
    "    imgs_len=len(imgs)\r\n",
    "    assert len(imgs)==len(labels),            \"length of the images({}) should be the same as labels({})\".format(len(imgs),len(labels))\r\n",
    "    index_list=list(range(imgs_len))\r\n",
    "\r\n",
    "    BATCH_SIZE=100\r\n",
    "\r\n",
    "    def data_generator():\r\n",
    "        if mode==train:\r\n",
    "            random.shuffle(index_list)\r\n",
    "        imgs_list=[]\r\n",
    "        labels_list=[]\r\n",
    "        for i in index_list:\r\n",
    "            img=np.reshape(imgs[i],[1,IMG_ROWS,IMG_CLOS]).astype('float32')\r\n",
    "            label=np.reshape(labels[i],[1]).astype('int64')\r\n",
    "            imgs_list.append(img)\r\n",
    "            labels_list.append(label)\r\n",
    "            if len(imgs_list)==BATCH_SIZE:\r\n",
    "                yield np.array(imgs_list),np.array(labels_list)\r\n",
    "                imgs_list=[]\r\n",
    "                labels_list=[]\r\n",
    "        if len(imgs_list)>0:\r\n",
    "            yield np.array(imgs_list),np.array(labels_list)\r\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn.functional as F \r\n",
    "from paddle.nn import Conv2D,MaxPool2D,Linear\r\n",
    "\r\n",
    "class Net(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(Net,self).__init__()\r\n",
    "        self.conv1=Conv2D(1,6,5,1,2)\r\n",
    "        self.conv2=Conv2D(6,16,5)\r\n",
    "        self.pool1=MaxPool2D(kernel_size=2,stride=2)\r\n",
    "        self.pool2=MaxPool2D(kernel_size=2,stride=2)\r\n",
    "        self.fc=Linear(in_features=16*5*5,out_features=10)\r\n",
    "    def forward(self,inputs,label):\r\n",
    "        x=self.conv1(inputs)\r\n",
    "        x=F.relu(x)\r\n",
    "        x=self.pool1(x)\r\n",
    "        x=self.conv2(x)\r\n",
    "        x=F.relu(x)\r\n",
    "        x=self.pool2(x)\r\n",
    "        x=paddle.reshape(x,[x.shape[0],16*5*5])\r\n",
    "        x=self.fc(x)\r\n",
    "        x=F.softmax(x)\r\n",
    "        if label is not None:\r\n",
    "            acc=paddle.metric.accuracy(input=x,label=label)\r\n",
    "            return x,acc\r\n",
    "        else:\r\n",
    "            return x\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDAPlace(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader=load_data('train')\n",
    "use_gpu=True\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :0, batch :0, loss :[2.3186667], accuracy :[0.09]\n",
      "epoch :0, batch :200, loss :[1.7549179], accuracy :[0.73]\n"
     ]
    }
   ],
   "source": [
    "def train(model):\n",
    "    model=Net()\n",
    "    model.train()\n",
    "    optim=paddle.optimizer.Adam(learning_rate=0.001,weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),parameters=model.parameters())\n",
    "\n",
    "    EPOCH_NUM=10\n",
    "\n",
    "    losses=[]\n",
    "    iters=[]\n",
    "    iter=0\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch,data in enumerate(train_loader()):\n",
    "            images,labels=data\n",
    "            images=paddle.to_tensor(images)\n",
    "            labels=paddle.to_tensor(labels)\n",
    "\n",
    "            pred,acc=model(images,labels)\n",
    "            loss=F.cross_entropy(pred,labels)\n",
    "            avg_loss=paddle.mean(loss)\n",
    "\n",
    "            if batch%200==0:\n",
    "                print(\"epoch :{}, batch :{}, loss :{}, accuracy :{}\".format(epoch,batch,avg_loss.numpy(),acc.numpy()))\n",
    "                losses.append(avg_loss.numpy()[0])\n",
    "                iters.append(iter)\n",
    "                iter+=100\n",
    "            avg_loss.backward()\n",
    "            optim.step()\n",
    "            optim.clear_grad()\n",
    "    paddle.save(model.state_dict(),'net.pdparams')\n",
    "    return iters,losses\n",
    "\n",
    "model=Net()\n",
    "iters,losses=train(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Train Loss',fontsize=24)\n",
    "plt.xlabel('Iterations',fontsize=14)\n",
    "plt.ylabel('Loss',fontsize=14)\n",
    "plt.plot(iters,losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluation(model):\r\n",
    "    print('start evaluation......')\r\n",
    "    params_file_path='net.pdparams'\r\n",
    "    params_dict=paddle.load(params_file_path)\r\n",
    "    model.load_dict(params_dict)\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "    eval_loader=load_data('eval')\r\n",
    "\r\n",
    "    acc_set=[]\r\n",
    "    avg_loss_set=[]\r\n",
    "    for batch,data in enumerate(eval_loader()):\r\n",
    "        images,labels=data\r\n",
    "        images=paddle.to_tensor(images)\r\n",
    "        labels=paddle.to_tensor(labels)\r\n",
    "        pred,acc=model(images,labels)\r\n",
    "        loss=F.cross_entropy(pred,labels)\r\n",
    "        avg_loss=paddle.mean(loss)\r\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\r\n",
    "        acc_set.append(float(acc.numpy()))\r\n",
    "\r\n",
    "    acc_val_mean=np.array(acc_set).mean()\r\n",
    "    avg_loss_val_mean=np.array(avg_loss_set).mean()\r\n",
    "\r\n",
    "    print(\"loss :{}, accuracy :{}\".format(avg_loss_val_mean,acc_val_mean))\r\n",
    "\r\n",
    "model=Net()\r\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
