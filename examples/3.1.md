### **归一化方法详解**

#### 1.1**概念**

数据标准化（归一化）处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。



#### 1.2**算法流程**

![img](https://img-blog.csdnimg.cn/20190325171855691.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Byb21pc2VqaWE=,size_16,color_FFFFFF,t_70)

#### 1.3**作用**

归一化的目的就是使得预处理的数据被限定在一定的范围内（比如[0,1]或者[-1,1]），从而消除奇异样本数据导致的不良影响。

1）在统计学中，归一化的具体作用是归纳统一样本的统计分布性。归一化在0~1之间是统计的概率分布，归一化在-1~+1之间是统计的坐标分布。

2）奇异样本数据是指相对于其他输入样本特别大或特别小的样本矢量（即特征向量），譬如，下面为具有两个特征的样本数据x1、x2、x3、x4、x5、x6（特征向量—>列向量）,其中x6这个样本的两个特征相对其他样本而言相差比较大，因此，x6认为是奇异样本数据。

![img](https://img-blog.csdn.net/20171027225346700)



#### 1.4**应用场景**

1）概率模型不需要归一化，因为这种模型不关心变量的取值，而是关心变量的分布和变量之间的条件概率；

2）SVM、线性回归之类的最优化问题需要归一化，是否归一化主要在于是否关心变量取值；

3）神经网络需要标准化处理，一般变量的取值在-1到1之间，这样做是为了弱化某些变量的值较大而对模型产生影响。一般神经网络中的隐藏层采用tanh激活函数比sigmod激活函数要好些，因为tanh双曲正切函数的取值[-1,1]之间，均值为0.

4）在K近邻算法中，如果不对解释变量进行标准化，那么具有小数量级的解释变量的影响就会微乎其微。


