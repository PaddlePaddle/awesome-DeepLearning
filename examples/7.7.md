损失函数方法补充

logLoss：

![img](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image001.png)

特点：log对数损失函数能非常好的表征概率分布，在很多场景尤其是多分类，如果需要知道结果属于每个类别的置信度，那它非常适合；健壮性不强，相比于hinge loss对噪声更敏感；逻辑回归的损失函数就是log对数损失函数。

hinge loss：

![img](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image002.png)

特点：实现了软间隔分类(这个Loss函数都可以做到)；保持了支持向量机解的稀疏性。

由于HingeLoss的零区域对应的正是非支持向量的普通样本,从而所有的普通样本都不参与最终超平面的决定，这才是支持向量机最大的优势所在,对训练样本数目的依赖大大减少,且提高了训练效率。

exp-loss：

![img](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image003.png)

特点：对离群点、噪声非常敏感。经常用在AdaBoost算法中。

cross-entropy loss：

![img](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image005.jpg)

特点：本质上也是一种对数似然函数，可用于二分类和多分类任务中；当使用sigmoid作为激活函数的时候，常用交叉熵损失函数而不用均方误差损失函数，因为它可以完美解决平方损失函数权重更新过慢的问题，具有“误差大的时候，权重更新快；误差小的时候，权重更新慢”的良好性质。

quadratic loss：

![img](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image007.jpg)

特点：常用于回归问题

absolution loss：

![img](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image009.jpg)

特点：log对数损失函数能非常好的表征概率分布，在很多场景尤其是多分类，如果需要知道结果属于每个类别的置信度，那它非常适合；健壮性不强，相比于hinge loss对噪声更敏感；逻辑回归的损失函数就是log对数损失函数。

0-1 loss：

![img](file:///C:\Users\apple\AppData\Local\Temp\msohtmlclip1\01\clip_image010.png)

特点：0-1损失函数直接对应分类判断错误的个数，但是它是一个非凸函数，不太适用；应用于感知机。



损失函数python代码实现

import numpy as np

 

y_hat = np.dot(X, w) + b

 

loss = np.sum((y_hat - y) ** 2) / num_train

 

dw = np.dot(X.T, (y_hat - y)) / num_train

db = np.sum((y_hat - y)) / num_train

 

②softmax+交叉熵损失函数代码实现：

 

输入层：（z1,z2,z3）

输出层：（y1,y2,y3）

label：（t1,t2,t3）

反向传播结果：（y1-t1,y2-t2,y3-t3）

 

class SoftmaxWithEntropyLoss(object):

def __init__(self):

self.loss = None

self.y = None

self.t = None

 

def forward(self, x, t):

self.t = t

self.y = softmax(x)

self.loss = cross_entropy_error(self.y, self.t)

 

def backward(self, dout):

batch_size = self.t.shape[0]

if self.t.size == self.y.size:

dx = (self.y - self.t) / batch_size

else:

dx = self.y.copy()

dx[np.arange(batch_size), self.t] -= 1

dx = dx / batch_size

 

return dx

 

 

 

def cross_entropy_error(y, t):

if y.ndim == 1:

t = t.reshape(1, t.size)

y = y.reshape(1, y.size)

 

if t.size == y.size:

t = t.argmax(axis=1)

 

batch_size = y.shape[0]

return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size





池化方法补充：

一般池化：

池化作用于图像中不重合的区域，定义池化窗口的大小为sizeX，即下图中红色正方形的边长，定义两个相邻池化窗口的水平位移/竖直位移为stride。一般池化由于每一池化窗口都是不重复的，所以sizeX=stride。

最常见的池化操作为平均池化mean pooling和最大池化max pooling：

平均池化：计算图像区域的平均值作为该区域池化后的值。

最大池化：选图像区域的最大值作为该区域池化后的值。

重叠池化：

重叠池化正如其名字所说的，相邻池化窗口之间会有重叠区域，此时sizeX>stride。

空金字塔池化：

空间金字塔池化可以把任何尺度的图像的卷积特征转化成相同维度，这不仅可以让CNN处理任意尺度的图像，还能避免cropping和warping操作，导致一些信息的丢失，具有非常重要的意义。



数据增强方法修改及补充：

数据增强可以分为，有监督的数据增强和无监督的数据增强方法。其中有监督的数据增强又可以分为单样本数据增强和多样本数据增强方法，无监督的数据增强分为生成新的数据和学习增强策略两个方向。

有监督数据增强，即采用预设的数据变换规则，在已有数据的基础上进行数据的扩增，包含单样本数据增强和多样本数据增强，其中单样本又包括几何操作类，颜色变换类。

单样本数据增强

所谓单样本数据增强，即增强一个样本的时候，全部围绕着该样本本身进行操作，包括几何变换类，颜色变换类等。

(1) 几何变换类

几何变换类即对图像进行几何变换，包括翻转，旋转，裁剪，变形，缩放等各类操作，下面展示其中的若干个操作。

(2) 颜色变换类

上面的几何变换类操作，没有改变图像本身的内容，它可能是选择了图像的一部分或者对像素进行了重分布。如果要改变图像本身的内容，就属于颜色变换类的数据增强了，常见的包括噪声、模糊、颜色变换、擦除、填充等等。

多样本数据增强

不同于单样本数据增强，多样本数据增强方法利用多个样本来产生新的样本，下面介绍几种方法。

(1) SMOTE

SMOTE即Synthetic Minority Over-sampling Technique方法，它是通过人工合成新样本来处理样本不平衡问题，从而提升分类器性能。

(2) SamplePairing

SamplePairing方法的原理非常简单，从训练集中随机抽取两张图片分别经过基础数据增强操作(如随机翻转等)处理后经像素以取平均值的形式叠加合成一个新的样本，标签为原样本标签中的一种。这两张图片甚至不限制为同一类别，这种方法对于医学图像比较有效。

(3) mixup

mixup是Facebook人工智能研究院和MIT在“Beyond Empirical Risk Minimization”中提出的基于邻域风险最小化原则的数据增强方法，它使用线性插值得到新样本数据。

②无监督的数据增强

无监督的数据增强方法包括两类：

(1) 通过模型学习数据的分布，随机生成与训练数据集分布一致的图片，代表方法GAN。

(2) 通过模型，学习出适合当前任务的数据增强方法，代表方法AutoAugment。

GAN

关于GAN(generative adversarial networks)，我们已经说的太多了。它包含两个网络，一个是生成网络，一个是对抗网络，基本原理如下：

(1) G是一个生成图片的网络，它接收随机的噪声z，通过噪声生成图片，记做G(z) 。

(2) D是一个判别网络，判别一张图片是不是“真实的”，即是真实的图片，还是由G生成的图片。

Autoaugmentation

AutoAugment是Google提出的自动选择最优数据增强方案的研究，这是无监督数据增强的重要研究方向。它的基本思路是使用增强学习从数据本身寻找最佳图像变换策略，对于不同的任务学习不同的增强方法，流程如下：

(1) 准备16个常用的数据增强操作。

(2) 从16个中选择5个操作，随机产生使用该操作的概率和相应的幅度，将其称为一个sub-policy，一共产生5个sub-polices。

(3) 对训练过程中每一个batch的图片，随机采用5个sub-polices操作中的一种。

(4) 通过模型在验证集上的泛化能力来反馈，使用的优化方法是增强学习方法。

(5) 经过80~100个epoch后网络开始学习到有效的sub-policies。

(6) 之后串接这5个sub-policies，然后再进行最后的训练。

总的来说，就是学习已有数据增强的组合策略，对于门牌数字识别等任务，研究表明剪切和平移等几何变换能够获得最佳效果。

5图像分类方法综述：

图像分类是根据图像的语义信息对不同类别图像进行区分，是计算机视觉的核心，是物体检测、图像分割、物体跟踪、行为分析、人脸识别等其他高层次视觉任务的基础。图像分类在许多领域都有着广泛的应用，如：安防领域的人脸识别和智能视频分析等，交通领域的交通场景识别，互联网领域基于内容的图像检索和相册自动归类，医学领域的图像识别等。

涵盖如下卷积神经网络：

\- LeNet：Yann LeCun等人于1998年第一次将卷积神经网络应用到图像分类任务上[1]，在手写数字识别任务上取得了巨大成功。

\- AlexNet：Alex Krizhevsky等人在2012年提出了AlexNet[2], 并应用在大尺寸图片数据集ImageNet上，获得了2012年ImageNet比赛冠军(ImageNet Large Scale Visual Recognition Challenge，ILSVRC）。

\- VGG：Simonyan和Zisserman于2014年提出了VGG网络结构[3]，是当前最流行的卷积神经网络之一，由于其结构简单、应用性极强而深受广大研究者欢迎。

\- GoogLeNet：Christian Szegedy等人在2014提出了GoogLeNet[4]，并取得了2014年ImageNet比赛冠军。

\- ResNet：Kaiming He等人在2015年提出了ResNet[5]，通过引入残差模块加深网络层数，在ImagNet数据集上的错误率降低到3.6%，超越了人眼识别水平。ResNet的设计思想深刻地影响了后来的深度神经网络的设计。

传统方法：图像预处理、特征提取和分类器设计，每一种都有多种方法。

深度学习方法：图像预处理和图像识别，其中图像识别中的骨干网络实现特征提取的功能，后面的softmax等实现图像分类