ShareBottom

概念

人们使用的大多数模型是一个模型完成一个任务的单任务模型，如果将多个任务混合在一起训练，可能出现参数之间互相干扰的情况二导致差于单独训练的效果。

当需要多任务混合训练时，为进行不相关任务的多任务学习，ShareBottom模型应运而生。ShareBottom模型是在MMOE模型之前提出的一种经典多任务模型架构。ShareBottom模型通过不同的任务共享相同的feature或feature_map从而实现多任务的优化算法。

模型

![v2-3844f316b51f39466398f7d1ccfc3f73_720w](C:\Users\apple\Desktop\image\v2-3844f316b51f39466398f7d1ccfc3f73_720w.png)



作用

shared-bottom 网络 ( 表示为函数 f ) 位于底部, 多个任务共用这一层.。往上, K 个子任务分别对应一个 tower network , 每个子任务分别通过output进行输出。 

场景

大多数的场景没有多任务学习的必要，但是如果在如推荐系统等场景中，想要达成某些目标的时候，必须用到多任务学习。以给用户推荐视频为例，我们既希望提高用户的点击率，同时也希望提高视频的播放时长，视频点赞、转发等等... 这些目标的达成并非是简单的相辅相成，更多的可能是相互竞争的关系。要是我们只让模型学习点击率，那么经过训练的模型推荐结果很可能导致标题党和封面党大行其道，真正的好的视频却被雪藏了，这显然不是我们希望看到的。而如果一味的追求高点赞，也可能就忽略了一些相对冷门的或新的佳作。因此，我们无法追求某个单一目标的达成，而需要同时优化这些有利于产品良性循环的任务目标，让它们相互平衡，从而提升用户体验，带来和留住更多的用户。

优缺点

- 优点：算法简单，模型简洁，线上算力较好。
- 缺点：这种架构极大地限制了模型表达的能力。因为模型在共享特征的上层直接接入了多个目标的输出，而由于多个任务各自有不同的数据分布，也就是说我们对不同任务的输出具有一定的差异性，而相同的特征输入会极大地削弱模型的多任务输出表达而在某种程度上降低了多目标模型的泛化能力。