# CNN-DSSM知识点补充：

## 概念

针对 DSSM 词袋模型丢失上下文信息的缺点，CNN-DSSM应运而生 。CNN-DSSM 与 DSSM 的区别主要在于输入层和表示层。

CNN-DSSM依然是由DSSM的作者提出，在语义特征计算部分采用CNN网络，网络结构如下图所示。在词向量的表达上依然采用了word hash。

## 模型

### 输入层

英文的处理方式，除了 letter-trigram，CNN-DSSM 还在输入层增加了word-trigram

![2](images\2.png)



如上图所示，word-trigram其实就是一个包含了上下文信息的滑动窗口。举个例子：把 online auto body ...这句话提取出前三个词 online auto，之后再 ==分别对==这三个词进行 letter-trigram 映射到一个 3 万维的向量空间里，然后把三个向量 concat 起来，最终映射到一个 9 万维的向量空间里。

不过trigram表示不能忽略了文本的上下文信息， 因此作者在word trigram的基础上增加了letter trigram。在一定的窗口大小内，对该窗口内的word进行拼接就是letter trigram，例如I have an apple，可以被拼接为 # I have, I have an, ...以此类推。

然后以上表示经过卷积层，max-pooling，和全连接之后得到query和doc的低维向量。最后计算相似度的时候还是cosine距离。

### 表示层

CNN-DSSM 的表示层由一个卷积神经网络组成，如下图所示：



![3](images\3.png)

**1.卷积层**

**卷积层的作用是提取滑动窗口下的上下文特征。** 以下图为例，假设输入层是一个 302`*`90000（302 行，9 万列）的矩阵，代表 302 个字向量（Query 的和 Doc 的长度一般小于 300，这里少了就补全，多了就截断），每个字向量有 9 万维。而卷积核是一个 3`*`90000 的权值矩阵，卷积核以步长为 1 向下移动，得到的 feature map 是一个 300`*`1 的矩阵，feature map 的计算公式是(输入层维数 302-卷积核大小 3 步长 1)/步长 1=300。而这样的卷积核有 300 个，所以形成了 300 个 300`*`1 的 feature map 矩阵。

![4](images\4.png)

**2.池化层**

池化层的作用是为句子找到**全局的上下文特征**。池化层以 Max-over-time pooling 的方式，每个 feature map 都取最大值，得到一个 300 维的向量。Max-over-pooling 可以解决可变长度的句子输入问题（因为不管 Feature Map 中有多少个值，只需要提取其中的最大值）。不过我们在上一步已经做了句子的定长处理（固定句子长度为 302），所以就没有可变长度句子的问题。最终池化层的输出为各个 Feature Map 的最大值，即一个 300`*`1 的向量。这里多提一句，之所以 Max pooling 层要保持固定的输出维度，是因为下一层全链接层要求有固定的输入层数，才能进行训练。

3.全连接层

最后通过全连接层把一个 300 维的向量转化为一个 128 维的低维语义向量。全连接层采用 tanh 函数：
$$
tanh(x)=\frac{1-e^{-2x}}{1+e^{-2x}}
$$

### 匹配层

CNN-DSSM 的匹配层和 DSSM 的一样，这里省略。

## 优缺点

**优点：**

**CNN-DSSM 通过卷积层提取了滑动窗口下的上下文信息，又通过池化层提取了全局的上下文信息，上下文信息得到较为有效的保留。**

**缺点：**

**对于间隔较远的上下文信息，难以有效保留。** 举个例子，I grew up in France... I speak fluent French，显然 France 和 French 是具有上下文依赖关系的，但是由于 CNN-DSSM 滑动窗口（卷积核）大小的限制，导致无法捕获该上下文信息。

# LSTM-DSSM知识点补充：

针对 CNN-DSSM 无法捕获较远距离上下文特征的缺点，有人提出了用LSTM-DSSM（Long-Short-Term Memory）来解决该问题。不过说 LSTM 之前，要先介绍它的"爸爸""RNN。

### RNN

RNN（Recurrent Neural Networks）可以被看做是同一神经网络的多次复制，每个神经网络模块会把消息传递给下一个。如果我们将这个循环展开：

[![img](https://camo.githubusercontent.com/1e5ef4629c2b491039ff1bfce04e724354682bb309c874ffc1c86a9adad41f5e/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535353935353233355f323931395f313530313535353935363233392e706e67)](https://camo.githubusercontent.com/1e5ef4629c2b491039ff1bfce04e724354682bb309c874ffc1c86a9adad41f5e/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535353935353233355f323931395f313530313535353935363233392e706e67)

假设输入 xi 为一个 query 中几个连续的词，hi 为输出。那么上一个神经元的输出 h(t-1) 与当前细胞的输入 Xt 拼接后经过 tanh 函数会输出 ht，同时把 ht 传递给下一个细胞。

[![img](https://camo.githubusercontent.com/6efdf6dfbe8c1fc367d4d9815618742d6d55eef409bf4931a56843c0eb458b60/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535353937353832365f393938395f313530313535353937363834362e706e67)](https://camo.githubusercontent.com/6efdf6dfbe8c1fc367d4d9815618742d6d55eef409bf4931a56843c0eb458b60/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535353937353832365f393938395f313530313535353937363834362e706e67)

不幸的是，在这个间隔不断增大时，RNN 会逐渐丧失学习到远距离信息的能力。因为 RNN 随着距离的加长，会导致梯度消失。简单来说，由于求导的链式法则，直接导致梯度被表示为连乘的形式，以至梯度消失（几个小于 1 的数相乘会逐渐趋向于 0）。

### LSTM

LSTM(（Long-Short-Term Memory）是一种 RNN 特殊的类型，可以学习长期依赖信息。我们分别来介绍它最重要的几个模块：

[![img](https://camo.githubusercontent.com/ae93d6b20c61cb98caefe5e1722bbc632825883e2bf571ad6d45f6de5f365c6e/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535353939333030305f363633305f313530313535353939333935392e706e67)](https://camo.githubusercontent.com/ae93d6b20c61cb98caefe5e1722bbc632825883e2bf571ad6d45f6de5f365c6e/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535353939333030305f363633305f313530313535353939333935392e706e67)

（0）细胞状态

细胞状态这条线可以理解成是一条信息的传送带，只有一些少量的线性交互。在上面流动可以保持信息的不变性。

[![img](https://camo.githubusercontent.com/edb65bf840ffa49130f53fe5927cd90865f137a07eacc9d68cbd7fd2b58e42c1/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535363037353636365f34345f313530313535363037363635352e706e67)](https://camo.githubusercontent.com/edb65bf840ffa49130f53fe5927cd90865f137a07eacc9d68cbd7fd2b58e42c1/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535363037353636365f34345f313530313535363037363635352e706e67)

（1）遗忘门

遗忘门 [5]由 Gers 提出，它用来控制细胞状态 cell 有哪些信息可以通过，继续往下传递。如下图所示，上一层的输出 h(t-1) concat 上本层的输入 xt，经过一个 sigmoid 网络（遗忘门）产生一个从 0 到 1 的数值 ft，然后与细胞状态 C(t-1) 相乘，最终决定有多少细胞状态可以继续往后传递。

[![img](https://camo.githubusercontent.com/5a01f427434c536ec008fec0250e608b81c68463db19150a0d8437ac9e044931/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535363130363638315f353330365f313530313535363130373637362e706e67)](https://camo.githubusercontent.com/5a01f427434c536ec008fec0250e608b81c68463db19150a0d8437ac9e044931/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535363130363638315f353330365f313530313535363130373637362e706e67)

（2）输入门

输入门决定要新增什么信息到细胞状态，这里包含两部分：一个 sigmoid 输入门和一个 tanh 函数。sigmoid 决定输入的信号控制，tanh 决定输入什么内容。如下图所示，上一层的输出 h(t-1) concat 上本层的输入 xt，经过一个 sigmoid 网络（输入门）产生一个从 0 到 1 的数值 it，同样的信息经过 tanh 网络做非线性变换得到结果 Ct，sigmoid 的结果和 tanh 的结果相乘，最终决定有哪些信息可以输入到细胞状态里。

[![img](https://camo.githubusercontent.com/216fe2cf9f07513806118f900297abf861a3b756b076dddee31e902d29b36e5b/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535363132313534375f333839385f313530313535363132323830362e706e67)](https://camo.githubusercontent.com/216fe2cf9f07513806118f900297abf861a3b756b076dddee31e902d29b36e5b/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535363132313534375f333839385f313530313535363132323830362e706e67)

（3）输出门

输出门决定从细胞状态要输出什么信息，这里也包含两部分：一个 sigmoid 输出门和一个 tanh 函数。sigmoid 决定输出的信号控制，tanh 决定输出什么内容。如下图所示，上一层的输出 h(t-1) concat 上本层的输入 xt，经过一个 sigmoid 网络（输出门）产生一个从 0 到 1 的数值 Ot，细胞状态 Ct 经过 tanh 网络做非线性变换，得到结果再与 sigmoid 的结果 Ot 相乘，最终决定有哪些信息可以输出，输出的结果 ht 会作为这个细胞的输出，也会作为传递个下一个细胞。

[![img](https://camo.githubusercontent.com/373dd7c665468d955d4d3223b5463c95246dfd0454b1534b63b44ba62aa1d0fe/68747470733a2f2f626c6f672d31303033393639322e66696c652e6d7971636c6f75642e636f6d2f313530313535363134333338335f343738385f313530313535363134343338322e706e67)](

## 概念

针对CNN-DSSM无法捕捉长文本的上下文的信息的缺点，引入了LSTM。同时在LSTM的cell中加入了peep hole。

和传统的LSTM不同，作者在遗忘门，输入门，输出门中都考虑了$C_{t-1}$和$C_t$，总体来说考虑的信息更丰富。

## 模型

模型的结构如下图所示：

![5](images\5.png)

看起来有点复杂，我们换一个图，读者可以看的更清晰：

![6](images\6.png)

**这里三条黑线就是所谓的 peephole，传统的 LSTM 中遗忘门、输入门和输出门只用了 h(t-1) 和 xt 来控制门缝的大小，peephole 的意思是说不但要考虑 h(t-1) 和 xt，也要考虑 Ct-1 和 Ct，其中遗忘门和输入门考虑了 Ct-1，而输出门考虑了 Ct。** 总体来说需要考虑的信息更丰富了。

好了，来看一个 LSTM-DSSM 整体的网络结构：

![7](images\7.png)

红色的部分可以清晰的看到残差传递的方向。

## 优缺点

**缺点：**

1. **DSSM 是端到端的模型** ，虽然省去了人工特征转化、特征工程和特征组合，但**端到端的模型有个问题就是效果不可控**。对于一些要保证较高的准确率的场景，用有监督人工标注的 Query 分类作为打底，再结合无监督的 Word2Vec、LDA 等进行语义特征的向量化，显然比较可控（至少 Query 分类的准确率可以达到 95% 以上）。
2. **DSSM 是弱监督模型**，因为引擎的点击曝光日志里 Query 和 Title 的语义信息比较弱。举个例子，搜索引擎第一页的信息往往都是 Query 的包含匹配，笔者统计过，完全的语义匹配只有不到 2%。这就意味着几乎所有的标题里都包含用户 Query 里的关键词，而仅用点击和曝光就能作为正负样例的判断？显然不太靠谱，因为大部分的用户进行点击时越靠前的点击的概率越大，而引擎的排序又是由 pCTR、CVR、CPC 等多种因素决定的。从这种非常弱的信号里提取出语义的相似性或者差别，那就**需要有海量的训练样本**。DSSM 论文中提到，实验的训练样本超过 1 亿。笔者和同事也亲测过，用传统 CTR 预估模型千万级的样本量来训练，模型无法收敛。可是这样海量的训练样本，恐怕只有搜索引擎才有吧？普通的搜索业务 Query 有上千万，可资源顶多只有几百万，像论文中说需要挑出点击和曝光置信度比较高且资源热度也比较高的作为训练样本，这样就过滤了 80% 的长尾 Query 和 Title 结果对，所以也只有搜索引擎才有这样的训练语料了吧。另一方面，超过 1 亿的训练样本作为输入，用深度学习模型做训练，需要大型的 GPU 集群，这个对于很多业务来说也是不具备的条件。

# MMoE多任务学习知识点补充：

## 概念



## 模型

**MMOE模型的结构图**如下图所示：

![8](images\8.png)

模型 (a) 最为常见，两个任务直接共享模型的 bottom 部分，只在最后处理时做区分，图 (a) 中使用了 Tower A 和 Tower B，然后分别接损失函数。函数表达式：
$$
y^k=h^k(f(x))
$$
模型 (b) 是常见的多任务学习模型。将 input 分别输入给三个 Expert，但三个 Expert 并不共享参数。同时将 input 输出给 Gate，Gate 输出每个 Expert 被选择的概率，然后将三个 Expert 的输出加权求和，输出给 Tower。有点 attention 的感觉。函数表达式：
$$
y^k=h^k(\sum_{i=1}^ng_if_i(x))
$$
· k 表示k个任务；

· n 表示n个expert network；

模型 (c) 是作者新提出的方法，对于不同的任务，模型的权重选择是不同的，所以作者为每个任务都配备一个 Gate 模型。对于不同的任务，特定的 Gate k 的输出表示不同的 Expert 被选择的概率，将多个 Expert 加权求和，得到$f^k(x)$，并输出给特定的 Tower 模型，用于最终的输出。函数表达式：
$$
f^k(x)=\sum_{i=1}^{n}g_i^k(x)f_i(x)
$$

$$
g^k(x)=softmax(\mathbb{W}_{g^k(x)} )
$$

其中： $g(x)$表示 gate 门的输出，为多层感知机模型，实现时为简单的线性变换加 softmax 层。

# ShareBottom多任务学习知识点补充：

## 概念

在推荐业务中经常有“既要、也要、还要”的场景，比如做视频推荐业务的时候既要提升用户对于视频的点击率，也希望同时提升用户观看视频的时长。面对这样的诉求，通常需要在推荐系统中使用多目标建模算法。

## 模型

多目标建模目前业内有两种模式，一种叫Shared-Bottom模式，另一种叫MOE，MOE又包含MMOE和OMOE两种。MMOE也是Google提出的一套多目标学习算法结果，被应用到了Google的内部推荐系统中。如下图所示：

![8](images\8.png)

Shared-Bottom的思路就是多个目标底层共用一套共享layer，在这之上基于不同的目标构建不同的Tower。这样的好处就是底层的layer复用，减少计算量，同时也可以防止过拟合的情况出现。

Shared-Bottom 优点：降低overfit风险，利用任务之间的关联性使模型学习效果更强

Shared-Bottom 缺点：任务之间的相关性将严重影响模型效果。假如任务之间相关性较低，模型的效果相对会较差。

# YouTube深度学习视频推荐系统

## 概念

YouTube 推荐系统的架构是一个典型的召回层加排序层的架构，其中候选集生成模型负责从百万候选集中召回几百个候选视频，排序模型负责几百个候选视频的精排，最终选出几十个推荐给用户。其推荐过程可以分成二级。第一级是用候选集生成模型，第二级是用排序模型。

候选集生成模型是一个典型的 Embedding MLP 的架构，要注意的是它的输出层一个多分类的输出层，预测的是用户点击了“哪个”视频。在候选集生成模型的 serving 过程中，需要从输出层提取出视频 Embedding，从最后一层 ReLU 层得到用户 Embedding，然后利用 最近邻搜索快速 得到候选集。

排序模型同样是一个 Embedding MLP 的架构，不同的是，它的输入层包含了更多的用户和视频的特征，输出层采用了 Weighted LR 作为输出层，并且使用观看时长作为正样本权重，让模型能够预测出观看时长，这更接近 YouTube 要达成的商业目标。

## 应用场景

youtube是世界上最大的视频内容平台，在如此体量的平台中，推荐系统是至关重要的。但是，youtube的视频推荐面临三方面的挑战：

1. Scale：视频和用户数量巨大，很多现有的推荐算法能够在小的数据集上表现得很好，但是在这里效果不佳。需要构建高度专业化的分布式学习算法和高效的服务系统来处理youtube庞大的用户和视频数量。
2. Freshness：这体现在两方面，一方面视频更新频繁，另一方面用户行为更新频繁。
3. Noise：相较于庞大的视频库，用户的行为是十分稀疏的，同时，我们基本上能获得的都是用户的隐式反馈信号。构造一个强健的系统是十分困难的。

## 整体架构

Youtube推荐系统的整体架构如下：

![](images\YouTube.jpeg)

由于网站视频数量太多，视频候选集太大，不宜用复杂网络直接进行推荐，这会造成响应时间的增加。因此，整个架构走粗排 + 精排两阶段的路子：

- Candidate Generation Model：在这一步，从成百上千万的视频中选择百量级的候选视频

- Ranking Model：这一步，完成对几百个候选视频的精排。

无论是候选集生成模型还是排序模型，YouTube 都采用了深度学习的解决方案。

## 候选集生成Candidate Generation

用于视频召回的候选集生成模型，架构如下图所示。

![](images\Candidate Generation.png)

最底层是它的输入层，输入的特征包括用户历史观看视频的 Embedding 向量，以及搜索词的 Embedding 向量。对于这些 Embedding 特征，YouTube 是利用用户的观看序列和搜索序列，采用了类似 Item2vec 的预训练方式生成的。

除了视频和搜索词 Embedding 向量，特征向量中还包括用户的地理位置 Embedding、年龄、性别等特征。这里我们需要注意的是，对于样本年龄这个特征，YouTube 不仅使用了原始特征值，还把经过平方处理的特征值也作为一个新的特征输入模型。
这个操作其实是为了挖掘特征非线性的特性。

确定好了特征，这些特征会在 concat 层中连接起来，输入到上层的 ReLU 神经网络进行训练。

三层 ReLU 神经网络过后，YouTube 又使用了 softmax 函数作为输出层。值得一提的是，这里的输出层不是要预测用户会不会点击这个视频，而是要预测用户会点击哪个视频，这就跟一般深度推荐模型不一样。

总的来讲，YouTube 推荐系统的候选集生成模型，是一个标准的利用了 Embedding 预训练特征的深度推荐模型，它遵循Embedding MLP 模型的架构，只是在最后的输出层有所区别。

## 候选集生成模型独特的线上服务方法

对于在线服务来说，有严格的性能要求，必须在几十毫秒内返回结果。因此，youtube没有重新跑一遍模型，而是通过保存用户的embedding和视频的embedding，通过最近邻搜索的方法得到top N的结果。

最终的结果是approx topN的结果，所以并不是直接计算用户embedding和每个视频embedding的内积。如果这样做的话，N个视频的内积计算 + 排序，时间复杂度大概是NlogN，这样很难满足时间复杂度要求。如果使用局部敏感哈希(Locality-Sensitive Hashing, LSH)等近似最近邻快速查找技术，时间复杂度是可以大大降低的。

## 排序模型

![](images\sorted.png)

输入层，相比于候选集生成模型需要对几百万候选集进行粗筛，排序模型只需对几百个候选视频进行排序，因此可以引入更多特征进行精排。具体来说，YouTube 的输入层从左至右引入的特征依次是：

- impression video ID embedding：当前候选视频的 Embedding；
- watched video IDs average embedding：用户观看过的最后 N 个视频 Embedding 的平均值；
- language embedding：用户语言的 Embedding 和当前候选视频语言的 Embedding；
- time since last watch：表示用户上次观看同频道视频距今的时间；
- previous impressions：该视频已经被曝光给该用户的次数；
- 这 5 类特征连接起来之后，需要再经过三层 ReLU 网络进行充分的特征交叉，然后就到了输出层。这里重点注意，排序模型的输出层与候选集生成模型又有所不同。不同主要有两点：一是候选集生成模型选择了 softmax 作为其输出层，而排序模型选择了 weighted logistic regression（加权逻辑回归）作为模型输出层；二是候选集生成模型预测的是用户会点击“哪个视频”，排序模型预测的是用户“要不要点击当前视频”。

其实，排序模型采用不同输出层的根本原因就在于，YouTube 想要更精确地预测 用户的观看时长，因为观看时长才是 YouTube 最看中的商业指标，而使用 Weighted LR 作为输出层，就可以实现这样的目标。

在 Weighted LR 的训练中，我们需要为每个样本设置一个权重，权重的大小，代表了这个样本的重要程度。为了能够预估观看时长，YouTube 将正样本的权重设置为用户观看这个视频的时长，然后再用 Weighted LR 进行训练，就可以让模型学到用户观看时长的信息。

对于排序模型，必须使用 TensorFlow Serving 等模型服务平台，来进行模型的线上推断。

## 训练和测试样本的处理

为了能够提高模型的训练效率和预测准确率，Youtube采取了诸多处理训练样本的工程措施，主要有3点：

- 候选集生成模型把推荐模型转换成 多分类问题，在预测下一次观看的场景中，每一个备选视频都会是一个分类，而如果采用softmax对其训练是很低效的。
  - Youtube采用word2vec中常用的 负采样训练方法减少每次预测的分类数量，从而加快整个模型的收敛速度。
- 在对训练集的预处理过程中，Youtube没有采用原始的用户日志，而是 对每个用户提取等数量的训练样本。
  - YouTube这样做的目的是减少高度活跃用户对模型损失的过度影响，使模型过于偏向活跃用户的行为模式，忽略数量更广大的长尾用户体验。
- 在处理测试集时，Youtube没有采用经典的随机留一法，而是一定要以用户最近一次观看的行为作为测试集。
  - 只留最后一次观看行为做测试集主要是为了避免引入未来信息(future information)，产生于事实不符的数据穿越问题。