## LSTM核心思想

LSTM的关键在于细胞的状态整个(绿色的图表示的是一个cell)，和穿过细胞的那条水平线。

细胞状态类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。

![](https://ai-studio-static-online.cdn.bcebos.com/51bfe1b857c84fedafb72459bbc41231dc2ae6b287a743049e6cc9b2f4979408)


若只有上面的那条水平线是没办法实现添加或者删除信息的。而是通过一种叫做 门（gates） 的结构来实现的。

门 可以实现选择性地让信息通过，主要是通过一个 sigmoid 的神经层 和一个逐点相乘的操作来实现的。

![](https://ai-studio-static-online.cdn.bcebos.com/1db106f564f74cff98f10e4dc9f6d37522de89127ae245b9a29152a4048eec04)



sigmoid 层输出（是一个向量）的每个元素都是一个在 0 和 1 之间的实数，表示让对应信息通过的权重（或者占比）。比如， 0 表示“不让任何信息通过”， 1 表示“让所有信息通过”。

LSTM通过三个这样的基本结构来实现信息的保护和控制。这三个门分别输入门、遗忘门和输出门。
## 深入理解LSTM
### 遗忘门

在我们 LSTM 中的第一步是决定我们会从细胞状态中丢弃什么信息。这个决定通过一个称为忘记门层完成。该门会读取 h t − 1 h_{t−1} ht−1​和 x t x_t xt​，输出一个在 0到 1之间的数值给每个在细胞状态 C t − 1 C_{t-1} Ct−1​中的数字。1 表示“完全保留”，0 表示“完全舍弃”。

![](https://ai-studio-static-online.cdn.bcebos.com/086848434ae7446787394772f92d4bee6604345c26484cc69a7237683b359333)


其中ht−1表示的是上一个cell的输出，xt表示的是当前细胞的输入。σσ表示sigmod函数。
### 输入门

下一步是决定让多少新的信息加入到 cell 状态 中来。实现这个需要包括两个 步骤：首先，一个叫做“input gate layer ”的 sigmoid 层决定哪些信息需要更新；一个 tanh 层生成一个向量，也就是备选的用来更新的内容，C^t 。在下一步，我们把这两部分联合起来，对 cell 的状态进行一个更新。

![](https://ai-studio-static-online.cdn.bcebos.com/9595b31b4bbb47b29cdc75316a4073ddaccb5892a65140fc8f28e6b50e4f0d3b)


### 输入门

现在是更新旧细胞状态的时间了，Ct−1更新为Ct。前面的步骤已经决定了将会做什么，我们现在就是实际去完成。

我们把旧状态与ft相乘，丢弃掉我们确定需要丢弃的信息。接着加上it∗C~t。这就是新的候选值，根据我们决定更新每个状态的程度进行变化。
输出门

最终，我们需要确定输出什么值。这个输出将会基于我们的细胞状态，但是也是一个过滤后的版本。首先，我们运行一个 sigmoid 层来确定细胞状态的哪个部分将输出出去。接着，我们把细胞状态通过 tanh 进行处理（得到一个在 -1 到 1 之间的值）并将它和 sigmoid 门的输出相乘，最终我们仅仅会输出我们确定输出的那部分。

![](https://ai-studio-static-online.cdn.bcebos.com/b7c9bbd5de824335ae4fe3fec8c58c10e56e2d1e9cad4743a4172799d2c6f22a)


