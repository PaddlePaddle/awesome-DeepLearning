# 深度学习基础知识（二）
标签（空格分隔）： 未分类

---

##①损失函数方法补充
Smooth L1损失：

Smooth L1损失函数是在Fast R-CNN中被提出，主要目的是为了防止梯度爆炸。

对于目标检测中的回归问题，最初大多采用均方误差损失  ，这样反向传播对w或者b求导时仍存在误差 。那么当预测值和目标值相差很大时，就容易造成梯度爆炸。

所以我们将这种均方误差形式，转变成另一种形式，其中：

![此处输入图片的描述][1]


  ①当 ![\[公式\]][2] 时，即预测值和目标值相差小于1，不易造成梯度爆炸，此时还原成均方误差损失形式并给一个0.5的平滑系数

②当 ![\[公式\]][3] 时，即预测值和目标值相差大于等于1，易造成梯度爆炸，此时降低损失次幂数这时候反向传播求导时候就不存在 ![\[公式\]][4] 这一项了，从而防止了梯度爆炸。


##②python代码实现
  
  def smooth_l1_loss(input, target, sigma, reduce=True, normalizer=1.0):
    beta = 1. / (sigma ** 2)
    diff = torch.abs(input - target)
    cond = diff < beta
    loss = torch.where(cond, 0.5 * diff ** 2 / beta, diff - 0.5 * beta)
    if reduce:
        return torch.sum(loss) / normalizer
    return torch.sum(loss, dim=1) / normalizer

##③池化方法补充
空间金字塔池化，使得任意大小的特征图都能够转换成固定大小的特征向量，这就是空间金字塔池化的意义（多尺度特征提取出固定大小的特征向量），送入全连接层。整体框架大致为：输入图像，卷积层提取特征，空间金字塔池化提取固定大小特征，全连接层。

![此处输入图片的描述][5]


   首先通过选择性搜索（selective search），对待检测的图片进行搜索出2000个候选窗口。这一步和R-CNN一样。

特征提取阶段。这一步就是和R-CNN最大的区别了，同样是用卷积神经网络进行特征提取，但是SPP-Net用的是金字塔池化。这一步骤的具体操作如下：把整张待检测的图片，输入CNN中，进行一次性特征提取，得到feature maps，然后在feature maps中找到各个候选框的区域，再对各个候选框采用金字塔空间池化，提取出固定长度的特征向量。而R-CNN输入的是每个候选框，然后在进入CNN，因为SPP-Net只需要一次对整张图片进行特征提取，速度是大大地快啊。江湖传说可一个提高100倍的速度，因为R-CNN就相当于遍历一个CNN两千次，而SPP-Net只需要遍历1次。

最后采用SVM算法进行特征向量分类识别，和R-CNN一样。

##④数据增强方法修改及补充
**Autoaugmentation**

AutoAugment是Google提出的自动选择最优数据增强方案的研究，这是无监督数据增强的重要研究方向。它的基本思路是使用增强学习从数据本身寻找最佳图像变换策略，对于不同的任务学习不同的增强方法，流程如下：

(1) 准备16个常用的数据增强操作。

(2) 从16个中选择5个操作，随机产生使用该操作的概率和相应的幅度，将其称为一个sub-policy，一共产生5个sub-polices。

(3) 对训练过程中每一个batch的图片，随机采用5个sub-polices操作中的一种。

(4) 通过模型在验证集上的泛化能力来反馈，使用的优化方法是增强学习方法。

(5) 经过80~100个epoch后网络开始学习到有效的sub-policies。

(6) 之后串接这5个sub-policies，然后再进行最后的训练。

总的来说，就是学习已有数据增强的组合策略，对于门牌数字识别等任务，研究表明剪切和平移等几何变换能够获得最佳效果。


而对于ImageNet中的图像分类任务，AutoAugment学习到了不使用剪切，也不完全反转颜色，因为这些变换会导致图像失真。AutoAugment学习到的是侧重于微调颜色和色相分布。

##⑤图像分类方法综述

传统图像分类算法
![此处输入图片的描述][6]


###深度学习算法
  
  1、CNN
  传统CNN包含卷积层、全连接层等组件，并采用softmax多类别分类器和多类交叉熵损失函数
  l 卷积层(convolution layer): 执行卷积操作提取底层到高层的特征，发掘出图片局部关联性质和空间不变性质。

l 池化层(pooling layer): 执行降采样操作。通过取卷积输出特征图中局部区块的最大值(max-pooling)或者均值(avg-pooling)。降采样也是图像处理中常见的一种操作，可以过滤掉一些不重要的高频信息。

l 全连接层(fully-connected layer，或者fc layer): 输入层到隐藏层的神经元是全部连接的。

l 非线性变化: 卷积层、全连接层后面一般都会接非线性变化函数，例如Sigmoid、Tanh、ReLu等来增强网络的表达能力，在CNN里最常使用的为ReLu激活函数。

l Dropout: 在模型训练阶段随机让一些隐层节点权重不工作，提高网络的泛化能力，一定程度上防止过拟合。

  ![此处输入图片的描述][7]
  2、VGG
  
  牛津大学VGG(Visual Geometry Group)组在2014年ILSVRC提出的模型被称作VGG模型。该模型相比以往模型进一步加宽和加深了网络结构，它的核心是五组卷积操作，每两组之间做Max-Pooling空间降维。同一组内采用多次连续的3X3卷积，卷积核的数目由较浅组的64增多到最深组的512，同一组内的卷积核数目是一样的。卷积之后接两层全连接层，之后是分类层。

由于每组内卷积层的不同，有11、13、16、19层这几种模型，下图展示一个16层的网络结构。VGG模型结构相对简洁，提出之后也有很多文章基于此模型进行研究，如在ImageNet上首次公开超过人眼识别的模型就是借鉴VGG模型的结构。

  ![此处输入图片的描述][8]
  3、GoogLeNet
  GoogLeNet 在2014年ILSVRC的获得了冠军，在介绍该模型之前我们先来了解NIN(Network in Network)模型和Inception模块，因为GoogLeNet模型由多组Inception模块组成，模型设计借鉴了NIN的一些思想。

NIN模型主要有两个特点：

1.引入了多层感知卷积网络(Multi-Layer Perceptron Convolution, MLPconv)代替一层线性卷积网络。MLPconv是一个微小的多层卷积网络，即在线性卷积后面增加若干层1x1的卷积，这样可以提取出高度非线性特征。

2.传统的CNN最后几层一般都是全连接层，参数较多。而NIN模型设计最后一层卷积层包含类别维度大小的特征图，然后采用全局均值池化(Avg-Pooling)替代全连接层，得到类别维度大小的向量，再进行分类。这种替代全连接层的方式有利于减少参数。

Inception模块如下图8所示，下图左是最简单的设计，输出是3个卷积层和一个池化层的特征拼接。这种设计的缺点是池化层不会改变特征通道数，拼接后会导致特征的通道数较大，经过几层这样的模块堆积后，通道数会越来越大，导致参数和计算量也随之增大。

为了改善这个缺点，下图右引入3个1x1卷积层进行降维，所谓的降维就是减少通道数，同时如NIN模型中提到的1x1卷积也可以修正线性特征。

  ![此处输入图片的描述][9]
  4、ResNet
  ResNet(Residual Network) 是2015年ImageNet图像分类、图像物体定位和图像物体检测比赛的冠军。针对随着网络训练加深导致准确度下降的问题，ResNet提出了残差学习方法来减轻训练深层网络的困难。

在已有设计思路(BN, 小卷积核，全卷积网络)的基础上，引入了残差模块。每个残差模块包含两条路径，其中一条路径是输入特征的直连通路，另一条路径对该特征做两到三次卷积操作得到该特征的残差，最后再将两条路径上的特征相加。

残差模块如图10所示，左边是基本模块连接方式，由两个输出通道数相同的3x3卷积组成。右边是瓶颈模块(Bottleneck)连接方式，之所以称为瓶颈，是因为上面的1x1卷积用来降维(图示例即256->64)，下面的1x1卷积用来升维(图示例即64->256)，这样中间3x3卷积的输入和输出通道数都较小

![此处输入图片的描述][10]


  [1]: https://pic1.zhimg.com/80/v2-3c8e2374fdb43666560924189362f9c4_720w.jpg
  [2]: https://www.zhihu.com/equation?tex=%7Cy-f%28z%29%7C%3C1
  [3]: https://www.zhihu.com/equation?tex=%7Cy-f%28z%29%7C%5Cgeq1
  [4]: https://www.zhihu.com/equation?tex=y-f%28z%29
  [5]: https://user-images.githubusercontent.com/86996619/125158598-bc999500-e1a4-11eb-8418-1e8422344dc9.png
  [6]: https://img-blog.csdnimg.cn/20200615201932843.png
  [7]: https://img-blog.csdnimg.cn/20200615202058322.png
  [8]: https://img-blog.csdnimg.cn/20200615202148341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0F2ZXJ5MTIzMTIz,size_16,color_FFFFFF,t_70
  [9]: https://img-blog.csdnimg.cn/20200615202310244.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0F2ZXJ5MTIzMTIz,size_16,color_FFFFFF,t_70
  [10]: https://img-blog.csdnimg.cn/2020061520232245.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0F2ZXJ5MTIzMTIz,size_16,color_FFFFFF,t_70