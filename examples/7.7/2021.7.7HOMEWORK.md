###2021.7.7HOMEWORK 
####损失函数补充
 其实顾名思义，smooth L1说的是光滑之后的L1，前面说过了L1损失的缺点就是有折点，不光滑，那如何让其变得光滑呢？ smooth L1损失函数为：
![Alt text](./4.png)

  smooth L1损失函数曲线如下图所示，作者这样设置的目的是想让loss对于离群点更加鲁棒，相比于L2损失函数，其对离群点（指的是距离中心较远的点）、异常值（outlier）不敏感，可控制梯度的量级使训练时不容易跑飞。 
  ![Alt text](./5.png)

  smooth L1损失函数曲线。 
 实现代码 
 

```
import numpy as np
import torch
 
import torch.nn.functional as F
 
a=torch.Tensor([1,5,3,0.5,0.9])
b=torch.Tensor([4,1,0,0.4,0.2])
 
loss1=F.smooth_l1_loss(a,b)
 
loss_part1=torch.abs(a-b)
loss_part2=loss_part1**2
loss_part2=loss_part2*0.50
 
print()
loss2=torch.where(loss_part1>=1,loss_part1-0.5,loss_part2)
loss2=torch.mean(loss2)
print(loss1)
print(loss2)
```

####池化方法补充
  1、简介 空间金字塔池化，使得任意大小的特征图都能够转换成固定大小的特征向量，这就是空间金字塔池化的意义（多尺度特征提取出固定大小的特征向量），送入全连接层。整体框架大致为：输入图像，卷积层提取特征，空间金字塔池化提取固定大小特征，全连接层。 
  具体的流程图如下：
![Alt text](./6.jpg)

 2、算法流程 首先通过选择性搜索（selective search），对待检测的图片进行搜索出2000个候选窗口。这一步和R-CNN一样。 特征提取阶段。这一步就是和R-CNN最大的区别了，同样是用卷积神经网络进行特征提取，但是SPP-Net用的是金字塔池化。这一步骤的具体操作如下：把整张待检测的图片，输入CNN中，进行一次性特征提取，得到feature maps，然后在feature maps中找到各个候选框的区域，再对各个候选框采用金字塔空间池化，提取出固定长度的特征向量。而R-CNN输入的是每个候选框，然后在进入CNN，因为SPP-Net只需要一次对整张图片进行特征提取，速度是大大地快啊。江湖传说可一个提高100倍的速度，因为R-CNN就相当于遍历一个CNN两千次，而SPP-Net只需要遍历1次。 最后采用SVM算法进行特征向量分类识别，和R-CNN一样。

####数据增强方法补充
谷歌大脑提出自动数据增强方法AutoAugment：可迁移至不同数据集
近日，来自谷歌大脑的研究者在 arXiv 上发表论文，提出一种自动搜索合适数据增强策略的方法 AutoAugment，该方法创建一个数据增强策略的搜索空间，利用搜索算法选取适合特定数据集的数据增强策略。此外，从一个数据集中学到的策略能够很好地迁移到其它相似的数据集上。
摘要
在本论文中，我们进一步研究了用于图像的数据增强技术，并提出了一个名为「AutoAugment」的简单过程，用来搜索改进的数据增强策略。本文主要的观点是创建一个数据增强策略的搜索空间，直接在感兴趣的数据集上评估特定策略的质量。在「AutoAugment」的实现过程中，我们设计了一个搜索空间，该搜索空间中的一个策略包含了许多子策略，我们为每个小批量（mini-batch）中的每张图像随机选择一个子策略。每个子策略由两个操作组成，每个操作都是类似于平移、旋转或剪切的图像处理函数，以及应用这些函数的概率和幅度（magnitude）。我们使用搜索算法来寻找最佳策略，这样神经网络就能在目标数据集上获得最高的验证准确率。我们的方法在 CIFAR-10、CIFAR-100、SVHN 和 ImageNet 上取得了目前最高的准确率（在不加入额外数据的情况下）。在 ImageNet 上，我们取得了 83.54% 的 Top-1 准确率。在 CIFAR-10 上，我们取得了 1.48% 的误差率，比之前最佳模型的误差率低 0.65%。在简化数据集上，AutoAugment 的性能与不使用任何非标注样本的半监督学习方法相当。最后，从一个数据集中学到的策略能够被很好地迁移到其它相似的数据集上。例如，在 ImageNet 上学到的策略能够让我们在细粒度视觉分类数据集 Stanford Cars 上取得目前最高的准确率，并且不用在额外的数据上对预训练的权重进行调优。
自动增强
作者将寻找最佳数据增强策略的问题形式化为一个离散搜索问题。在搜索空间中，一个策略由 5 个子策略组成，每个子策略又包含依次被应用的两个图像处理操作，每个操作也都和两个超参数相关：1）应用操作的概率 2）操作的幅度。
图 1 展示了在搜索空间中的一个包含 5 个子策略的策略示例。第一个子策略指定了依次进行对 X 坐标的剪切（ShearX）和图像翻转操作（Invert）。应用 ShearX 操作的概率是 0.9，并且当应用这个操作时，其幅度为十分之七。接着，作者以 0.8 的概率应用 Invert 操作，该操作不使用幅度信息。作者强调这些操作需要按照指定顺序执行。 图 1：在 SVHN 上发现的一个策略，以及如何使用它在给定用于训练神经网络的原始图像的条件下来生成增强后的数据。这个策略包含 5 个子策略。对于小批量中的每一张图像，作者均匀地随机选取一个子策略去生成一张变换后的图像来训练神经网络。每个子策略由两个操作组成，每个操作都与两个数值相关联：调用操作的概率、操作的幅度。由于存在调用操作的概率，因此该操作在这个小批量中可能不被应用。然而，如果它被应用了，这个应用的幅度就是固定的。作者通过展示即使使用相同的子策略，一个示例图片能够在不同的小批量中被不同地变换，强调了应用子策略的随机性。正如文中所解释的，在 SVHN 上，AutoAugment 更常采取几何变换措施。我们可以从中看出为什么翻转（Invert）在 SVHN 上是一个被普遍选择的操作，因为图像中的数字在这种变换下具有不变性。

####图像分类方法
#####Nearest Neighbor
"Nearest Neighbor"是处理图像分类问题一个较为简单、直接、粗暴的方法：首先在系统中“记住”所有已经标注好类别的图像（其实这就是训练集），当遇到一个要判断的还未标注的图像（也就是测试集中的某个图像）时，就去比较这个图像与“记住的”图像的“相似性”，找到那个最相似的已经标注好的图像，用那个图像的类别作为正在分类的图像的类别，这也就是"Nearest Neighbor"名称的含义。
#####K-Nearest Neighbor
"K-Nearest Neighbor"是很自然想到的一个在"Nearest Neighbor"基础上进行改进的方法，与"Nearest Neighbor"不同的是，"K-Nearest Neighbor"不再将“最接近”的那一个图像的类别作为预测图像的类别，而是选出K个与预测图像“最接近”的图像，看其中哪个类别占的比例最高，就将其作为预测图像的类别，这样可以在某种程度上增加预测模型的稳定性。
此处的K是一个hyper-parameter（超参数），也就是不能由模型学得，而是需要自己去设定，可以尝试的值如10、5、20等，具体选取哪个值可以通过Cross Validation（交叉验证法）来确定。
#####Linear Classification
上面的"Nearest Neighbor"和"K-Nearest Neighbor"方法，都是直接比较图像的相似性，存在测试效率太低的问题，并且不能够提取图像的语义信息，导致错误率很高。
Linear Classification利用一个“全连接层”(Fully Connected Layer)，输入图像的所有像素值，经过全连接层的运算后输出每个类别的“得分”，最终选取得分最高的类别作为图像的类别。
#####Convolutional Neural Network(CNN，卷积神经网络)
利用CNN可以进一步提高图像分类的正确率，甚至已经可以超过人类。
实验发现，具有3个卷积层的网络，可以将图片分类的精度提升到70%左右，相较于前面的方法已经有了很大的进步，但其实利用深度神经网络还可以表现的更好（所谓的“深度神经网络”其实就是让网络具有更多的卷积层，变得“更深”），一些深度的网络已经可以将图片分类的精度提升到了95%以上。