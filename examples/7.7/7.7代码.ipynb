{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/aistudio/data': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **1. ResNet**\n",
    "\n",
    "&emsp;&emsp;LeNet 和 AlexNet的提出开启了卷积神经网络应用的先河，随后的GoogleNet、VGG等网络使用了更小的卷积核并加大了深度，证明了卷积神经网络在处理图像问题方面具有更加好的性能；但是随着层数的不断加深，卷积神经网络也暴露出来许多问题：\n",
    "\n",
    "&emsp;&emsp;1.理论上讲，层数越多、模型越复杂，其性能就应该越好；但是实验证明随着层数的不断加深，性能反而有所下降。\n",
    "\n",
    "&emsp;&emsp;2.深度卷积网络往往存在着梯度消失/梯度爆炸的问题；由于梯度反向传播过程中，如果梯度都大于1，则每一层大于1的梯度会不断相乘，使梯度呈指数型增长；同理如果梯度都小于1，梯度则会逐渐趋于零；使得深度卷积网络难以训练。\n",
    "\n",
    "&emsp;&emsp;3.训练深层网络时会出现退化：随着网络深度的增加，准确率达到饱和，然后迅速退化。\n",
    "\n",
    "&emsp;&emsp;而ResNet提出的残差结构，则一定程度上缓解了模型退化和梯度消失问题：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6f8bf8f0bc2146a59e903d757b4614a0513b4a735ec94bc9ab602cf27c42996b)\n",
    "\n",
    "&emsp;&emsp;作者提出，在一个结构单元中，如果我们想要学习的映射本来是y=H(x)，那么跟学习y=F(x)+x这个映射是等效的；这样就将本来回归的目标函数H(x)转化为F(x)+x，即F(x) = H(x) - x，称之为残差。\n",
    "\n",
    "&emsp;&emsp;于是，ResNet相当于将学习目标改变了，不再是学习一个完整的输出，而是目标值H(x)和x的差值，即去掉映射前后相同的主体部分，从而突出微小的变化，也能够将不同的特征层融合。而且y=F(x)+x在反向传播求导时，x项的导数恒为1这样也解决了梯度消失问题。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **2.DenseNet**\n",
    "\n",
    "&emsp;&emsp;DenseNet 的主要思想是将每一层都与后面的层都紧密（Dense）连接起来，将特征图重复利用，网络更窄，参数更少，对特征层能够更有效地利用和传递，并减轻了梯度消失的问题。\n",
    "\n",
    "&emsp;&emsp;网络结构如图：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/94a4783006be4b018f37c10b09396e2ce8a52acc0e294e9d9c65eda1e5daa9ef)\n",
    "\n",
    "&emsp;&emsp;其基本的结构单元为：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1a769f62b5e143508ddeb06ddcd9c2ba697b46760c2c4b038541a6502d0c8386)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **代码实现**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#导入需要的包\r\n",
    "import numpy as np\r\n",
    "import paddle as paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from PIL import Image\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: \u001b[93m\n",
      "Warning:\n",
      "API \"paddle.dataset.mnist.train\" is deprecated since 2.0.0, and will be removed in future versions. Please use \"paddle.vision.datasets.MNIST\" instead.\n",
      "reason: Please use new dataset API which supports paddle.io.DataLoader \u001b[0m\n",
      "  \"\"\"\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: \u001b[93m\n",
      "Warning:\n",
      "API \"paddle.dataset.mnist.test\" is deprecated since 2.0.0, and will be removed in future versions. Please use \"paddle.vision.datasets.MNIST\" instead.\n",
      "reason: Please use new dataset API which supports paddle.io.DataLoader \u001b[0m\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: \u001b[93m\n",
      "Warning:\n",
      "API \"paddle.dataset.mnist.train\" is deprecated since 2.0.0, and will be removed in future versions. Please use \"paddle.vision.datasets.MNIST\" instead.\n",
      "reason: Please use new dataset API which supports paddle.io.DataLoader \u001b[0m\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "BUF_SIZE=128 # 每次缓存队列中保存数据的个数\r\n",
    "BATCH_SIZE=32 # 批次大小\r\n",
    "\r\n",
    "train_reader = paddle.batch(\r\n",
    "    paddle.reader.shuffle(paddle.dataset.mnist.train(),\r\n",
    "                          buf_size=BUF_SIZE),\r\n",
    "    batch_size=BATCH_SIZE) # paddle 给的数据迭代器\r\n",
    "\r\n",
    "test_reader = paddle.batch(\r\n",
    "    paddle.reader.shuffle(paddle.dataset.mnist.test(),\r\n",
    "                          buf_size=BUF_SIZE),\r\n",
    "    batch_size=BATCH_SIZE)    \r\n",
    "\r\n",
    "train_data=paddle.dataset.mnist.train();  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义DenseNet\r\n",
    "\r\n",
    "class DenseNet(): \r\n",
    "    def __init__(self, layers, dropout_prob):\r\n",
    "        self.layers = layers\r\n",
    "        self.dropout_prob = dropout_prob\r\n",
    "\r\n",
    "    def bottleneck_layer(self, input, fliter_num, name):\r\n",
    "        bn = fluid.layers.batch_norm(input=input, act='relu', name=name + '_bn1')\r\n",
    "        conv1 = fluid.layers.conv2d(input=bn, num_filters=fliter_num * 4, filter_size=1, name=name + '_conv1')\r\n",
    "        dropout = fluid.layers.dropout(x=conv1, dropout_prob=self.dropout_prob)\r\n",
    "\r\n",
    "        bn = fluid.layers.batch_norm(input=dropout, act='relu', name=name + '_bn2')\r\n",
    "        conv2 = fluid.layers.conv2d(input=bn, num_filters=fliter_num, filter_size=3, padding=1, name=name + '_conv2')\r\n",
    "        dropout = fluid.layers.dropout(x=conv2, dropout_prob=self.dropout_prob)\r\n",
    "\r\n",
    "        return dropout\r\n",
    "\r\n",
    "    def dense_block(self, input, block_num, fliter_num, name):\r\n",
    "        layers = []\r\n",
    "        layers.append(input)#拼接到列表\r\n",
    "\r\n",
    "        x = self.bottleneck_layer(input, fliter_num, name=name + '_bottle_' + str(0))\r\n",
    "        layers.append(x)\r\n",
    "        for i in range(block_num - 1):\r\n",
    "            x = paddle.fluid.layers.concat(layers, axis=1)\r\n",
    "            x = self.bottleneck_layer(x, fliter_num, name=name + '_bottle_' + str(i + 1))\r\n",
    "            layers.append(x)\r\n",
    "\r\n",
    "        return paddle.fluid.layers.concat(layers, axis=1)\r\n",
    "\r\n",
    "    def transition_layer(self, input, fliter_num, name):\r\n",
    "        bn = fluid.layers.batch_norm(input=input, act='relu', name=name + '_bn1')\r\n",
    "        conv1 = fluid.layers.conv2d(input=bn, num_filters=fliter_num, filter_size=1, name=name + '_conv1') \r\n",
    "        dropout = fluid.layers.dropout(x=conv1, dropout_prob=self.dropout_prob)\r\n",
    "\r\n",
    "        return fluid.layers.pool2d(input=dropout, pool_size=2, pool_type='avg', pool_stride=2) \r\n",
    "    def net(self, input, class_dim=1000): \r\n",
    "\r\n",
    "        layer_count_dict = {\r\n",
    "            9: (32, [3, 3, 6])\r\n",
    "        }\r\n",
    "        layer_conf = layer_count_dict[self.layers]\r\n",
    "\r\n",
    "        conv = fluid.layers.conv2d(input=input, num_filters=layer_conf[0] * 2, \r\n",
    "            filter_size=3, name='densenet_conv0')\r\n",
    "        conv = fluid.layers.pool2d(input=conv, pool_size=2, pool_padding=1, pool_type='max', pool_stride=2)\r\n",
    "        for i in range(len(layer_conf[1]) - 1):\r\n",
    "            conv = self.dense_block(conv, layer_conf[1][i], layer_conf[0], 'dense_' + str(i))\r\n",
    "            conv = self.transition_layer(conv, layer_conf[0], name='trans_' + str(i))\r\n",
    "\r\n",
    "        conv = self.dense_block(conv, layer_conf[1][-1], layer_conf[0], 'dense_' + str(len(layer_conf[1])))\r\n",
    "        conv = fluid.layers.pool2d(input=conv, global_pooling=True, pool_type='avg')\r\n",
    "        out = fluid.layers.fc(conv, class_dim, act='softmax')\r\n",
    "\r\n",
    "        return out\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入输出层\r\n",
    "paddle.enable_static()\r\n",
    "image = fluid.layers.data(name='image', shape=[1, 28, 28], dtype='float32')#单通道，28*28像素值\r\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64') # 图片标签\r\n",
    "# 获取分类器\r\n",
    "model = DenseNet(9, 0.5)\r\n",
    "out = model.net(input=image, class_dim=10)\r\n",
    "# 获取损失函数和准确率函数\r\n",
    "cost = fluid.layers.cross_entropy(input=out, label=label)  #使用交叉熵损失函数,描述真实样本标签和预测概率之间的差值\r\n",
    "avg_cost = fluid.layers.mean(cost)\r\n",
    "acc = fluid.layers.accuracy(input=out, label=label) # 定义准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义优化方法\r\n",
    "optimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.001)   #使用Adam算法进行优化\r\n",
    "opts = optimizer.minimize(avg_cost)\r\n",
    "# 定义一个使用CPU的解析器\r\n",
    "place = fluid.CPUPlace()\r\n",
    "exe = fluid.Executor(place)\r\n",
    "exe.run(fluid.default_startup_program())\r\n",
    "\r\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[image, label])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_train_iter=0\r\n",
    "all_train_iters=[]\r\n",
    "all_train_costs=[]\r\n",
    "all_train_accs=[]\r\n",
    "\r\n",
    "#绘制训练时loss图像\r\n",
    "def draw_train_process(title,iters,costs,accs,label_cost,lable_acc):\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    plt.xlabel(\"iter\", fontsize=20)\r\n",
    "    plt.ylabel(\"cost/acc\", fontsize=20)\r\n",
    "    plt.plot(iters, costs,color='red',label=label_cost) \r\n",
    "    plt.plot(iters, accs,color='green',label=lable_acc) \r\n",
    "    plt.legend()\r\n",
    "    plt.grid()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:2.25162, Accuracy:0.12500\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM=1  # 调参 训练轮数\r\n",
    "for pass_id in range(EPOCH_NUM):\r\n",
    "    # 进行训练\r\n",
    "    for batch_id, data in enumerate(train_reader()):                         #遍历train_reader\r\n",
    "        train_cost, train_acc = exe.run(program=fluid.default_main_program(),#运行主程序\r\n",
    "                                        feed=feeder.feed(data),              #给模型喂入数据\r\n",
    "                                        fetch_list=[avg_cost, acc])          #fetch 误差、准确率                                          \r\n",
    "        all_train_iter=all_train_iter+1\r\n",
    "        all_train_iters.append(all_train_iter)\r\n",
    "        all_train_costs.append(train_cost[0])\r\n",
    "        all_train_accs.append(train_acc[0])        \r\n",
    "        # 每100个batch打印一次信息  误差、准确率\r\n",
    "        if batch_id % 200 == 0:\r\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\r\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))\r\n",
    "\r\n",
    "    # 进行测试\r\n",
    "    test_accs = []\r\n",
    "    test_costs = []\r\n",
    "    #每训练一轮 进行一次测试\r\n",
    "    for batch_id, data in enumerate(test_reader()):                         #遍历test_reader\r\n",
    "        test_cost, test_acc = exe.run(program=fluid.default_main_program(), #执行训练程序\r\n",
    "                                      feed=feeder.feed(data),               #喂入数据\r\n",
    "                                      fetch_list=[avg_cost, acc])           #fetch 误差、准确率\r\n",
    "        test_accs.append(test_acc[0])                                       #每个batch的准确率\r\n",
    "        test_costs.append(test_cost[0])                                     #每个batch的误差                              \r\n",
    "    # 求测试结果的平均值\r\n",
    "    test_cost = (sum(test_costs) / len(test_costs))                         #每轮的平均误差\r\n",
    "    test_acc = (sum(test_accs) / len(test_accs))                            #每轮的平均准确率\r\n",
    "    print('Test:%d, Cost:%0.5f, Accuracy:%0.5f' % (pass_id, test_cost, test_acc))    \r\n",
    "draw_train_process(\"training\",all_train_iters,all_train_costs,all_train_accs,\"trainning cost\",\"trainning acc\")\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
