# 概述
Loss 是深度学习算法中重要的一部分，它的主要功能是评价网络预测的准确性和指导权重更新。合适的 Loss 可以让网络收敛更快，预测更准。下面简要介绍了损失函数以及7种常用损失函数的形式，性质，参数，区别及使用场景，并给出了Python + Numpy实现，是对awesome-DeepLearning repo中损失函数的补充。主要内容包括：
- L1(Mean Absolute Error)
- Huber Loss
- LogCosh Loss
- Weighed Cross Entropy
- Balanced Cross Entropy
- Focal Loss
- Hinge Loss

## 损失函数介绍
形式化的，我们可以这样描述**监督学习**: 给算法一个有标签的训练数据集 $(X, Y)$，希望算法能学习出一个 $X->Y$ 的映射关系 $f$，使得不仅对于训练集中的 $x$，有$f(x)$ 与对应的 $y$ 接近，而且对不在训练集中的 $x$， $f(x)$ 也与实际的 $y$ 接近。

但具体怎么操作呢？我们在理解监督学习概念的时候可以用 “接近” 这样定性的描述，但是算法需要一个函数来量化模型给出的预测和训练数据中对应标签的差异，我们把这个函数叫做Loss。形式化的，可以将Loss定义为网络预测值 $p$ 和实际标签 $y$ 的函数 $L(p, y)$。

不同的学习任务输出的形式不同，定义 “接近” 的标准也不同，Loss 因此有很多种，但大致可以分为两类: 回归 Loss 和 分类 Loss。 

# 符号
下面的表达式都按照这个符号标准：
- x:训练数据集中的一个输入
- y:训练数据集中的一个输出
- p:网络针对一个输入给出的预测值
- M:分类问题中的类别数量
- N:输入loss的数据条数，可以理解为Batch Size
- i:第i条数据
- j:第j个输出

# 回归 Loss

## Mean Absolute Error (L1 Loss)
$$L1 Loss = \frac{1}{N} \sum \left | y - p \right |$$

L1 Loss 同 MSE 损失是分类问题中出现的最频繁的 Loss，二者很类似，而且一些性质比较着解释更清楚，因此放在一起。首先计算方法上 L1 Loss 是求所有预测值和标签距离的平均数，MSE 损失是求预测值和标签距离平方的平均数。二者的结构很类似，区别就是一个用了绝对值一个用了平方。在性质上，二者主要在对离群点鲁棒性，梯度和是否可微三方面不同，这也是对这两个 Loss 进行选择的标准。

### 离群点鲁棒性
离群点是数据中明显偏离整体分布的点。比如整理数据的时候 1.5 忘写小数点变成了 15，而其他数据都是1.x，那这个数据点就是一个离群点。 **MSE 损失比 L1 对离群点更敏感。**  MSE 损失对于预测值和标签的距离做了平方，当距离大于 1 的时候平方操作会放大误差，因此离群点的 Loss 会非常大，导致 MSE 损失对其倾斜更多的权重。相比之下 L1 Loss 只做了绝对值，所以对离群点不如 MSE 损失敏感。

### 梯度
对 L1 和 MSE 损失求导可以知道 L1 Loss 的梯度一直是 $\plusmn 1$，而 MSE 损失的梯度是正比于 Loss 值的，Loss 值越大梯度越大。这一点 MSE 损失是优于 L1 的，体现在两个方面。当Loss非常大的时候，L1的梯度一直是$1$，这样收敛的速度比 MSE 慢。其次当 Loss 很接近0的时候L1的梯度还是1，这个大梯度容易让网络越过 Loss 最低点，导致 Loss 在最低点附近震荡，相比之下 MSE 在 Loss 接近0的时候梯度也接近0，不存在这样震荡的问题。因此在离群点不多的前提下，希望网络更快更稳定地收敛应该选择 MSE Loss。

### 可微
因为L1 Loss是个分段函数，所以在最低点是不可微的。MSE则全程可微，最后一定会稳定收敛到一个最优解。虽然性质上 MSE 优于 L1，但是实际使用时反向传递都由框架实现，因此不影响选择。

下面是实现：


```python
# 初始化一些环境，这个部分下面所有Loss都会用到
import numpy as np

def l1_loss(pred, label):
    loss = np.abs(pred - label)
    loss = np.mean(loss)
    return loss

pred_val = np.array([[1], [2], [3] ],dtype="float32")
gt_val = np.array([[1], [3], [6] ],dtype="float32")

loss_value=l1_loss(pred_val, gt_val)
print("L1 Loss:", loss_value)
```

    L1 Loss: 1.3333334

# Mean Bias Error
$$MeanBiasError = \frac{1}{N} (p-y)$$

MBE是不做绝对值的 L1 Loss，它的一个主要的问题是正负 Loss 会相互抵消，在深度学习的应用极少。但是因为没做绝对值所以可以看出网络预测的结果是偏大还是偏小，除非有这个非常具体的需求不要基本用不上 MBE。


```python
def mean_bias_error(pred, label):
    loss = pred - label
    loss = np.mean(loss)
    return loss

pred_val = np.array([[3], [2], [1] ],dtype="float32")
gt_val = np.array([[1], [2], [3] ],dtype="float32")

loss_value=mean_bias_error(pred_val, gt_val)
print("MBE:", loss_value)
```

    MBE: 0.0


# Huber loss(Smooth L1 Loss)

$$HuberLoss = \left \{ \begin{matrix}
\frac{1}{2}(y - p)^{2} & |y-p| \leq\delta \\ 
\delta|y-p|-\frac{1}{2}\delta^{2} & otherwise
\end{matrix}\right.$$

Huber是 L1 和 MSE Loss 的分段组合。前面我们已经知道 L1 在有离群点时性能好，MSE 在接近零点处稳定收敛, 于是将二者组合：在零点附近用MSE，其余位置用 L1 就形成了 Huber Loss。具体的选择范围用 $\delta$ 划分。 $\delta$ 取 1 的 Huber Loss 也叫 Smooth L1 Loss，所以说 Smooth L1 是 Huber 的一种情况。

分段组合克服了两个 Loss 各自的一部分弱点，Huber Loss对离群点没有 MSE 敏感，在零点附近也不会出现 L1 的震荡。通过调节 $\delta$ 可以调节 Huber Loss 对离群点的敏感度，$\delta$ 越大，使用MSE的区间越大，对离群点越敏感; 反之 $\delta$ 越小越不敏感。

如果数据中存在需要克服的离群点，但是 L1 没有达到想要的效果，可以尝试 Huber Loss，它在 Loss 很小时会带来更好的收敛。



```python
def huber_loss(pred, true, delta=1):
    loss = np.where(np.abs(true-pred) <= delta , 0.5*((true-pred)**2), delta*np.abs(true - pred) - 0.5*(delta**2))
    loss = np.mean(loss)
    return loss

pred_val = np.array([[4], [2], [1] ],dtype="float32")
gt_val = np.array([[1], [2], [3] ],dtype="float32")

loss_value=huber_loss(pred_val, gt_val, 2)
print("Huber Loss:", loss_value)
```

    Huber Loss: 2.0


# log-cosh
$$LogCosh=log(cosh(y-p))$$

形如其名，Log-cosh 计算上是先做cosh之后做log。这个函数的特点是在 Loss 比较小的时候类似 $\frac{1}{2}x^{2}$ ，而在值比较大的时候近似于 $|y-p|-log(2)$。 他基本和 Huber Loss的性质相同，但是处处二阶可微。

因为涉及到log和指数操作，从纯 Loss 的计算角度比之前的平方更复杂。它的主要优点在于二阶可导，因此常在在类似 Boosting 有这种要求的优化方法中使用。



```python
def logcosh(pred,true):
    loss = np.log(np.cosh(pred - true))
    return np.sum(loss)

pred_val = np.array([[4], [2], [1] ],dtype="float32")
gt_val = np.array([[1], [2], [3] ],dtype="float32")

loss_value=logcosh(pred_val, gt_val)
print("Log-Cosh:", loss_value)
```

    Log-Cosh: 3.6343312

# 分类 Loss

分类问题和回归问题最明显的区别是分类问题输出的是一些概率，范围是0～1。我们一般在网络的输出层用 Sigmoid 函数 $\frac{1}{1+e^{-x}}$ 实现这个限制。为了说明方便，下文将网络最后一层进入启动函数 Sigmoid 之前的值称为 $O$，将经过 Sigmoid 之后的概率称为 $P$。下面是 Sigmoid 的函数图像

![](https://ai-studio-static-online.cdn.bcebos.com/d5d8fdbd2b1143afa7783b03b419bb8d0d8e7a13e54f44a5b78134a2ffa38de3)

可以看出，这个函数的函数值在输入比较大（或比较小）的时候极其接近1（或0），函数值在4的时候已经是0.982，而且很平，导数很小。我们可以设想训练中的一个情况：使用MSE Loss而且网络最后一层的 $O$ 比较大（初始化如果做的不好很可能第一个batch就是这样）。这种情况对应Sigmoid图像中X轴右侧的一个点，我们来分析此时 Loss 相对 $O$ 的梯度。在这个位置 Sigmoid 很平，所以就算 $O$ 有很大的变化对应的 $P$ 变化也很小，反映到 Loss 上变化也很小。因此当 $O$ 较大或较小的时候 Loss 的梯度都很小，会导致训练缓慢。相比之下分类 Loss 在输出接近0或1的时候极其敏感，一点很小的变化都会给 Loss 带来很大的变化，因此训练更快。

额外要说一下，分类问题里面有二分类（比如猫狗二分类）也有分成多类（比如ImageNet）的情况，多分类情况可以转换多个为二分类问题，下面主要以二分类为例介绍。

## Weighed Cross Entropy和Balanced Cross Entropy
$$WeighedCrossEntropy=-\frac{1}{N}\sum_{i=1}^{N}[wy_{i}log(p_{i})+(1-y_{i})log(1-p_{i})]$$

$$BalancedCrossEntropy=-\frac{1}{N}\sum_{i=1}^{N}[\beta y_{i}log(p_{i})+(1-\beta)(1-y_{i})log(1-p_{i})]$$

这两个 Loss 都是在交叉熵损失的基础上给 $y=1$ 和 $y=0$ 赋了不同的权重，这个权重主要解决类别不均衡的问题。

比如一个猫狗二分类数据集里面有 80 张猫和 20 张狗。就算算法根本不看输入的是什么而只是全都分类成猫，在训练集上也能取得 80% 的准确率。这显然不是我们想要的。WCE和BCE通过给不同的类别的数据产生的 Loss 赋予不同的权重克服标签不均衡。比如 WCE 给 $y=1$ 的类别一个权重 $w$， $y=0$ 的类别相当于给了权重 $1$。如果 w=1 这就是标准交叉熵，但是比如现在 $y=1$ 的类别占数据集中的1/3，$y=0$ 的类别占数据集中的2/3。这种情况下 $w$ 给2，表示可以理解为分错了一个 $y=1$ 的情况相于分错了两个，这就平衡了两个类别数量不均衡的情况。Balanced Cross Entropy也类似，只是这个函数分别给了$y=0$ 和 $y=1$ 分别以 $1-\beta$ 和 $\beta$的权重，可以认为这个beta设为 $y=0$ 的类别在数据集中的比例正好能平衡两个类别的不均衡现象。

因此如果数据集中存在这种标签不均衡的现象，选择WCE或BCE都可以降低其对训练的影响，区别就是要像上面分析的根据具体的 Loss 选择合适的参数值。


```python
def wce_loss(logits,label,weight):

    logits = logits * (1-1e-05)  # 缩放预测值，以防出现log(0)

    loss =  -1 * (np.log2(logits)*label * weight + \
           np.log2(1 - logits) * (1-label))
    print(loss)
    loss = np.mean(loss)
    return loss

pred_val = np.array([[0.9], [0.1], [1] ],dtype="float32")
gt_val = np.array([[1], [0], [1] ],dtype="float32")
weight = 1

loss_value=wce_loss(pred_val, gt_val,weight)
print("WCE Loss:", loss_value)
```

    WCE Loss: 0.10134452



```python
def balanced_ce_loss(logits,label,beta):

    logits = logits * (1-1e-05)  # 缩放预测值，以防出现log(0)

    loss =  -1 * (np.log2(logits)*label * beta + \
           np.log2(1 - logits) * (1-label)) * (1 - beta)
    loss = np.mean(loss)
    return loss

pred_val = np.array([[0.9], [0.1], [1] ],dtype="float32")
gt_val = np.array([[1], [0], [1] ],dtype="float32")
beta = 0.5

loss_value=balanced_ce_loss(pred_val, gt_val,beta)
print("Balanced Cross Entropy:", loss_value)
```

    Balanced Cross Entropy: 0.03800292


## Focal Loss
$$FocalLoss=-\frac{1}{N}\sum_{i=1}^{N}[\alpha(1-p_{i})^{\gamma}y_{i}log(p_{i}))+(1-\alpha)p_{i}^{\gamma}(1-y_{i})log(1-p_{i})]$$

Focal Loss 是交叉熵损失的进一步改进。从上面的公式可以看出它在 Balanced Cross Entropy 基础上，在$y=0$ 时乘上了一个预测值的 $\gamma$ 次方，$y=1$ 时乘上了一个 (1-预测值) 的 $\gamma$ 次方。这项的意思是让算法  **更加关注那些不确定的情况，忽略很确定的情况。** 比如如果 $y=0$ 说明我们希望 $p=0$ ，如果此时 $p$ 已经接近 0 了那么 $p^{gamma}$ 就会很接近0，这样这项的 Loss 就会很小，反之会很大。因此通过这一项Focal Loss实现了让网络关注更难的case的功能。

Focal Loss在分割场景下比较常用，因为通常对目标进行分割时主要的偏差都出在边界上。相比目标中间的部分，边界通常不容易划分，这样数据中就存在难易程度的区别。这种情况下使用 Focal Loss 有可能比 BCE 或 WCE 取得更好的性能。此外通过调整Focal Loss中的参数，他可以退化成前面的三个 Loss。 因此用 Focal Loss调节参数就相当于实验了三种 Loss，代码上比较方便。


```python
def focal_loss(logits, label, alpha, gamma):
    '''
        alpha 越大越关注y=1的情况
        gamma 越大越关注不确定的情况
    '''
    logits = logits * (1-1e-05)  # 缩放预测值，以防出现log(0)

    p_1 = - alpha*np.power(1-logits,gamma)*np.log2(logits)*label
    p_0 = - (1-alpha)*np.power(logits,gamma)*np.log2(1-logits)*(1-label)
    loss = p_0 + p_1
    loss = np.mean(loss)
    return loss

pred_val = np.array([[0.9], [0.1], [1] ],dtype="float32")
gt_val = np.array([[1], [0], [1] ],dtype="float32")
alpha = 0.25
gamma = 2

loss_value=focal_loss(pred_val, gt_val,alpha,gamma)
print("Focal Loss:", loss_value)
```

    Focal Loss: 0.0005067004


# Hinge Loss
$$HingeLoss=\frac{1}{N}\sum_{i=1}^{N}max(0,1-y_{i}p_{i})$$

Hinge Loss 主要用在支持向量机中，它的标签和之前的0/1不同，正例的标签是1，负例的标签是-1。Hinge Loss的图像如下：

![](https://ai-studio-static-online.cdn.bcebos.com/72fa02b239b4495dac82e23622e196d536109f138ddb4985ba515dd0dc206872)

可以看出它不仅惩罚错误的预测，而且惩罚不自信的正确预测。和前面的交叉熵相比，Hinge Loss本身在形式上更简单，运算更快，而且因为一些情况下 Loss 是 0 不需要进行反向传递因此训练速度快。如果不是很关注正确性但是需要作出实时决策或者进行少量在线训练， Hinge 是很合适的。


```python
def hinge_loss(pred, label):
    zeros = np.zeros_like(pred)
    loss = np.maximum(zeros,1-(pred*label))
    loss = np.mean(loss)
    return loss

pred_val = np.array([[0.9], [0.1], [1] ],dtype="float32")
gt_val = np.array([[1], [-1], [1] ],dtype="float32")

loss_value=hinge_loss(pred_val, gt_val)
print("Hinge Loss:",loss_value)
```

    Hinge Loss: 0.4



