# 7.7一、深度学习基础知识
#### ①损失函数方法补充
Smooth L1损失函数（回归）
Smooth L1损失函数是在Fast R-CNN中被提出，他的bound box的回归方式使用了该损失函数

对于目标检测中的回归问题，最初大多采用均方误差损失
![Alt text](./1625916740969.png)
这样反向传播对w或者b求导时仍存在
![Alt text](./1625916758774.png)
那么当预测值和目标值相差很大时，就容易造成梯度爆炸。

所以我们将
![Alt text](./1625916825170.png)

这种均方误差形式，转变成
![Alt text](./1625916876598.png)


这种形式
smoothL1主要公式如下：
![Alt text](./1625916883173.png)

当预测框与 ground truth 差别过大时，梯度值不至于过大；
当预测框与 ground truth 差别很小时，梯度值足够小。
Smooth L1 Loss结合了L2 Loss收敛更快，且在0点有导数，便于收敛的好处。也在边界区域结合了L1 Loss的好处，让网络对异常值更加robust，能够在偏移值较大时还能拉回来
![Alt text](./1625916892681.png)


#### ②损失函数python代码实现

    def smooth_l1_loss(bbox_pred, bbox_targets, bbox_inside_weights, bbox_outside_weights, sigma=1.0, dim=[1]):
    '''
    bbox_pred   ：预测框
    bbox_targets：标签框
    bbox_inside_weights：
    bbox_outside_weights：
    '''  
    sigma_2 = sigma ** 2
    box_diff = bbox_pred - bbox_targets
    in_box_diff = bbox_inside_weights * box_diff
    abs_in_box_diff = tf.abs(in_box_diff)
    # tf.less 返回 True or False； a<b,返回True， 否则返回False。
    smoothL1_sign = tf.stop_gradient(tf.to_float(tf.less(abs_in_box_diff, 1. / sigma_2)))
    # 实现公式中的条件分支
    in_loss_box = tf.pow(in_box_diff, 2) * (sigma_2 / 2.) * smoothL1_sign + (abs_in_box_diff - (0.5 / sigma_2)) * (1. - smoothL1_sign)
    out_loss_box = bbox_outside_weights * in_loss_box
    loss_box = tf.reduce_mean(tf.reduce_sum(out_loss_box, axis=dim))
    return loss_box

#### ③池化方法补充
空金字塔池化（Spatial Pyramid Pooling）
空间金字塔池化可以把任何尺度的图像的卷积特征转化成相同维度，这不仅可以让CNN处理任意尺度的图像，还能避免cropping和warping操作，导致一些信息的丢失，具有非常重要的意义。

 

一般的CNN都需要输入图像的大小是固定的，这是因为全连接层的输入需要固定输入维度，但在卷积操作是没有对图像尺度有限制，所有作者提出了空间金字塔池化，先让图像进行卷积操作，然后转化成维度相同的特征输入到全连接层，这个可以把CNN扩展到任意大小的图像。
![Alt text](./1625917157217.png)

空间金字塔池化的思想来自于Spatial Pyramid Model，它一个pooling变成了多个scale的pooling。用不同大小池化窗口作用于卷积特征，我们可以得到1X1,2X2,4X4的池化结果，由于conv5中共有256个过滤器，所以得到1个256维的特征，4个256个特征，以及16个256维的特征，然后把这21个256维特征链接起来输入全连接层，通过这种方式把不同大小的图像转化成相同维度的特征。

![Alt text](./1625917172472.png)
对于不同的图像要得到相同大小的pooling结果，就需要根据图像的大小动态的计算池化窗口的大小和步长。假设conv5输出的大小为a*a，需要得到n*n大小的池化结果，可以让窗口大小sizeX为，步长为 。下图以conv5输出的大小为13*13为例。
![Alt text](./1625917198580.png)

#### ④数据增强方法修改及补充
缩放比例（Scale）
图像可以向外或向内缩放。向外缩放时，最终图像尺寸将大于原始图像尺寸。大多数图像框架从新图像中剪切出一个部分，其大小等于原始图像。我们将在下一节中处理向内缩放，因为它会缩小图像大小，迫使我们对超出边界的内容做出假设。
裁剪（Crop）
与缩放不同，我们只是从原始图像中随机抽样一个部分。然后，我们将此部分的大小调整为原始图像大小。这种方法通常称为随机裁剪。以下是随机裁剪的示例。仔细观察，你会发现此方法与缩放之间的区别。
移位（Translation）
移位只涉及沿X或Y方向（或两者）移动图像。在下面的示例中，我们假设图像在其边界之外具有黑色背景，并且被适当地移位。这种增强方法非常有用，因为大多数对象几乎可以位于图像的任何位置。这迫使你的卷积神经网络看到所有角落。
#### ⑤图像分类方法综述
1 图像分类与检测概述
当我们面对一张图片的时候，最基础的任务就是这张图片是什么，是风景图还是人物图、是描写建筑物的还是关于食物的，这就是分类。分类作为一个较为笼统的目标，还是较为好达成的。当知道了图像的类别的时候，进一步的就是检测了，例如我知道这个图像是关于人脸的，那么这个人脸在哪里，能不能把它框出来。检测作为一个较为精细的目标，达成的难度可以说是远大于分类的。

1.1 图像分类与检测的难点

不只是图像分类与检测，几乎所有的关于机器学习的难点，都是特征提取这一步，一旦找到好的特征，分类与检测就变的很容易了。所谓的特征提取就是指构建一种提取算法，提取出图像里目标对象的特征，例如人脸的边缘特征、皮肤的颜色特征等，这个特征需要尽可能的将目标物体与其他物体区分开来，例如需要区分的物体是黑猫和白猫，那么毫无疑问颜色特征是一个很好的特征。但是，生活中遇到的难题往往都是很难去提取特征的，例如在嘈杂的街道上检测行人与车辆，这种任务对于检测算法的正确率要求很高，因为一不小心漏检或错检一个人可能就会带来一场车祸。

1.2 图像分类与检测的评价指标

图像分类的指标比较常见，就是分类的正确率，例如猫狗分类，100张中99张分类正确，那么正确率就是99%的正确率。对于目标检测来说，评价指标就多了一些，主要是检错率、漏检率以及检测meaniou，检错率是指一张图片上有两只猫一只狗，而你的模型检测出了三只猫，那么那第三只猫就是检错的，检错率就是33%；漏检的意思是如果你将上面的图片只检测出一只猫和一只狗的话，那就是漏检了一只猫，漏检率33%；mean_iou指的是你检测出来的目标物体的框和真实的框之间的交并比，如下图：
![Alt text](./1625921584939.png)


2 传统的图像分类与检测方法
传统的图像分类与检测的步骤大致是两步：特征提取-》训练分类器

在特征提取阶段，设计者会尝试各种通用特征或者自己设计的特征对图像进行特征提取，我们以人脸检测为例，通用的特征就是HOG、SURF、LBP等特征，而对于人脸效果比较好的特征有鼎鼎大名的haar特征。在选定了这些备用特征之后，设计者会进行尝试特征与权衡利弊，因为对于计算机来说，特征的唯一性、通用性越好，所意味的计算量就越大，设计者必须在保证速度的情况下选择尽量好的特征。

当选择了计算量适中同时能达到要求的准确率的特征例如LBP和haar特征之后，使用传统的机器学习方法例如朴素贝叶斯、adaboost、随机森林等建模方法，训练出一个分类模型，使用这个分类模型来进行图像分类或检测。模型的选择通常要比特征选择简单的多，只需要把备选的模型都试一遍，挑效果最好的模型进行调参，调到极致之后，一个人脸检测模型就做出来的。

走这么一套传统图像检测方法的流程，需要很长的时间，并且每一步都需要做好，最终的模型才会有较好的效果，一旦中间的一步出现错误就会牵一发而动全身。所以使用传统方法做图像处理是需要很大代价的。

3 现今的图像分类和检测方法
自从2015年深度学习占领各大图像处理比赛榜首之后，现在的图像处理大部分使用的方法都是深度学习，也就是神经网络。神经网络通过很多的神经元构建成一层一层的网络，通过激活层来使得模型有很强的非线性拟合的能力。设计者只需要将图像输入，然后告诉模型需要的结果是什么，模型便会自动的学习特征提取与结果映射。

通过深度学习，剩下设计者在传统图像处理时最为费时费力的特征提取的那一部分。设计者只需要设计网络结果，使得网络自动提取的特征越好，效果就会也好，正确率越高。

神经网络本质上是矩阵相乘与非线性的组合，通过很多很多的滤波核，来过滤对结果最为有用的特征而抑制对结果没有用的特征，来进行学习与分类。

现在在工程中最为常用的还是vgg、resnet、inception这几种结构，设计者通常会先直接套用原版的模型对数据进行训练一次，然后选择效果较为好的模型进行微调与模型缩减。因为工程上使用的模型必须在精度高的同时速度要快。常用的模型缩减的方法是减少卷积和个数与减少resnet的模块数。

现在常用的检测模型，还是FRCNN、Mask-RCNN、YOLO、SSD等网络模型，一方面精度确实是高，另一方面速度现在进过优化也可以做到实时了。像上面的人脸检测的功能，只需要准备好人脸图片及对应的框标注文件，便可直接跑模型，得到一个还不错的检测模型。

4 总结
深度学习对于图像处理非常有用，但同时也有一些弊端，例如需要大量数据、调参很依靠经验，需要的计算能力很高等，适合处理很复杂的现实生活场景。传统的图像处理对于特定场景下简单的任务例如文本文档的检测、矫正等，还是非常有用且高效的。