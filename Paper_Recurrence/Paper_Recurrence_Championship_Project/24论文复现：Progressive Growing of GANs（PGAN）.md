# è®ºæ–‡å¤ç°ï¼šProgressive Growing of GANs for Improved Quality, Stability, and Variation
---

## ä¸€ã€ç®€ä»‹
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒ GAN çš„æ–¹æ³•â€”â€”åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ­¥å¢åŠ ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨çš„å·ç§¯å±‚ï¼šä»ä½åˆ†è¾¨ç‡å¼€å§‹ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œæ·»åŠ æ›´é«˜åˆ†è¾¨ç‡çš„å·ç§¯å±‚ï¼Œå¯¹æ›´åŠ ç²¾ç»†çš„ç»†èŠ‚è¿›è¡Œå»ºæ¨¡ï¼Œç”Ÿæˆæ›´é«˜åˆ†è¾¨ç‡å’Œè´¨é‡çš„å›¾åƒã€‚
![0](https://img-blog.csdnimg.cn/13d251cb1f6441e5b8efb3f963af29d7.jpg)

è¿™ä¸ªæ–¹æ³•æ—¢åŠ å¿«äº† GAN çš„è®­ç»ƒé€Ÿåº¦ï¼Œåˆå¢åŠ äº†è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œå› ä¸ºé¢„å…ˆè®­ç»ƒçš„ä½åˆ†è¾¨ç‡å±‚èƒ½ç»™æ›´éš¾æ”¶æ•›çš„é«˜åˆ†è¾¨ç‡å±‚å¸¦æ¥æ›´æœ‰åˆ©äºè®­ç»ƒçš„éšè—ç¼–ç ã€‚

æœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼° GAN ç”Ÿæˆå›¾åƒçš„æŒ‡æ ‡â€”â€”Sliced Wasserstein Distanceï¼ˆSWDï¼‰ï¼Œæ¥è¯„ä¼°æºå›¾å’Œç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå˜åŒ–ã€‚

è®ºæ–‡é“¾æ¥ï¼š[Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://paperswithcode.com/paper/progressive-growing-of-gans-for-improved)


## äºŒã€å¤ç°ç²¾åº¦
å‚è€ƒå®˜æ–¹å¼€æºçš„ pytorch ç‰ˆæœ¬ä»£ç  [https://github.com/facebookresearch/pytorch_GAN_zoo](https://github.com/facebookresearch/pytorch_GAN_zoo)ï¼ŒåŸºäº paddlepaddle æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå¯¹æ–‡çŒ®ç®—æ³•è¿›è¡Œå¤ç°åï¼Œæœ¬é¡¹ç›®è¾¾åˆ°çš„æµ‹è¯•ç²¾åº¦ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚ å‚è€ƒæ–‡çŒ®çš„æœ€é«˜ç²¾åº¦ä¸º CelebA MS-SSIM=0.2838, SWD=2.64(64)
| æŒ‡æ ‡ | SWD Ã— $10^3$ | MS-SSIM |
| --- | --- | -- |
| åˆ†è¾¨ç‡ | 128ã€64ã€32ã€16 | 128 |
| paddle ç‰ˆæœ¬ç²¾åº¦ | 4.46ã€**2.61**ã€4.98ã€11.41 | **0.2719** |
| å‚è€ƒæ–‡çŒ®ç²¾åº¦ | 4.62ã€**2.64**ã€3.78ã€6.06 | **0.2838** |

è¶…å‚æ•°é…ç½®å¦‚ä¸‹ï¼š
> è¯¦è§ `PGAN-Paddle/models/trainer/standard_configurations/pgan_config.py`

|è¶…å‚æ•°å|è®¾ç½®å€¼| è¯´æ˜ |
| --- | --- | --- |
| miniBatchSize | 32 | Mini batch size |
| initBiasToZero | True | æ˜¯å¦æŠŠç½‘ç»œçš„ bias åˆå§‹åŒ–ä¸º 0ï¼Ÿ
|perChannelNormalization | True| Per channel normalization |
| lossMode | WGANGP | loss modeï¼Œé»˜è®¤ |
| lambdaGP | 10.0 |  Gradient penalty coefficient (WGANGP) |
|leakyness|0.2| Leakyness of the leakyRelU activation function |
| epsilonD| 0.001 | Weight penalty on $D(x)^2$ |
| miniBatchStdDev | True | Mini batch regularization |
| baseLearningRate | 0.001 | Base learning rate|
| GDPP | False | æ˜¯å¦ä½¿ç”¨ GDPP loss åŠ å…¥è®­ç»ƒï¼Ÿ|

## ä¸‰ã€æ•°æ®é›†
æœ¬é¡¹ç›®ä½¿ç”¨çš„æ˜¯ celeba æ•°æ®é›†ã€‚ï¼ˆCelebAï¼‰æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡äººè„¸å±æ€§æ•°æ®é›†ï¼Œæ‹¥æœ‰è¶…è¿‡ 20 ä¸‡å¼ åäººå¤´åƒã€‚è¯¥æ•°æ®é›†ä¸­çš„å›¾åƒåŒ…å«å¤§é‡å§¿åŠ¿å˜åŒ–å’ŒèƒŒæ™¯å™ªéŸ³ä»¥åŠæ¨¡ç³Šã€‚

- æ•°æ®é›†æ¦‚è¿°ï¼š
  - å›¾åƒæ•°é‡ï¼š202599 å¼ äººè„¸å›¾åƒ
  - å›¾åƒå¤§å°ï¼š178 Ã— 218 åˆ†è¾¨ç‡
  - æ•°æ®é›†åç§°ï¼š`img_align_celeba`

- æ•°æ®é›†é“¾æ¥ï¼š[CELEBA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)


## å››ã€ç¯å¢ƒä¾èµ–
- ç¡¬ä»¶ï¼š
  - x86 cpuï¼ˆRAM >= 16 GBï¼‰
  - NVIDIA GPUï¼ˆVRAM >= 32 GBï¼‰
  - CUDA + cuDNN
- æ¡†æ¶ï¼š
  - paddlepaddle-gpu==0.0.0ï¼ˆnightly build ç‰ˆæœ¬ï¼‰
- å…¶å®ƒä¾èµ–é¡¹ï¼š
  - numpy >= 1.19.2
  - scipy = 1.6.2
  - h5py = 3.2.1
  - imageio = 2.9.0



paddlepaddle æœ€æ–°ç¨³å®šç‰ˆä¼šåœ¨ `paddle.autograd.grad()` å¤„å‡ºé”™ï¼Œéœ€è¦å®‰è£… nightly build ç‰ˆæœ¬


```python
# å¦‚æœéœ€è¦è¿›è¡ŒæŒä¹…åŒ–å®‰è£…, éœ€è¦ä½¿ç”¨æŒä¹…åŒ–è·¯å¾„, å¦‚ä¸‹æ–¹ä»£ç ç¤ºä¾‹:
# If a persistence installation is required,
# you need to use the persistence path as the following:
!mkdir /home/aistudio/external-libraries
!python -m pip install paddlepaddle-gpu==0.0.0.post101 -f https://www.paddlepaddle.org.cn/whl/linux/gpu/develop.html -t /home/aistudio/external-libraries
```


```python
# åŒæ—¶æ·»åŠ å¦‚ä¸‹ä»£ç , è¿™æ ·æ¯æ¬¡ç¯å¢ƒ(kernel)å¯åŠ¨çš„æ—¶å€™åªè¦è¿è¡Œä¸‹æ–¹ä»£ç å³å¯:
# Also add the following code,
# so that every time the environment (kernel) starts,
# just run the following code:
import sys
sys.path.append('/home/aistudio/external-libraries')
```

## äº”ã€å¿«é€Ÿå¼€å§‹

### 5.1 è®­ç»ƒ

#### step1: æ•°æ®é¢„å¤„ç†

åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰å…ˆè§£å‹ä¸‹è½½çš„ `img_align_celeba.zip` æ•°æ®é›†ï¼Œç„¶åä½¿ç”¨ `datasets.py` è„šæœ¬å¯¹è§£å‹åçš„æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼š

æ¯ä¸ªå›¾åƒä¼šè¢« cropped åˆ° 128Ã—128 åˆ†è¾¨ç‡
```
python datasets.py celeba_cropped $PATH_TO_CELEBA/img_align_celeba/ -o $OUTPUT_DATASET
```
å¤„ç†å®Œæˆåï¼Œä¼šåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ç”Ÿæˆé…ç½®æ–‡ä»¶ `config_celeba_cropped.json` å¹¶è‡ªåŠ¨å†™å…¥äº†ä»¥ä¸‹å†…å®¹ï¼ŒæŒ‡å®šäº†é¢„å¤„ç†æ•°æ®é›†è·¯å¾„ä»¥åŠé€å±‚è®­ç»ƒçš„ç›¸åº”è¿­ä»£æ¬¡æ•°ï¼š
```json
{
  "pathDB": "img_dataset/celeba_cropped",
  "config": {
    "maxIterAtScale": [
      48000,
      96000,
      96000,
      96000,
      96000,
      96000
    ]
  }
}
```
å¯ä»¥åœ¨ config ä¸­ä¿®æ”¹è®­ç»ƒé…ç½®ï¼Œæ¯”å¦‚è°ƒæ•´ batch_sizeï¼Œå®ƒä¼šè¦†ç›– `standard configuration` ä¸­çš„é»˜è®¤é…ç½®ï¼Œä»¥ä¸‹æ˜¯æˆ‘çš„è®­ç»ƒé…ç½®ï¼š
```json
{
  "pathDB": "img_dataset/celeba_cropped",
  "config": {
    "miniBatchScheduler": {"0": 64, "1": 64, "2": 64, "3": 64, "4": 32, "5": 22},
    "configScheduler": {
      "0": {"baseLearningRate": 0.003},
      "1": {"baseLearningRate": 0.003},
      "2": {"baseLearningRate": 0.003},
      "3": {"baseLearningRate": 0.003},
      "4": {"baseLearningRate": 0.001},
      "5": {"baseLearningRate": 0.001}
    },
    "maxIterAtScale": [
      48000,
      96000,
      96000,
      96000,
      96000,
      160000
    ]
  }
}
```
> `miniBatchScheduler` ä¸­å¯ä»¥é’ˆå¯¹ä¸åŒçš„ scale è®¾ç½®ä¸åŒçš„ batch_sizeï¼Œå› ä¸ºéšç€ scale çš„å¢åŠ ï¼Œéœ€è¦å‡å° batch_size æ¥é˜²æ­¢çˆ†æ˜¾å­˜ã€‚`configScheduler` ä¸­å¯ä»¥é’ˆå¯¹ä¸åŒçš„ scale è®¾ç½®ä¸åŒçš„ learning_rateã€‚åœ¨ä»£ç  `PGAN-Paddle/models/progressive_gan.py` ä¸­æˆ‘è¿˜åŠ å…¥äº†è‡ªé€‚åº”å­¦ä¹ ç‡è¡°å‡ç­–ç•¥ï¼ˆlr.ReduceOnPlateauï¼‰ã€‚



```python
!unzip -d work/img_dataset/ /home/aistudio/data/data107578/img_align_celeba.zip
!python datasets.py celeba_cropped work/img_dataset/img_align_celeba/ -o work/img_dataset/celeba_cropped
```

#### step2: è¿è¡Œè®­ç»ƒ

æ¥ç€è¿è¡Œä»¥ä¸‹å‘½ä»¤ä»é›¶å¼€å§‹è®­ç»ƒ PGANï¼š
```
python train.py PGAN -c config_celeba_cropped.json --restart -n celeba_cropped --np_vis
```
ç„¶åç­‰å‡ å¤©ï¼ˆæˆ‘ç”¨ T4 å’Œç™¾åº¦ AI studio çš„ V100ï¼Œå‰åè·‘äº† 6 å¤©ã€‚æ‰€ä»¥å®ƒåˆ°åº•åŠ é€Ÿäº†ä»€ä¹ˆå‘¢ :stuck_out_tongue_closed_eyes: ï¼‰ã€‚ã€‚ã€‚å„ä¸ªé˜¶æ®µè®­ç»ƒå¥½çš„æ¨¡å‹ä¼šè¢«è½¬å‚¨åˆ° `output_networks/celeba_cropped` ä¸­ã€‚è®­ç»ƒå®Œæˆååº”è¯¥å¾—åˆ° 128 x 128 åˆ†è¾¨ç‡çš„ç”Ÿæˆå›¾åƒã€‚

å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œé‡å¯è®­ç»ƒæ—¶å¯ä»¥æŠŠ `--restart` å»æ‰ï¼Œè®­ç»ƒä¼šä» `output_networks/celeba_cropped` ä¸­ä¿å­˜çš„æœ€æ–°æ¨¡å‹å¼€å§‹ã€‚å¦‚æœæƒ³ä½¿ç”¨ GDPP lossï¼Œå¯ä»¥åŠ å…¥ `--GDPP True`ã€‚

`output_networks/celeba_cropped` ä¸­ä¼šä¿å­˜æ¯ä¸ªé˜¶æ®µè®­ç»ƒå®Œæˆçš„ï¼š
- æ¨¡å‹ï¼š`celeba_cropped_s$scale_i$iters.pdparams`
- é…ç½®æ–‡ä»¶ï¼š`celeba_cropped_s$scale_i$iters_tmp_config.json`
- refVectorsï¼š`celeba_cropped_refVectors.pdparams`
- lossesï¼š`celeba_cropped_losses.pkl`
- ç”Ÿæˆçš„å›¾åƒï¼š`celeba_cropped_s$scale_i$iters_avg.jpg`ã€`celeba_cropped_s$scale_i$iters.jpg`ï¼Œ`_avg.jpg` å›¾åƒæ•ˆæœæ›´å¥½ï¼Œé¢„æµ‹æ—¶é»˜è®¤ä½¿ç”¨å…¶æ¥è®¡ç®—æŒ‡æ ‡ã€‚
![2](https://img-blog.csdnimg.cn/7fe8ba1e0259449ebd00d035819fec49.jpg)


```python

# !python -m paddle.distributed.launch train.py PGAN -c config_celeba_cropped.json --restart -n celeba_cropped --no_vis
!python train.py PGAN -c config_celeba_cropped.json -n celeba_cropped --np_vis  # | tee -a work/log5.txt

```

    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/adamw.py:21: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
      from collections import Callable
    Running PGAN
    Got configScheduler: {'0': {'baseLearningRate': 0.003}, '1': {'baseLearningRate': 0.003}, '2': {'baseLearningRate': 0.001}, '3': {'baseLearningRate': 0.001}, '4': {'baseLearningRate': 0.001}, '5': {'baseLearningRate': 0.001}}
    Got miniBatchScheduler: {'0': 64, '1': 64, '2': 64, '3': 64, '4': 32, '5': 22}
    W0920 11:49:42.317597   529 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1
    W0920 11:49:42.321697   529 device_context.cc:465] device: 0, cuDNN Version: 7.6.
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/parallel.py:587: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.
      warnings.warn("The program will return to single-card operation. "
    size 10
    202599 images found
    202599 images detected
    Model found at path output_networks/celeba_cropped/celeba_cropped_s4_i64000.pdparams, pursuing the training
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py:412: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
      if isinstance(obj, collections.Iterable) and not isinstance(obj, (
    Average network found !
    Scale 4, updating the training configuration
    {'baseLearningRate': 0.001}
    size (64, 64)
    202599 images found
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:130: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      if data.dtype == np.object:
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:130: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      if data.dtype == np.object:
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py:382: UserWarning: [93m
    Warning:
    tensor.grad will return the tensor value of the gradient. This is an incompatible upgrade for tensor.grad API.  It's return type changes from numpy.ndarray in version 2.0 to paddle.Tensor in version 2.1.0.  If you want to get the numpy value of the gradient, you can use :code:`x.grad.numpy()` [0m
      warnings.warn(warning_msg)
    [4 :  64100] loss G : -1.501 loss D : 8.629
    [4 :  64200] loss G : 0.467 loss D : 8.941
    [4 :  64300] loss G : -11.279 loss D : 7.198
    [4 :  64400] loss G : -14.752 loss D : 9.246
    [4 :  64500] loss G : -4.466 loss D : 5.007
    ^C


### 5.2 é¢„æµ‹

**è®­ç»ƒå¥½çš„æœ€ç»ˆæ¨¡å‹å¯åˆ°ç™¾åº¦ç½‘ç›˜è‡ªå–ï¼š[celeba_cropped_s5_i96000](https://pan.baidu.com/s/1-wvYpLYiEUGpBi3xT31roA )**ï¼Œæå–ç ï¼š6nv9ã€‚å°†å…¶ä¸­çš„æ–‡ä»¶æ”¾åˆ°é¡¹ç›®çš„ `output_networks/celeba_cropped` ä¸­ï¼Œåœ¨ `.json` æ–‡ä»¶ä¸­æŒ‡å®š `refVectors.pdparams` çš„è·¯å¾„ï¼Œ`losses.pkl` å¯ä»¥æ²¡æœ‰ã€‚
> å¦‚éœ€è¦è¿è¡Œ i80000.pdparams æ¨¡å‹ï¼Œå¯ä»¥æŠŠ `.json` æ–‡ä»¶çš„æ–‡ä»¶åæ”¹æˆå¯¹åº”çš„ i80000ï¼Œå› ä¸ºéœ€è¦é€šè¿‡è¿™ä¸ªæ–‡ä»¶æ‰¾åˆ° `refVectors.pdparams` çš„è·¯å¾„ã€‚

#### step1: å›¾åƒç”Ÿæˆ

é€šè¿‡ä»¥ä¸‹å‘½ä»¤ä½¿ç”¨ `output_networks/celeba_cropped` ä¸­ä¿å­˜çš„æœ€æ–°æ¨¡å‹æ¥ç”Ÿæˆå›¾åƒï¼š
```
python eval.py visualization -n celeba_cropped -m PGAN --np_vis
```
å¦‚æœä½ æƒ³æŒ‡å®šæŸä¸ªé˜¶æ®µçš„æ¨¡å‹ï¼ŒåŠ å…¥ `-s $scale` å’Œ `-i $iter`ï¼š
```
python eval.py visualization -n celeba_cropped -m PGAN -s $SCALE -i $ITER --np_vis
```
ä»¥ä¸Šä¸¤ä¸ªå‘½ä»¤ç”Ÿæˆçš„å›¾åƒä¿å­˜åœ¨ `output_networks/celeba_cropped` ä¸­ï¼Œåä¸ºï¼š`celeba_cropped_s$scale_i$iter_fullavg.jpg`

éšæœºç”Ÿæˆä¸€äº›å›¾åƒï¼š
```
python eval.py visualization -n celeba_cropped -m PGAN --save_dataset $PATH_TO_THE_OUTPUT_DATASET --size_dataset $SIZE_OF_THE_OUTPUT --np_vis
```
å…¶ä¸­ï¼Œ`$SIZE_OF_THE_OUTPUT` è¡¨ç¤ºè¦ç”Ÿæˆå¤šå°‘å¼ å›¾åƒã€‚

#### step2: è¯„ä¼°æŒ‡æ ‡

**SWD & MS-SSIM metric**

è¿è¡Œï¼š
```
python eval.py laplacian_SWD -c config_celeba_cropped.json -n celeba_cropped -m PGAN -s 5 -i 64000 --np_vis
```
å®ƒä¼šåœ¨ `config_celeba_cropped.json` é‡ŒæŒ‡å®šçš„æ•°æ®è·¯å¾„ä¸­éšæœºéå† 16000 å¼ æºå›¾åƒåŠå…¶ç”Ÿæˆå›¾åƒæ¥è®¡ç®— SWD æŒ‡æ ‡ï¼ŒMerging the results çš„è¿‡ç¨‹ä¼šå ç”¨ä¸å°‘ CPU å†…å­˜ï¼ˆ18 GB å·¦å³ï¼‰å’Œæ—¶é—´ã€‚è¿è¡Œåä¼šè¾“å‡ºï¼š
```
Running laplacian_SWD
Checkpoint found at scale 5, iter 64000
Average network found !
202599 images found
Generating the fake dataset...
 |####################################################################################################| 100.0%
 |####################################################################################################| 100.0%
Merging the results, please wait it can take some time...
 |####################################################################################################| 100.0%

     resolution               128               64               32  16 (background)
	   score         0.006042         0.002615         0.004997         0.011406
     ms-ssim score    0.2719  
...OK
```
å…¶ä¸­ç›¸åº”çš„æŒ‡æ ‡æ•°å€¼ä¼šä¿å­˜åœ¨ `output_networks/celeba_cropped/celeba_cropped_swd.json` ä¸­ã€‚


```python
# import paddle.vision.models as models

# res18 = models.resnet18(pretrained=True)
!python eval.py laplacian_SWD -c config_celeba_cropped.json -n celeba_cropped -m PGAN -s 5 -i 80000 --np_vis

```

    Running laplacian_SWD
    W0914 20:27:31.217519   434 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1
    W0914 20:27:31.221930   434 device_context.cc:422] device: 0, cuDNN Version: 7.6.
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/parallel.py:515: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.
      warnings.warn("The program will return to single-card operation. "
    Checkpoint found at scale 5, iter 80000
    Average network found !
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      if data.dtype == np.object:
    202599 images found
    Generating the fake dataset...
     |####################################################################################################| 100.0%
     |####################################################################################################| 100.0%
    Merging the results, please wait it can take some time...
     |####################################################################################################| 100.0%

         resolution               128               64               32  16 (background)
               score         0.004998         0.005541         0.006348         0.018050
    ms-ssim score      0.265151
    ...OK



```python
!python eval.py visualization -n celeba_cropped -m PGAN -s 5 -i 80000 --np_vis

```

    Running visualization
    W0914 19:06:03.102860  2048 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1
    W0914 19:06:03.107743  2048 device_context.cc:422] device: 0, cuDNN Version: 7.6.
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/parallel.py:515: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.
      warnings.warn("The program will return to single-card operation. "
    Average network found !
    ...OK



```python
!python eval.py visualization -n celeba_cropped -m PGAN -s 5 -i 80000 --save_dataset work/img_dataset --size_dataset 10 --np_vis

```

    Running visualization
    W0914 19:08:49.752194  2329 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1
    W0914 19:08:49.757010  2329 device_context.cc:422] device: 0, cuDNN Version: 7.6.
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/parallel.py:515: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.
      warnings.warn("The program will return to single-card operation. "
    Average network found !
    Exporting a fake dataset at path work/img_dataset
    ...OK


## å…­ã€ä»£ç ç»“æ„ä¸è¯¦ç»†è¯´æ˜
### 6.1 ä»£ç ç»“æ„
```
â”œâ”€â”€ models                    # åŒ…å«æ¨¡å‹å®šä¹‰ã€æŸå¤±å‡½æ•°ã€æ•°æ®é›†è¯»å–ã€è®­ç»ƒæµ‹è¯•æ–¹æ³•
â”‚   â”œâ”€â”€ datasets              # è¯»å–æ•°æ®é›†
â”‚   â”œâ”€â”€ eval                  # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€æŒ‡æ ‡è¯„ä¼°
â”‚   â”œâ”€â”€ loss_criterions       # æŸå¤±å‡½æ•°å®šä¹‰
â”‚   â”œâ”€â”€ metrics               # è¯„ä¼°æŒ‡æ ‡
â”‚   â”œâ”€â”€ networks              # ç½‘ç»œæ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ trainer               # è®­ç»ƒç­–ç•¥å°è£…
â”‚   â”œâ”€â”€ utils                 # å·¥å…·åŒ…
â”‚   â”œâ”€â”€ UTs                   # æœªä½¿ç”¨
â”‚	â”œâ”€â”€ base_GAN.py           # GANçˆ¶ç±»
â”‚	â”œâ”€â”€ gan_visualizer.py     # GAN è®­ç»ƒä¸­é—´å›¾åƒä¿å­˜
â”‚   â”œâ”€â”€ progressive_gan.py    # PGAN
â”‚	â”œâ”€â”€ README.md             # models' readme
â”œâ”€â”€ output_networks           # ä¿å­˜è®­ç»ƒå’Œé¢„æµ‹ç»“æœ
â”œâ”€â”€ visualization             # å¯è§†åŒ–ã€å›¾åƒä¿å­˜
â”œâ”€â”€ CODE_OF_CONDUCT.md  
â”œâ”€â”€ config_celeba_cropped.json   # æ•°æ®é¢„å¤„ç†åç”Ÿæˆçš„é…ç½®æ–‡ä»¶
â”œâ”€â”€ CONTRIBUTING.md  
â”œâ”€â”€ datasets.py                # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”œâ”€â”€ eval.py                    # é¢„æµ‹ã€ç”Ÿæˆå›¾åƒè„šæœ¬
â”œâ”€â”€ hubconf.py                 # ç”¨äºåŠ è½½é¢„è®­ç»ƒçš„å‚è€ƒä»£ç ï¼Œæœªä½¿ç”¨
â”œâ”€â”€ LICENSE                    # å¼€æºåè®®
â”œâ”€â”€ README.md                  # ä¸»é¡µ readme
â”œâ”€â”€ requirements.txt           # é¡¹ç›®çš„å…¶å®ƒä¾èµ–
â”œâ”€â”€ save_feature_extractor.py    # æœªä½¿ç”¨
â”œâ”€â”€ train.py                     # è®­ç»ƒè„šæœ¬
```

### 6.2 å‚æ•°è¯´æ˜
è§ [äºŒã€å¤ç°ç²¾åº¦](#äºŒã€å¤ç°ç²¾åº¦)

### 6.3 è®­ç»ƒæµç¨‹
è§ [äº”ã€å¿«é€Ÿå¼€å§‹](#äº”ã€å¿«é€Ÿå¼€å§‹)

æ‰§è¡Œè®­ç»ƒå¼€å§‹åï¼Œå°†å¾—åˆ°ç±»ä¼¼å¦‚ä¸‹çš„è¾“å‡ºã€‚æ¯ 100 ä¸ªè¿­ä»£ä¼šæ‰“å°å½“å‰ [scale:    iters]  ä»¥åŠç”Ÿæˆå™¨æŸå¤±ã€è¾¨åˆ«å™¨æŸå¤±ã€‚

ä¸€ä¸ª scale ä»£è¡¨æ·»åŠ äº†ä¸€å±‚ï¼Œ`scale = len(maxIterAtScale)`ï¼Œ`maxIterAtScale` æŒ‡å®šäº†é€å±‚è®­ç»ƒçš„æ¯å±‚ç›¸åº”è¿­ä»£æ¬¡æ•°ã€‚
 `config_celeba_cropped.json`ï¼š
```json
{
  "pathDB": "img_dataset/celeba_cropped",
  "config": {
    "maxIterAtScale": [
      48000,
      96000,
      96000,
      96000,
      96000,
      96000
    ]
  }
}
```

å¼€å¤´çš„ loss ä¼šæ¯”è¾ƒå¤§ï¼Œå¤§å°ä¸è®¾ç½®çš„ batch_size æˆæ­£æ¯”ï¼Œåˆ° 3000 ä¸ªè¿­ä»£å loss è¶‹äºç¨³å®šï¼Œç¨³ä¸‹æ¥çš„æ—¶é—´æˆ–è®¸ä¹Ÿè·Ÿè®¾ç½®çš„ batch_size å¤§å°æœ‰å…³ã€‚


### 6.4 æµ‹è¯•æµç¨‹
è§ [äº”ã€å¿«é€Ÿå¼€å§‹](#äº”ã€å¿«é€Ÿå¼€å§‹)

ä½¿ç”¨æœ€ç»ˆçš„é¢„è®­ç»ƒæ¨¡å‹ `celeba_cropped_s5_i96000.pdparams` ç”Ÿæˆçš„å›¾åƒå¦‚ä¸‹ï¼š

![3](https://img-blog.csdnimg.cn/26afed935c61443da4d0e5bb7f9bee97.png)


## ä¸ƒã€å®éªŒæ•°æ®æ¯”è¾ƒåŠå¤ç°å¿ƒå¾—
![5](https://img-blog.csdnimg.cn/670632d67ade4085985397c04bb1717f.png)

**miniBatchSize**
åŸæ–‡çš„å®éªŒä¸­ï¼ŒPGAN çš„ batch_size é…ç½®æ˜¯ 64ï¼Œä¸æ˜¯æºç ä¸­é»˜è®¤è®¾ç½®çš„ 16ï¼Œbatch_size = 16 çš„é…ç½®åœ¨è®ºæ–‡ä¸­æ˜¯åœ¨æ·»åŠ é«˜åˆ†è¾¨ç‡å±‚ä¹‹åæ‰ä¸‹è°ƒçš„ï¼ˆä¹Ÿèµ·åˆ°é™ä½æ˜¾å­˜çš„æ•ˆæœï¼‰ï¼Œå¦‚æœä»å¤´åˆ°å°¾éƒ½ä½¿ç”¨ batch_size=16 ä¼šå¯¼è‡´å›¾åƒç”Ÿæˆçš„æ•ˆæœä¸å¥½ã€‚

ä½†æ˜¯æˆ‘å¤ç°æ—¶æ²¡æœ‰æ³¨æ„åˆ°æ­¤å¤„ï¼Œå¤ç°çš„ paddle ç‰ˆæœ¬ç›´æ¥ä½¿ç”¨æºç é»˜è®¤çš„ batch_size=16 è¿›è¡Œè®­ç»ƒï¼Œå‘ç°æ˜¾å­˜è¿˜å‰©ä½™å¾ˆå¤šï¼Œäºæ˜¯æ”¹æˆ batch_size=32ï¼Œå‘ç°å¼€å¤´çš„ loss å˜å¾—å¾ˆå¤§ï¼Œä½†æ˜¯ä¹Ÿå¾ˆå¿«æ”¶æ•›åˆ°ç¨³å®šçš„ 20 ä»¥å†…ã€‚è®­ç»ƒåˆ° scale=5 æ—¶ï¼ŒPGAN å¢åŠ çš„é«˜åˆ†è¾¨ç‡å±‚ä¼šå¯¼è‡´ 32 GB çš„æ˜¾å­˜çˆ†æ»¡ï¼Œéœ€è¦å°† batch_size ä¸‹è°ƒè‡³ 16 æˆ–æ›´å°ã€‚

**SWD metric**
é¢„æµ‹è¿‡ç¨‹ä¼šåœ¨æ•´ä¸ª celeba_cropped æ•°æ®é›†ä¸­éšæœºé‡‡æ · 16000 å¼ å›¾åƒæ¥é¢„æµ‹å¹¶è®¡ç®—ä¸€ä¸ªæ¨¡å‹çš„ä¸åŒ scale ä¸‹æ¯å¯¹å›¾åƒï¼ˆè¾“å…¥å›¾åƒå’Œå¯¹åº”çš„ç”Ÿæˆå›¾åƒï¼‰çš„ SWD æŒ‡æ ‡ï¼Œç”¨åŒæ ·çš„æ¨¡å‹æ¯æ¬¡è®¡ç®—å¾—åˆ°çš„æŒ‡æ ‡ç»“æœæœ‰æ‰€ä¸åŒã€‚

**MS-SSIM metric**
ç”±äºæºä»£ç æ²¡æœ‰æä¾› MS-SSIM çš„å®ç°ï¼Œæˆ‘å‚è€ƒ GitHub çš„å¼€æº pytorch ç‰ˆæœ¬ [https://github.com/VainF/pytorch-msssim/blob/master/pytorch_msssim/ssim.py](https://github.com/VainF/pytorch-msssim/blob/master/pytorch_msssim/ssim.py) æ¥è®¡ç®— MS-SSIM æŒ‡æ ‡ï¼Œå¾—åˆ°çš„ç»“æœè·Ÿè®ºæ–‡ä¸­åœ¨ celeba æ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æœå·®ä¸å¤šã€‚è®ºæ–‡ä¸­è¯´ SWD æŒ‡æ ‡èƒ½æ›´å¥½åæ˜ å›¾åƒè´¨é‡ä»¥åŠç»“æ„çš„å·®å¼‚å’Œå˜åŒ–ï¼Œè€Œ MS-SSIM åªæµ‹é‡è¾“å‡ºä¹‹é—´çš„å˜åŒ–ï¼Œä¸ä¼šåæ˜ ç”Ÿæˆå›¾åƒå’Œè®­ç»ƒé›†çš„å·®å¼‚ï¼Œæ‰€ä»¥åœ¨ç”Ÿæˆå›¾åƒå‘ç”Ÿäº†æ˜æ˜¾æ”¹å–„åï¼ŒMS-SSIM æŒ‡æ ‡ä¹Ÿå‡ ä¹æ²¡æœ‰å˜åŒ–ï¼ŒSWD æŒ‡æ ‡çš„ç»“æœå˜å¥½äº†ä¸€ç‚¹ã€‚

**ç”Ÿæˆæ•ˆæœ**
è®ºæ–‡ä¸­è¯´æ˜åœ¨è§„å®šçš„è¿­ä»£æ¬¡æ•°å†…ç½‘ç»œå¹¶æ²¡æœ‰å®Œå…¨æ”¶æ•›ï¼Œè€Œæ˜¯è¾¾åˆ°æŒ‡å®šè¿­ä»£æ¬¡æ•°åå°±åœæ­¢è®­ç»ƒï¼Œæ‰€ä»¥ç”Ÿæˆçš„å›¾åƒè¿˜ä¸å¤Ÿå®Œç¾ï¼Œå¦‚æœæƒ³è¦ç”Ÿæˆæ›´å®Œç¾çš„å›¾åƒï¼Œé‚£å¾—å†ç­‰ä¸Šå¥½å‡ å¤©ï¼Ÿ

**API è½¬æ¢**
å°† pytorch ç‰ˆæœ¬ä»£ç è½¬ä¸º paddle æœ‰äº› API åœ¨ paddle ä¸­æ˜¯æ²¡æœ‰çš„ï¼Œä½†æ˜¯ numpy é‡Œæ˜¯è‚¯å®šéƒ½æœ‰çš„ :smile:ï¼Œæ‰¾ä¸åˆ°çš„ API ç”¨ numpy æ¥æ­ä¸ªæ¡¥ï¼Œè¿™æ˜¯å¾ˆä¸é”™çš„å¤ç°åŠæ³•ã€‚

## å…«ã€æ¨¡å‹ä¿¡æ¯
| ä¿¡æ¯ | è¯´æ˜ |
| --- | --- |
| å‘å¸ƒè€… | ç»ç»å­ |
| æ—¶é—´ | 2021.09 |
| æ¡†æ¶ç‰ˆæœ¬ | paddlepaddle 0.0.0 ï¼ˆdevelop ç‰ˆæœ¬ï¼‰ |
| åº”ç”¨åœºæ™¯ | GAN å›¾åƒç”Ÿæˆ |
| æ”¯æŒç¡¬ä»¶ | GPUã€CPUï¼ˆRAM >= 16 GBï¼‰ |
| Github åœ°å€ | [PGAN-Paddle](https://github.com/GXU-GMU-MICCAI/PGAN-Paddle) |

è¯·ç‚¹å‡»[æ­¤å¤„](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)æŸ¥çœ‹æœ¬ç¯å¢ƒåŸºæœ¬ç”¨æ³•.  <br>
Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions.
