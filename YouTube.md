五、YouTube
1  Youtube推荐系统 整体架构
    由于网站视频数量太多，视频候选集太大，不宜用复杂网络直接进行推荐，这会造成响应时间的增加。因此，整个架构走粗排 + 精排两阶段的路子：
 Candidate Generation Model：在这一步，从成百上千万的视频中选择百量级的候选视频
 Ranking Model：这一步，完成对几百个候选视频的精排。

候选集生成Candidate Generation
      假设这样一个视频十天前发布的，许多用户在当前观看了该视频，那么在当天会产生许多Sample Log，而在后面的九天里，观看记录不多，Sample Log也很少。如果我们没有加入
Example Age这个特征的话，无论何时训练模型，这个视频对应的分类概率都是差不多的，但是如果我们加入这个特征，模型就会知道，如果这条记录是十天前产生的话，
该视频会有很高的分类概率，如果是最近几天产生的话，分类概率应该低一些，这样可以更加逼近实际的数据。
      在对待用户的搜索历史或者观看历史时，可以看到Youtube并没有选择时序模型，而是完全摒弃了序列关系，采用求平均的方式对历史记录进行了处理。这是因为考虑时序关系，
用户的推荐结果将过多受最近观看或搜索的一个视频的影响。
      在离线训练阶段，我们将其视为了一个分类问题。我们使用隐式反馈来进行学习，用户完整观看过一个视频，便视作一个正例。
      在线服务来说，有严格的性能要求，须在几十毫秒内返回结果。即youtube没有重新跑一遍模型，而是通过保存用户的embedding和视频的embedding，通过最近邻搜索的方法得到结果。
排序Ranking
      排序过程是对生成的候选集做进一步细粒度的排序。模型的结构图如下所示：
      在排序阶段，输入的特征主要有：
impression video ID embedding: 当前要计算的video的embedding
watched video IDs average embedding: 用户观看过的最后N个视频embedding的average pooling
language embedding: 用户语言的embedding和当前视频语言的embedding
time since last watch: 用户上次观看同频道时间距现在的时间间隔
previous impressions: 该视频已经被曝光给该用户的次数
特征处理主要包含对于离散变量的处理和连续变量的处理。
      对于离散变量，这里主要是视频ID，Youtube这里的做法是有两点：
1、只保留用户最常点击的N个视频的embedding，剩余的长视频的embedding被赋予全0值。解释主要有两点，一是出现次数较少的视频的embedding没法被充分训练。
二是也可以节省线上服务宝贵的内存资源。
2、对于相同域的特征可以共享embedding，比如用户点击过的视频ID，用户观看过的视频ID，用户收藏过的视频ID等等，这些公用一套embedding可以使其更充分的学习，
同时减少模型的大小，加速模型的训练。
      对于连续特征，主要进行归一化处理，神经网络对于输入的分布及特征的尺度是十分敏感。


