**深度学习基础知识：**
**1. 深度学习的发展历史：**
第一代神经网络（1958~1969）：MCP神经元数学模型（1943）→单层感知机（1957）→单层感知机不能实现XOR问题（1969）
第二代神经网络（1986~1998）：BP算法（1986）→卷积神经网络-LeNet（1998）
统计学习方法（1986~2006）：决策树方法（1986）→线性SVM（1995）→AdaBoost（1997）→KernelSVM（2000）→随机森林（2001）→图模型（2001）
第三代神经网络-DL（2006-至今）：快速发展期（2006-2012）→爆发期（2012至今）
![](https://ai-studio-static-online.cdn.bcebos.com/5d66c2b7d89f435492f5ca933ae8a3508e389c4bff3b453eaba8dc3fabd93165)
**2. 人工智能、机器学习、深度学习有什么区别和联系:**
深度学习∈机器学习∈人工智能
**3. 神经元、单层感知机、多层感知机:**
（1）神经元：即人工神经元，它是模拟生物神经元的一个数学模型，通过对输入进行权重分配相加，再经过阈值处理和激活函数获得非线性特质，主要结构如下图：
![](https://ai-studio-static-online.cdn.bcebos.com/ca556349c7cf4580b680c6318087c949df61e7e0aa0a4977b44eb293a1023f4f)
（2）单层感知机：单层感知机是二分类的线性分类模型，输入是被感知数据集的特征向量，输出时数据集的类别{+1,-1}，主要结构如下图：
![](https://ai-studio-static-online.cdn.bcebos.com/bdf9608e9c1a4de4bb4c71c93ad43096dbfde4f3a29d49dd9a30eb15f70ec96a)
（3）多层感知机：即人工神经网络，除了输入输出层，它中间可以有多个隐层，最简单的MLP只含一个隐层，即三层的结构，主要结构如下图：
![](https://ai-studio-static-online.cdn.bcebos.com/3c37dd9c36b94c75bd0d7d056cfd0643f1881627ae1443be9f2f4cea12a220fb)
**4. 什么是前向传播：**
所谓前向传播,就是给网络输入一个样本向量,该样本向量的各元素,经过各隐藏层的逐级加权求和+非线性激活,最终由输出层输出一个预测向量的过程，简单描述即，网络如何根据输入X得到输出Y的过程就是前向传播。
![](https://ai-studio-static-online.cdn.bcebos.com/a168ab1fe48f49bf9a7b82f92d29ed9279eb5b66ca514001a6b4e9dd0d0cf0aa)
输入层→隐含层→输出层
**5. 什么是后向传播：**
后向传播(Back—PropagationNetwork，简称BP网络)是一种神经网络学习算法，在通过前向传播得到由任意一组随机参数W和b计算出的网络预测结果后，我们可以利用损失函数相对于每个参数的梯度来对他们进行修正。
![](https://ai-studio-static-online.cdn.bcebos.com/463a2c5af8ae4350b6e8f8eafcfd52e3c20af6de8e5e47fe9e7353fca722376f)
计算总误差→隐含层→输出层的权值更新→隐含层→隐含层的权值更新
