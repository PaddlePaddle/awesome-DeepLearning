一、损失函数补充及代码
19种损失函数
1. L1范数损失 L1Loss
计算 output 和 target 之差的绝对值。
torch.nn.L1Loss(reduction='mean')
参数：
reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。
2 均方误差损失 MSELoss
计算 output 和 target 之差的均方差。
torch.nn.MSELoss(reduction='mean')
参数：
reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。
3 交叉熵损失 CrossEntropyLoss
当训练有 C 个类别的分类问题时很有效. 可选参数 weight 必须是一个1维 Tensor, 权重将被分配给各个类别. 对于不平衡的训练集非常有效。
在多分类任务中，经常采用 softmax 激活函数+交叉熵损失函数，因为交叉熵描述了两个概率分布的差异，然而神经网络输出的是向量，并不是概率分布的形式。所以需要 softmax激活函数将一个向量进行“归一化”成概率分布的形式，再采用交叉熵损失函数计算 loss。
Image1
torch.nn.CrossEntropyLoss(weight=None,ignore_index=-100, reduction='mean')
参数：
weight (Tensor, optional) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor
ignore_index (int, optional) – 设置一个目标值, 该目标值会被忽略, 从而不会影响到 输入的梯度。
reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。
4 KL 散度损失 KLDivLoss
计算 input 和 target 之间的 KL 散度。KL 散度可用于衡量不同的连续分布之间的距离, 在连续的输出分布的空间上(离散采样)上进行直接回归时 很有效.
torch.nn.KLDivLoss(reduction='mean')
参数：
reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。
5 二进制交叉熵损失 BCELoss
二分类任务时的交叉熵计算函数。用于测量重构的误差, 例如自动编码机. 注意目标的值 t[i] 的范围为0到1之间.
torch.nn.BCELoss(weight=None, reduction='mean')
参数：
weight (Tensor, optional) – 自定义的每个 batch 元素的 loss 的权重. 必须是一个长度为 “nbatch” 的 的 Tensor
6 BCEWithLogitsLoss
BCEWithLogitsLoss损失函数把 Sigmoid 层集成到了 BCELoss 类中. 该版比用一个简单的 Sigmoid 层和 BCELoss 在数值上更稳定, 因为把这两个操作合并为一个层之后, 可以利用 log-sum-exp 的 技巧来实现数值稳定.
torch.nn.BCEWithLogitsLoss(weight=None, reduction='mean', pos_weight=None)
参数：
weight (Tensor, optional) – 自定义的每个 batch 元素的 loss 的权重. 必须是一个长度 为 “nbatch” 的 Tensor
7 MarginRankingLoss
torch.nn.MarginRankingLoss(margin=0.0, reduction='mean')
对于 mini-batch(小批量) 中每个实例的损失函数如下:
Image2  参数：
margin:默认值0

8 HingeEmbeddingLoss
torch.nn.HingeEmbeddingLoss(margin=1.0,  reduction='mean')
对于 mini-batch(小批量) 中每个实例的损失函数如下:
Image3 参数：
margin:默认值1
9 多标签分类损失 MultiLabelMarginLoss
torch.nn.MultiLabelMarginLoss(reduction='mean')
对于mini-batch(小批量) 中的每个样本按如下公式计算损失:
image4
10 平滑版L1损失 SmoothL1Loss
也被称为 Huber 损失函数。
torch.nn.SmoothL1Loss(reduction='mean')
image5
其中
Image6
11 2分类的logistic损失 SoftMarginLoss
torch.nn.SoftMarginLoss(reduction='mean')

image7
12 多标签 one-versus-all 损失 MultiLabelSoftMarginLoss
torch.nn.MultiLabelSoftMarginLoss(weight=None, reduction='mean')

image8
13 cosine 损失 CosineEmbeddingLoss
torch.nn.CosineEmbeddingLoss(margin=0.0, reduction='mean')
image9
参数：
margin:默认值0
14 多类别分类的hinge损失 MultiMarginLoss
torch.nn.MultiMarginLoss(p=1, margin=1.0, weight=None,  reduction='mean')
image10
参数：
p=1或者2 默认值：1margin:默认值1
15 三元组损失 TripletMarginLoss
和孪生网络相似，具体例子：给一个A，然后再给B、C，看看B、C谁和A更像。
Image11
torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, reduction='mean')
image12
其中：
image13
16 连接时序分类损失 CTCLoss
CTC连接时序分类损失，可以对没有对齐的数据进行自动对齐，主要用在没有事先对齐的序列化数据训练上。比如语音识别、ocr识别等等。
torch.nn.CTCLoss(blank=0, reduction='mean')
参数：
reduction-三个值，none: 不使用约简；mean:返回loss和的平均值； sum:返回loss的和。默认：mean。
17 负对数似然损失 NLLLoss
负对数似然损失. 用于训练 C 个类别的分类问题.
torch.nn.NLLLoss(weight=None, ignore_index=-100,  reduction='mean')
参数：
weight (Tensor, optional) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor
ignore_index (int, optional) – 设置一个目标值, 该目标值会被忽略, 从而不会影响到 输入的梯度.
18 NLLLoss2d
对于图片输入的负对数似然损失. 它计算每个像素的负对数似然损失.
torch.nn.NLLLoss2d(weight=None, ignore_index=-100, reduction='mean')
参数：
weight (Tensor, optional) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor
reduction-三个值，none: 不使用约简；mean:返回loss和的平均值； sum:返回loss的和。默认：mean。
19 PoissonNLLLoss
目标值为泊松分布的负对数似然损失
torch.nn.PoissonNLLLoss(log_input=True, full=False,  eps=1e-08,  reduction='mean')
参数：
log_input (bool, optional) – 如果设置为 True , loss 将会按照公 式 exp(input) - target * input 来计算, 如果设置为 False , loss 将会按照 input - target * log(input+eps) 计算.
full (bool, optional) – 是否计算全部的 loss, i. e. 加上 Stirling 近似项 target * log(target) - target + 0.5 * log(2 * pi * target).
eps (float, optional) – 默认值: 1e-8

二、池化方法补充
#池化方法
池化操作是卷积神经网络中的一个特殊的操作，主要就是在一定的区域内提出该区域的关键信息(一个亚采样过程)。其操作往往出现在卷积层之后，它能起到减少卷积层输出的特征量数目的作用，从而能减少模型参数同时能改善过拟合现象。池化操作通过池化模板和步长两个关键变量构成。模板描述了提取信息区域的大小(size_PL)，一般是一个方形窗口；步长(stride)描述了窗口在卷积层输出特征图上的移动步长，一般和模板边长相等(即模板移动前后不重叠)。
##平均池化(averager pooling)
平均池化是对池化模板进行均值化操作，这能保留模板内的数据的整体特征从而背景信息。
image14

##最大池化(max pooling)
最大池化是保留模板内信息的最大值，这是在提取纹理特征，保留更多的局部细节。
image15

##随机池化(stochastic pooling)
模板内元素值大的被选中的概率也大，这种方法既不会一直选择max值。但这种池化效果并不稳定即不能保证池化的结果一定是好的，可能产生更坏的结果。随机池化伴随着概率矩阵，每个元素对应一个被选取的概率，模板内概率和为1。
image16

##重叠池化(overlapping pooling)
前三种池化方法一般设置stride和size_PL相等，可以称之为一般方法。如果步长和池化模板尺寸不相等且两个池化区域存在重叠，这种池化方法称之为重叠池化。
image17

##金字塔池化(spatial pyramid pooling)
一般CNN对输入的图像尺寸有着特定的要求，因为这是全卷积层的神经元个数对输入的特征维度是固定的。但采用金字塔池化，则可以将任意图像的卷积特征图像转化为所指定维度的特征向量输入给全卷积层。这就解决了CNN输入图像可以是任意尺寸的问题。
空间金字塔池化是将池化层转化为多尺度的池化，即利用多个不同大小尺度的池化模板来进行池化操作。
image18

三、数据增强
1、什么是数据增强？
数据增强也叫数据扩增，意思是在不实质性的增加数据的情况下，让有限的数据产生等价于更多数据的价值。
每张图对于网络来说都是不同的输入，加上原图就将数据扩充到原来的10倍。假如我们输入网络的图片的分辨率大小是256×256，若采用随机裁剪成224×224的方式，那么一张图最多可以产生32×32张不同的图，数据量扩充将近1000倍。虽然许多的图相似度太高，实际的效果并不等价，但仅仅是这样简单的一个操作，效果已经非凡了。
如果再辅助其他的数据增强方法，将获得更好的多样性，这就是数据增强的本质。
数据增强可以分为，有监督的数据增强和无监督的数据增强方法。其中有监督的数据增强又可以分为单样本数据增强和多样本数据增强方法，无监督的数据增强分为生成新的数据和学习增强策略两个方向。
2、有监督的数据增强
有监督数据增强，即采用预设的数据变换规则，在已有数据的基础上进行数据的扩增，包含单样本数据增强和多样本数据增强，其中单样本又包括几何操作类，颜色变换类。
2.1. 单样本数据增强
所谓单样本数据增强，即增强一个样本的时候，全部围绕着该样本本身进行操作，包括几何变换类，颜色变换类等。
(1) 几何变换类
几何变换类即对图像进行几何变换，包括翻转，旋转，裁剪，变形，缩放等各类操作，下面展示其中的若干个操作。
▲水平翻转和垂直翻转
▲随机旋转
▲随机裁剪
▲变形缩放
翻转操作和旋转操作，对于那些对方向不敏感的任务，比如图像分类，都是很常见的操作，在caffe等框架中翻转对应的就是mirror操作。
翻转和旋转不改变图像的大小，而裁剪会改变图像的大小。通常在训练的时候会采用随机裁剪的方法，在测试的时候选择裁剪中间部分或者不裁剪。值得注意的是，在一些竞赛中进行模型测试时，一般都是裁剪输入的多个版本然后将结果进行融合，对预测的改进效果非常明显。
以上操作都不会产生失真，而缩放变形则是失真的。
很多的时候，网络的训练输入大小是固定的，但是数据集中的图像却大小不一，此时就可以选择上面的裁剪成固定大小输入或者缩放到网络的输入大小的方案，后者就会产生失真，通常效果比前者差。
(2) 颜色变换类
上面的几何变换类操作，没有改变图像本身的内容，它可能是选择了图像的一部分或者对像素进行了重分布。如果要改变图像本身的内容，就属于颜色变换类的数据增强了，常见的包括噪声、模糊、颜色变换、擦除、填充等等。
基于噪声的数据增强就是在原来的图片的基础上，随机叠加一些噪声，最常见的做法就是高斯噪声。更复杂一点的就是在面积大小可选定、位置随机的矩形区域上丢弃像素产生黑色矩形块，从而产生一些彩色噪声，以Coarse Dropout方法为代表，甚至还可以对图片上随机选取一块区域并擦除图像信息。
▲添加Coarse Dropout噪声
颜色变换的另一个重要变换是颜色扰动，就是在某一个颜色空间通过增加或减少某些颜色分量，或者更改颜色通道的顺序。
▲颜色扰动
几何变换类，颜色变换类的数据增强方法细致数来还有非常多
2.2. 多样本数据增强
不同于单样本数据增强，多样本数据增强方法利用多个样本来产生新的样本
(1) SMOTE[1]
SMOTE即Synthetic Minority Over-sampling Technique方法，它是通过人工合成新样本来处理样本不平衡问题，从而提升分类器性能。
类不平衡现象是很常见的，它指的是数据集中各类别数量不近似相等。如果样本类别之间相差很大，会影响分类器的分类效果。假设小样本数据数量极少，如仅占总体的1%，则即使小样本被错误地全部识别为大样本，在经验风险最小化策略下的分类器识别准确率仍能达到99%，但由于没有学习到小样本的特征，实际分类效果就会很差。
SMOTE方法是基于插值的方法，它可以为小样本类合成新的样本，主要流程为：
第一步，定义好特征空间，将每个样本对应到特征空间中的某一点，根据样本不平衡比例确定好一个采样倍率N；
第二步，对每一个小样本类样本(x,y)，按欧氏距离找出K个最近邻样本，从中随机选取一个样本点，假设选择的近邻点为(xn,yn)。在特征空间中样本点与最近邻样本点的连线段上随机选取一点作为新样本点，满足以下公式：
第三步，重复以上的步骤，直到大、小样本数量平衡。
在python中，SMOTE算法已经封装到了imbalanced-learn库中，如下图为算法实现的数据增强的实例，左图为原始数据特征空间图，右图为SMOTE算法处理后的特征空间图。
(2) SamplePairing[2]
SamplePairing方法的原理非常简单，从训练集中随机抽取两张图片分别经过基础数据增强操作(如随机翻转等)处理后经像素以取平均值的形式叠加合成一个新的样本，标签为原样本标签中的一种。这两张图片甚至不限制为同一类别，这种方法对于医学图像比较有效。
经SamplePairing处理后可使训练集的规模从N扩增到N×N。实验结果表明，因SamplePairing数据增强操作可能引入不同标签的训练样本，导致在各数据集上使用SamplePairing训练的误差明显增加，而在验证集上误差则有较大幅度降低。
尽管SamplePairing思路简单，性能上提升效果可观，符合奥卡姆剃刀原理，但遗憾的是可解释性不强。
(3) mixup[3]
mixup是Facebook人工智能研究院和MIT在“Beyond Empirical Risk Minimization”中提出的基于邻域风险最小化原则的数据增强方法，它使用线性插值得到新样本数据。
令(xn,yn)是插值生成的新数据，(xi,yi)和(xj,yj)是训练集随机选取的两个数据，则数据生成方式如下
λ的取指范围介于0到1。提出mixup方法的作者们做了丰富的实验，实验结果表明可以改进深度学习模型在ImageNet数据集、CIFAR数据集、语音数据集和表格数据集中的泛化误差，降低模型对已损坏标签的记忆，增强模型对对抗样本的鲁棒性和训练生成对抗网络的稳定性。
SMOTE，SamplePairing，mixup三者思路上有相同之处，都是试图将离散样本点连续化来拟合真实样本分布，不过所增加的样本点在特征空间中仍位于已知小样本点所围成的区域内。如果能够在给定范围之外适当插值，也许能实现更好的数据增强效果。
3、无监督的数据增强
无监督的数据增强方法包括两类：
(1) 通过模型学习数据的分布，随机生成与训练数据集分布一致的图片，代表方法GAN[4]。
(2) 通过模型，学习出适合当前任务的数据增强方法，代表方法AutoAugment[5]。
3.1 GAN
关于GAN(generative adversarial networks)，我们已经说的太多了。它包含两个网络，一个是生成网络，一个是对抗网络，基本原理如下：
(1) G是一个生成图片的网络，它接收随机的噪声z，通过噪声生成图片，记做G(z) 。
(2) D是一个判别网络，判别一张图片是不是“真实的”，即是真实的图片，还是由G生成的图片。
2 Autoaugmentation[5]
AutoAugment是Google提出的自动选择最优数据增强方案的研究，这是无监督数据增强的重要研究方向。它的基本思路是使用增强学习从数据本身寻找最佳图像变换策略，对于不同的任务学习不同的增强方法，流程如下：
(1) 准备16个常用的数据增强操作。
(2) 从16个中选择5个操作，随机产生使用该操作的概率和相应的幅度，将其称为一个sub-policy，一共产生5个sub-polices。
(3) 对训练过程中每一个batch的图片，随机采用5个sub-polices操作中的一种。
(4) 通过模型在验证集上的泛化能力来反馈，使用的优化方法是增强学习方法。
(5) 经过80~100个epoch后网络开始学习到有效的sub-policies。
(6) 之后串接这5个sub-policies，然后再进行最后的训练。
总的来说，就是学习已有数据增强的组合策略，对于门牌数字识别等任务，研究表明剪切和平移等几何变换能够获得最佳效果。
而对于ImageNet中的图像分类任务，AutoAugment学习到了不使用剪切，也不完全反转颜色，因为这些变换会导致图像失真。AutoAugment学习到的是侧重于微调颜色和色相分布。

四、图像分类综述
. 图像分类概述
1.1 
图像分类是指根据一定的分类规则将图像自动分到一组预定义类别中的过程。
1.2 
图像分类方法的划分十分多样。根据图像语义内容的不同层次可以将图像分类划分为：
（1）对象分类 object categorization
（2）场景分类 scene classification
（3）事件分类 event classification
（4）情感分类 emotion classification
1.3
视觉一致的图像分类：主要依据是图像内容的视觉感知一致性（看起来一样，差不多）而不是功能一致性（用途差不多，一样）。
基于场景的图像分类：根据图像拍摄时所处的物理环境类别来对图像进行分类
对象分类和目标识别：对象分类是指判定一个图像中是否出现了某个对象类别的方法但他并不需要定为或者分割出图像中的对象；
对象识别或目标识别：通常指从新的图像中找出以前证件出现过的同一对象。
1.4  
图像分类的应用
网络图像检索
视频分析与检索
医学图像分类
医学图像数据挖掘
图像检测
遥感图像分类
1.5 图像分类的基本过程
基本操作是建立 图像内容的描述，然后利用机器学习方法学习图像类别，最后利用学习得到的模型对未知图像进行分类。
 
一般来说，图像分类性能主要与图像特征提取和分类方法密切相关。图像特征提取是图像分类的基础，提取的图像特征应能代表各种不同的图像属性；
分类方法是图像分类的核心，最终的分类准确性与分类方法密切相关。
2. 图像的特征处理
2.1 
图像特征是对凸显特性或属性的描述。每一幅图像都有其自身的特征，如：亮度、边缘的轮廓、纹理或色彩。
图像特征的提取和表示是凸显分类的基础，所选取的特征应该能充分表示图像语义内容，对环境的改变也应具有一定的鲁棒性和稳定性；
2.2
图像分类中提取的特征主要有两类：
（1）底层视觉特征
（2）局部不变特征
A。底层视觉特征
包括颜色、形状和纹理三大类。
颜色：
常用的颜色空间包括：RGB。HSV空间、以及反颜色空间（opponent color space）等等
目前，颜色特征的提取主要集中在全局颜色特征和空间颜色特征两个方面：
全局颜色特征的提取方法：颜色直方图、颜色矩和颜色熵等。不包括图像颜色的空间分布特征；
图像颜色空间分布特征的方法：改进的颜色直方图法、颜色聚合向量、颜色集、颜色相关图等。
形状：
描述形状的方法通常分为基于区域的形状描述方法和基于轮廓的形状描述方法两种。
基于区域的形状描述方法：注重集合形状的全局特征，描述形状局部特征的能力有限，常用特征有：几何不变矩、Legendre矩、Zenike矩、复数矩等；
基于轮廓的形状描述方法又可以分为基于空间域的方法和基于变换域的方法：
基于空间域：即集合特征描述方法。主要通过抽取边界的曲率、关键点、表姐长度等形状特征来描述物体的轮廓，节省存储空间，特征提取速度慢，对轮廓特性的描述相对抽象；
基于变换域的轮廓描述方法 主要将目标轮廓的边缘点数据变换到频率域中，从信号频率的角度来解释轮廓信息，特征提取速度快、对存储空间的需求适中、在表现人的主观视觉方面有局限性。
纹理
纹理特征是不依赖于颜色和亮度的反映图像中同质现象的视觉特征，其本质是刻画像素的邻域灰度空间分布规律。是所有物体表面共有的内在特性；
提取方法目前主要有四类：
基于统计的：主要通过统计图像中像素的灰度分布规律来描述纹理特征，如共生矩阵、Tamura纹理特征等；
基于几何的：将纹理看做是纹理基元按照一定的集合规则排列的组合，如利用结构法提取纹理基元等；
基于模型的：以图形的构造模型为基础，采用模型的参数为纹理特征，典型的方法如：马尔可夫随机场、同步自回归模型法和Wold模型法等；
基于信号处理的：利用信号处理的频率分析理论图区纹理特征，如小波变换、Gabor滤波法等
B。局部不变特征
也称为局部特征
首要任务是要提取出更加稳定的图像特征来描述图像。
稳定：希望该特征能对旋转、尺度缩放、仿射变换、视角变化、光照变化等图像变化因素保持一定的不变形，对运动、遮挡、噪声等因素也保持较好的可匹配性；
提取分为两个部分：特征点（或区域）探测和特征描述
特征点探测：采用一定的规则或者策略从图像中选取一些有代表性的特征点或特征区域；
特征描述：根据特征点探测所得特征点或特征区域，提取出满足一定不变性要求的特征向量；
3. 图像分类的流程
（1）数据集的选择：Oliva and Torralba（OT）、Fei-fei Li and Perona（FP），Lazebnik，Schmid and Ponce（LPS）
（2）特征的提取和表达
（3）数据字典的建立
（4）词典模型的表示
（5）分类器的学习：SVM；贝叶斯
（6）训练集的表达
（7）分类性能评估方法：eg，分类准确率 Classification Accuracy


