

# Jing_Homework(07.07.1)-DL Base

> author @ jingc0116 A.T . gmail.com

## 1. 损失函数方法补充

​	合页损失(Hinge Loss)是一种二分类损失函数，适用于**maximum-margin**的分类. 在支持向量机(Support Vector Machine)中，模型的损失函数本质上就是HingeLoss + L2正则化. 由于函数形状像一个合页，因此命名为合页损失函数. 

<img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210710113015557.png" alt="image-20210710113015557" style="zoom:67%;" />

​	横轴表示函数间隔，纵轴表示loss大小.   公式定义为
$$
J_{hinge} = \sum_{i = 1} ^ {N} max(0, \quad 1 - sgn(y_i)\hat{y}_i)
$$
​	上图中的损失函数表示为当 y 是正类时，$sgn(y) = +1$ , 模型输出的负值会有较大的惩罚，输出正值但在 $(0, 1)$ 区间中则会有一个较小的惩罚，可见，HingeLoss对于置信度不高的预测结果也会有一个惩罚. 使用HingeLoss的直观理解为：**找到一个决策边界，使得所有数据点都被这个边界正确、高置信度地分类. ** 



## 2. 损失函数的代码实现

```python
def HingeLoss(y, y_true):
    if not (y.shape[0] == y_true.shape[0]):
        print('y.shape = {}, 'y_true.shape ={}'.format(X.shape, y.shape))
        sys.exit()

    output = 1.0 - (y * y_true)
    output *= np.asarray((output > 0.0),dtype=float)

    return output
```

## 3. 池化方法补充

​	**随机池化(Stochastic Pooling)** 是Zeiler等人于ICLR2013提出的一种池化操作，计算过程如下：

- 将方格中所有元素同时除以它们的sum，得到概率矩阵
- 按照概率随机选中方格
- pooling得到的值就是方格位置的值

<img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210710140029406.png" alt="image-20210710140029406" style="zoom:67%;" />

​		随机池化只需对特征图中的元素按照其概率值大小随机选择，即元素值大的被选中的概率也大，而不像max-pooling那样，永远只取那个最大值元素，这使得随机池化具有更强的泛化能力。在反向传播求导时，只需保留前向传播已经记录被选中节点的位置的值，其它值都为0,这和max-pooling的反向传播非常类似。

## 4. 数据增强方法修改及补充

- **数据增广**
    - 常规增广
        - 图像解码(ImageDecode)、随机裁剪(RandCrop)、水平方向随机翻转(RandFlip)、归一化(Normalize)、batch_size多张图像堆叠
    - GAN生成
        - 通过生成对抗网络得到与训练集同类型的数据，增强数据集
- **数据变换**
    - **常规变换**
        - 旋转、裁剪、变形、缩放等
        - AutoAugment：针对数据集，搜索最佳变换策略，针对每幅图像随机挑选一个子策略，依概率决定是否执行子策略中的每种变换
        - RandAugment：随机增广，所有子策略以同样的概率被选择到，对于每幅图像依概率决定是否执行子策略中的每种变换
    - **图像混叠**
        - CutMix：从一幅图中随机裁剪出ROI，覆盖当前图像中对应的区域
            - <img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210710141458195.png" alt="image-20210710141458195" style="zoom:67%;" />
        - Mixup：两幅图像相加混合在一起
            - <img src="https://msigl62m-1258130641.cos.ap-shanghai.myqcloud.com/%20typora-user-images/image-20210710141512998.png" alt="image-20210710141512998" style="zoom:67%;" />



## 5. 图像分类方法综述

### 5.1 传统方法

​		传统方法需要建立完整的图像分类模型，一般包括底层特征学习、特征编码、空间约束、分类器设计、模型融合等几个阶段。

**1).** **底层特征提取**: 通常从图像中按照固定步长、尺度提取大量局部特征描述。常用的局部特征包括SIFT(Scale-Invariant Feature Transform, 尺度不变特征转换) 、HOG(Histogram of Oriented Gradient, 方向梯度直方图) 、LBP(Local Binary Pattern, 局部二值模式)等，一般也采用多种特征描述，防止丢失过多的有用信息。

**2).** **特征编码**: 底层特征中包含了大量冗余与噪声，为了提高特征表达的鲁棒性，需要使用一种特征变换算法对底层特征进行编码，称作特征编码。常用的特征编码方法包括向量量化编码、稀疏编码、局部线性约束编码、Fisher向量编码等。

**3).** **空间特征约束**: 特征编码之后一般会经过空间特征约束，也称作特征汇聚。特征汇聚是指在一个空间范围内，对每一维特征取最大值或者平均值，可以获得一定特征不变形的特征表达。金字塔特征匹配是一种常用的特征汇聚方法，这种方法提出将图像均匀分块，在分块内做特征汇聚。

**4).** **通过分类器分类**: 经过前面步骤之后一张图像可以用一个固定维度的向量进行描述，接下来就是经过分类器对图像进行分类。通常使用的分类器包括SVM(Support Vector Machine, 支持向量机)、随机森林等。而使用核方法的SVM是最为广泛的分类器，在传统图像分类任务上性能很好。



### 5.2 基于深度学习的图像分类方法

​	Alex Krizhevsky在2012年ILSVRC提出的CNN模型取得了历史性的突破，效果大幅度超越传统方法，获得了ILSVRC2012冠军，该模型被称作AlexNet。这也是首次将深度学习用于大规模图像分类中。从AlexNet之后，涌现了一系列CNN模型，不断地在ImageNet上刷新成绩，随着模型变得越来越深以及精妙的结构设计，Top-5的错误率也越来越低，降到了3.5%附近。而在同样的ImageNet数据集上，人眼的辨识错误率大概在5.1%，也就是目前的深度学习模型的识别能力已经超过了人眼。

​	深度学习的图像分类算法主要基于卷积神经网络CNN。典型的CNN分类网络有AlexNet、VGG、GoogLeNet、ResNet等。

